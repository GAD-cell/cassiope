,title,authors,filename,referencecount,abstract_length,acronym_presence,content_references,equations,figures,pages,paragraphs,sections,subsections,subsubsections,tables,title_length,words,referencecount_per_page,figures_tables_per_page,equations_per_page,subsections_per_page,citationcount
0,(Individual) Fairness for k-Clustering,8,Individual Fairness for k-Clustering,54,182,False,41,52,48,27,9,11,12,0,2,38,12601,2.0,1.8518518518518519,1.9259259259259258,0.4444444444444444,71
1,A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation,8,A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation,81,123,False,204,124,43,28,0,12,21,0,6,108,16720,2.892857142857143,1.75,4.428571428571429,0.75,8
2,A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems,8,A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems,69,228,False,91,82,39,26,0,17,16,8,2,67,12201,2.6538461538461537,1.5769230769230769,3.1538461538461537,0.6153846153846154,2
3,A Modern Self-Referential Weight Matrix That Learns to Modify Itself,8,A Modern Self-Referential Weight Matrix That Learns to Modify Itself,76,165,False,212,6,23,18,24,11,10,0,20,68,12136,4.222222222222222,2.388888888888889,0.3333333333333333,0.5555555555555556,20
4,A Riemannian Block Coordinate Descent Method for Computing the Projection Robust Wasserstein Distance,8,A Riemannian Block Coordinate Descent Method for Computing the Projection Robust Wasserstein Distance,34,226,False,70,75,26,33,5,10,3,1,26,101,13523,1.0303030303030303,1.5757575757575757,2.272727272727273,0.09090909090909091,34
5,A Study on Transformer Configuration and Training Objective,8,A Study on Transformer Configuration and Training Objective,43,142,False,136,8,22,13,0,11,6,0,12,59,8357,3.3076923076923075,2.6153846153846154,0.6153846153846154,0.46153846153846156,3
6,A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization,8,A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization,57,138,False,160,76,38,17,7,12,13,0,16,87,12045,3.3529411764705883,3.176470588235294,4.470588235294118,0.7647058823529411,28
8,Acceleration for Compressed Gradient Descent in Distributed and Federated Optimization,8,Acceleration for Compressed Gradient Descent in Distributed and Federated Optimization,32,214,False,72,121,40,23,3,9,21,0,2,86,12948,1.391304347826087,1.826086956521739,5.260869565217392,0.9130434782608695,124
10,Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed Bandits,8,Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed Bandits,32,211,False,62,346,0,29,2,14,24,4,2,75,14649,1.103448275862069,0.06896551724137931,11.931034482758621,0.8275862068965517,11
11,Adaptive gradient descent without descent,8,Adaptive gradient descent without descent,46,153,False,43,139,30,22,8,9,10,0,0,41,10752,2.090909090909091,1.3636363636363635,6.318181818181818,0.45454545454545453,75
12,Adversarial Filters of Dataset Biases,8,Adversarial Filters of Dataset Biases,61,28,False,12,0,3,14,0,5,11,4,2,37,9479,4.357142857142857,0.35714285714285715,0.0,0.7857142857142857,188
14,Almost Tune-Free Variance Reduction,8,Almost Tune-Free Variance Reduction,30,153,False,96,122,27,22,0,10,18,0,2,35,11242,1.3636363636363635,1.3181818181818181,5.545454545454546,0.8181818181818182,16
15,An Equivalence Between Data Poisoning and Byzantine Gradient Attacks,8,An Equivalence Between Data Poisoning and Byzantine Gradient Attacks,89,154,False,236,516,158,40,16,42,68,24,4,68,24876,2.225,4.05,12.9,1.7,16
16,Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model,8,Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model,33,173,False,83,46,18,10,1,8,3,0,6,95,6895,3.3,2.4,4.6,0.3,23
17,Approximate Bayesian Computation with Domain Expert in the Loop,8,Approximate Bayesian Computation with Domain Expert in the Loop,52,125,False,68,30,29,13,17,8,8,0,6,63,8263,4.0,2.6923076923076925,2.3076923076923075,0.6153846153846154,4
18,Associative Memory in Iterated Overparameterized Sigmoid Autoencoders,8,Associative Memory in Iterated Overparameterized Sigmoid Autoencoders,40,125,False,61,386,57,26,0,12,23,0,0,69,12290,1.5384615384615385,2.1923076923076925,14.846153846153847,0.8846153846153846,11
19,AutoIP: A United Framework to Integrate Physics into Gaussian Processes,8,AutoIP A United Framework to Integrate Physics into Gaussian Processes,48,214,False,84,37,27,12,4,9,4,0,10,70,8466,4.0,3.0833333333333335,3.0833333333333335,0.3333333333333333,9
20,"BINOCULARS for efficient, nonmyopic sequential experimental design",8,BINOCULARS for efficient nonmyopic sequential experimental design,41,1,True,98,38,19,13,0,11,4,0,12,66,8072,3.1538461538461537,2.3846153846153846,2.923076923076923,0.3076923076923077,39
21,Bayesian Attention Belief Networks,8,Bayesian Attention Belief Networks,84,168,False,234,22,12,14,0,13,20,17,18,34,10537,6.0,2.142857142857143,1.5714285714285714,1.4285714285714286,21
22,Bayesian Optimization of Composite Functions,8,Bayesian Optimization of Composite Functions,49,167,False,91,104,22,18,0,13,15,0,2,44,10011,2.7222222222222223,1.3333333333333333,5.777777777777778,0.8333333333333334,63
23,Better Training using Weight-Constrained Stochastic Dynamics,8,Better Training using Weight-Constrained Stochastic Dynamics,71,151,False,103,269,32,26,0,11,18,1,10,60,18118,2.730769230769231,1.6153846153846154,10.346153846153847,0.6923076923076923,5
24,Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification,8,Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification,65,171,False,106,145,23,20,14,8,22,1,12,87,12343,3.25,1.75,7.25,1.1,10
25,Boosted Density Estimation Remastered,8,Boosted Density Estimation Remastered,41,145,False,133,67,14,36,1,8,5,6,2,37,15824,1.1388888888888888,0.4444444444444444,1.8611111111111112,0.1388888888888889,9
26,Breaking the Curse of Many Agents: Provable Mean Embedding Q-Iteration for Mean-Field Reinforcement Learning,8,Breaking the Curse of Many Agents Provable Mean Embedding Q-Iteration for Mean-Field Reinforcement Learning,94,110,False,104,8,0,31,0,8,12,0,0,107,14526,3.032258064516129,0.0,0.25806451612903225,0.3870967741935484,24
28,"Calibration, Entropy Rates, and Memory in Language Models",8,Calibration Entropy Rates and Memory in Language Models,64,1,False,60,107,9,24,10,14,6,1,4,57,9278,2.6666666666666665,0.5416666666666666,4.458333333333333,0.25,30
29,Causal Strategic Linear Regression,8,Causal Strategic Linear Regression,46,165,False,63,32,12,17,7,10,7,0,0,34,10913,2.7058823529411766,0.7058823529411765,1.8823529411764706,0.4117647058823529,60
30,Characterizing Structural Regularities of Labeled Data in Overparameterized Models,8,Characterizing Structural Regularities of Labeled Data in Overparameterized Models,44,156,False,57,10,184,17,0,15,3,0,4,82,10571,2.588235294117647,11.058823529411764,0.5882352941176471,0.17647058823529413,69
31,Closing the convergence gap of SGD without replacement,8,Closing the convergence gap of SGD without replacement,24,156,True,124,242,26,38,2,11,14,3,2,54,17891,0.631578947368421,0.7368421052631579,6.368421052631579,0.3684210526315789,51
32,Combating Label Noise in Deep Learning Using Abstention,8,Combating Label Noise in Deep Learning Using Abstention,41,221,False,90,16,35,14,0,10,6,1,4,55,8931,2.9285714285714284,2.7857142857142856,1.1428571428571428,0.42857142857142855,157
33,Competitive caching with machine learned advice,8,Competitive caching with machine learned advice,41,238,False,60,4,3,28,19,7,16,0,4,47,14764,1.4642857142857142,0.25,0.14285714285714285,0.5714285714285714,299
34,Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings,8,Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings,66,178,True,1,208,3,29,5,13,13,0,0,93,13564,2.2758620689655173,0.10344827586206896,7.172413793103448,0.4482758620689655,5
35,Conjugate Energy-Based Models,8,Conjugate Energy-Based Models,61,114,False,113,100,22,19,8,14,13,0,16,29,12234,3.210526315789474,2.0,5.2631578947368425,0.6842105263157895,2
37,Continuous Control with Action Quantization from Demonstrations,8,Continuous Control with Action Quantization from Demonstrations,91,122,False,336,36,66,21,42,26,24,18,44,63,12413,4.333333333333333,5.238095238095238,1.7142857142857142,1.1428571428571428,15
38,Convergence Rates of Variational Inference in Sparse Deep Learning,8,Convergence Rates of Variational Inference in Sparse Deep Learning,84,124,False,140,129,0,38,0,14,11,0,0,66,15008,2.210526315789474,0.0,3.3947368421052633,0.2894736842105263,33
39,Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms,8,Coordinated Attacks against Contextual Bandits Fundamental Limits and Defense Mechanisms,48,204,False,35,84,14,18,19,11,12,0,0,88,11705,2.6666666666666665,0.7777777777777778,4.666666666666667,0.6666666666666666,5
40,Countering Language Drift with Seeded Iterated Learning,8,Countering Language Drift with Seeded Iterated Learning,65,166,False,158,8,79,20,26,14,7,0,6,55,12211,3.25,4.25,0.4,0.35,61
41,D2: Decentralized Training over Decentralized Data,8,D2 Decentralized Training over Decentralized Data,42,243,False,73,170,6,25,8,7,3,0,0,49,9229,1.68,0.24,6.8,0.12,302
43,Dataset Condensation via Efficient Synthetic-Data Parameterization,8,Dataset Condensation via Efficient Synthetic-Data Parameterization,40,142,False,160,27,28,17,13,14,20,0,28,66,11233,2.3529411764705883,3.2941176470588234,1.588235294117647,1.1764705882352942,73
44,Decomposed Mutual Information Estimation for Contrastive Representation Learning,8,Decomposed Mutual Information Estimation for Contrastive Representation Learning,58,199,False,188,62,7,21,10,10,18,3,16,80,12523,2.761904761904762,1.0952380952380953,2.9523809523809526,0.8571428571428571,24
45,Deep Latent State Space Models for Time-Series Generation,8,Deep Latent State Space Models for Time-Series Generation,58,0,False,28,8,30,19,0,10,14,0,12,57,9750,3.0526315789473686,2.210526315789474,0.42105263157894735,0.7368421052631579,12
46,DeepMDP: Learning Continuous Latent Space Models for Representation Learning,8,DeepMDP Learning Continuous Latent Space Models for Representation Learning,62,156,False,125,106,49,31,0,15,38,4,4,75,17984,2.0,1.7096774193548387,3.4193548387096775,1.2258064516129032,239
47,Density Constrained Reinforcement Learning,8,Density Constrained Reinforcement Learning,54,164,False,66,62,42,16,4,9,18,0,2,42,10371,3.375,2.75,3.875,1.125,31
48,Differentiable Compositional Kernel Learning for Gaussian Processes,8,Differentiable Compositional Kernel Learning for Gaussian Processes,35,133,False,107,116,55,21,0,17,19,2,8,67,11948,1.6666666666666667,3.0,5.523809523809524,0.9047619047619048,68
50,Directed Graph Embeddings in Pseudo-Riemannian Manifolds,8,Directed Graph Embeddings in Pseudo-Riemannian Manifolds,36,120,False,84,50,18,14,6,8,13,10,12,56,9506,2.5714285714285716,2.142857142857143,3.5714285714285716,0.9285714285714286,12
51,Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations,8,Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations,68,176,False,134,58,23,19,0,10,17,0,4,80,11469,3.5789473684210527,1.4210526315789473,3.0526315789473686,0.8947368421052632,37
52,Distribution Regression with Sliced Wasserstein Kernels,8,Distribution Regression with Sliced Wasserstein Kernels,64,200,False,139,198,6,23,4,16,4,0,6,55,14197,2.782608695652174,0.5217391304347826,8.608695652173912,0.17391304347826086,11
53,Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation,8,Do We Really Need to Access the Source Data Source Hypothesis Transfer for Unsupervised Domain Adaptation,79,158,False,170,24,20,12,0,6,12,0,18,105,9287,6.583333333333333,3.1666666666666665,2.0,1.0,877
54,DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations,8,DreamerPro Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations,41,178,False,120,16,12,12,0,7,5,1,6,99,6747,3.4166666666666665,1.5,1.3333333333333333,0.4166666666666667,40
55,Early Classification for Agricultural Monitoring from Satellite Time Series,8,Early Classification for Agricultural Monitoring from Satellite Time Series,17,130,False,26,8,6,5,0,5,6,0,2,75,3693,3.4,1.6,1.6,1.2,17
56,Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables,8,Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables,47,164,False,51,8,27,11,0,8,6,0,0,84,7161,4.2727272727272725,2.4545454545454546,0.7272727272727273,0.5454545454545454,540
57,Efficient nonparametric statistical inference on population feature importance using Shapley values,8,Efficient nonparametric statistical inference on population feature importance using Shapley values,32,171,False,74,112,9,15,0,13,8,0,2,99,10709,2.1333333333333333,0.7333333333333333,7.466666666666667,0.5333333333333333,59
58,Energy-Based Processes for Exchangeable Data,8,Energy-Based Processes for Exchangeable Data,75,120,False,288,132,40,32,11,13,24,4,4,44,12436,2.34375,1.375,4.125,0.75,10
59,Equivariant Transformer Networks,8,Equivariant Transformer Networks,34,103,False,118,24,46,15,0,19,15,0,16,32,8919,2.2666666666666666,4.133333333333334,1.6,1.0,61
60,Estimating the number and effect sizes of non-null hypotheses,8,Estimating the number and effect sizes of non-null hypotheses,43,129,False,22,299,24,31,0,10,18,0,0,61,16375,1.3870967741935485,0.7741935483870968,9.64516129032258,0.5806451612903226,3
61,Explainability Techniques for Graph Convolutional Networks,8,Explainability Techniques for Graph Convolutional Networks,48,66,False,48,10,143,21,4,8,15,8,0,58,7196,2.2857142857142856,6.809523809523809,0.47619047619047616,0.7142857142857143,209
62,Exploring and Exploiting Hubness Priors for High-Quality GAN Latent Sampling,8,Exploring and Exploiting Hubness Priors for High-Quality GAN Latent Sampling,41,183,True,83,0,85,14,0,12,10,0,14,76,7963,2.9285714285714284,7.071428571428571,0.0,0.7142857142857143,2
64,Fast Composite Optimization and Statistical Recovery in Federated Learning,8,Fast Composite Optimization and Statistical Recovery in Federated Learning,76,233,False,149,340,12,29,11,12,15,0,2,74,16774,2.6206896551724137,0.4827586206896552,11.724137931034482,0.5172413793103449,8
65,Fast Variance Reduction Method with Stochastic Batch Size,8,Fast Variance Reduction Method with Stochastic Batch Size,32,204,False,34,146,14,17,1,7,16,0,2,57,10025,1.8823529411764706,0.9411764705882353,8.588235294117647,0.9411764705882353,5
66,Feature Quantization Improves GAN Training,8,Feature Quantization Improves GAN Training,48,156,True,115,18,83,22,22,10,19,0,18,42,10275,2.1818181818181817,4.590909090909091,0.8181818181818182,0.8636363636363636,41
67,Federated Reinforcement Learning: Linear Speedup Under Markovian Sampling,8,Federated Reinforcement Learning Linear Speedup Under Markovian Sampling,0,1,False,99,461,3,69,1,11,17,6,2,72,30284,0.0,0.07246376811594203,6.681159420289855,0.2463768115942029,42
68,Finding trainable sparse networks through Neural Tangent Transfer,8,Finding trainable sparse networks through Neural Tangent Transfer,56,132,False,108,49,40,17,10,10,12,0,8,65,10149,3.2941176470588234,2.823529411764706,2.8823529411764706,0.7058823529411765,26
69,FloWaveNet : A Generative Flow for Raw Audio,8,FloWaveNet  A Generative Flow for Raw Audio,17,153,False,39,26,12,9,0,7,13,0,8,43,5796,1.8888888888888888,2.2222222222222223,2.888888888888889,1.4444444444444444,160
70,Frequency Bias in Neural Networks for Input of Non-Uniform Density,8,Frequency Bias in Neural Networks for Input of Non-Uniform Density,26,159,False,38,247,46,25,0,12,9,0,0,66,14234,1.04,1.84,9.88,0.36,123
72,GDPP: Learning Diverse Generations Using Determinantal Point Process,8,GDPP Learning Diverse Generations Using Determinantal Point Process,46,221,True,109,16,36,10,7,6,2,0,10,67,6732,4.6,4.6,1.6,0.2,56
73,Gauge Equivariant Convolutional Networks and the Icosahedral CNN,8,Gauge Equivariant Convolutional Networks and the Icosahedral CNN,59,180,True,62,38,22,15,4,13,17,3,6,64,11333,3.933333333333333,1.8666666666666667,2.533333333333333,1.1333333333333333,355
75,Generative Adversarial User Model for Reinforcement Learning Based Recommendation System,8,Generative Adversarial User Model for Reinforcement Learning Based Recommendation System,30,151,False,63,57,30,15,0,12,13,0,6,88,9540,2.0,2.4,3.8,0.8666666666666667,161
78,Graph Neural Networks Inspired by Classical Iterative Algorithms,8,Graph Neural Networks Inspired by Classical Iterative Algorithms,70,197,False,122,102,23,20,0,18,35,4,26,64,13728,3.5,2.45,5.1,1.75,58
83,Hyperbolic Entailment Cones for Learning Hierarchical Embeddings,8,Hyperbolic Entailment Cones for Learning Hierarchical Embeddings,37,116,False,115,116,16,13,22,14,4,0,2,64,8218,2.8461538461538463,1.3846153846153846,8.923076923076923,0.3076923076923077,219
84,"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition",8,Imperceptible Robust and Targeted Adversarial Examples for Automatic Speech Recognition,31,128,False,94,62,3,13,8,15,12,5,6,87,9233,2.3846153846153846,0.6923076923076923,4.769230769230769,0.9230769230769231,333
85,Improved Bounds on Minimax Regret under Logarithmic Loss via Self-Concordance,8,Improved Bounds on Minimax Regret under Logarithmic Loss via Self-Concordance,36,88,False,100,293,0,25,5,14,20,1,0,77,13994,1.44,0.0,11.72,0.8,0
86,Improving Adversarial Robustness via Promoting Ensemble Diversity,8,Improving Adversarial Robustness via Promoting Ensemble Diversity,48,162,False,68,62,15,13,0,8,17,0,10,65,9560,3.6923076923076925,1.9230769230769231,4.769230769230769,1.3076923076923077,369
87,Improving Screening Processes via Calibrated Subset Selection,8,Improving Screening Processes via Calibrated Subset Selection,56,1,False,98,312,12,30,0,22,30,0,0,61,14072,1.8666666666666667,0.4,10.4,1.0,14
88,Individually Fair Learning with One-Sided Feedback,8,Individually Fair Learning with One-Sided Feedback,72,1,False,131,144,2,25,3,11,15,2,0,50,12640,2.88,0.08,5.76,0.6,3
89,Information-Theoretic Considerations in Batch Reinforcement Learning,8,Information-Theoretic Considerations in Batch Reinforcement Learning,58,91,False,115,106,0,27,6,13,11,0,0,68,17010,2.1481481481481484,0.0,3.925925925925926,0.4074074074074074,307
90,Interactively Learning Preference Constraints in Linear Bandits,8,Interactively Learning Preference Constraints in Linear Bandits,30,166,False,77,84,63,23,20,10,14,0,4,63,12881,1.3043478260869565,2.9130434782608696,3.652173913043478,0.6086956521739131,7
91,Interventional Contrastive Learning with Meta Semantic Regularizer,8,Interventional Contrastive Learning with Meta Semantic Regularizer,39,186,False,132,64,30,13,0,24,18,0,16,66,8745,3.0,3.5384615384615383,4.923076923076923,1.3846153846153846,12
92,Is Local SGD Better than Minibatch SGD?,8,Is Local SGD Better than Minibatch SGD,41,119,True,114,236,3,31,9,10,3,1,4,38,16268,1.3225806451612903,0.22580645161290322,7.612903225806452,0.0967741935483871,215
94,Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics,8,Koopman Q-learning Offline Reinforcement Learning via Symmetries of Dynamics,40,213,False,131,62,17,23,12,10,15,0,10,76,15659,1.7391304347826086,1.173913043478261,2.6956521739130435,0.6521739130434783,15
95,Langevin Monte Carlo for Contextual Bandits,8,Langevin Monte Carlo for Contextual Bandits,50,179,False,142,150,16,21,3,10,10,0,4,43,13026,2.380952380952381,0.9523809523809523,7.142857142857143,0.47619047619047616,19
96,LatentGNN: Learning Efficient Non-local Relations for Visual Recognition,8,LatentGNN Learning Efficient Non-local Relations for Visual Recognition,49,176,False,76,24,6,10,9,6,6,6,6,71,7390,4.9,1.2,2.4,0.6,78
97,Learning Calibratable Policies using Programmatic Style-Consistency,8,Learning Calibratable Policies using Programmatic Style-Consistency,60,150,False,89,14,50,17,5,12,5,0,36,67,10804,3.5294117647058822,5.0588235294117645,0.8235294117647058,0.29411764705882354,14
98,Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning,8,Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning,61,195,False,108,152,64,31,20,12,16,0,4,86,17093,1.967741935483871,2.193548387096774,4.903225806451613,0.5161290322580645,30
99,Learning Linear-Quadratic Regulators Efficiently with only $\sqrt{T}$ Regret,8,Learning Linear-Quadratic Regulators Efficiently with only sqrtT Regret,36,29,False,62,216,0,30,4,10,30,0,0,71,13041,1.2,0.0,7.2,1.0,154
101,Learning Transferable Visual Models From Natural Language Supervision,8,Learning Transferable Visual Models From Natural Language Supervision,220,216,False,514,0,67,48,12,15,20,6,34,69,35678,4.583333333333333,2.1041666666666665,0.0,0.4166666666666667,14151
102,Learning from a Learning User for Optimal Recommendations,8,Learning from a Learning User for Optimal Recommendations,42,153,False,53,146,23,36,7,11,7,0,2,57,16189,1.1666666666666667,0.6944444444444444,4.055555555555555,0.19444444444444445,3
103,Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization,8,Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization,51,196,False,47,44,66,22,0,6,10,0,14,83,6298,2.3181818181818183,3.6363636363636362,2.0,0.45454545454545453,6
105,Leveraging Non-uniformity in First-order Non-convex Optimization,8,Leveraging Non-uniformity in First-order Non-convex Optimization,28,1,False,384,1076,66,48,62,26,36,0,0,64,26391,0.5833333333333334,1.375,22.416666666666668,0.75,36
106,Linear Transformers Are Secretly Fast Weight Programmers,8,Linear Transformers Are Secretly Fast Weight Programmers,71,155,False,165,82,15,16,9,14,16,2,12,56,11096,4.4375,1.6875,5.125,1.0,132
107,Log-Euclidean Signatures for Intrinsic Distances Between Unaligned Datasets,8,Log-Euclidean Signatures for Intrinsic Distances Between Unaligned Datasets,69,157,False,182,28,49,23,2,12,11,2,10,75,12382,3.0,2.5652173913043477,1.2173913043478262,0.4782608695652174,4
108,Lower Bounds for Smooth Nonconvex Finite-Sum Optimization,8,Lower Bounds for Smooth Nonconvex Finite-Sum Optimization,33,172,False,198,112,0,21,0,7,10,0,4,57,7984,1.5714285714285714,0.19047619047619047,5.333333333333333,0.47619047619047616,42
109,MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,8,MSplit LBI Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning,54,159,True,134,25,6,10,0,6,10,1,10,109,7940,5.4,1.6,2.5,1.0,23
110,Matrix Completion with Model-free Weighting,8,Matrix Completion with Model-free Weighting,57,148,False,186,145,0,35,0,14,9,0,8,43,13327,1.6285714285714286,0.22857142857142856,4.142857142857143,0.2571428571428571,3
111,Median Matrix Completion: from Embarrassment to Optimality,8,Median Matrix Completion from Embarrassment to Optimality,38,177,False,105,127,3,26,0,8,10,2,10,57,10835,1.4615384615384615,0.5,4.884615384615385,0.38461538461538464,1
112,Meta-learning for mixed linear regression,8,Meta-learning for mixed linear regression,60,1,False,120,580,36,41,2,32,32,0,16,41,15631,1.4634146341463414,1.2682926829268293,14.146341463414634,0.7804878048780488,54
114,Model Function Based Conditional Gradient Method with Armijo-like Line Search,8,Model Function Based Conditional Gradient Method with Armijo-like Line Search,48,154,False,56,72,2,20,6,7,7,3,0,77,7819,2.4,0.1,3.6,0.35,4
115,Modeling Irregular Time Series with Continuous Recurrent Units,8,Modeling Irregular Time Series with Continuous Recurrent Units,61,159,False,169,70,16,18,31,14,22,11,6,62,10705,3.388888888888889,1.2222222222222223,3.888888888888889,1.2222222222222223,35
116,Monte Carlo Variational Auto-Encoders,8,Monte Carlo Variational Auto-Encoders,36,145,False,117,306,40,18,11,19,44,9,18,37,10448,2.0,3.2222222222222223,17.0,2.4444444444444446,33
117,Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts,8,Multi-Grained Vision Language Pre-Training Aligning Texts with Visual Concepts,57,118,False,69,16,15,16,0,7,15,0,12,78,9343,3.5625,1.6875,1.0,0.9375,201
118,Multinomial Logit Bandit with Low Switching Cost,8,Multinomial Logit Bandit with Low Switching Cost,23,97,False,35,161,0,25,18,12,8,0,0,48,15840,0.92,0.0,6.44,0.32,15
119,Natural Analysts in Adaptive Data Analysis,8,Natural Analysts in Adaptive Data Analysis,21,236,False,49,51,0,22,2,12,24,0,0,42,10690,0.9545454545454546,0.0,2.3181818181818183,1.0909090909090908,15
120,Neighborhood Contrastive Learning Applied to Online Patient Monitoring,8,Neighborhood Contrastive Learning Applied to Online Patient Monitoring,43,115,False,151,10,45,21,16,13,17,0,26,70,10094,2.0476190476190474,3.380952380952381,0.47619047619047616,0.8095238095238095,33
121,Neural Laplace: Learning diverse classes of differential equations in the Laplace domain,8,Neural Laplace Learning diverse classes of differential equations in the Laplace domain,62,168,False,365,120,97,22,0,38,5,0,44,87,12338,2.8181818181818183,6.409090909090909,5.454545454545454,0.22727272727272727,11
123,Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for Non-Convex Optimization,8,Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for Non-Convex Optimization,51,206,False,61,348,16,39,0,9,20,4,0,86,15451,1.3076923076923077,0.41025641025641024,8.923076923076923,0.5128205128205128,25
124,Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information,8,Nonparametric Regression with Comparisons Escaping the Curse of Dimensionality with Ordinal Information,41,196,False,93,254,46,52,0,9,21,10,4,103,21507,0.7884615384615384,0.9615384615384616,4.884615384615385,0.40384615384615385,7
127,On Implicit Regularization in β-VAEs,8,On Implicit Regularization in β-VAEs,52,164,False,83,56,86,23,0,8,5,0,6,36,9982,2.260869565217391,4.0,2.4347826086956523,0.21739130434782608,44
128,On Proximal Policy Optimization's Heavy-tailed Gradients,8,On Proximal Policy Optimizations Heavy-tailed Gradients,42,1,False,0,8,0,24,0,8,1,0,0,56,13787,1.75,0.0,0.3333333333333333,0.041666666666666664,7
129,On the Convergence of Inexact Predictor-Corrector Methods for Linear Programming,8,On the Convergence of Inexact Predictor-Corrector Methods for Linear Programming,40,164,False,96,301,8,39,0,12,13,0,0,80,16634,1.0256410256410255,0.20512820512820512,7.717948717948718,0.3333333333333333,2
130,On the Identifiability and Estimation of Causal Location-Scale Noise Models,8,On the Identifiability and Estimation of Causal Location-Scale Noise Models,60,161,False,215,68,18,17,6,14,7,0,4,75,12246,3.5294117647058822,1.2941176470588236,4.0,0.4117647058823529,23
131,On the Relation between Quality-Diversity Evaluation and Distribution-Fitting Goal in Text Generation,8,On the Relation between Quality-Diversity Evaluation and Distribution-Fitting Goal in Text Generation,40,107,False,96,152,32,16,0,17,16,0,4,101,10762,2.5,2.25,9.5,1.0,4
132,One Policy to Control Them All: Shared Modular Policies for Agent-Agnostic Control,8,One Policy to Control Them All Shared Modular Policies for Agent-Agnostic Control,44,185,False,45,8,24,12,6,10,16,0,0,81,9122,3.6666666666666665,2.0,0.6666666666666666,1.3333333333333333,116
133,Online Learning for Min Sum Set Cover and Pandora's Box,8,Online Learning for Min Sum Set Cover and Pandoras Box,48,0,False,67,84,0,31,3,9,14,2,0,55,13203,1.5483870967741935,0.0,2.7096774193548385,0.45161290322580644,9
134,Open-ended Learning in Symmetric Zero-sum Games,8,Open-ended Learning in Symmetric Zero-sum Games,55,159,False,102,136,22,18,16,14,13,0,0,47,11038,3.0555555555555554,1.2222222222222223,7.555555555555555,0.7222222222222222,142
135,Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits,8,Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits,49,141,False,126,172,10,27,1,10,13,3,0,113,11027,1.8148148148148149,0.37037037037037035,6.37037037037037,0.48148148148148145,1
136,Optimization from Structured Samples for Coverage Functions,8,Optimization from Structured Samples for Coverage Functions,19,174,False,13,52,0,11,3,8,7,2,0,59,8629,1.7272727272727273,0.0,4.7272727272727275,0.6363636363636364,1
138,PAGE: A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization,8,PAGE A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization,56,206,True,142,179,24,25,0,12,10,0,2,85,14044,2.24,1.04,7.16,0.4,99
139,PackIt: A Virtual Environment for Geometric Planning,8,PackIt A Virtual Environment for Geometric Planning,34,142,False,38,0,16,11,0,8,3,0,8,51,7850,3.090909090909091,2.1818181818181817,0.0,0.2727272727272727,10
140,Partially Exchangeable Networks and Architectures for Learning Summary Statistics in Approximate Bayesian Computation,8,Partially Exchangeable Networks and Architectures for Learning Summary Statistics in Approximate Bayesian Computation,38,115,False,124,32,38,16,1,7,14,2,42,117,8604,2.375,5.0,2.0,0.875,30
141,Personalized Federated Learning through Local Memorization,8,Personalized Federated Learning through Local Memorization,70,167,False,222,36,14,23,1,10,5,0,6,58,12913,3.0434782608695654,0.8695652173913043,1.565217391304348,0.21739130434782608,54
142,Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks,8,Plug  Play Attacks Towards Robust and Flexible Model Inversion Attacks,51,1,False,86,84,33,24,0,10,19,0,20,71,15418,2.125,2.2083333333333335,3.5,0.7916666666666666,34
143,Poolingformer: Long Document Modeling with Pooling Attention,8,Poolingformer Long Document Modeling with Pooling Attention,44,138,False,101,24,7,10,0,6,6,7,14,59,7186,4.4,2.1,2.4,0.6,80
144,Predictive Coding for Locally-Linear Control,8,Predictive Coding for Locally-Linear Control,49,160,False,74,84,5,18,0,12,24,6,2,44,10312,2.7222222222222223,0.3888888888888889,4.666666666666667,1.3333333333333333,22
145,Privacy Aware Offloading of Deep Neural Networks,8,Privacy Aware Offloading of Deep Neural Networks,16,89,False,13,0,45,3,0,8,1,1,10,48,2155,5.333333333333333,18.333333333333332,0.0,0.3333333333333333,18
146,Probabilistic Sequential Shrinking: A Best Arm Identification Algorithm for Stochastic Bandits with Corruptions,8,Probabilistic Sequential Shrinking A Best Arm Identification Algorithm for Stochastic Bandits with Corruptions,32,220,False,70,154,22,22,0,11,13,0,4,110,12792,1.4545454545454546,1.1818181818181819,7.0,0.5909090909090909,10
147,Prompting Decision Transformer for Few-Shot Policy Generalization,8,Prompting Decision Transformer for Few-Shot Policy Generalization,43,155,False,81,6,24,15,8,10,15,0,14,65,8748,2.8666666666666667,2.533333333333333,0.4,1.0,73
148,Provably Correct Optimization and Exploration with Non-linear Policies,8,Provably Correct Optimization and Exploration with Non-linear Policies,44,1,False,101,320,15,42,9,14,17,3,6,70,19142,1.0476190476190477,0.5,7.619047619047619,0.40476190476190477,12
150,Quantization Algorithms for Random Fourier Features,8,Quantization Algorithms for Random Fourier Features,72,270,False,46,170,104,34,0,9,26,0,4,51,15887,2.1176470588235294,3.176470588235294,5.0,0.7647058823529411,11
151,ROMA: Multi-Agent Reinforcement Learning with Emergent Roles,8,ROMA Multi-Agent Reinforcement Learning with Emergent Roles,68,149,True,54,74,51,18,0,10,14,0,4,59,10590,3.7777777777777777,3.0555555555555554,4.111111111111111,0.7777777777777778,149
152,Randomized Dimensionality Reduction for Facility Location and Single-Linkage Clustering,8,Randomized Dimensionality Reduction for Facility Location and Single-Linkage Clustering,28,180,False,64,130,14,25,11,14,14,0,0,87,20192,1.12,0.56,5.2,0.56,6
153,Reconstructing Nonlinear Dynamical Systems from Multi-Modal Time Series,8,Reconstructing Nonlinear Dynamical Systems from Multi-Modal Time Series,100,202,False,117,96,24,21,5,9,15,0,0,71,15090,4.761904761904762,1.1428571428571428,4.571428571428571,0.7142857142857143,12
154,Regret Minimization with Performative Feedback,8,Regret Minimization with Performative Feedback,44,197,False,94,134,12,36,15,12,23,0,0,46,15390,1.2222222222222223,0.3333333333333333,3.7222222222222223,0.6388888888888888,24
155,Reliable Measures of Spread in High Dimensional Latent Spaces,8,Reliable Measures of Spread in High Dimensional Latent Spaces,43,141,False,67,40,40,15,5,12,16,0,22,61,9461,2.8666666666666667,4.133333333333334,2.6666666666666665,1.0666666666666667,0
156,Resource Allocation in Multi-armed Bandit Exploration: Overcoming Nonlinear Scaling with Adaptive Parallelism,8,Resource Allocation in Multi-armed Bandit Exploration Overcoming Nonlinear Scaling with Adaptive Parallelism,39,229,False,107,121,42,27,0,12,14,0,0,108,17130,1.4444444444444444,1.5555555555555556,4.481481481481482,0.5185185185185185,5
157,Revisiting Fundamentals of Experience Replay,8,Revisiting Fundamentals of Experience Replay,58,141,False,138,2,60,19,5,14,16,0,6,44,9561,3.0526315789473686,3.473684210526316,0.10526315789473684,0.8421052631578947,179
158,Ripple Attention for Visual Perception with Sub-quadratic Complexity,8,Ripple Attention for Visual Perception with Sub-quadratic Complexity,70,134,False,173,38,16,18,24,13,20,0,16,68,12227,3.888888888888889,1.7777777777777777,2.111111111111111,1.1111111111111112,3
159,Robust Learning-Augmented Caching: An Experimental Study,8,Robust Learning-Augmented Caching An Experimental Study,28,160,False,103,2,13,14,11,9,7,0,0,55,8777,2.0,0.9285714285714286,0.14285714285714285,0.5,12
160,Robustifying Sequential Neural Processes,8,Robustifying Sequential Neural Processes,32,169,False,219,12,33,18,0,29,40,23,16,40,8830,1.7777777777777777,2.7222222222222223,0.6666666666666666,2.2222222222222223,24
161,SGA: A Robust Algorithm for Partial Recovery of Tree-Structured Graphical Models with Noisy Samples,8,SGA A Robust Algorithm for Partial Recovery of Tree-Structured Graphical Models with Noisy Samples,39,183,True,181,110,39,23,0,18,13,3,0,98,14215,1.6956521739130435,1.6956521739130435,4.782608695652174,0.5652173913043478,9
165,Second-order regression models exhibit progressive sharpening to the edge of stability,8,Second-order regression models exhibit progressive sharpening to the edge of stability,28,184,False,70,660,130,26,0,18,38,8,0,86,14307,1.0769230769230769,5.0,25.384615384615383,1.4615384615384615,16
166,Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training,8,Self-PU Self Boosted and Calibrated Positive-Unlabeled Training,34,171,True,42,42,12,11,0,5,10,15,14,63,7285,3.090909090909091,2.3636363636363638,3.8181818181818183,0.9090909090909091,61
167,Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees,8,Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees,74,220,False,133,434,18,59,2,9,19,0,8,89,24492,1.2542372881355932,0.4406779661016949,7.3559322033898304,0.3220338983050847,7
168,Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances,8,Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances,74,144,True,189,148,32,23,1,9,17,1,6,70,15053,3.217391304347826,1.6521739130434783,6.434782608695652,0.7391304347826086,6
169,Simultaneous Inference for Massive Data: Distributed Bootstrap,8,Simultaneous Inference for Massive Data Distributed Bootstrap,32,81,False,37,324,33,50,0,11,15,0,2,61,23422,0.64,0.7,6.48,0.3,14
170,Small-GAN: Speeding Up GAN Training Using Core-sets,8,Small-GAN Speeding Up GAN Training Using Core-sets,76,164,True,138,8,0,12,5,7,16,0,14,50,6451,6.333333333333333,1.1666666666666667,0.6666666666666666,1.3333333333333333,52
171,Sparse Convex Optimization via Adaptively Regularized Hard Thresholding,8,Sparse Convex Optimization via Adaptively Regularized Hard Thresholding,42,211,False,54,216,16,41,9,7,18,9,4,71,14547,1.024390243902439,0.4878048780487805,5.2682926829268295,0.43902439024390244,12
172,Spectrally approximating large graphs with smaller graphs,8,Spectrally approximating large graphs with smaller graphs,45,104,False,32,132,18,22,6,7,12,0,0,57,9638,2.0454545454545454,0.8181818181818182,6.0,0.5454545454545454,80
173,State Relevance for Off-Policy Evaluation,8,State Relevance for Off-Policy Evaluation,25,83,False,60,96,46,20,11,14,17,0,6,41,12165,1.25,2.6,4.8,0.85,3
174,Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning,8,Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning,45,131,False,128,32,20,12,0,16,22,11,16,85,7417,3.75,3.0,2.6666666666666665,1.8333333333333333,6
175,Stochastic Variance-Reduced Policy Gradient,8,Stochastic Variance-Reduced Policy Gradient,46,166,False,115,111,6,23,4,14,11,0,2,43,13369,2.0,0.34782608695652173,4.826086956521739,0.4782608695652174,156
177,"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",8,Style Tokens Unsupervised Style Modeling Control and Transfer in End-to-End Speech Synthesis,32,128,False,68,0,98,11,0,14,24,16,16,92,6918,2.909090909090909,10.363636363636363,0.0,2.1818181818181817,709
178,Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization,8,Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization,51,131,False,133,102,94,33,0,15,23,3,20,87,18197,1.5454545454545454,3.4545454545454546,3.090909090909091,0.696969696969697,1
179,TAN without a burn: Scaling Laws of DP-SGD,8,TAN without a burn Scaling Laws of DP-SGD,57,161,True,262,44,46,13,34,15,22,0,24,41,8518,4.384615384615385,5.384615384615385,3.3846153846153846,1.6923076923076923,27
180,Team Belief DAG: Generalizing the Sequence Form to Team Games for Fast Computation of Correlated Team Max-Min Equilibria via Regret Minimization,8,Team Belief DAG Generalizing the Sequence Form to Team Games for Fast Computation of Correlated Team Max-Min Equilibria via Regret Minimization,41,214,True,89,18,2,23,0,14,5,0,0,143,15221,1.7826086956521738,0.08695652173913043,0.782608695652174,0.21739130434782608,7
181,Test-time Adaptation with Slot-Centric Models,8,Test-time Adaptation with Slot-Centric Models,94,158,False,227,4,30,16,36,11,13,7,14,45,11420,5.875,2.75,0.25,0.8125,7
184,The case for 4-bit precision: k-bit Inference Scaling Laws,8,The case for 4-bit precision k-bit Inference Scaling Laws,55,204,False,91,16,45,24,9,12,10,0,2,57,10732,2.2916666666666665,1.9583333333333333,0.6666666666666666,0.4166666666666667,96
185,Three Operator Splitting with a Nonconvex Loss Function,8,Three Operator Splitting with a Nonconvex Loss Function,54,140,False,144,294,7,27,0,13,7,0,0,55,11740,2.0,0.25925925925925924,10.88888888888889,0.25925925925925924,8
186,Topological Data Analysis of Decision Boundaries with Application to Model Selection,8,Topological Data Analysis of Decision Boundaries with Application to Model Selection,29,74,False,48,20,76,17,3,11,8,0,24,84,8525,1.7058823529411764,5.882352941176471,1.1764705882352942,0.47058823529411764,38
187,Towards Fast Computation of Certified Robustness for ReLU Networks,8,Towards Fast Computation of Certified Robustness for ReLU Networks,55,1,False,81,198,4,26,4,21,27,9,34,66,17426,2.1153846153846154,1.4615384615384615,7.615384615384615,1.0384615384615385,643
188,Towards understanding how momentum improves generalization in deep learning,8,Towards understanding how momentum improves generalization in deep learning,51,1,False,111,1622,73,76,41,25,50,28,18,75,32162,0.6710526315789473,1.1973684210526316,21.342105263157894,0.6578947368421053,20
189,Training Your Sparse Neural Network Better with Any Mask,8,Training Your Sparse Neural Network Better with Any Mask,53,199,False,101,0,30,12,9,7,11,0,10,56,7986,4.416666666666667,3.3333333333333335,0.0,0.9166666666666666,22
190,Tree Edit Distance Learning via Adaptive Symbol Embeddings,8,Tree Edit Distance Learning via Adaptive Symbol Embeddings,42,197,False,111,14,2,12,0,7,5,0,2,58,8472,3.5,0.3333333333333333,1.1666666666666667,0.4166666666666667,21
192,Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels,8,Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels,33,139,False,69,54,24,13,0,10,8,0,4,74,9619,2.5384615384615383,2.1538461538461537,4.153846153846154,0.6153846153846154,325
193,Unique Properties of Wide Minima in Deep Networks,8,Unique Properties of Wide Minima in Deep Networks,27,184,False,52,272,32,25,3,18,8,0,2,49,14264,1.08,1.36,10.88,0.32,3
194,Unsupervised Skill Discovery with Bottleneck Option Learning,8,Unsupervised Skill Discovery with Bottleneck Option Learning,46,108,False,132,22,162,20,0,16,14,0,0,60,12710,2.3,8.1,1.1,0.7,25
195,Value Alignment Verification,8,Value Alignment Verification,49,171,False,68,102,47,26,7,15,20,6,0,28,17528,1.8846153846153846,1.8076923076923077,3.923076923076923,0.7692307692307693,24
196,Variational Nearest Neighbor Gaussian Processes,8,Variational Nearest Neighbor Gaussian Processes,49,138,False,111,78,29,17,12,9,14,3,6,47,10620,2.8823529411764706,2.0588235294117645,4.588235294117647,0.8235294117647058,14
197,Warm-starting Contextual Bandits: Robustly Combining Supervised and Bandit Feedback,8,Warm-starting Contextual Bandits Robustly Combining Supervised and Bandit Feedback,29,83,False,31,149,373,42,23,18,4,1,0,82,19282,0.6904761904761905,8.880952380952381,3.5476190476190474,0.09523809523809523,23
199,Why bigger is not always better: on finite and infinite neural networks,8,Why bigger is not always better on finite and infinite neural networks,18,181,False,43,188,11,20,0,11,9,1,0,70,10773,0.9,0.55,9.4,0.45,46
200,Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model,8,Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model,52,228,False,49,20,37,16,0,6,13,9,22,70,10602,3.25,3.6875,1.25,0.8125,32
201,(Locally) Differentially Private Combinatorial Semi-Bandits,8,Locally Differentially Private Combinatorial Semi-Bandits,49,191,False,122,113,0,20,0,7,14,0,2,59,12580,2.45,0.1,5.65,0.7,17
202,A Differentiable Gaussian-like Distribution on Hyperbolic Space for Gradient-Based Learning,8,A Differentiable Gaussian-like Distribution on Hyperbolic Space for Gradient-Based Learning,27,123,False,47,62,66,20,0,12,18,0,14,91,8260,1.35,4.0,3.1,0.9,15
204,A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network,8,A Modular Analysis of Provable Acceleration via Polyaks Momentum Training a Wide ReLU Network and a Deep Linear Network,110,230,False,149,430,6,38,0,14,18,0,4,120,21571,2.8947368421052633,0.2631578947368421,11.31578947368421,0.47368421052631576,18
205,A Rigorous Study of Integrated Gradients Method and Extensions to Internal Neuron Attributions,8,A Rigorous Study of Integrated Gradients Method and Extensions to Internal Neuron Attributions,41,199,False,195,58,35,25,0,22,15,0,2,94,15614,1.64,1.48,2.32,0.6,34
207,A data-driven approach for learning to control computers,8,A data-driven approach for learning to control computers,32,168,False,78,0,42,17,9,6,9,0,4,56,9498,1.8823529411764706,2.7058823529411766,0.0,0.5294117647058824,49
208,ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks,8,ASAM Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks,42,106,True,115,53,21,13,0,9,5,0,20,95,7876,3.230769230769231,3.1538461538461537,4.076923076923077,0.38461538461538464,177
209,Acceleration of SVRG and Katyusha X by Inexact Preconditioning,8,Acceleration of SVRG and Katyusha X by Inexact Preconditioning,32,149,True,38,214,27,18,0,12,5,0,0,62,10537,1.7777777777777777,1.5,11.88888888888889,0.2777777777777778,6
210,Active Sampling for Min-Max Fairness,8,Active Sampling for Min-Max Fairness,47,103,False,172,19,22,13,5,10,4,0,2,36,9095,3.6153846153846154,1.8461538461538463,1.4615384615384615,0.3076923076923077,34
211,Adaptive scale-invariant online algorithms for learning linear models,8,Adaptive scale-invariant online algorithms for learning linear models,30,143,False,80,119,22,21,12,13,2,0,4,69,12554,1.4285714285714286,1.2380952380952381,5.666666666666667,0.09523809523809523,27
212,Adversarial Generation of Time-Frequency Features with application in audio synthesis,8,Adversarial Generation of Time-Frequency Features with application in audio synthesis,66,140,False,75,48,28,13,8,10,5,0,4,85,9178,5.076923076923077,2.4615384615384617,3.6923076923076925,0.38461538461538464,60
214,Almost Unsupervised Text to Speech and Automatic Speech Recognition,8,Almost Unsupervised Text to Speech and Automatic Speech Recognition,48,203,False,106,36,8,11,9,7,9,0,8,67,8055,4.363636363636363,1.4545454545454546,3.272727272727273,0.8181818181818182,92
215,An Estimation and Analysis Framework for the Rasch Model,8,An Estimation and Analysis Framework for the Rasch Model,37,137,False,68,134,16,9,9,10,11,2,4,56,6793,4.111111111111111,2.2222222222222223,14.88888888888889,1.2222222222222223,6
216,Analysis of Stochastic Processes through Replay Buffers,8,Analysis of Stochastic Processes through Replay Buffers,41,112,False,103,182,18,22,0,11,18,0,0,55,12202,1.8636363636363635,0.8181818181818182,8.272727272727273,0.8181818181818182,4
217,Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets,8,Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets,79,142,False,141,238,34,35,25,13,19,0,8,69,19188,2.257142857142857,1.2,6.8,0.5428571428571428,0
218,Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections,8,Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections,69,168,False,119,271,49,33,1,13,9,0,0,69,18928,2.090909090909091,1.4848484848484849,8.212121212121213,0.2727272727272727,14
219,AutoML-Zero: Evolving Machine Learning Algorithms From Scratch,8,AutoML-Zero Evolving Machine Learning Algorithms From Scratch,114,191,False,99,71,27,23,0,9,5,0,14,61,18131,4.956521739130435,1.7826086956521738,3.0869565217391304,0.21739130434782608,191
220,Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent,8,Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent,32,137,False,56,56,28,13,0,10,12,0,0,66,8555,2.4615384615384617,2.1538461538461537,4.3076923076923075,0.9230769230769231,122
222,Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams,8,Beyond 12-Approximation for Submodular Maximization on Massive Data Streams,46,132,False,28,126,11,28,8,11,8,1,0,75,16627,1.6428571428571428,0.39285714285714285,4.5,0.2857142857142857,79
223,"Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",8,Binary Classification with Karmic Threshold-Quasi-Concave Metrics,29,166,False,92,10,0,10,10,7,11,0,2,65,7207,2.9,0.2,1.0,1.1,29
224,Boosting Frank-Wolfe by Chasing Gradients,8,Boosting Frank-Wolfe by Chasing Gradients,44,0,False,144,190,53,34,2,9,18,0,0,41,12989,1.2941176470588236,1.5588235294117647,5.588235294117647,0.5294117647058824,25
225,Breaking the Curse of Space Explosion: Towards Efficient NAS with Curriculum Search,8,Breaking the Curse of Space Explosion Towards Efficient NAS with Curriculum Search,48,154,True,104,18,16,12,0,12,10,0,4,82,8969,4.0,1.6666666666666667,1.5,0.8333333333333334,56
226,CATE: Computation-aware Neural Architecture Encoding with Transformers,8,CATE Computation-aware Neural Architecture Encoding with Transformers,87,1,True,118,8,25,14,0,10,9,0,18,69,9564,6.214285714285714,3.0714285714285716,0.5714285714285714,0.6428571428571429,18
227,Causal Transformer for Estimating Counterfactual Outcomes,8,Causal Transformer for Estimating Counterfactual Outcomes,68,172,False,133,96,21,37,21,21,23,0,26,57,19267,1.837837837837838,1.2702702702702702,2.5945945945945947,0.6216216216216216,49
228,Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions,8,Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions,39,127,False,90,28,47,18,0,10,16,0,0,82,11554,2.1666666666666665,2.611111111111111,1.5555555555555556,0.8888888888888888,82
229,Cluster Explanation via Polyhedral Descriptions,8,Cluster Explanation via Polyhedral Descriptions,41,0,False,55,14,22,22,0,6,11,0,6,47,10507,1.8636363636363635,1.2727272727272727,0.6363636363636364,0.5,3
230,Combinatorial Blocking Bandits with Stochastic Delays,8,Combinatorial Blocking Bandits with Stochastic Delays,37,1,False,45,126,6,23,2,10,2,0,0,53,15197,1.608695652173913,0.2608695652173913,5.478260869565218,0.08695652173913043,6
231,Complementary-Label Learning for Arbitrary Losses and Models,8,Complementary-Label Learning for Arbitrary Losses and Models,40,126,False,125,48,26,13,6,10,10,0,8,60,7774,3.076923076923077,2.6153846153846154,3.6923076923076925,0.7692307692307693,87
232,ConQUR: Mitigating Delusional Bias in Deep Q-learning,8,ConQUR Mitigating Delusional Bias in Deep Q-learning,36,105,False,80,8,50,21,0,13,23,0,26,52,12434,1.7142857142857142,3.619047619047619,0.38095238095238093,1.0952380952380953,3
233,"Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation",8,Connect Not Collapse Explaining Contrastive Learning for Unsupervised Domain Adaptation,64,0,False,2,12,11,40,0,6,1,1,0,88,20839,1.6,0.275,0.3,0.025,60
234,Constrained Variational Policy Optimization for Safe Reinforcement Learning,8,Constrained Variational Policy Optimization for Safe Reinforcement Learning,46,143,False,57,154,38,25,0,9,21,0,2,75,13616,1.84,1.6,6.16,0.84,46
235,Continuous Coordination As a Realistic Scenario for Lifelong Learning,8,Continuous Coordination As a Realistic Scenario for Lifelong Learning,59,230,False,100,10,39,19,0,12,8,2,14,69,10639,3.1052631578947367,2.789473684210526,0.5263157894736842,0.42105263157894735,33
236,Convergence and Recovery Guarantees of the K-Subspaces Method for Subspace Clustering,8,Convergence and Recovery Guarantees of the K-Subspaces Method for Subspace Clustering,66,123,False,133,446,5,35,0,12,22,0,10,85,20572,1.8857142857142857,0.42857142857142855,12.742857142857142,0.6285714285714286,6
237,Coordinated Double Machine Learning,8,Coordinated Double Machine Learning,27,138,False,43,60,33,15,0,12,13,5,0,35,8797,1.8,2.2,4.0,0.8666666666666667,3
238,Cramming: Training a Language Model on a Single GPU in One Day,8,Cramming Training a Language Model on a Single GPU in One Day,145,184,True,244,0,19,27,17,10,7,1,18,61,14003,5.37037037037037,1.3703703703703705,0.0,0.25925925925925924,52
239,DADAO: Decoupled Accelerated Decentralized Asynchronous Optimization for Time-Varying Gossips,8,DADAO Decoupled Accelerated Decentralized Asynchronous Optimization for Time-Varying Gossips,56,203,True,143,98,7,23,20,11,8,0,4,92,13446,2.4347826086956523,0.4782608695652174,4.260869565217392,0.34782608695652173,4
240,Data Amplification: Instance-Optimal Property Estimation,8,Data Amplification Instance-Optimal Property Estimation,65,0,False,44,302,6,45,23,12,21,7,0,55,14732,1.4444444444444444,0.13333333333333333,6.711111111111111,0.4666666666666667,20
241,Dataset Condensation with Contrastive Signals,8,Dataset Condensation with Contrastive Signals,37,199,False,73,40,3,13,16,7,6,0,0,45,8245,2.8461538461538463,0.23076923076923078,3.076923076923077,0.46153846153846156,51
242,Decoupled Greedy Learning of CNNs,8,Decoupled Greedy Learning of CNNs,40,191,False,167,52,24,15,9,10,9,0,6,33,9307,2.6666666666666665,2.0,3.466666666666667,0.6,97
243,Deep Models of Interactions Across Sets,8,Deep Models of Interactions Across Sets,34,199,False,84,46,21,12,10,10,12,0,8,39,8356,2.8333333333333335,2.4166666666666665,3.8333333333333335,1.0,140
245,Deploying Convolutional Networks on Untrusted Platforms Using 2D Holographic Reduced Representations,8,Deploying Convolutional Networks on Untrusted Platforms Using 2D Holographic Reduced Representations,39,130,False,64,2,197,27,0,11,8,0,16,100,10579,1.4444444444444444,7.888888888888889,0.07407407407407407,0.2962962962962963,4
246,Differentiable Dynamic Programming for Structured Prediction and Attention,8,Differentiable Dynamic Programming for Structured Prediction and Attention,65,140,False,126,150,33,28,33,11,22,0,6,74,15121,2.3214285714285716,1.3928571428571428,5.357142857142857,0.7857142857142857,121
247,Differentially Private Optimization on Large Model at Small Cost,8,Differentially Private Optimization on Large Model at Small Cost,61,162,False,72,16,97,28,5,12,29,1,20,64,13770,2.1785714285714284,4.178571428571429,0.5714285714285714,1.0357142857142858,22
249,Disentangled Federated Learning for Tackling Attributes Skew via Invariant Aggregation and Diversity Transferring,8,Disentangled Federated Learning for Tackling Attributes Skew via Invariant Aggregation and Diversity Transferring,36,155,False,43,204,21,15,0,7,8,0,8,113,8561,2.4,1.9333333333333333,13.6,0.5333333333333333,22
250,Distribution-free calibration guarantees for histogram binning without sample splitting,8,Distribution-free calibration guarantees for histogram binning without sample splitting,29,140,False,112,83,36,25,0,10,14,0,0,87,13455,1.16,1.44,3.32,0.56,27
251,Does Data Augmentation Lead to Positive Margin?,8,Does Data Augmentation Lead to Positive Margin,38,129,False,40,56,17,18,13,9,21,0,0,46,13639,2.111111111111111,0.9444444444444444,3.111111111111111,1.1666666666666667,36
252,DropNet: Reducing Neural Network Complexity via Iterative Pruning,8,DropNet Reducing Neural Network Complexity via Iterative Pruning,38,92,False,38,0,86,19,0,13,11,0,4,64,10241,2.0,4.7368421052631575,0.0,0.5789473684210527,35
253,Easy Variational Inference for Categorical Models via an Independent Binary Approximation,8,Easy Variational Inference for Categorical Models via an Independent Binary Approximation,53,172,False,174,278,65,40,22,28,69,44,20,89,26144,1.325,2.125,6.95,1.725,1
254,Efficient Online Learning for Dynamic k-Clustering,8,Efficient Online Learning for Dynamic k-Clustering,54,134,False,34,41,30,27,0,13,4,0,0,50,8768,2.0,1.1111111111111112,1.5185185185185186,0.14814814814814814,3
255,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,8,EfficientNet Rethinking Model Scaling for Convolutional Neural Networks,54,129,False,108,12,24,11,9,9,6,0,16,71,6980,4.909090909090909,3.6363636363636362,1.0909090909090908,0.5454545454545454,13312
256,Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments,8,Enforcing Hard Constraints with Soft Barriers Safe Reinforcement Learning in Unknown Stochastic Environments,75,190,False,83,42,24,12,1,5,5,0,2,108,9140,6.25,2.1666666666666665,3.5,0.4166666666666667,22
257,Equivariant message passing for the prediction of tensorial properties and molecular spectra,8,Equivariant message passing for the prediction of tensorial properties and molecular spectra,71,130,False,92,33,18,13,1,10,11,2,10,92,8138,5.461538461538462,2.1538461538461537,2.5384615384615383,0.8461538461538461,349
258,Estimation and Quantization of Expected Persistence Diagrams,8,Estimation and Quantization of Expected Persistence Diagrams,58,185,False,144,93,33,18,0,11,2,0,0,60,12390,3.2222222222222223,1.8333333333333333,5.166666666666667,0.1111111111111111,8
259,Explainability as statistical inference,8,Explainability as statistical inference,66,159,False,146,28,39,29,11,14,18,3,4,39,14740,2.2758620689655173,1.4827586206896552,0.9655172413793104,0.6206896551724138,2
260,Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL,8,Exponential Lower Bounds for Batch Reinforcement Learning Batch RL can be Exponentially Harder than Online RL,58,1,True,89,172,4,33,43,17,34,0,0,109,19211,1.7575757575757576,0.12121212121212122,5.212121212121212,1.0303030303030303,67
261,Fair Generalized Linear Models with a Convex Penalty,8,Fair Generalized Linear Models with a Convex Penalty,40,141,False,120,84,62,23,0,14,35,0,8,52,12839,1.7391304347826086,3.0434782608695654,3.652173913043478,1.5217391304347827,10
264,Feature Selection using e-values,8,Feature Selection using e-values,65,161,False,112,22,19,21,12,15,9,0,4,32,12975,3.0952380952380953,1.0952380952380953,1.0476190476190477,0.42857142857142855,1
266,Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks,8,Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks,76,1,False,87,297,18,31,6,14,13,0,0,104,13448,2.4516129032258065,0.5806451612903226,9.580645161290322,0.41935483870967744,850
267,Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,8,Flow Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,40,125,False,106,22,36,16,0,7,5,4,4,99,4997,2.5,2.5,1.375,0.3125,393
268,Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions,8,Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions,64,177,False,70,44,26,16,0,8,13,0,6,86,11005,4.0,2.0,2.75,0.8125,18
269,Function Contrastive Learning of Transferable Meta-Representations,8,Function Contrastive Learning of Transferable Meta-Representations,42,200,False,102,20,61,20,11,13,10,5,10,66,12067,2.1,3.55,1.0,0.5,15
270,GEOMetrics: Exploiting Geometric Structure for Graph-Encoded Objects,8,GEOMetrics Exploiting Geometric Structure for Graph-Encoded Objects,61,165,False,141,28,51,17,0,13,12,0,14,67,9201,3.588235294117647,3.823529411764706,1.6470588235294117,0.7058823529411765,86
271,Gaussian Mixture Variational Autoencoder with Contrastive Learning for Multi-Label Classification,8,Gaussian Mixture Variational Autoencoder with Contrastive Learning for Multi-Label Classification,57,170,False,66,58,30,16,4,8,12,5,18,97,9487,3.5625,3.0,3.625,0.75,18
272,Generalized Federated Learning via Sharpness Aware Minimization,8,Generalized Federated Learning via Sharpness Aware Minimization,55,181,False,70,272,33,30,0,12,18,0,10,63,18010,1.8333333333333333,1.4333333333333333,9.066666666666666,0.6,71
273,Generative Causal Explanations for Graph Neural Networks,8,Generative Causal Explanations for Graph Neural Networks,35,154,False,50,26,36,14,0,10,4,0,16,56,9806,2.5,3.7142857142857144,1.8571428571428572,0.2857142857142857,113
275,Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech,8,Grad-TTS A Diffusion Probabilistic Model for Text-to-Speech,36,136,True,48,82,15,13,0,7,14,0,4,59,8038,2.769230769230769,1.4615384615384615,6.3076923076923075,1.0769230769230769,322
276,Graph Optimal Transport for Cross-Domain Alignment,8,Graph Optimal Transport for Cross-Domain Alignment,68,179,False,252,32,24,12,22,12,14,0,36,50,7922,5.666666666666667,5.0,2.6666666666666665,1.1666666666666667,116
277,Group Fisher Pruning for Practical Network Compression,8,Group Fisher Pruning for Practical Network Compression,53,210,False,101,8,22,12,0,6,6,0,12,54,9341,4.416666666666667,2.8333333333333335,0.6666666666666666,0.5,87
279,Hindering Adversarial Attacks with Implicit Neural Representations,8,Hindering Adversarial Attacks with Implicit Neural Representations,56,179,False,302,24,118,25,0,20,22,14,28,66,12606,2.24,5.84,0.96,0.88,4
282,Implicit Bias of Linear RNNs,8,Implicit Bias of Linear RNNs,56,159,False,35,187,16,30,16,9,9,0,2,28,11259,1.8666666666666667,0.6,6.233333333333333,0.3,10
284,Improving Ensemble Distillation With Weight Averaging and Diversifying Perturbation,8,Improving Ensemble Distillation With Weight Averaging and Diversifying Perturbation,33,141,False,135,31,26,15,13,9,18,0,4,83,9680,2.2,2.0,2.066666666666667,1.2,5
285,Improving Task-free Continual Learning by Distributionally Robust Memory Evolution,8,Improving Task-free Continual Learning by Distributionally Robust Memory Evolution,39,209,False,65,54,22,15,11,11,8,0,18,82,9425,2.6,2.6666666666666665,3.6,0.5333333333333333,22
287,Information-Theoretic Local Minima Characterization and Regularization,8,Information-Theoretic Local Minima Characterization and Regularization,56,123,False,130,62,12,16,1,13,6,5,6,70,10097,3.5,1.125,3.875,0.375,15
288,Interference and Generalization in Temporal Difference Learning,8,Interference and Generalization in Temporal Difference Learning,59,152,False,108,62,42,20,0,12,13,0,0,63,10627,2.95,2.1,3.1,0.65,50
290,Is Pessimism Provably Efficient for Offline RL?,8,Is Pessimism Provably Efficient for Offline RL,98,228,True,131,70,9,67,7,10,24,4,0,46,34873,1.462686567164179,0.13432835820895522,1.044776119402985,0.3582089552238806,283
291,KNAS: Green Neural Architecture Search,8,KNAS Green Neural Architecture Search,63,1,True,108,64,17,13,12,11,6,0,4,37,8084,4.846153846153846,1.6153846153846154,4.923076923076923,0.46153846153846156,40
292,LARNet: Lie Algebra Residual Network for Face Recognition,8,LARNet Lie Algebra Residual Network for Face Recognition,75,184,False,89,134,21,17,0,11,7,5,10,56,11447,4.411764705882353,1.8235294117647058,7.882352941176471,0.4117647058823529,23
293,Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents,8,Language Models as Zero-Shot Planners Extracting Actionable Knowledge for Embodied Agents,55,166,False,100,6,18,33,11,9,19,0,14,89,16513,1.6666666666666667,0.9696969696969697,0.18181818181818182,0.5757575757575758,592
294,Layered Sampling for Robust Optimization Problems,8,Layered Sampling for Robust Optimization Problems,52,156,False,45,104,23,15,3,8,7,0,4,49,10881,3.466666666666667,1.8,6.933333333333334,0.4666666666666667,5
295,Learning Classifiers for Target Domain with Limited or No Labels,8,Learning Classifiers for Target Domain with Limited or No Labels,76,141,False,99,22,9,12,0,5,7,0,6,64,8994,6.333333333333333,1.25,1.8333333333333333,0.5833333333333334,10
296,Learning Fair Policies in Multiobjective (Deep) Reinforcement Learning with Average and Discounted Rewards,8,Learning Fair Policies in Multiobjective Deep Reinforcement Learning with Average and Discounted Rewards,39,185,False,88,45,68,21,10,12,10,0,6,106,11972,1.8571428571428572,3.5238095238095237,2.142857142857143,0.47619047619047616,61
297,Learning Localized Spatio-Temporal Models From Streaming Data,8,Learning Localized Spatio-Temporal Models From Streaming Data,27,104,False,36,85,35,12,0,11,6,0,2,61,7190,2.25,3.0833333333333335,7.083333333333333,0.5,1
298,Learning Portable Representations for High-Level Planning,8,Learning Portable Representations for High-Level Planning,38,95,False,60,0,30,10,0,7,5,0,2,57,5336,3.8,3.2,0.0,0.5,34
299,Learning What and Where to Transfer,8,Learning What and Where to Transfer,31,181,False,73,12,25,12,5,8,9,0,8,35,6888,2.5833333333333335,2.75,1.0,0.75,127
300,Learning in Integer Latent Variable Models with Nested Automatic Differentiation,8,Learning in Integer Latent Variable Models with Nested Automatic Differentiation,19,99,False,51,28,19,11,2,11,8,0,0,80,7879,1.7272727272727273,1.7272727272727273,2.5454545454545454,0.7272727272727273,3
301,Learning to Infer Program Sketches,8,Learning to Infer Program Sketches,34,119,False,210,28,26,16,0,16,16,0,20,34,8814,2.125,2.875,1.75,1.0,100
302,Learning to branch: Generalization guarantees and limits of data-independent discretization,8,Learning to branch Generalization guarantees and limits of data-independent discretization,64,1,False,115,76,42,49,26,11,8,8,0,90,29283,1.3061224489795917,0.8571428571428571,1.5510204081632653,0.16326530612244897,98
305,Logarithmic Regret for Adversarial Online Control,8,Logarithmic Regret for Adversarial Online Control,53,1,False,181,447,0,54,16,11,39,12,0,49,22846,0.9814814814814815,0.0,8.277777777777779,0.7222222222222222,62
306,Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries,8,Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries,52,168,False,3,22,17,16,0,11,10,0,4,75,10309,3.25,1.3125,1.375,0.625,2
308,Matrix Sketching for Secure Collaborative Machine Learning,8,Matrix Sketching for Secure Collaborative Machine Learning,71,170,False,87,64,12,22,21,14,14,0,2,58,14355,3.227272727272727,0.6363636363636364,2.909090909090909,0.6363636363636364,7
309,Mediated Uncoupled Learning: Learning Functions without Direct Input-output Correspondences,8,Mediated Uncoupled Learning Learning Functions without Direct Input-output Correspondences,39,184,False,67,248,28,22,3,9,20,4,2,90,13711,1.7727272727272727,1.3636363636363635,11.272727272727273,0.9090909090909091,1
310,Meta-learning with Stochastic Linear Bandits,8,Meta-learning with Stochastic Linear Bandits,40,139,False,50,100,12,22,4,11,10,1,0,44,9404,1.8181818181818181,0.5454545454545454,4.545454545454546,0.45454545454545453,50
311,Mitigating Bias in Adaptive Data Gathering via Differential Privacy,8,Mitigating Bias in Adaptive Data Gathering via Differential Privacy,42,152,False,58,9,14,26,0,10,10,0,0,67,11388,1.6153846153846154,0.5384615384615384,0.34615384615384615,0.38461538461538464,31
312,Model Fusion with Kullback-Leibler Divergence,8,Model Fusion with Kullback-Leibler Divergence,35,123,False,67,52,25,13,4,11,9,0,4,45,8554,2.6923076923076925,2.230769230769231,4.0,0.6923076923076923,25
313,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,8,Modeling Others using Oneself in Multi-Agent Reinforcement Learning,39,127,False,37,8,39,11,0,6,5,0,0,67,8074,3.5454545454545454,3.5454545454545454,0.7272727272727273,0.45454545454545453,179
314,Monte-Carlo Tree Search as Regularized Policy Optimization,8,Monte-Carlo Tree Search as Regularized Policy Optimization,48,99,False,141,121,73,22,30,9,21,0,2,58,12118,2.1818181818181817,3.409090909090909,5.5,0.9545454545454546,54
317,Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation,8,Navigation Turing Test NTT Learning to Evaluate Human-Like Navigation,36,150,True,128,0,96,13,0,16,26,0,16,71,9194,2.769230769230769,8.615384615384615,0.0,2.0,17
318,Nested Subspace Arrangement for Representation of Relational Data,8,Nested Subspace Arrangement for Representation of Relational Data,32,111,False,23,19,39,11,0,7,5,0,4,65,6035,2.909090909090909,3.909090909090909,1.7272727272727273,0.45454545454545453,3
321,Non-Autoregressive Electron Redistribution Modeling for Reaction Prediction,8,Non-Autoregressive Electron Redistribution Modeling for Reaction Prediction,30,167,False,156,196,72,10,2,36,26,8,40,75,7363,3.0,11.2,19.6,2.6,13
322,Nonparametric Score Estimators,8,Nonparametric Score Estimators,41,119,False,200,149,58,22,13,12,15,3,12,30,13065,1.8636363636363635,3.1818181818181817,6.7727272727272725,0.6818181818181818,18
323,Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap,8,Of Moments and Matching A Game-Theoretic Framework for Closing the Imitation Gap,49,139,False,65,132,26,19,0,14,27,0,30,80,12818,2.5789473684210527,2.9473684210526314,6.947368421052632,1.4210526315789473,51
324,On Characterizing GAN Convergence Through Proximal Duality Gap,8,On Characterizing GAN Convergence Through Proximal Duality Gap,44,203,True,45,128,47,20,0,11,14,0,8,62,12274,2.2,2.75,6.4,0.7,3
325,On Improving Model-Free Algorithms for Decentralized Multi-Agent Reinforcement Learning,8,On Improving Model-Free Algorithms for Decentralized Multi-Agent Reinforcement Learning,115,154,False,297,242,13,51,0,14,9,0,2,87,25588,2.2549019607843137,0.29411764705882354,4.745098039215686,0.17647058823529413,45
326,On Relativistic f-Divergences,8,On Relativistic f-Divergences,32,189,False,98,130,6,29,0,7,15,3,2,29,12196,1.103448275862069,0.27586206896551724,4.482758620689655,0.5172413793103449,16
327,On the Convergence of Nesterov's Accelerated Gradient Method in Stochastic Settings,8,On the Convergence of Nesterovs Accelerated Gradient Method in Stochastic Settings,45,139,False,74,162,43,20,0,13,11,0,0,83,11906,2.25,2.15,8.1,0.55,51
328,On the Impact of the Activation Function on Deep Neural Networks Training,8,On the Impact of the Activation Function on Deep Neural Networks Training,19,146,False,36,118,37,22,0,8,10,0,6,73,11894,0.8636363636363636,1.9545454545454546,5.363636363636363,0.45454545454545453,165
330,One Size Fits All: Can We Train One Denoiser for All Noise Levels?,8,One Size Fits All Can We Train One Denoiser for All Noise Levels,34,185,False,28,58,19,11,0,10,15,0,2,64,7735,3.090909090909091,1.9090909090909092,5.2727272727272725,1.3636363636363635,17
332,OpenFE: Automated Feature Generation with Expert-level Performance,8,OpenFE Automated Feature Generation with Expert-level Performance,56,158,False,165,26,6,22,8,14,24,2,32,65,13517,2.5454545454545454,1.7272727272727273,1.1818181818181819,1.0909090909090908,4
333,Optimal Randomized First-Order Methods for Least-Squares Problems,8,Optimal Randomized First-Order Methods for Least-Squares Problems,35,188,False,107,220,9,21,0,7,17,4,2,65,12650,1.6666666666666667,0.5238095238095238,10.476190476190476,0.8095238095238095,28
334,Optimization of Graph Neural Networks: Implicit Acceleration by Skip Connections and More Depth,8,Optimization of Graph Neural Networks Implicit Acceleration by Skip Connections and More Depth,72,154,False,88,258,56,40,3,10,13,13,2,94,19219,1.8,1.45,6.45,0.325,57
335,Out-of-Distribution Generalization via Risk Extrapolation (REx),8,Out-of-Distribution Generalization via Risk Extrapolation REx,96,184,False,190,51,66,29,5,14,22,6,18,63,15665,3.310344827586207,2.896551724137931,1.7586206896551724,0.7586206896551724,687
336,PAGE-PG: A Simple and Loopless Variance-Reduced Policy Gradient Method with Probabilistic Gradient Estimation,8,PAGE-PG A Simple and Loopless Variance-Reduced Policy Gradient Method with Probabilistic Gradient Estimation,33,142,True,60,120,6,17,0,11,3,0,6,108,11127,1.9411764705882353,0.7058823529411765,7.0588235294117645,0.17647058823529413,12
337,Paging with Succinct Predictions,8,Paging with Succinct Predictions,49,0,False,52,28,0,18,16,5,5,0,0,32,11399,2.7222222222222223,0.0,1.5555555555555556,0.2777777777777778,4
338,Partially Linear Additive Gaussian Graphical Models,8,Partially Linear Additive Gaussian Graphical Models,70,118,False,131,184,34,21,1,13,16,6,0,51,11092,3.3333333333333335,1.619047619047619,8.761904761904763,0.7619047619047619,14
339,Personalized Federated Learning using Hypernetworks,8,Personalized Federated Learning using Hypernetworks,64,156,False,85,18,23,14,6,10,18,3,8,51,9333,4.571428571428571,2.2142857142857144,1.2857142857142858,1.2857142857142858,215
340,Plug-In Inversion: Model-Agnostic Inversion for Vision with Data Augmentations,8,Plug-In Inversion Model-Agnostic Inversion for Vision with Data Augmentations,49,122,False,266,4,803,26,6,23,31,0,2,77,8083,1.8846153846153846,30.96153846153846,0.15384615384615385,1.1923076923076923,10
341,PopSkipJump: Decision-Based Attack for Probabilistic Classifiers,8,PopSkipJump Decision-Based Attack for Probabilistic Classifiers,26,138,False,77,35,53,24,24,10,11,2,6,63,13488,1.0833333333333333,2.4583333333333335,1.4583333333333333,0.4583333333333333,2
342,Predictive Multiplicity in Classification,8,Predictive Multiplicity in Classification,70,110,False,56,24,28,16,25,9,7,0,6,41,7691,4.375,2.125,1.5,0.4375,93
343,Privacy for Free: How does Dataset Condensation Help Privacy?,8,Privacy for Free How does Dataset Condensation Help Privacy,46,189,False,80,122,30,19,0,12,17,0,10,59,12484,2.4210526315789473,2.1052631578947367,6.421052631578948,0.8947368421052632,72
345,Proper Network Interpretability Helps Adversarial Robustness in Classification,8,Proper Network Interpretability Helps Adversarial Robustness in Classification,40,127,False,142,34,154,22,18,17,3,0,20,78,10551,1.8181818181818181,7.909090909090909,1.5454545454545454,0.13636363636363635,54
346,Provably Efficient Algorithms for Multi-Objective Competitive RL,8,Provably Efficient Algorithms for Multi-Objective Competitive RL,38,149,True,124,138,10,30,9,12,5,0,4,64,12913,1.2666666666666666,0.4666666666666667,4.6,0.16666666666666666,18
347,Pure Exploration and Regret Minimization in Matching Bandits,8,Pure Exploration and Regret Minimization in Matching Bandits,23,71,False,36,462,38,49,30,30,56,18,4,60,23200,0.46938775510204084,0.8571428571428571,9.428571428571429,1.1428571428571428,5
348,RRL: Resnet as representation for Reinforcement Learning,8,RRL Resnet as representation for Reinforcement Learning,67,183,True,99,20,78,16,0,17,41,4,4,55,9935,4.1875,5.125,1.25,2.5625,86
349,Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning,8,Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning,53,165,False,119,22,23,14,0,12,7,0,4,75,10243,3.7857142857142856,1.9285714285714286,1.5714285714285714,0.5,44
350,Recovering AES Keys with a Deep Cold Boot Attack,8,Recovering AES Keys with a Deep Cold Boot Attack,49,148,True,116,90,18,12,0,13,25,0,8,48,8097,4.083333333333333,2.1666666666666665,7.5,2.0833333333333335,1
351,Regret and Cumulative Constraint Violation Analysis for Online Convex Optimization with Long Term Constraints,8,Regret and Cumulative Constraint Violation Analysis for Online Convex Optimization with Long Term Constraints,44,171,False,133,197,12,16,0,12,6,0,6,109,9743,2.75,1.125,12.3125,0.375,33
352,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,8,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,57,153,False,438,23,23,20,0,11,10,0,32,96,14533,2.85,2.75,1.15,0.5,1314
353,Responsive Safety in Reinforcement Learning by PID Lagrangian Methods,8,Responsive Safety in Reinforcement Learning by PID Lagrangian Methods,40,157,True,66,88,61,22,0,13,17,3,2,69,10260,1.8181818181818181,2.8636363636363638,4.0,0.7727272727272727,184
354,Revisiting Label Smoothing and Knowledge Distillation Compatibility: What was Missing?,8,Revisiting Label Smoothing and Knowledge Distillation Compatibility What was Missing,58,153,False,291,2,43,27,0,21,5,0,50,84,18177,2.1481481481481484,3.4444444444444446,0.07407407407407407,0.18518518518518517,29
355,Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning,8,Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning,61,171,False,117,470,6,55,23,14,24,3,2,69,25551,1.1090909090909091,0.14545454545454545,8.545454545454545,0.43636363636363634,40
356,Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile,8,Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile,62,207,False,71,114,24,17,0,15,7,0,8,74,10928,3.6470588235294117,1.8823529411764706,6.705882352941177,0.4117647058823529,4
357,Robustly Disentangled Causal Mechanisms: Validating Deep Representations for Interventional Robustness,8,Robustly Disentangled Causal Mechanisms Validating Deep Representations for Interventional Robustness,33,113,False,162,45,50,24,3,14,8,2,2,101,11208,1.375,2.1666666666666665,1.875,0.3333333333333333,138
358,SGD: General Analysis and Improved Rates,8,SGD General Analysis and Improved Rates,49,202,True,72,203,27,23,5,18,21,0,2,39,12346,2.130434782608696,1.2608695652173914,8.826086956521738,0.9130434782608695,300
359,Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences,8,Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences,86,175,False,256,48,12,24,6,40,52,0,124,75,16945,3.5833333333333335,5.666666666666667,2.0,2.1666666666666665,84
360,Scalable Certified Segmentation via Randomized Smoothing,8,Scalable Certified Segmentation via Randomized Smoothing,72,1,False,153,65,48,19,13,10,14,0,16,56,12111,3.789473684210526,3.3684210526315788,3.4210526315789473,0.7368421052631579,30
362,Secure Distributed Training at Scale,8,Secure Distributed Training at Scale,114,160,False,318,422,34,61,15,14,23,10,8,36,36174,1.8688524590163935,0.6885245901639344,6.918032786885246,0.3770491803278688,13
363,Self-Supervised Exploration via Disagreement,8,Self-Supervised Exploration via Disagreement,47,174,False,61,4,23,10,10,6,7,0,0,44,7219,4.7,2.3,0.4,0.7,326
366,Simultaneously Learning Stochastic and Adversarial Bandits with General Graph Feedback,8,Simultaneously Learning Stochastic and Adversarial Bandits with General Graph Feedback,25,205,False,76,74,0,10,4,8,6,0,2,86,7603,2.5,0.2,7.4,0.6,5
367,"Smooth p-Wasserstein Distance: Structure, Empirical Approximation, and Statistical Applications",8,Smooth p-Wasserstein Distance Structure Empirical Approximation and Statistical Applications,73,175,False,105,205,16,23,5,17,23,0,0,94,16700,3.1739130434782608,0.6956521739130435,8.91304347826087,1.0,21
368,Sparse Double Descent: Where Network Pruning Aggravates Overfitting,8,Sparse Double Descent Where Network Pruning Aggravates Overfitting,88,186,False,140,0,222,25,0,8,18,0,2,66,12957,3.52,8.96,0.0,0.72,22
369,Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks,8,Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks,59,141,False,63,282,37,22,0,20,19,0,0,80,14142,2.6818181818181817,1.6818181818181819,12.818181818181818,0.8636363636363636,162
370,State Space Expectation Propagation: Efficient Inference Schemes for Temporal Gaussian Processes,8,State Space Expectation Propagation Efficient Inference Schemes for Temporal Gaussian Processes,54,116,False,117,151,15,19,16,16,18,0,4,95,12147,2.8421052631578947,1.0,7.947368421052632,0.9473684210526315,11
371,Stochastic Differential Equations with Variational Wishart Diffusions,8,Stochastic Differential Equations with Variational Wishart Diffusions,36,102,False,63,70,12,11,3,6,10,2,4,69,7174,3.272727272727273,1.4545454545454546,6.363636363636363,0.9090909090909091,7
372,Stochastic Video Generation with a Learned Prior,8,Stochastic Video Generation with a Learned Prior,43,115,False,88,16,40,12,0,8,5,0,0,48,6931,3.5833333333333335,3.3333333333333335,1.3333333333333333,0.4166666666666667,473
373,Strength from Weakness: Fast Learning Using Weak Supervision,8,Strength from Weakness Fast Learning Using Weak Supervision,71,130,False,64,76,16,21,17,9,6,0,0,59,12068,3.380952380952381,0.7619047619047619,3.619047619047619,0.2857142857142857,29
374,Sub-Goal Trees - a Framework for Goal-Based Reinforcement Learning,8,Sub-Goal Trees - a Framework for Goal-Based Reinforcement Learning,52,1,False,101,106,33,29,1,13,14,0,8,66,15101,1.793103448275862,1.4137931034482758,3.6551724137931036,0.4827586206896552,28
375,Supervised Off-Policy Ranking,8,Supervised Off-Policy Ranking,50,237,False,20,10,107,17,8,6,12,0,12,29,8310,2.9411764705882355,7.0,0.5882352941176471,0.7058823529411765,4
376,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,8,TAPAS Tricks to Accelerate encrypted Prediction As a Service,43,149,True,79,4,9,14,10,7,12,4,6,60,7174,3.0714285714285716,1.0714285714285714,0.2857142857142857,0.8571428571428571,104
377,Tell me why! Explanations support learning relational and causal structure,8,Tell me why Explanations support learning relational and causal structure,87,161,False,222,1,55,23,4,9,15,2,4,74,14064,3.782608695652174,2.5652173913043477,0.043478260869565216,0.6521739130434783,32
378,Testing Group Fairness via Optimal Transport Projections,8,Testing Group Fairness via Optimal Transport Projections,43,148,False,92,238,11,24,2,11,15,1,8,56,12890,1.7916666666666667,0.7916666666666666,9.916666666666666,0.625,23
379,The Geometry of Robust Value Functions,8,The Geometry of Robust Value Functions,26,187,False,37,290,36,24,0,11,9,0,0,38,10589,1.0833333333333333,1.5,12.083333333333334,0.375,5
380,The Numerical Stability of Hyperbolic Representation Learning,8,The Numerical Stability of Hyperbolic Representation Learning,40,154,False,116,92,73,25,13,10,19,2,10,61,13047,1.6,3.32,3.68,0.76,7
381,The continuous categorical: a novel simplex-valued exponential family,8,The continuous categorical a novel simplex-valued exponential family,66,182,False,61,82,28,21,0,10,18,7,4,68,11863,3.142857142857143,1.5238095238095237,3.9047619047619047,0.8571428571428571,17
382,Thresholded LASSO Bandit,8,Thresholded LASSO Bandit,34,186,True,312,724,186,51,22,32,54,22,8,24,24207,0.6666666666666666,3.803921568627451,14.196078431372548,1.0588235294117647,14
383,Topological Singularity Detection at Multiple Scales,8,Topological Singularity Detection at Multiple Scales,40,165,False,82,14,121,23,14,9,16,0,2,52,12362,1.7391304347826086,5.3478260869565215,0.6086956521739131,0.6956521739130435,4
386,Training data-efficient image transformers & distillation through attention,8,Training data-efficient image transformers  distillation through attention,66,133,False,117,9,10,22,23,7,5,0,22,75,8399,3.0,1.4545454545454546,0.4090909090909091,0.22727272727272727,4706
387,Tropical Geometry of Deep Neural Networks,8,Tropical Geometry of Deep Neural Networks,28,120,False,55,106,11,18,0,12,13,0,0,41,12363,1.5555555555555556,0.6111111111111112,5.888888888888889,0.7222222222222222,114
389,Understanding and correcting pathologies in the training of learned optimizers,8,Understanding and correcting pathologies in the training of learned optimizers,49,158,False,73,12,62,20,0,15,13,1,0,78,10058,2.45,3.1,0.6,0.65,131
390,Universal Equivariant Multilayer Perceptrons,8,Universal Equivariant Multilayer Perceptrons,50,131,False,47,60,6,11,2,6,10,1,4,44,8096,4.545454545454546,0.9090909090909091,5.454545454545454,0.9090909090909091,38
391,Unsupervised Speech Decomposition via Triple Information Bottleneck,8,Unsupervised Speech Decomposition via Triple Information Bottleneck,38,1,False,41,22,6,16,0,5,5,0,2,67,10762,2.375,0.5,1.375,0.3125,149
392,Value Function Based Difference-of-Convex Algorithm for Bilevel Hyperparameter Selection Problems,8,Value Function Based Difference-of-Convex Algorithm for Bilevel Hyperparameter Selection Problems,45,110,False,122,212,6,19,4,11,18,10,18,97,14956,2.3684210526315788,1.263157894736842,11.157894736842104,0.9473684210526315,18
393,Variational Open-Domain Question Answering,8,Variational Open-Domain Question Answering,73,116,False,81,32,15,28,26,21,22,4,16,42,17499,2.607142857142857,1.1071428571428572,1.1428571428571428,0.7857142857142857,5
394,Wasserstein Adversarial Examples via Projected Sinkhorn Iterations,8,Wasserstein Adversarial Examples via Projected Sinkhorn Iterations,34,191,False,67,104,72,14,21,10,14,0,2,66,9101,2.4285714285714284,5.285714285714286,7.428571428571429,1.0,193
395,When AUC meets DRO: Optimizing Partial AUC for Deep Learning with Non-Convex Convergence Guarantee,8,When AUC meets DRO Optimizing Partial AUC for Deep Learning with Non-Convex Convergence Guarantee,44,143,True,76,220,47,25,0,12,14,0,10,97,16074,1.76,2.28,8.8,0.56,18
396,"""Why did the Model Fail?"": Attributing Model Performance Changes to Distribution Shifts",8,Why did the Model Fail Attributing Model Performance Changes to Distribution Shifts,77,193,False,248,108,178,29,40,23,28,0,36,83,14374,2.6551724137931036,7.379310344827586,3.7241379310344827,0.9655172413793104,10
397,Zero-Shot Knowledge Distillation in Deep Networks,8,Zero-Shot Knowledge Distillation in Deep Networks,28,163,False,39,8,28,17,0,12,12,0,14,49,9548,1.6470588235294117,2.4705882352941178,0.47058823529411764,0.7058823529411765,207
398,1-bit Adam: Communication Efficient Large-Scale Training with Adam's Convergence Speed,8,1-bit Adam Communication Efficient Large-Scale Training with Adams Convergence Speed,44,223,False,100,363,60,21,22,27,20,0,6,85,11029,2.0952380952380953,3.142857142857143,17.285714285714285,0.9523809523809523,60
399,A Differentiable Point Process with Its Application to Spiking Neural Networks,8,A Differentiable Point Process with Its Application to Spiking Neural Networks,24,130,False,67,66,15,14,0,12,11,6,2,78,10580,1.7142857142857142,1.2142857142857142,4.714285714285714,0.7857142857142857,4
402,A Sample Complexity Separation between Non-Convex and Convex Meta-Learning,8,A Sample Complexity Separation between Non-Convex and Convex Meta-Learning,34,197,False,87,215,4,34,15,12,18,0,0,74,15963,1.0,0.11764705882352941,6.323529411764706,0.5294117647058824,25
403,A Tale of Two Efficient and Informative Negative Sampling Distributions,8,A Tale of Two Efficient and Informative Negative Sampling Distributions,36,188,False,60,2,23,13,3,8,12,0,14,71,9123,2.769230769230769,2.8461538461538463,0.15384615384615385,0.9230769230769231,9
404,A hybrid variance-reduced method for decentralized stochastic non-convex optimization,8,A hybrid variance-reduced method for decentralized stochastic non-convex optimization,54,171,False,58,146,10,21,0,14,17,0,4,85,12933,2.5714285714285716,0.6666666666666666,6.9523809523809526,0.8095238095238095,34
406,Acceleration via Fractal Learning Rate Schedules,8,Acceleration via Fractal Learning Rate Schedules,95,1,False,148,182,48,45,20,15,41,0,0,48,20621,2.111111111111111,1.0666666666666667,4.044444444444444,0.9111111111111111,16
408,Adaptive Conformal Predictions for Time Series,8,Adaptive Conformal Predictions for Time Series,45,137,False,100,146,55,29,2,13,26,4,4,46,17434,1.5517241379310345,2.0344827586206895,5.0344827586206895,0.896551724137931,68
409,Adaptive stochastic gradient algorithms on Riemannian manifolds,8,Adaptive stochastic gradient algorithms on Riemannian manifolds,58,172,False,174,130,144,39,0,12,19,0,0,63,14783,1.4871794871794872,3.6923076923076925,3.3333333333333335,0.48717948717948717,3
410,Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks,8,Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks,47,247,False,73,341,7,34,3,13,16,0,0,73,17608,1.3823529411764706,0.20588235294117646,10.029411764705882,0.47058823529411764,46
411,Adversarial robustness guarantees for random deep neural networks,8,Adversarial robustness guarantees for random deep neural networks,93,160,False,116,368,60,25,0,24,28,0,8,65,13643,3.72,2.72,14.72,1.12,8
412,Almost surely constrained convex optimization,8,Almost surely constrained convex optimization,42,112,False,56,160,15,20,0,7,7,0,0,45,9638,2.1,0.75,8.0,0.35,25
413,An Explicitly Relational Neural Network Architecture,8,An Explicitly Relational Neural Network Architecture,36,111,False,30,8,73,25,0,13,2,0,6,52,12760,1.44,3.16,0.32,0.08,59
414,Analysis of stochastic Lanczos quadrature for spectrum approximation,8,Analysis of stochastic Lanczos quadrature for spectrum approximation,60,196,False,80,198,49,21,0,10,11,0,0,68,11771,2.857142857142857,2.3333333333333335,9.428571428571429,0.5238095238095238,13
415,Approximate Group Fairness for Clustering,8,Approximate Group Fairness for Clustering,46,163,False,42,33,37,20,6,10,10,0,4,41,13720,2.3,2.05,1.65,0.5,12
416,Asymmetric Loss Functions for Learning with Noisy Labels,8,Asymmetric Loss Functions for Learning with Noisy Labels,39,149,False,63,96,83,23,0,10,16,0,14,56,15395,1.6956521739130435,4.217391304347826,4.173913043478261,0.6956521739130435,40
417,AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning,8,AutoPrognosis Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning,40,182,False,46,26,12,10,0,5,9,3,4,110,7309,4.0,1.6,2.6,0.9,78
418,BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation,8,BLIP Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation,60,135,True,63,0,3,12,0,10,16,0,2,103,8191,5.0,0.4166666666666667,0.0,1.3333333333333333,1942
419,Bayesian Counterfactual Risk Minimization,8,Bayesian Counterfactual Risk Minimization,37,81,False,88,148,6,30,0,9,12,0,2,41,11212,1.2333333333333334,0.26666666666666666,4.933333333333334,0.4,26
421,Beyond Adaptive Submodularity: Approximation Guarantees of Greedy Policy with Adaptive Submodularity Ratio,8,Beyond Adaptive Submodularity Approximation Guarantees of Greedy Policy with Adaptive Submodularity Ratio,25,126,False,109,177,14,22,19,17,14,0,4,105,13426,1.1363636363636365,0.8181818181818182,8.045454545454545,0.6363636363636364,24
422,Bio-Inspired Hashing for Unsupervised Similarity Search,8,Bio-Inspired Hashing for Unsupervised Similarity Search,61,188,False,94,48,21,17,0,13,8,0,26,55,11965,3.588235294117647,2.764705882352941,2.823529411764706,0.47058823529411764,19
423,Boosting Graph Structure Learning with Dummy Nodes,8,Boosting Graph Structure Learning with Dummy Nodes,45,161,False,12,0,3,13,0,7,12,4,2,50,9718,3.4615384615384617,0.38461538461538464,0.0,0.9230769230769231,14
424,Breaking the Deadly Triad with a Target Network,8,Breaking the Deadly Triad with a Target Network,65,128,False,162,346,9,31,0,13,9,0,4,47,16554,2.096774193548387,0.41935483870967744,11.161290322580646,0.2903225806451613,33
425,CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods,8,CAUSE Learning Granger Causality from Event Sequences using Attribution Methods,41,1,True,118,73,23,18,5,5,10,2,4,79,11649,2.2777777777777777,1.5,4.055555555555555,0.5555555555555556,37
426,"Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?",8,Can Autonomous Vehicles Identify Recover From and Adapt to Distribution Shifts,74,170,False,217,20,62,17,0,13,5,8,8,80,8883,4.352941176470588,4.117647058823529,1.1764705882352942,0.29411764705882354,140
428,Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks,8,Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks,47,188,False,90,28,29,13,4,10,8,0,4,95,8369,3.6153846153846154,2.5384615384615383,2.1538461538461537,0.6153846153846154,39
430,Combinatorial Pure Exploration of Dueling Bandit,8,Combinatorial Pure Exploration of Dueling Bandit,43,216,False,69,163,6,36,13,10,20,0,0,48,19717,1.1944444444444444,0.16666666666666666,4.527777777777778,0.5555555555555556,8
431,Complexity of Linear Regions in Deep Networks,8,Complexity of Linear Regions in Deep Networks,26,223,False,52,163,29,16,0,11,8,0,0,45,11384,1.625,1.8125,10.1875,0.5,195
433,Connecting Interpretability and Robustness in Decision Trees through Separation,8,Connecting Interpretability and Robustness in Decision Trees through Separation,68,170,False,78,16,39,22,18,11,15,2,8,79,13910,3.090909090909091,2.1363636363636362,0.7272727272727273,0.6818181818181818,15
434,Constraining the Dynamics of Deep Probabilistic Models,8,Constraining the Dynamics of Deep Probabilistic Models,46,1,False,135,22,37,13,0,9,8,5,2,54,8052,3.5384615384615383,3.0,1.6923076923076923,0.6153846153846154,27
435,Continuous Graph Neural Networks,8,Continuous Graph Neural Networks,46,175,False,64,100,11,15,0,12,7,1,18,32,8539,3.066666666666667,1.9333333333333333,6.666666666666667,0.4666666666666667,112
436,Convergence guarantees for a class of non-convex and non-smooth optimization problems,8,Convergence guarantees for a class of non-convex and non-smooth optimization problems,43,167,False,63,266,13,50,62,13,29,8,2,85,21941,0.86,0.3,5.32,0.58,69
437,Coordinated Exploration in Concurrent Reinforcement Learning,8,Coordinated Exploration in Concurrent Reinforcement Learning,21,91,False,26,0,16,18,0,5,5,5,0,60,7382,1.1666666666666667,0.8888888888888888,0.0,0.2777777777777778,36
438,Cross-Domain 3D Equivariant Image Embeddings,8,Cross-Domain 3D Equivariant Image Embeddings,57,150,False,104,14,30,15,2,9,15,5,12,44,8669,3.8,2.8,0.9333333333333333,1.0,22
439,DAG-GNN: DAG Structure Learning with Graph Neural Networks,8,DAG-GNN DAG Structure Learning with Graph Neural Networks,54,203,True,107,38,24,12,0,7,11,3,8,57,7286,4.5,2.6666666666666665,3.1666666666666665,0.9166666666666666,357
440,Data Augmentation as Feature Manipulation: a story of desert cows and grass cows,8,Data Augmentation as Feature Manipulation a story of desert cows and grass cows,28,155,False,37,182,24,38,10,13,13,0,0,79,21735,0.7368421052631579,0.631578947368421,4.7894736842105265,0.34210526315789475,16
441,Dataset Condensation with Differentiable Siamese Augmentation,8,Dataset Condensation with Differentiable Siamese Augmentation,62,109,False,81,11,18,12,17,5,11,0,14,61,8742,5.166666666666667,2.6666666666666665,0.9166666666666666,0.9166666666666666,170
442,Decoupled Parallel Backpropagation with Convergence Guarantee,8,Decoupled Parallel Backpropagation with Convergence Guarantee,25,178,False,22,52,49,12,0,10,8,0,6,61,6937,2.0833333333333335,4.583333333333333,4.333333333333333,0.6666666666666666,87
444,DeepReDuce: ReLU Reduction for Fast Private Inference,8,DeepReDuce ReLU Reduction for Fast Private Inference,42,141,False,55,2,0,14,0,13,13,0,0,52,9481,3.0,0.0,0.14285714285714285,0.9285714285714286,71
446,Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution,8,Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution,46,136,False,115,20,17,11,0,6,8,0,8,80,7726,4.181818181818182,2.272727272727273,1.8181818181818181,0.7272727272727273,20
448,Directional Graph Networks,8,Directional Graph Networks,55,156,False,75,99,24,23,5,8,32,0,2,26,14065,2.391304347826087,1.1304347826086956,4.304347826086956,1.391304347826087,144
449,Disentangled Generative Models for Robust Prediction of System Dynamics,8,Disentangled Generative Models for Robust Prediction of System Dynamics,46,84,False,111,22,91,27,0,16,28,0,22,71,13155,1.7037037037037037,4.185185185185185,0.8148148148148148,1.037037037037037,4
450,Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning,8,Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning,45,184,False,174,208,24,25,0,14,12,3,0,91,13607,1.8,0.96,8.32,0.48,6
451,Does label smoothing mitigate label noise?,8,Does label smoothing mitigate label noise,46,1,False,95,26,44,18,0,9,13,0,14,41,8008,2.5555555555555554,3.2222222222222223,1.4444444444444444,0.7222222222222222,284
452,Dropout: Explicit Forms and Capacity Control,8,Dropout Explicit Forms and Capacity Control,56,102,False,124,112,40,26,2,11,10,0,2,43,13099,2.1538461538461537,1.6153846153846154,4.3076923076923075,0.38461538461538464,30
453,Efficient Amortised Bayesian Inference for Hierarchical and Nonlinear Dynamical Systems,8,Efficient Amortised Bayesian Inference for Hierarchical and Nonlinear Dynamical Systems,51,178,False,71,37,55,25,11,12,13,0,4,87,11332,2.04,2.36,1.48,0.52,21
454,Efficient Online ML API Selection for Multi-Label Classification Tasks,8,Efficient Online ML API Selection for Multi-Label Classification Tasks,63,178,True,90,372,38,31,24,10,9,0,18,70,17416,2.032258064516129,1.8064516129032258,12.0,0.2903225806451613,10
455,EfficientNetV2: Smaller Models and Faster Training,8,EfficientNetV2 Smaller Models and Faster Training,50,148,False,117,2,20,11,19,8,11,0,26,49,7878,4.545454545454546,4.181818181818182,0.18181818181818182,1.0,1584
456,Enhanced POET: Open-Ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions,8,Enhanced POET Open-Ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions,78,296,True,70,0,45,23,0,9,10,7,8,118,12820,3.391304347826087,2.3043478260869565,0.0,0.43478260869565216,95
457,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,8,Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization,21,97,True,25,108,0,12,0,11,6,0,0,92,7235,1.75,0.0,9.0,0.5,211
458,Estimation in Rotationally Invariant Generalized Linear Models via Approximate Message Passing,8,Estimation in Rotationally Invariant Generalized Linear Models via Approximate Message Passing,67,141,False,60,221,33,35,26,11,4,0,0,94,16304,1.9142857142857144,0.9428571428571428,6.314285714285714,0.11428571428571428,23
459,Explainable and Discourse Topic-aware Neural Language Understanding,8,Explainable and Discourse Topic-aware Neural Language Understanding,21,161,False,52,24,9,13,0,12,11,0,24,67,9111,1.6153846153846154,2.5384615384615383,1.8461538461538463,0.8461538461538461,7
460,Exponential Reduction in Sample Complexity with Learning of Ising Model Dynamics,8,Exponential Reduction in Sample Complexity with Learning of Ising Model Dynamics,61,120,False,73,162,34,29,2,12,17,6,2,80,16147,2.103448275862069,1.2413793103448276,5.586206896551724,0.5862068965517241,3
462,Fast Decoding in Sequence Models using Discrete Latent Variables,8,Fast Decoding in Sequence Models using Discrete Latent Variables,51,168,False,79,32,12,10,6,7,4,2,8,64,7203,5.1,2.0,3.2,0.4,209
463,Fast and Private Submodular and k-Submodular Functions Maximization with Matroid Constraints,8,Fast and Private Submodular and k-Submodular Functions Maximization with Matroid Constraints,38,159,False,85,115,0,21,0,10,16,2,0,92,11470,1.8095238095238095,0.0,5.476190476190476,0.7619047619047619,27
464,Feature Space Particle Inference for Neural Network Ensembles,8,Feature Space Particle Inference for Neural Network Ensembles,70,136,False,154,32,18,17,0,14,12,1,28,61,9509,4.117647058823529,2.7058823529411766,1.8823529411764706,0.7058823529411765,9
465,Fenrir: Physics-Enhanced Regression for Initial Value Problems,8,Fenrir Physics-Enhanced Regression for Initial Value Problems,71,108,False,179,154,30,19,17,10,24,0,0,61,10225,3.736842105263158,1.5789473684210527,8.105263157894736,1.263157894736842,6
466,Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent,8,Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent,61,201,False,199,295,0,34,0,15,14,0,0,85,18205,1.7941176470588236,0.0,8.676470588235293,0.4117647058823529,97
467,Flow Models for Arbitrary Conditional Likelihoods,8,Flow Models for Arbitrary Conditional Likelihoods,36,214,False,48,40,66,19,9,12,18,5,10,49,9313,1.894736842105263,4.0,2.1052631578947367,0.9473684210526315,34
468,FriendlyCore: Practical Differentially Private Aggregation,8,FriendlyCore Practical Differentially Private Aggregation,45,141,False,108,87,35,54,7,12,25,23,0,57,26822,0.8333333333333334,0.6481481481481481,1.6111111111111112,0.46296296296296297,23
469,Function-space Inference with Sparse Implicit Processes,8,Function-space Inference with Sparse Implicit Processes,39,203,False,174,76,49,18,0,20,13,2,6,55,15863,2.1666666666666665,3.0555555555555554,4.222222222222222,0.7222222222222222,9
471,Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients,8,Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients,111,178,False,80,96,40,29,0,16,11,0,6,103,17083,3.8275862068965516,1.5862068965517242,3.310344827586207,0.3793103448275862,10
472,Generalized Leverage Scores: Geometric Interpretation and Applications,8,Generalized Leverage Scores Geometric Interpretation and Applications,33,170,False,57,55,14,15,0,12,5,0,0,69,9457,2.2,0.9333333333333333,3.6666666666666665,0.3333333333333333,2
473,Generative Coarse-Graining of Molecular Conformations,8,Generative Coarse-Graining of Molecular Conformations,73,240,False,251,166,67,24,0,29,56,9,26,53,13953,3.0416666666666665,3.875,6.916666666666667,2.3333333333333335,23
474,Geometry of the Loss Landscape in Overparameterized Neural Networks: Symmetries and Invariances,8,Geometry of the Loss Landscape in Overparameterized Neural Networks Symmetries and Invariances,38,213,False,58,198,47,29,0,11,16,0,0,94,19370,1.3103448275862069,1.6206896551724137,6.827586206896552,0.5517241379310345,57
475,Gradient Based Clustering,8,Gradient Based Clustering,37,166,False,77,210,18,12,0,7,2,0,0,25,10313,3.0833333333333335,1.5,17.5,0.16666666666666666,6
476,Graph Resistance and Learning from Pairwise Comparisons,8,Graph Resistance and Learning from Pairwise Comparisons,35,169,False,47,124,11,15,0,8,7,0,2,55,9808,2.3333333333333335,0.8666666666666667,8.266666666666667,0.4666666666666667,9
477,Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings,8,Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings,42,0,False,180,331,31,52,4,14,18,0,10,74,22195,0.8076923076923077,0.7884615384615384,6.365384615384615,0.34615384615384615,6
478,HexaGAN: Generative Adversarial Nets for Real World Classification,8,HexaGAN Generative Adversarial Nets for Real World Classification,45,142,False,45,32,28,17,0,8,18,9,14,65,9097,2.6470588235294117,2.4705882352941178,1.8823529411764706,1.0588235294117647,35
481,Hyperparameter Selection for Imitation Learning,8,Hyperparameter Selection for Imitation Learning,57,138,False,90,0,38,16,0,8,14,0,8,47,9671,3.5625,2.875,0.0,0.875,12
482,Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation,8,Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation,65,143,False,72,36,32,15,3,10,12,8,8,78,9627,4.333333333333333,2.6666666666666665,2.4,0.8,92
483,Improved Confidence Bounds for the Linear Logistic Model and Applications to Bandits,8,Improved Confidence Bounds for the Linear Logistic Model and Applications to Bandits,43,142,False,166,348,15,42,4,14,10,1,2,84,22819,1.0238095238095237,0.40476190476190477,8.285714285714286,0.23809523809523808,14
484,Improving Expert Predictions with Conformal Prediction,8,Improving Expert Predictions with Conformal Prediction,55,1,False,79,70,34,26,0,17,3,0,6,54,12468,2.1153846153846154,1.5384615384615385,2.6923076923076925,0.11538461538461539,9
485,Improving Transformers with Probabilistic Attention Keys,8,Improving Transformers with Probabilistic Attention Keys,110,195,False,4,38,0,27,0,10,4,1,0,56,16602,4.074074074074074,0.0,1.4074074074074074,0.14814814814814814,21
486,Inductive Bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters,8,Inductive Bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters,75,150,False,78,10,41,17,0,10,9,0,10,94,13363,4.411764705882353,3.0,0.5882352941176471,0.5294117647058824,8
487,Informative Dropout for Robust Representation Learning: A Shape-bias Perspective,8,Informative Dropout for Robust Representation Learning A Shape-bias Perspective,76,175,False,148,10,21,18,0,8,20,13,26,79,11012,4.222222222222222,2.611111111111111,0.5555555555555556,1.1111111111111112,94
488,Interferometric Graph Transform: a Deep Unsupervised Graph Representation,8,Interferometric Graph Transform a Deep Unsupervised Graph Representation,63,144,False,98,53,12,12,1,7,6,8,10,72,7803,5.25,1.8333333333333333,4.416666666666667,0.5,5
489,Intrinsic Reward Driven Imitation Learning via Generative Model,8,Intrinsic Reward Driven Imitation Learning via Generative Model,42,133,False,64,17,41,15,0,7,5,11,22,63,8976,2.8,4.2,1.1333333333333333,0.3333333333333333,39
490,Is Space-Time Attention All You Need for Video Understanding?,8,Is Space-Time Attention All You Need for Video Understanding,73,147,False,87,16,24,13,0,7,8,0,16,60,10500,5.615384615384615,3.076923076923077,1.2307692307692308,0.6153846153846154,1366
491,KO codes: inventing nonlinear encoding and decoding for reliable wireless communication via deep-learning,8,KO codes inventing nonlinear encoding and decoding for reliable wireless communication via deep-learning,65,222,True,50,24,64,21,1,18,15,4,4,104,13096,3.0952380952380953,3.238095238095238,1.1428571428571428,0.7142857142857143,27
492,LEAPSANDBOUNDS: A Method for Approximately Optimal Algorithm Configuration,8,LEAPSANDBOUNDS A Method for Approximately Optimal Algorithm Configuration,20,156,True,37,16,14,11,0,17,5,0,0,73,8242,1.8181818181818181,1.2727272727272727,1.4545454545454546,0.45454545454545453,33
493,Laplacian Regularized Few-Shot Learning,8,Laplacian Regularized Few-Shot Learning,52,171,False,95,26,6,11,0,4,9,0,10,39,8117,4.7272727272727275,1.4545454545454546,2.3636363636363638,0.8181818181818182,132
494,Lazy Estimation of Variable Importance for Large Neural Networks,8,Lazy Estimation of Variable Importance for Large Neural Networks,43,227,False,48,130,36,25,0,10,22,6,4,64,11655,1.72,1.6,5.2,0.88,3
495,Learning Compact Neural Networks with Regularization,8,Learning Compact Neural Networks with Regularization,69,115,False,72,342,17,46,2,14,19,6,2,52,22312,1.5,0.41304347826086957,7.434782608695652,0.41304347826086957,40
496,Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations,8,Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations,56,232,False,135,81,15,23,13,10,18,0,8,77,11771,2.4347826086956523,1.0,3.5217391304347827,0.782608695652174,78
497,Learning Long Term Dependencies via Fourier Recurrent Units,8,Learning Long Term Dependencies via Fourier Recurrent Units,28,1,False,37,158,42,32,12,14,7,0,6,59,10503,0.875,1.5,4.9375,0.21875,37
498,Learning Quadratic Games on Networks,8,Learning Quadratic Games on Networks,57,252,False,63,22,33,15,0,9,14,0,4,36,8968,3.8,2.466666666666667,1.4666666666666666,0.9333333333333333,13
499,Learning What to Defer for Maximum Independent Sets,8,Learning What to Defer for Maximum Independent Sets,71,166,False,186,16,0,16,0,9,13,0,0,51,9448,4.4375,0.0,1.0,0.8125,42
500,Learning in Nonzero-Sum Stochastic Games with Potentials,8,Learning in Nonzero-Sum Stochastic Games with Potentials,65,161,False,99,249,25,33,0,17,11,2,0,56,18086,1.9696969696969697,0.7575757575757576,7.545454545454546,0.3333333333333333,38
501,Learning to Infer Structures of Network Games,8,Learning to Infer Structures of Network Games,45,148,False,96,34,32,19,15,12,9,0,8,45,11296,2.3684210526315788,2.1052631578947367,1.7894736842105263,0.47368421052631576,5
502,Learning to simulate and design for structural engineering,8,Learning to simulate and design for structural engineering,49,156,False,34,25,36,17,0,13,19,9,22,58,8887,2.8823529411764706,3.411764705882353,1.4705882352941178,1.1176470588235294,24
503,Leveraging Procedural Generation to Benchmark Reinforcement Learning,8,Leveraging Procedural Generation to Benchmark Reinforcement Learning,30,97,False,61,0,56,19,0,16,24,0,4,68,9175,1.5789473684210527,3.1578947368421053,0.0,1.263157894736842,435
504,Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and Costs,8,Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and Costs,49,192,False,0,0,0,19,0,6,4,0,0,75,11411,2.5789473684210527,0.0,0.0,0.21052631578947367,39
505,Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently,8,Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently,37,111,False,69,329,0,34,0,7,22,3,0,71,17182,1.088235294117647,0.0,9.676470588235293,0.6470588235294118,58
506,Lower-bounded proper losses for weakly supervised classification,8,Lower-bounded proper losses for weakly supervised classification,40,138,False,124,103,12,21,4,16,17,0,14,64,14955,1.9047619047619047,1.2380952380952381,4.904761904761905,0.8095238095238095,2
507,Machine Theory of Mind,8,Machine Theory of Mind,78,186,False,63,12,45,21,0,12,16,5,2,22,15521,3.7142857142857144,2.238095238095238,0.5714285714285714,0.7619047619047619,381
508,Matrix-Free Preconditioning in Online Learning,8,Matrix-Free Preconditioning in Online Learning,31,99,False,93,244,50,23,0,13,14,0,0,46,11202,1.3478260869565217,2.1739130434782608,10.608695652173912,0.6086956521739131,15
509,Megaverse: Simulating Embodied Agents at One Million Experiences per Second,8,Megaverse Simulating Embodied Agents at One Million Experiences per Second,44,119,False,69,6,41,18,0,4,7,1,14,74,8942,2.4444444444444446,3.0555555555555554,0.3333333333333333,0.3888888888888889,18
510,MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration,8,MetaCURE Meta Reinforcement Learning with Empowerment-Driven Exploration,38,132,False,122,26,48,14,0,13,9,0,6,72,7333,2.7142857142857144,3.857142857142857,1.8571428571428572,0.6428571428571429,22
513,Modeling Sparse Deviations for Compressed Sensing using Generative Models,8,Modeling Sparse Deviations for Compressed Sensing using Generative Models,49,195,False,73,49,31,16,0,10,6,0,0,73,10083,3.0625,1.9375,3.0625,0.375,72
514,More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models,8,More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models,61,152,False,68,157,20,30,3,14,6,0,0,92,13878,2.033333333333333,0.6666666666666666,5.233333333333333,0.2,58
515,Multi-Object Representation Learning with Iterative Variational Inference,8,Multi-Object Representation Learning with Iterative Variational Inference,44,134,False,106,20,260,28,38,24,40,4,4,73,10581,1.5714285714285714,9.428571428571429,0.7142857142857143,1.4285714285714286,427
516,Multiplicative Weights Updates as a distributed constrained optimization algorithm: Convergence to second-order stationary points almost always,8,Multiplicative Weights Updates as a distributed constrained optimization algorithm Convergence to second-order stationary points almost always,0,165,False,45,43,13,15,2,6,7,0,0,142,7480,0.0,0.8666666666666667,2.8666666666666667,0.4666666666666667,15
517,NeRF-VAE: A Geometry Aware 3D Scene Generative Model,8,NeRF-VAE A Geometry Aware 3D Scene Generative Model,54,158,True,101,22,37,17,15,11,16,5,2,51,11151,3.176470588235294,2.2941176470588234,1.2941176470588236,0.9411764705882353,112
518,Nested bandits,8,Nested bandits,30,1,False,73,264,47,35,3,10,16,0,0,14,16623,0.8571428571428571,1.3428571428571427,7.542857142857143,0.45714285714285713,0
520,NeuralEF: Deconstructing Kernels by Deep Neural Networks,8,NeuralEF Deconstructing Kernels by Deep Neural Networks,49,155,False,52,102,39,17,0,10,15,2,4,55,10461,2.8823529411764706,2.5294117647058822,6.0,0.8823529411764706,13
521,Non-Monotonic Sequential Text Generation,8,Non-Monotonic Sequential Text Generation,71,129,False,119,16,44,21,29,4,13,1,18,40,10142,3.380952380952381,2.9523809523809526,0.7619047619047619,0.6190476190476191,116
522,Nonparametric Sparse Tensor Factorization with Hierarchical Gamma Processes,8,Nonparametric Sparse Tensor Factorization with Hierarchical Gamma Processes,65,232,False,190,50,39,15,0,12,9,1,0,75,11023,4.333333333333333,2.6,3.3333333333333335,0.6,6
524,On Collective Robustness of Bagging Against Data Poisoning,8,On Collective Robustness of Bagging Against Data Poisoning,46,165,False,122,88,40,20,4,30,36,0,48,58,14191,2.3,4.4,4.4,1.8,18
526,On Reward-Free RL with Kernel and Neural Function Approximations: Single-Agent MDP and Markov Game,8,On Reward-Free RL with Kernel and Neural Function Approximations Single-Agent MDP and Markov Game,48,189,True,98,678,0,69,0,12,20,0,0,97,27520,0.6956521739130435,0.0,9.826086956521738,0.2898550724637681,19
527,On the Convergence of SARSA with Linear Function Approximation,8,On the Convergence of SARSA with Linear Function Approximation,42,185,True,214,390,9,34,3,12,12,0,2,62,15444,1.2352941176470589,0.3235294117647059,11.470588235294118,0.35294117647058826,3
528,On the Implicit Bias of Dropout,8,On the Implicit Bias of Dropout,28,80,False,57,110,23,17,3,12,3,0,0,31,11979,1.6470588235294117,1.3529411764705883,6.470588235294118,0.17647058823529413,61
529,On the Relationship between Data Efficiency and Error for Uncertainty Sampling,8,On the Relationship between Data Efficiency and Error for Uncertainty Sampling,19,2,False,57,68,33,22,0,13,37,12,2,78,9582,0.8636363636363636,1.5909090909090908,3.090909090909091,1.6818181818181819,29
530,"One for One, or All for All: Equilibria and Optimality of Collaboration in Federated Learning",8,One for One or All for All Equilibria and Optimality of Collaboration in Federated Learning,32,176,False,53,75,15,23,17,17,17,0,4,92,14543,1.391304347826087,0.8260869565217391,3.260869565217391,0.7391304347826086,32
531,Online Learning with Imperfect Hints,8,Online Learning with Imperfect Hints,42,172,False,71,238,0,17,4,11,6,0,0,36,11506,2.4705882352941178,0.0,14.0,0.35294117647058826,48
532,Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics,8,Opening the Blackbox Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics,54,260,False,77,36,18,11,0,8,9,4,8,106,7235,4.909090909090909,2.3636363636363638,3.272727272727273,0.8181818181818182,28
534,Optimization-Derived Learning with Essential Convergence Analysis of Training and Hyper-training,8,Optimization-Derived Learning with Essential Convergence Analysis of Training and Hyper-training,77,167,False,87,334,43,32,0,11,18,0,14,96,18277,2.40625,1.78125,10.4375,0.5625,5
535,Out-of-distribution Detection with Deep Nearest Neighbors,8,Out-of-distribution Detection with Deep Nearest Neighbors,79,128,False,163,10,12,14,24,12,2,0,14,57,9590,5.642857142857143,1.8571428571428572,0.7142857142857143,0.14285714285714285,254
538,Partially Observed Exchangeable Modeling,8,Partially Observed Exchangeable Modeling,49,135,False,52,48,53,15,0,8,12,4,2,40,9415,3.2666666666666666,3.6666666666666665,3.2,0.8,4
539,Personalized Federated Learning via Variational Bayesian Inference,8,Personalized Federated Learning via Variational Bayesian Inference,57,133,False,126,108,26,18,0,9,10,0,6,66,10127,3.1666666666666665,1.7777777777777777,6.0,0.5555555555555556,52
540,Plug-and-Play Methods Provably Converge with Properly Trained Denoisers,8,Plug-and-Play Methods Provably Converge with Properly Trained Denoisers,86,119,False,109,81,17,16,13,10,6,0,6,71,9605,5.375,1.4375,5.0625,0.375,283
541,Popular decision tree algorithms are provably noise tolerant,8,Popular decision tree algorithms are provably noise tolerant,46,119,False,48,142,2,17,11,20,10,0,0,60,10605,2.7058823529411766,0.11764705882352941,8.352941176470589,0.5882352941176471,2
543,Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design,8,Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design,53,143,False,82,125,20,17,17,13,10,1,12,83,10203,3.1176470588235294,1.8823529411764706,7.352941176470588,0.5882352941176471,1
544,"Probability Functional Descent: A Unifying Perspective on GANs, Variational Inference, and Reinforcement Learning",8,Probability Functional Descent A Unifying Perspective on GANs Variational Inference and Reinforcement Learning,57,93,False,92,113,0,18,0,10,9,0,4,110,9176,3.1666666666666665,0.2222222222222222,6.277777777777778,0.5,24
545,Proper losses for discrete generative models,8,Proper losses for discrete generative models,24,136,False,42,48,0,20,4,16,24,0,0,44,10798,1.2,0.0,2.4,1.2,1
546,Provably Efficient Exploration in Policy Optimization,8,Provably Efficient Exploration in Policy Optimization,83,130,False,133,10,0,55,0,11,13,0,0,53,17565,1.509090909090909,0.0,0.18181818181818182,0.23636363636363636,246
548,Quantum Expectation-Maximization for Gaussian Mixture Models,8,Quantum Expectation-Maximization for Gaussian Mixture Models,64,133,False,135,54,3,21,4,9,5,4,2,60,16897,3.0476190476190474,0.23809523809523808,2.5714285714285716,0.23809523809523808,22
549,RSC: Accelerate Graph Neural Networks Training via Randomized Sparse Computations,8,RSC Accelerate Graph Neural Networks Training via Randomized Sparse Computations,62,198,True,97,20,56,18,0,25,39,17,26,80,11838,3.4444444444444446,4.555555555555555,1.1111111111111112,2.1666666666666665,6
550,Randomized Smoothing of All Shapes and Sizes,8,Randomized Smoothing of All Shapes and Sizes,98,190,False,206,518,70,49,32,18,29,14,6,44,34107,2.0,1.5510204081632653,10.571428571428571,0.5918367346938775,178
552,Regret minimization in stochastic non-convex learning via a proximal-gradient approach,8,Regret minimization in stochastic non-convex learning via a proximal-gradient approach,39,1,False,4,0,0,23,5,7,1,1,0,86,11372,1.6956521739130435,0.0,0.0,0.043478260869565216,16
553,Remember and Forget for Experience Replay,8,Remember and Forget for Experience Replay,47,166,False,136,44,21,16,0,11,4,1,0,41,11023,2.9375,1.3125,2.75,0.25,82
554,Restarted Nonconvex Accelerated Gradient Descent: No More Polylogarithmic Factor in the O(ε-7/4) Complexity,8,Restarted Nonconvex Accelerated Gradient Descent No More Polylogarithmic Factor in the Oε-74 Complexity,57,140,False,156,332,34,29,0,6,12,9,0,105,15341,1.9655172413793103,1.1724137931034482,11.448275862068966,0.41379310344827586,17
555,Revisiting Over-smoothing and Over-squashing using Ollivier's Ricci Curvature,8,Revisiting Over-smoothing and Over-squashing using Olliviers Ricci Curvature,82,116,False,88,82,16,24,0,15,15,0,32,77,15047,3.4166666666666665,2.0,3.4166666666666665,0.625,17
556,Risk-Averse No-Regret Learning in Online Convex Games,8,Risk-Averse No-Regret Learning in Online Convex Games,31,219,False,38,124,20,19,0,11,11,0,0,53,11375,1.631578947368421,1.0526315789473684,6.526315789473684,0.5789473684210527,7
557,Robust Models Are More Interpretable Because Attributions Look Normal,8,Robust Models Are More Interpretable Because Attributions Look Normal,60,166,False,138,38,40,23,7,14,11,0,4,69,10459,2.608695652173913,1.9130434782608696,1.6521739130434783,0.4782608695652174,16
558,Robustness Implies Generalization via Data-Dependent Generalization Bounds,8,Robustness Implies Generalization via Data-Dependent Generalization Bounds,58,150,False,150,151,87,30,2,15,17,2,0,74,17463,1.9333333333333333,2.9,5.033333333333333,0.5666666666666667,16
559,SGD Learns One-Layer Networks in WGANs,8,SGD Learns One-Layer Networks in WGANs,44,70,True,71,128,8,24,0,12,16,0,0,38,10390,1.8333333333333333,0.3333333333333333,5.333333333333333,0.6666666666666666,34
562,Scalable Spike-and-Slab,8,Scalable Spike-and-Slab,59,147,False,108,58,54,20,13,10,10,1,4,23,13015,2.95,2.9,2.9,0.5,6
563,Secure Quantized Training for Deep Learning,8,Secure Quantized Training for Deep Learning,78,129,False,353,65,31,27,36,16,10,2,14,43,15190,2.888888888888889,1.6666666666666667,2.4074074074074074,0.37037037037037035,37
564,Self-Supervised Prototypical Transfer Learning for Few-Shot Classification,8,Self-Supervised Prototypical Transfer Learning for Few-Shot Classification,44,142,False,198,0,20,17,4,6,13,10,34,74,8377,2.588235294117647,3.176470588235294,0.0,0.7647058823529411,42
565,Separating value functions across time-scales,8,Separating value functions across time-scales,42,188,False,114,86,339,54,0,11,15,3,8,45,11680,0.7777777777777778,6.425925925925926,1.5925925925925926,0.2777777777777778,25
566,Short-Term Plasticity Neurons Learning to Learn and Forget,8,Short-Term Plasticity Neurons Learning to Learn and Forget,74,210,False,119,14,21,19,2,6,23,4,8,58,12078,3.8947368421052633,1.5263157894736843,0.7368421052631579,1.2105263157894737,11
567,SinDDM: A Single Image Denoising Diffusion Model,8,SinDDM A Single Image Denoising Diffusion Model,35,153,False,119,24,117,39,14,12,19,0,2,47,11126,0.8974358974358975,3.051282051282051,0.6153846153846154,0.48717948717948717,31
569,Sparse Feature Selection Makes Batch Reinforcement Learning More Sample Efficient,8,Sparse Feature Selection Makes Batch Reinforcement Learning More Sample Efficient,69,207,False,113,504,4,44,7,15,24,4,0,81,17745,1.5681818181818181,0.09090909090909091,11.454545454545455,0.5454545454545454,25
570,SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks,8,SpeqNets Sparsity-aware Permutation-equivariant Graph Networks,135,138,False,518,140,12,32,36,14,12,2,24,62,15985,4.21875,1.125,4.375,0.375,28
571,State Space Gaussian Processes with Non-Gaussian Likelihood,8,State Space Gaussian Processes with Non-Gaussian Likelihood,44,108,False,81,55,10,12,0,6,14,4,2,59,7621,3.6666666666666665,1.0,4.583333333333333,1.1666666666666667,29
572,Stochastic Flows and Geometric Optimization on the Orthogonal Group,8,Stochastic Flows and Geometric Optimization on the Orthogonal Group,45,141,False,48,102,25,24,12,9,16,17,0,67,14121,1.875,1.0416666666666667,4.25,0.6666666666666666,7
573,Stochastic Wasserstein Barycenters,8,Stochastic Wasserstein Barycenters,0,97,False,65,47,33,15,1,8,10,2,0,34,6194,0.0,2.2,3.1333333333333333,0.6666666666666666,60
574,Stronger and Faster Wasserstein Adversarial Attacks,8,Stronger and Faster Wasserstein Adversarial Attacks,43,1,False,45,146,40,30,0,16,31,2,16,51,15085,1.4333333333333333,1.8666666666666667,4.866666666666666,1.0333333333333334,29
575,Sublinear quantum algorithms for training linear and kernel-based classifiers,8,Sublinear quantum algorithms for training linear and kernel-based classifiers,45,137,False,126,184,3,31,2,7,9,5,2,77,15296,1.4516129032258065,0.16129032258064516,5.935483870967742,0.2903225806451613,68
576,Supervised Tree-Wasserstein Distance,8,Supervised Tree-Wasserstein Distance,30,157,False,62,36,36,15,0,8,20,0,10,36,8558,2.0,3.066666666666667,2.4,1.3333333333333333,10
577,TIDE: Time Derivative Diffusion for Deep Learning on Graphs,8,TIDE Time Derivative Diffusion for Deep Learning on Graphs,48,137,True,78,30,21,16,9,7,17,0,22,58,9957,3.0,2.6875,1.875,1.0625,4
579,Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise,8,Text Generation with Diffusion Language Models A Pre-training Approach with Continuous Paragraph Denoise,47,133,False,57,26,9,13,9,8,13,0,0,104,8986,3.6153846153846154,0.6923076923076923,2.0,1.0,26
580,The Heavy-Tail Phenomenon in SGD,8,The Heavy-Tail Phenomenon in SGD,68,247,True,318,728,66,39,0,22,18,12,0,32,17751,1.7435897435897436,1.6923076923076923,18.666666666666668,0.46153846153846156,92
581,The Odds are Odd: A Statistical Test for Detecting Adversarial Examples,8,The Odds are Odd A Statistical Test for Detecting Adversarial Examples,34,111,False,49,44,23,12,0,8,18,0,14,70,8899,2.8333333333333335,3.0833333333333335,3.6666666666666665,1.5,150
583,Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks,8,Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks,60,233,False,111,332,7,39,2,15,16,0,0,91,16411,1.5384615384615385,0.1794871794871795,8.512820512820513,0.41025641025641024,67
584,Topologically Densified Distributions,8,Topologically Densified Distributions,40,118,False,75,142,28,23,0,11,12,0,6,37,11478,1.7391304347826086,1.4782608695652173,6.173913043478261,0.5217391304347826,12
589,Understanding Failures in Out-of-Distribution Detection with Deep Generative Models,8,Understanding Failures in Out-of-Distribution Detection with Deep Generative Models,31,166,False,90,28,8,13,9,11,10,0,4,83,9922,2.3846153846153846,0.9230769230769231,2.1538461538461537,0.7692307692307693,81
590,Understanding invariance via feedforward inversion of discriminatively trained classifiers,8,Understanding invariance via feedforward inversion of discriminatively trained classifiers,34,236,False,99,11,88,16,0,14,9,0,8,90,8765,2.125,6.0,0.6875,0.5625,7
591,Universal Hopfield Networks: A General Framework for Single-Shot Associative Memory Models,8,Universal Hopfield Networks A General Framework for Single-Shot Associative Memory Models,52,177,False,118,28,47,24,0,16,9,0,6,89,10898,2.1666666666666665,2.2083333333333335,1.1666666666666667,0.375,30
592,Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion,8,Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion,66,178,False,127,40,27,17,21,9,6,0,18,97,8702,3.8823529411764706,2.6470588235294117,2.3529411764705883,0.35294117647058826,75
593,"Value Iteration in Continuous Actions, States and Time",8,Value Iteration in Continuous Actions States and Time,65,152,False,56,48,30,14,0,12,10,0,0,54,10457,4.642857142857143,2.142857142857143,3.4285714285714284,0.7142857142857143,23
594,Variational Sparse Coding with Learned Thresholding,8,Variational Sparse Coding with Learned Thresholding,61,164,False,84,58,97,25,0,13,11,2,12,51,10526,2.44,4.36,2.32,0.44,6
595,WaveFlow: A Compact Flow-based Model for Raw Audio,8,WaveFlow A Compact Flow-based Model for Raw Audio,52,146,False,152,20,17,11,0,8,10,0,14,49,7648,4.7272727272727275,2.8181818181818183,1.8181818181818181,0.9090909090909091,97
596,When Are Linear Stochastic Bandits Attackable?,8,When Are Linear Stochastic Bandits Attackable,32,154,False,95,108,10,27,5,12,4,0,0,45,12604,1.1851851851851851,0.37037037037037035,4.0,0.14814814814814814,10
597,Why does Throwing Away Data Improve Worst-Group Error?,8,Why does Throwing Away Data Improve Worst-Group Error,26,132,False,51,417,27,50,16,11,12,0,2,53,23135,0.52,0.58,8.34,0.24,6
598,Zero-Shot Text-to-Image Generation,8,Zero-Shot Text-to-Image Generation,64,83,False,92,6,88,20,0,12,16,0,4,34,11537,3.2,4.6,0.3,0.8,3173
599,3D Infomax improves GNNs for Molecular Property Prediction,8,3D Infomax improves GNNs for Molecular Property Prediction,77,137,False,94,22,22,24,1,10,21,0,36,58,13913,3.2083333333333335,2.4166666666666665,0.9166666666666666,0.875,136
600,A Differential Entropy Estimator for Training Neural Networks,8,A Differential Entropy Estimator for Training Neural Networks,84,193,False,251,74,30,25,31,11,19,4,22,61,13148,3.36,2.08,2.96,0.76,14
601,A Generalization of ViT/MLP-Mixer to Graphs,8,A Generalization of ViTMLP-Mixer to Graphs,96,196,False,317,26,22,23,0,18,18,0,32,42,14113,4.173913043478261,2.347826086956522,1.1304347826086956,0.782608695652174,37
602,"A New Formalism, Method and Open Issues for Zero-Shot Coordination",8,A New Formalism Method and Open Issues for Zero-Shot Coordination,50,201,False,44,379,26,84,7,16,28,0,12,66,43871,0.5952380952380952,0.4523809523809524,4.511904761904762,0.3333333333333333,23
603,A Sampling Based Method for Tensor Ring Decomposition,8,A Sampling Based Method for Tensor Ring Decomposition,78,119,False,172,110,18,21,2,11,16,3,14,53,12595,3.7142857142857144,1.5238095238095237,5.238095238095238,0.7619047619047619,21
604,A Temporal-Difference Approach to Policy Gradient Estimation,8,A Temporal-Difference Approach to Policy Gradient Estimation,38,165,False,0,0,0,24,0,6,2,0,0,60,13514,1.5833333333333333,0.0,0.0,0.08333333333333333,0
605,A kernel Stein test of goodness of fit for sequential models,8,A kernel Stein test of goodness of fit for sequential models,42,142,False,100,41,25,18,19,13,24,4,4,60,11850,2.3333333333333335,1.6111111111111112,2.2777777777777777,1.3333333333333333,2
606,Abstraction Mechanisms Predict Generalization in Deep Neural Networks,8,Abstraction Mechanisms Predict Generalization in Deep Neural Networks,57,145,False,32,10,23,10,0,5,5,0,0,69,6201,5.7,2.3,1.0,0.5,5
608,Active Testing: An Efficient and Robust Framework for Estimating Accuracy,8,Active Testing An Efficient and Robust Framework for Estimating Accuracy,49,200,False,36,24,26,10,0,4,5,0,0,72,7123,4.9,2.6,2.4,0.5,11
609,Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift,8,Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift,57,200,False,97,98,18,29,17,13,9,0,16,108,12124,1.9655172413793103,1.1724137931034482,3.3793103448275863,0.3103448275862069,0
610,Adversarial Learning with Local Coordinate Coding,8,Adversarial Learning with Local Coordinate Coding,28,132,False,69,75,33,14,0,10,12,0,8,49,8193,2.0,2.9285714285714284,5.357142857142857,0.8571428571428571,36
611,Adversarially Robust Models may not Transfer Better: Sufficient Conditions for Domain Transferability from the View of Regularization,8,Adversarially Robust Models may not Transfer Better Sufficient Conditions for Domain Transferability from the View of Regularization,56,174,False,78,290,107,33,0,10,13,0,0,132,18690,1.696969696969697,3.242424242424242,8.787878787878787,0.3939393939393939,7
612,Alternately Optimized Graph Neural Networks,8,Alternately Optimized Graph Neural Networks,69,1,False,150,72,15,19,0,16,17,3,24,43,12788,3.6315789473684212,2.0526315789473686,3.789473684210526,0.8947368421052632,3
613,An Imitation Learning Approach for Cache Replacement,8,An Imitation Learning Approach for Cache Replacement,53,254,False,96,12,27,14,14,11,14,0,6,52,10567,3.7857142857142856,2.357142857142857,0.8571428571428571,1.0,65
614,Analytic Marching: An Analytic Meshing Solution from Deep Implicit Surface Networks,8,Analytic Marching An Analytic Meshing Solution from Deep Implicit Surface Networks,31,177,False,44,26,21,13,0,10,7,0,6,82,8106,2.3846153846153846,2.076923076923077,2.0,0.5384615384615384,20
615,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,8,Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions,46,154,False,46,388,23,36,4,15,21,5,4,70,16973,1.2777777777777777,0.75,10.777777777777779,0.5833333333333334,27
616,Asymptotics of Ridge Regression in Convolutional Models,8,Asymptotics of Ridge Regression in Convolutional Models,46,28,False,12,6,3,14,0,8,13,4,2,55,9948,3.2857142857142856,0.35714285714285715,0.42857142857142855,0.9285714285714286,2
617,AutoSNN: Towards Energy-Efficient Spiking Neural Networks,8,AutoSNN Towards Energy-Efficient Spiking Neural Networks,69,154,False,76,24,39,17,0,12,19,5,22,56,12911,4.0588235294117645,3.588235294117647,1.411764705882353,1.1176470588235294,42
618,BOCK : Bayesian Optimization with Cylindrical Kernels,8,BOCK  Bayesian Optimization with Cylindrical Kernels,40,1,True,65,36,26,14,0,10,14,0,8,52,8615,2.857142857142857,2.4285714285714284,2.5714285714285716,1.0,116
619,Bayesian Deconditional Kernel Mean Embeddings,8,Bayesian Deconditional Kernel Mean Embeddings,23,132,False,86,198,14,22,26,16,8,0,8,45,13422,1.0454545454545454,1.0,9.0,0.36363636363636365,7
620,Bayesian Quadrature for Multiple Related Integrals,8,Bayesian Quadrature for Multiple Related Integrals,59,154,False,71,116,35,19,4,9,9,6,0,50,10994,3.1052631578947367,1.8421052631578947,6.105263157894737,0.47368421052631576,35
621,Beyond Backprop: Online Alternating Minimization with Auxiliary Variables,8,Beyond Backprop Online Alternating Minimization with Auxiliary Variables,49,1,False,124,170,28,21,0,20,27,4,8,72,11989,2.3333333333333335,1.7142857142857142,8.095238095238095,1.2857142857142858,47
622,Biological Sequence Design with GFlowNets,8,Biological Sequence Design with GFlowNets,51,173,False,120,22,12,16,8,10,15,5,26,41,11307,3.1875,2.375,1.375,0.9375,94
623,Boosting for Control of Dynamical Systems,8,Boosting for Control of Dynamical Systems,14,60,False,34,44,6,9,12,8,9,0,2,41,6024,1.5555555555555556,0.8888888888888888,4.888888888888889,1.0,12
624,Breaking the Limits of Message Passing Graph Neural Networks,8,Breaking the Limits of Message Passing Graph Neural Networks,43,184,False,153,130,27,18,0,20,11,0,12,60,15273,2.388888888888889,2.1666666666666665,7.222222222222222,0.6111111111111112,96
625,CHiVE: Varying Prosody in Speech Synthesis with a Linguistically Driven Dynamic Hierarchical Conditional Variational Network,8,CHiVE Varying Prosody in Speech Synthesis with a Linguistically Driven Dynamic Hierarchical Conditional Variational Network,33,195,False,30,4,18,10,0,6,9,2,6,123,7350,3.3,2.4,0.4,0.9,70
626,Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?,8,Can Increasing Input Dimensionality Improve Deep Reinforcement Learning,37,214,False,54,8,23,11,0,6,11,0,6,71,7149,3.3636363636363638,2.6363636363636362,0.7272727272727273,1.0,28
627,Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings,8,Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings,32,170,False,45,6,46,15,10,8,5,0,2,74,8257,2.1333333333333333,3.2,0.4,0.3333333333333333,45
630,Combining Differentiable PDE Solvers and Graph Neural Networks for Fluid Flow Prediction,8,Combining Differentiable PDE Solvers and Graph Neural Networks for Fluid Flow Prediction,26,135,True,42,26,59,16,10,9,5,0,2,88,7501,1.625,3.8125,1.625,0.3125,166
631,Composable Core-sets for Determinant Maximization: A Simple Near-Optimal Algorithm,8,Composable Core-sets for Determinant Maximization A Simple Near-Optimal Algorithm,42,152,False,42,35,15,18,12,7,7,0,0,81,8716,2.3333333333333335,0.8333333333333334,1.9444444444444444,0.3888888888888889,17
632,Concentric mixtures of Mallows models for top-k rankings: sampling and identifiability,8,Concentric mixtures of Mallows models for top-k rankings sampling and identifiability,34,157,False,50,136,5,9,5,16,5,0,0,85,5976,3.7777777777777777,0.5555555555555556,15.11111111111111,0.5555555555555556,8
633,Connecting Sphere Manifolds Hierarchically for Regularization,8,Connecting Sphere Manifolds Hierarchically for Regularization,45,92,False,64,39,21,14,0,6,10,0,8,61,8372,3.2142857142857144,2.0714285714285716,2.7857142857142856,0.7142857142857143,3
635,Continuous-Time Analysis of Accelerated Gradient Methods via Conservation Laws in Dilated Coordinate Systems,8,Continuous-Time Analysis of Accelerated Gradient Methods via Conservation Laws in Dilated Coordinate Systems,109,119,False,147,295,0,29,8,13,22,7,0,108,15968,3.7586206896551726,0.0,10.172413793103448,0.7586206896551724,7
636,Convergence of First-Order Methods for Constrained Nonconvex Optimization with Dependent Data,8,Convergence of First-Order Methods for Constrained Nonconvex Optimization with Dependent Data,44,171,False,217,318,7,32,4,18,12,0,2,93,18226,1.375,0.28125,9.9375,0.375,2
637,Coresets for Clustering in Graphs of Bounded Treewidth,8,Coresets for Clustering in Graphs of Bounded Treewidth,59,175,False,64,57,17,18,17,6,9,0,2,54,13335,3.2777777777777777,1.0555555555555556,3.1666666666666665,0.5,27
638,Cross-Gradient Aggregation for Decentralized Learning from Non-IID data,8,Cross-Gradient Aggregation for Decentralized Learning from Non-IID data,44,175,True,305,582,107,24,0,20,36,0,42,71,12522,1.8333333333333333,6.208333333333333,24.25,1.5,39
639,DAGs with No Curl: An Efficient DAG Structure Learning Approach,8,DAGs with No Curl An Efficient DAG Structure Learning Approach,62,189,True,165,62,12,28,1,18,15,2,22,62,23304,2.2142857142857144,1.2142857142857142,2.2142857142857144,0.5357142857142857,40
640,Data Augmentation for Meta-Learning,8,Data Augmentation for Meta-Learning,34,114,False,82,2,6,15,4,6,14,0,14,35,9115,2.2666666666666666,1.3333333333333333,0.13333333333333333,0.9333333333333333,64
641,Dataset Dynamics via Gradient Flows in Probability Space,8,Dataset Dynamics via Gradient Flows in Probability Space,53,128,False,106,45,77,19,9,13,15,0,4,56,10974,2.789473684210526,4.2631578947368425,2.3684210526315788,0.7894736842105263,17
642,Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices,8,Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices,58,178,False,102,34,53,20,19,12,14,1,2,90,15227,2.9,2.75,1.7,0.7,55
643,Deep Network Approximation in Terms of Intrinsic Parameters,8,Deep Network Approximation in Terms of Intrinsic Parameters,75,213,False,33,230,47,26,0,7,12,3,4,59,15583,2.8846153846153846,1.9615384615384615,8.846153846153847,0.46153846153846156,5
644,DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale,8,DeepSpeed-MoE Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale,53,217,True,74,2,47,31,14,8,14,10,12,99,14418,1.7096774193548387,1.903225806451613,0.06451612903225806,0.45161290322580644,145
645,Descending through a Crowded Valley - Benchmarking Deep Learning Optimizers,8,Descending through a Crowded Valley - Benchmarking Deep Learning Optimizers,185,207,False,55,0,12,37,11,5,5,1,0,75,21333,5.0,0.32432432432432434,0.0,0.13513513513513514,131
646,Differentiable Likelihoods for Fast Inversion of 'Likelihood-Free' Dynamical Systems,8,Differentiable Likelihoods for Fast Inversion of Likelihood-Free Dynamical Systems,50,126,False,160,176,20,16,0,16,20,5,0,84,11004,3.125,1.25,11.0,1.25,18
647,Differentially Private Query Release Through Adaptive Projection,8,Differentially Private Query Release Through Adaptive Projection,45,159,False,107,28,100,20,15,19,30,1,4,64,9490,2.25,5.2,1.4,1.5,47
648,Dirichlet Simplex Nest and Geometric Inference,8,Dirichlet Simplex Nest and Geometric Inference,39,95,False,79,92,45,17,22,9,10,2,4,46,11733,2.2941176470588234,2.8823529411764706,5.411764705882353,0.5882352941176471,4
649,Disentangled Sequential Autoencoder,8,Disentangled Sequential Autoencoder,32,171,False,81,14,48,12,19,9,4,0,0,35,7514,2.6666666666666665,4.0,1.1666666666666667,0.3333333333333333,243
650,Distributional Reinforcement Learning for Efficient Exploration,8,Distributional Reinforcement Learning for Efficient Exploration,47,111,False,59,32,33,11,0,9,8,0,2,63,6143,4.2727272727272725,3.1818181818181817,2.909090909090909,0.7272727272727273,77
651,Does the Data Induce Capacity Control in Deep Learning?,8,Does the Data Induce Capacity Control in Deep Learning,52,191,False,114,76,59,37,11,16,24,2,8,54,16995,1.4054054054054055,1.8108108108108107,2.054054054054054,0.6486486486486487,8
652,Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images,8,Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images,81,175,False,89,19,69,12,0,8,8,2,6,91,8361,6.75,6.25,1.5833333333333333,0.6666666666666666,3
653,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,8,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning,23,164,False,96,339,27,38,1,17,22,0,0,82,24663,0.6052631578947368,0.7105263157894737,8.921052631578947,0.5789473684210527,103
654,Efficient Optimistic Exploration in Linear-Quadratic Regulators via Lagrangian Relaxation,8,Efficient Optimistic Exploration in Linear-Quadratic Regulators via Lagrangian Relaxation,18,136,False,123,1016,10,60,21,18,30,13,0,89,34132,0.3,0.16666666666666666,16.933333333333334,0.5,20
655,EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture,8,EfficientTTS An Efficient and High-Quality Text-to-Speech Architecture,31,174,False,22,46,30,15,0,11,19,0,10,70,6812,2.066666666666667,2.6666666666666665,3.066666666666667,1.2666666666666666,32
656,Enhancing Robustness of Neural Networks through Fourier Stabilization,8,Enhancing Robustness of Neural Networks through Fourier Stabilization,32,155,False,45,96,31,16,4,13,8,0,2,69,10445,2.0,2.0625,6.0,0.5,11
657,Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap,8,Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap,43,173,False,63,162,6,27,7,8,14,0,0,74,11979,1.5925925925925926,0.2222222222222222,6.0,0.5185185185185185,22
659,Explainable k-Means and k-Medians Clustering,8,Explainable k-Means and k-Medians Clustering,57,232,False,50,56,36,32,28,20,34,10,4,44,17012,1.78125,1.25,1.75,1.0625,112
660,Exponentially Many Local Minima in Quantum Neural Networks,8,Exponentially Many Local Minima in Quantum Neural Networks,61,162,False,140,204,63,27,20,13,13,0,4,58,16980,2.259259259259259,2.4814814814814814,7.555555555555555,0.48148148148148145,35
661,Fair Learning with Private Demographic Data,8,Fair Learning with Private Demographic Data,42,91,False,70,232,3,37,4,8,6,4,2,43,15957,1.135135135135135,0.13513513513513514,6.27027027027027,0.16216216216216217,62
662,Fast Differentiable Sorting and Ranking,8,Fast Differentiable Sorting and Ranking,45,171,False,114,122,21,17,27,10,11,0,2,39,10201,2.6470588235294117,1.3529411764705883,7.176470588235294,0.6470588235294118,166
663,Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack,8,Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack,54,172,False,202,24,77,20,0,14,3,0,22,81,11466,2.7,4.95,1.2,0.15,6
664,Feature and Parameter Selection in Stochastic Linear Bandits,8,Feature and Parameter Selection in Stochastic Linear Bandits,41,173,False,107,252,23,32,1,13,20,3,0,60,18569,1.28125,0.71875,7.875,0.625,5
665,FetchSGD: Communication-Efficient Federated Learning with Sketching,8,FetchSGD Communication-Efficient Federated Learning with Sketching,84,136,False,154,54,56,29,3,11,16,0,2,66,16952,2.896551724137931,2.0,1.8620689655172413,0.5517241379310345,283
666,Fingerprint Policy Optimisation for Robust Reinforcement Learning,8,Fingerprint Policy Optimisation for Robust Reinforcement Learning,31,156,False,52,8,30,12,0,8,13,0,4,65,7923,2.5833333333333335,2.8333333333333335,0.6666666666666666,1.0833333333333333,17
667,Flow-Guided Sparse Transformer for Video Deblurring,8,Flow-Guided Sparse Transformer for Video Deblurring,57,139,False,72,28,21,10,1,5,11,0,6,51,7397,5.7,2.7,2.8,1.1,39
669,Functional Generalized Empirical Likelihood Estimation for Conditional Moment Restrictions,8,Functional Generalized Empirical Likelihood Estimation for Conditional Moment Restrictions,71,140,False,242,166,6,29,14,9,16,3,4,90,14733,2.4482758620689653,0.3448275862068966,5.724137931034483,0.5517241379310345,6
670,GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models,8,GLIDE Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models,51,130,True,150,2,195,20,0,15,16,0,8,91,9541,2.55,10.15,0.1,0.8,2099
671,Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for Safety-Critical Applications,8,Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for Safety-Critical Applications,51,163,False,170,214,36,16,0,18,22,0,8,99,9921,3.1875,2.75,13.375,1.375,12
672,Generalized Linear Rule Models,8,Generalized Linear Rule Models,34,121,False,43,26,61,17,0,9,7,0,12,30,9722,2.0,4.294117647058823,1.5294117647058822,0.4117647058823529,53
673,Generative Cooperative Networks for Natural Language Generation,8,Generative Cooperative Networks for Natural Language Generation,39,155,False,80,36,8,13,7,7,7,2,0,63,8344,3.0,0.6153846153846154,2.769230769230769,0.5384615384615384,10
675,Gradient Descent Finds Global Minima of Deep Neural Networks,8,Gradient Descent Finds Global Minima of Deep Neural Networks,59,1,False,87,455,0,45,2,16,11,0,0,60,21026,1.3111111111111111,0.0,10.11111111111111,0.24444444444444444,1013
676,Graph Structure of Neural Networks,8,Graph Structure of Neural Networks,67,1,False,172,24,72,15,0,30,30,0,8,34,10228,4.466666666666667,5.333333333333333,1.6,2.0,112
678,Hierarchical Clustering with Structural Constraints,8,Hierarchical Clustering with Structural Constraints,33,166,False,50,75,21,23,19,11,5,0,2,51,11426,1.434782608695652,1.0,3.260869565217391,0.21739130434782608,44
679,Hiring Under Uncertainty,8,Hiring Under Uncertainty,25,159,False,29,38,10,12,4,8,9,2,0,24,8312,2.0833333333333335,0.8333333333333334,3.1666666666666665,0.75,11
680,How to Learn when Data Reacts to Your Model: Performative Gradient Descent,8,How to Learn when Data Reacts to Your Model Performative Gradient Descent,30,137,False,24,123,15,21,3,11,14,0,0,73,9893,1.4285714285714286,0.7142857142857143,5.857142857142857,0.6666666666666666,56
681,I-BERT: Integer-only BERT Quantization,8,I-BERT Integer-only BERT Quantization,102,184,True,77,36,6,15,0,11,16,0,10,37,9912,6.8,1.0666666666666667,2.4,1.0666666666666667,241
682,Implicit Generative Modeling for Efficient Exploration,8,Implicit Generative Modeling for Efficient Exploration,44,157,False,120,18,43,15,0,7,12,4,4,54,9817,2.933333333333333,3.1333333333333333,1.2,0.8,11
685,Improving Visual Quality of Unrestricted Adversarial Examples with Wavelet-VAE,8,Improving Visual Quality of Unrestricted Adversarial Examples with Wavelet-VAE,20,91,True,23,14,6,6,0,6,5,0,4,78,3584,3.3333333333333335,1.6666666666666667,2.3333333333333335,0.8333333333333334,1
686,Inductive Biases and Variable Creation in Self-Attention Mechanisms,8,Inductive Biases and Variable Creation in Self-Attention Mechanisms,78,106,False,106,235,13,43,44,12,20,2,0,67,21550,1.813953488372093,0.3023255813953488,5.465116279069767,0.46511627906976744,77
687,"Informed Learning by Wide Neural Networks: Convergence, Generalization and Sampling Complexity",8,Informed Learning by Wide Neural Networks Convergence Generalization and Sampling Complexity,101,152,False,216,702,30,43,0,34,54,14,0,93,26826,2.3488372093023258,0.6976744186046512,16.325581395348838,1.255813953488372,1
688,Intermediate Layer Optimization for Inverse Problems using Deep Generative Models,8,Intermediate Layer Optimization for Inverse Problems using Deep Generative Models,74,122,False,95,101,95,21,0,7,16,5,2,81,12546,3.5238095238095237,4.619047619047619,4.809523809523809,0.7619047619047619,68
689,Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs,8,Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs,63,141,False,111,89,36,28,11,11,15,0,14,117,18219,2.25,1.7857142857142858,3.1785714285714284,0.5357142857142857,12
690,Isometric Gaussian Process Latent Variable Model for Dissimilarity Data,8,Isometric Gaussian Process Latent Variable Model for Dissimilarity Data,44,96,False,86,50,17,10,9,6,10,0,2,71,6857,4.4,1.9,5.0,1.0,4
691,Katalyst: Boosting Convex Katayusha for Non-Convex Problems with a Large Condition Number,8,Katalyst Boosting Convex Katayusha for Non-Convex Problems with a Large Condition Number,29,213,False,97,117,10,12,4,9,2,0,2,88,7739,2.4166666666666665,1.0,9.75,0.16666666666666666,5
692,LEEP: A New Measure to Evaluate Transferability of Learned Representations,8,LEEP A New Measure to Evaluate Transferability of Learned Representations,62,115,True,185,16,40,14,0,8,9,0,2,73,9659,4.428571428571429,3.0,1.1428571428571428,0.6428571428571429,161
693,Large Batch Experience Replay,8,Large Batch Experience Replay,43,176,False,156,32,36,24,0,17,8,0,12,29,11333,1.7916666666666667,2.0,1.3333333333333333,0.3333333333333333,8
694,LazyIter: A Fast Algorithm for Counting Markov Equivalent DAGs and Designing Experiments,8,LazyIter A Fast Algorithm for Counting Markov Equivalent DAGs and Designing Experiments,19,195,False,63,20,4,11,0,8,9,0,0,87,7786,1.7272727272727273,0.36363636363636365,1.8181818181818181,0.8181818181818182,10
695,Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry,8,Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry,38,96,False,80,40,9,10,0,5,7,3,4,75,5955,3.8,1.3,4.0,0.7,365
697,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,8,Learning Longer-term Dependencies in RNNs with Auxiliary Losses,56,162,False,60,0,18,11,0,6,12,4,12,63,7189,5.090909090909091,2.727272727272727,0.0,1.0909090909090908,163
698,Learning Randomly Perturbed Structured Predictors for Direct Loss Minimization,8,Learning Randomly Perturbed Structured Predictors for Direct Loss Minimization,35,107,False,114,173,16,18,0,9,12,0,10,78,10823,1.9444444444444444,1.4444444444444444,9.61111111111111,0.6666666666666666,6
699,Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling,8,Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling,83,200,False,75,54,25,17,0,11,13,0,14,71,12214,4.882352941176471,2.2941176470588234,3.176470588235294,0.7647058823529411,49
700,Learning interpretable continuous-time models of latent stochastic dynamical systems,8,Learning interpretable continuous-time models of latent stochastic dynamical systems,27,121,False,53,146,30,13,0,11,19,7,0,84,8588,2.076923076923077,2.3076923076923075,11.23076923076923,1.4615384615384615,67
701,Learning to Initiate and Reason in Event-Driven Cascading Processes,8,Learning to Initiate and Reason in Event-Driven Cascading Processes,53,204,False,106,64,24,26,3,19,21,0,10,67,16510,2.0384615384615383,1.3076923076923077,2.4615384615384617,0.8076923076923077,0
702,Learning unknown ODE models with Gaussian processes,8,Learning unknown ODE models with Gaussian processes,49,112,True,82,56,12,13,1,7,8,0,2,51,6327,3.769230769230769,1.0769230769230769,4.3076923076923075,0.6153846153846154,77
704,Linearity Grafting: Relaxed Neuron Pruning Helps Certifiable Robustness,8,Linearity Grafting Relaxed Neuron Pruning Helps Certifiable Robustness,72,184,False,151,4,27,13,25,8,5,0,22,70,9321,5.538461538461538,3.769230769230769,0.3076923076923077,0.38461538461538464,5
705,Logarithmic Regret for Reinforcement Learning with Linear Function Approximation,8,Logarithmic Regret for Reinforcement Learning with Linear Function Approximation,44,153,False,132,184,0,26,0,11,17,0,0,80,11645,1.6923076923076923,0.0,7.076923076923077,0.6538461538461539,82
706,LyaNet: A Lyapunov Framework for Training Neural ODEs,8,LyaNet A Lyapunov Framework for Training Neural ODEs,44,130,False,76,66,14,17,0,10,14,0,2,52,9226,2.588235294117647,0.9411764705882353,3.8823529411764706,0.8235294117647058,34
707,Machine Unlearning for Random Forests,8,Machine Unlearning for Random Forests,96,264,False,200,20,98,29,28,22,46,0,36,37,15989,3.310344827586207,4.620689655172414,0.6896551724137931,1.5862068965517242,111
708,Max-Mahalanobis Linear Discriminant Analysis Networks,8,Max-Mahalanobis Linear Discriminant Analysis Networks,36,159,False,91,109,15,13,0,8,11,0,6,53,8920,2.769230769230769,1.6153846153846154,8.384615384615385,0.8461538461538461,48
709,Memory-Based Model Editing at Scale,8,Memory-Based Model Editing at Scale,51,177,False,105,16,0,15,15,8,4,0,0,35,10993,3.4,0.0,1.0666666666666667,0.26666666666666666,153
710,MetaFun: Meta-Learning with Iterative Functional Updates,8,MetaFun Meta-Learning with Iterative Functional Updates,44,94,False,124,52,13,16,7,8,8,0,12,55,8737,2.75,1.5625,3.25,0.5,62
711,Mitigating Memorization of Noisy Labels by Clipping the Model Prediction,8,Mitigating Memorization of Noisy Labels by Clipping the Model Prediction,85,167,False,144,34,13,19,11,14,9,0,18,72,11696,4.473684210526316,1.631578947368421,1.7894736842105263,0.47368421052631576,12
712,Model Selection in Batch Policy Optimization,8,Model Selection in Batch Policy Optimization,52,0,False,24,153,0,45,0,15,12,0,0,44,16225,1.1555555555555554,0.0,3.4,0.26666666666666666,9
714,More Efficient Off-Policy Evaluation through Regularized Targeted Learning,8,More Efficient Off-Policy Evaluation through Regularized Targeted Learning,25,188,False,58,276,6,24,14,13,25,0,0,74,16140,1.0416666666666667,0.25,11.5,1.0416666666666667,37
716,Multiplying Matrices Without Multiplying,8,Multiplying Matrices Without Multiplying,78,130,False,104,77,33,22,4,12,29,0,0,40,15097,3.5454545454545454,1.5,3.5,1.3181818181818181,26
717,Near Input Sparsity Time Kernel Embeddings via Adaptive Sampling,8,Near Input Sparsity Time Kernel Embeddings via Adaptive Sampling,27,144,False,46,103,0,17,3,13,8,1,2,64,14928,1.588235294117647,0.11764705882352941,6.0588235294117645,0.47058823529411764,19
718,Nesterov Accelerated Shuffling Gradient Method for Convex Optimization,8,Nesterov Accelerated Shuffling Gradient Method for Convex Optimization,57,122,False,12,0,3,30,0,6,12,4,2,70,15157,1.9,0.16666666666666666,0.0,0.4,10
719,Neural Network Attributions: A Causal Perspective,8,Neural Network Attributions A Causal Perspective,42,114,False,50,42,30,17,4,8,16,10,0,48,11457,2.4705882352941178,1.7647058823529411,2.4705882352941178,0.9411764705882353,121
720,Neurally-Guided Structure Inference,8,Neurally-Guided Structure Inference,48,118,False,137,2,22,11,8,6,9,0,8,35,7453,4.363636363636363,2.727272727272727,0.18181818181818182,0.8181818181818182,6
721,Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation,8,Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation,136,118,False,379,229,21,36,23,19,18,2,14,85,20959,3.7777777777777777,0.9722222222222222,6.361111111111111,0.5,26
722,Normalized Flat Minima: Exploring Scale Invariant Definition of Flat Minima for Neural Networks using PAC-Bayesian Analysis,8,Normalized Flat Minima Exploring Scale Invariant Definition of Flat Minima for Neural Networks using PAC-Bayesian Analysis,65,152,True,121,78,18,25,7,14,18,0,2,122,7891,2.6,0.8,3.12,0.72,65
723,Off-Policy Actor-Critic with Shared Experience Replay,8,Off-Policy Actor-Critic with Shared Experience Replay,56,144,False,130,44,15,20,1,10,14,1,4,53,10282,2.8,0.95,2.2,0.7,61
724,On Conditional Versus Marginal Bias in Multi-Armed Bandits,8,On Conditional Versus Marginal Bias in Multi-Armed Bandits,27,164,False,56,117,27,18,0,8,14,0,0,58,12540,1.5,1.5,6.5,0.7777777777777778,10
725,On Last-Iterate Convergence Beyond Zero-Sum Games,8,On Last-Iterate Convergence Beyond Zero-Sum Games,97,234,False,261,396,26,62,10,11,14,0,0,49,25405,1.564516129032258,0.41935483870967744,6.387096774193548,0.22580645161290322,29
727,On the Convergence of the Shapley Value in Parametric Bayesian Learning Games,8,On the Convergence of the Shapley Value in Parametric Bayesian Learning Games,26,151,False,19,60,29,17,2,9,6,0,10,77,11423,1.5294117647058822,2.2941176470588234,3.5294117647058822,0.35294117647058826,11
728,On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games,8,On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games,28,150,False,40,98,0,13,2,12,7,0,0,96,9590,2.1538461538461537,0.0,7.538461538461538,0.5384615384615384,1
729,On the Robustness of CountSketch to Adaptive Inputs,8,On the Robustness of CountSketch to Adaptive Inputs,55,128,False,39,290,4,28,31,13,22,8,0,51,18178,1.9642857142857142,0.14285714285714285,10.357142857142858,0.7857142857142857,14
730,One-Shot Segmentation in Clutter,8,One-Shot Segmentation in Clutter,43,164,False,64,0,12,10,0,9,24,0,4,32,6963,4.3,1.6,0.0,2.4,36
732,Operation-Aware Soft Channel Pruning using Differentiable Masks,8,Operation-Aware Soft Channel Pruning using Differentiable Masks,38,142,False,84,26,19,10,7,6,13,0,16,63,7181,3.8,3.5,2.6,1.3,113
733,Optimal Regret Algorithm for Pseudo-1d Bandit Convex Optimization,8,Optimal Regret Algorithm for Pseudo-1d Bandit Convex Optimization,24,177,False,75,93,8,25,8,8,6,0,0,65,10655,0.96,0.32,3.72,0.24,5
734,Optimization-Induced Graph Implicit Nonlinear Diffusion,8,Optimization-Induced Graph Implicit Nonlinear Diffusion,61,187,False,108,56,9,14,0,14,14,0,18,55,9120,4.357142857142857,1.9285714285714286,4.0,1.0,23
735,Out-of-sample extension of graph adjacency spectral embedding,8,Out-of-sample extension of graph adjacency spectral embedding,41,145,False,108,140,9,31,0,10,8,0,0,61,12574,1.3225806451612903,0.2903225806451613,4.516129032258065,0.25806451612903225,15
736,PAPRIKA: Private Online False Discovery Rate Control,8,PAPRIKA Private Online False Discovery Rate Control,18,199,True,37,70,32,25,2,8,5,0,4,51,12063,0.72,1.44,2.8,0.2,6
737,Parallel Machine Translation with Disentangled Context Transformer,8,Parallel Machine Translation with Disentangled Context Transformer,37,146,False,116,28,18,12,13,8,14,0,14,66,7930,3.0833333333333335,2.6666666666666665,2.3333333333333335,1.1666666666666667,31
738,Particle Flow Bayes' Rule,8,Particle Flow Bayes Rule,32,92,False,90,93,61,14,0,10,11,2,2,24,9219,2.2857142857142856,4.5,6.642857142857143,0.7857142857142857,7
740,PoF: Post-Training of Feature Extractor for Improving Generalization,8,PoF Post-Training of Feature Extractor for Improving Generalization,47,160,False,36,20,24,10,0,6,7,0,4,67,7307,4.7,2.8,2.0,0.7,1
741,Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules,8,Population Based Augmentation Efficient Learning of Augmentation Policy Schedules,53,120,False,52,0,26,14,0,9,9,0,0,81,7493,3.7857142857142856,1.8571428571428572,0.0,0.6428571428571429,356
742,Predictor-Corrector Policy Optimization,8,Predictor-Corrector Policy Optimization,72,175,False,201,224,30,31,8,16,20,12,4,39,18786,2.3225806451612905,1.096774193548387,7.225806451612903,0.6451612903225806,21
743,Private Adaptive Gradient Methods for Convex Optimization,8,Private Adaptive Gradient Methods for Convex Optimization,34,166,False,87,214,8,26,2,13,18,1,2,57,11449,1.3076923076923077,0.38461538461538464,8.23076923076923,0.6923076923076923,39
744,Probably Approximately Metric-Fair Learning,8,Probably Approximately Metric-Fair Learning,36,160,False,44,150,0,40,22,8,17,3,0,43,18801,0.9,0.0,3.75,0.425,79
745,Proportionally Fair Clustering,8,Proportionally Fair Clustering,37,113,False,47,10,33,18,3,7,13,3,2,30,9987,2.0555555555555554,1.9444444444444444,0.5555555555555556,0.7222222222222222,116
746,Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Transitions,8,Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Transitions,52,156,False,82,518,6,59,0,10,8,0,0,108,24763,0.8813559322033898,0.1016949152542373,8.779661016949152,0.13559322033898305,9
747,Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup,8,Puzzle Mix Exploiting Saliency and Local Statistics for Optimal Mixup,42,141,False,81,18,56,17,0,13,18,3,22,69,9848,2.4705882352941178,4.588235294117647,1.0588235294117647,1.0588235294117647,296
748,Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions,8,Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions,57,174,False,222,438,0,32,3,8,13,5,0,73,18414,1.78125,0.0,13.6875,0.40625,2
749,RaFM: Rank-Aware Factorization Machines,8,RaFM Rank-Aware Factorization Machines,18,124,False,21,118,12,13,0,10,12,6,8,38,7685,1.3846153846153846,1.5384615384615385,9.076923076923077,0.9230769230769231,11
750,Randomly Projected Additive Gaussian Processes for Regression,8,Randomly Projected Additive Gaussian Processes for Regression,46,187,False,104,42,34,14,0,9,14,1,4,61,8591,3.2857142857142856,2.7142857142857144,3.0,1.0,24
751,Recovery Bounds on Class-Based Optimal Transport: A Sum-of-Norms Regularization Framework,8,Recovery Bounds on Class-Based Optimal Transport A Sum-of-Norms Regularization Framework,40,116,False,87,229,41,28,1,16,20,5,4,88,14798,1.4285714285714286,1.6071428571428572,8.178571428571429,0.7142857142857143,0
752,Regularized Online Allocation Problems: Fairness and Beyond,8,Regularized Online Allocation Problems Fairness and Beyond,61,204,False,124,162,6,46,16,11,13,0,2,58,18337,1.326086956521739,0.17391304347826086,3.5217391304347827,0.2826086956521739,40
753,Removing Batch Normalization Boosts Adversarial Training,8,Removing Batch Normalization Boosts Adversarial Training,62,184,False,113,14,33,13,5,15,25,4,16,56,8183,4.769230769230769,3.769230769230769,1.0769230769230769,1.9230769230769231,28
754,Rethinking Attention-Model Explainability through Faithfulness Violation Test,8,Rethinking Attention-Model Explainability through Faithfulness Violation Test,74,149,False,83,10,33,18,1,11,13,0,10,77,8618,4.111111111111111,2.388888888888889,0.5555555555555556,0.7222222222222222,26
755,Revisiting Peng's Q(λ) for Modern Reinforcement Learning,8,Revisiting Pengs Qλ for Modern Reinforcement Learning,48,169,False,183,136,50,26,46,19,19,0,6,56,15500,1.8461538461538463,2.1538461538461537,5.230769230769231,0.7307692307692307,13
756,Rissanen Data Analysis: Examining Dataset Characteristics via Description Length,8,Rissanen Data Analysis Examining Dataset Characteristics via Description Length,110,165,False,172,8,45,18,17,11,16,10,2,79,11334,6.111111111111111,2.611111111111111,0.4444444444444444,0.8888888888888888,19
757,Robust Multi-Objective Bayesian Optimization Under Input Noise,8,Robust Multi-Objective Bayesian Optimization Under Input Noise,95,149,False,218,60,37,36,0,19,28,0,12,62,22187,2.638888888888889,1.3611111111111112,1.6666666666666667,0.7777777777777778,22
758,Robustness and Accuracy Could Be Reconcilable by (Proper) Definition,8,Robustness and Accuracy Could Be Reconcilable by Proper Definition,108,153,False,232,116,21,20,0,12,26,0,8,68,12590,5.4,1.45,5.8,1.3,71
759,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,8,SGD and Hogwild Convergence Without the Bounded Gradients Assumption,24,171,True,37,200,14,24,0,10,14,0,0,68,12826,1.0,0.5833333333333334,8.333333333333334,0.5833333333333334,191
760,Safe Reinforcement Learning in Constrained Markov Decision Processes,8,Safe Reinforcement Learning in Constrained Markov Decision Processes,28,131,False,84,187,12,16,15,14,12,0,2,68,10344,1.75,0.875,11.6875,0.75,103
761,Scalable Deep Gaussian Markov Random Fields for General Graphs,8,Scalable Deep Gaussian Markov Random Fields for General Graphs,45,1,False,59,12,15,22,0,12,11,3,0,62,13732,2.0454545454545454,0.6818181818181818,0.5454545454545454,0.5,3
762,Scalable Training of Inference Networks for Gaussian-Process Models,8,Scalable Training of Inference Networks for Gaussian-Process Models,57,153,False,153,54,40,16,10,9,15,0,8,67,9881,3.5625,3.0,3.375,0.9375,18
763,SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching,8,SeedGNN Graph Neural Networks for Supervised Seeded Graph Matching,78,190,False,116,34,68,32,19,14,14,0,8,66,15439,2.4375,2.375,1.0625,0.4375,0
764,Self-Supervised Representation Learning via Latent Graph Prediction,8,Self-Supervised Representation Learning via Latent Graph Prediction,68,153,False,135,52,6,18,13,12,10,0,20,67,12319,3.7777777777777777,1.4444444444444444,2.888888888888889,0.5555555555555556,19
765,Sequential Cooperative Bayesian Inference,8,Sequential Cooperative Bayesian Inference,38,1,False,48,110,61,25,0,11,14,0,0,41,14370,1.52,2.44,4.4,0.56,11
766,Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search,8,Shortest Edit Path Crossover A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search,53,193,False,120,60,64,26,0,8,18,0,2,123,22503,2.0384615384615383,2.5384615384615383,2.3076923076923075,0.6923076923076923,1
767,SinFusion: Training Diffusion Models on a Single Image or Video,8,SinFusion Training Diffusion Models on a Single Image or Video,72,153,False,96,6,65,16,19,16,6,0,8,62,10211,4.5,4.5625,0.375,0.375,34
768,Smoothed Action Value Functions for Learning Gaussian Policies,8,Smoothed Action Value Functions for Learning Gaussian Policies,30,140,False,90,93,40,12,0,13,10,0,2,62,8242,2.5,3.5,7.75,0.8333333333333334,27
769,Sparse Gaussian Processes with Spherical Harmonic Features,8,Sparse Gaussian Processes with Spherical Harmonic Features,23,117,False,79,98,15,14,1,7,15,0,6,58,9683,1.6428571428571428,1.5,7.0,1.0714285714285714,44
770,Spread Divergence,8,Spread Divergence,61,84,False,121,101,46,22,0,22,10,8,2,17,12402,2.772727272727273,2.1818181818181817,4.590909090909091,0.45454545454545453,17
771,State-Regularized Recurrent Neural Networks,8,State-Regularized Recurrent Neural Networks,74,171,False,154,16,74,20,0,13,12,0,12,43,12609,3.7,4.3,0.8,0.6,33
772,Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization,8,Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization,29,132,False,140,418,5,17,3,23,32,2,4,62,8576,1.7058823529411764,0.5294117647058824,24.58823529411765,1.8823529411764706,18
773,Stochastic bandits with arm-dependent delays,8,Stochastic bandits with arm-dependent delays,31,125,False,122,101,14,18,19,16,5,0,0,44,10506,1.7222222222222223,0.7777777777777778,5.611111111111111,0.2777777777777778,34
774,Stronger generalization bounds for deep nets via a compression approach,8,Stronger generalization bounds for deep nets via a compression approach,42,148,False,79,50,44,39,2,16,31,5,6,71,16355,1.0769230769230769,1.2820512820512822,1.2820512820512822,0.7948717948717948,581
775,Sublinear-Time Clustering Oracle for Signed Graphs,8,Sublinear-Time Clustering Oracle for Signed Graphs,28,239,False,63,149,32,37,0,13,10,0,2,50,20574,0.7567567567567568,0.918918918918919,4.027027027027027,0.2702702702702703,1
776,SurCo: Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems,8,SurCo Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems,97,148,False,185,28,32,19,8,12,11,2,14,82,11867,5.105263157894737,2.4210526315789473,1.4736842105263157,0.5789473684210527,11
777,TPC: Transformation-Specific Smoothing for Point Cloud Models,8,TPC Transformation-Specific Smoothing for Point Cloud Models,49,156,True,73,173,11,22,0,12,25,5,22,60,13577,2.227272727272727,1.5,7.863636363636363,1.1363636363636365,10
778,TempoRL: Learning When to Act,8,TempoRL Learning When to Act,40,145,False,71,12,46,18,7,15,5,3,10,28,11831,2.2222222222222223,3.111111111111111,0.6666666666666666,0.2777777777777778,17
781,The Power of Adaptivity for Stochastic Submodular Cover,8,The Power of Adaptivity for Stochastic Submodular Cover,61,144,False,79,71,63,44,14,13,26,1,0,55,22784,1.3863636363636365,1.4318181818181819,1.6136363636363635,0.5909090909090909,8
783,Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations,8,Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations,42,180,False,103,186,26,30,17,13,15,0,4,108,17918,1.4,1.0,6.2,0.5,1
784,Topologically faithful image segmentation via induced matching of persistence barcodes,8,Topologically faithful image segmentation via induced matching of persistence barcodes,53,199,False,61,11,68,30,10,17,17,1,12,86,13088,1.7666666666666666,2.6666666666666665,0.36666666666666664,0.5666666666666667,7
785,"Towards Noise-adaptive, Problem-adaptive (Accelerated) Stochastic Gradient Descent",8,Towards Noise-adaptive Problem-adaptive Accelerated Stochastic Gradient Descent,39,198,False,142,329,4,45,0,12,18,5,0,82,21052,0.8666666666666667,0.08888888888888889,7.311111111111111,0.4,9
786,Tractable structured natural gradient descent using local parameterizations,8,Tractable structured natural gradient descent using local parameterizations,64,1,False,240,623,48,57,0,19,29,13,4,75,30522,1.1228070175438596,0.9122807017543859,10.929824561403509,0.5087719298245614,22
788,Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems,8,Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems,103,203,False,188,20,53,12,0,6,6,0,8,73,8542,8.583333333333334,5.083333333333333,1.6666666666666667,0.5,87
790,Understanding self-supervised Learning Dynamics without Contrastive Pairs,8,Understanding self-supervised Learning Dynamics without Contrastive Pairs,36,121,False,63,214,39,23,4,18,23,4,28,73,15484,1.565217391304348,2.9130434782608696,9.304347826086957,1.0,241
791,Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows,8,Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows,50,135,False,188,128,22,26,0,8,16,14,0,82,16600,1.9230769230769231,0.8461538461538461,4.923076923076923,0.6153846153846154,10
792,Unsupervised Transfer Learning for Spatiotemporal Predictive Networks,8,Unsupervised Transfer Learning for Spatiotemporal Predictive Networks,54,147,False,86,16,21,11,20,6,9,0,12,69,7777,4.909090909090909,3.0,1.4545454545454546,0.8181818181818182,17
793,Value-at-Risk Optimization with Gaussian Processes,8,Value-at-Risk Optimization with Gaussian Processes,25,109,False,73,88,27,14,0,14,9,0,0,50,10524,1.7857142857142858,1.9285714285714286,6.285714285714286,0.6428571428571429,24
794,Variational Wasserstein gradient flow,8,Variational Wasserstein gradient flow,91,176,False,208,172,95,44,8,19,35,6,16,37,15722,2.0681818181818183,2.522727272727273,3.909090909090909,0.7954545454545454,39
796,When Does Self-Supervision Help Graph Convolutional Networks?,8,When Does Self-Supervision Help Graph Convolutional Networks,58,138,False,71,20,6,10,0,6,7,0,16,60,7511,5.8,2.2,2.0,0.7,182
797,Why the Rich Get Richer? On the Balancedness of Random Partition Models,8,Why the Rich Get Richer On the Balancedness of Random Partition Models,92,147,False,158,57,23,21,0,10,20,0,14,70,14528,4.380952380952381,1.7619047619047619,2.7142857142857144,0.9523809523809523,6
798,Zero-Shot Voice Style Transfer with Only Autoencoder Loss,8,Zero-Shot Voice Style Transfer with Only Autoencoder Loss,34,144,False,43,104,23,12,2,7,11,0,2,57,8331,2.8333333333333335,2.0833333333333335,8.666666666666666,0.9166666666666666,376
799,3DLinker: An E(3) Equivariant Variational Autoencoder for Molecular Linker Design,8,3DLinker An E3 Equivariant Variational Autoencoder for Molecular Linker Design,60,205,False,143,44,12,14,0,11,11,0,10,80,8921,4.285714285714286,1.5714285714285714,3.142857142857143,0.7857142857142857,29
800,A Distributed Second-Order Algorithm You Can Trust,8,A Distributed Second-Order Algorithm You Can Trust,28,153,False,42,138,24,18,12,9,17,4,2,50,10585,1.5555555555555556,1.4444444444444444,7.666666666666667,0.9444444444444444,31
801,A Generative Model for Molecular Distance Geometry,8,A Generative Model for Molecular Distance Geometry,49,95,False,76,20,42,19,0,13,11,0,12,50,7845,2.5789473684210527,2.8421052631578947,1.0526315789473684,0.5789473684210527,90
802,A New Perspective on the Effects of Spectrum in Graph Neural Networks,8,A New Perspective on the Effects of Spectrum in Graph Neural Networks,59,120,False,84,100,38,19,0,16,5,0,8,69,10722,3.1052631578947367,2.4210526315789473,5.2631578947368425,0.2631578947368421,15
803,A Scalable Second Order Method for Ill-Conditioned Matrix Completion from Few Samples,8,A Scalable Second Order Method for Ill-Conditioned Matrix Completion from Few Samples,86,141,False,143,295,18,45,0,14,13,0,0,85,21623,1.9111111111111112,0.4,6.555555555555555,0.28888888888888886,14
804,A Theoretical Analysis of Contrastive Unsupervised Representation Learning,8,A Theoretical Analysis of Contrastive Unsupervised Representation Learning,29,393,False,60,204,9,19,0,16,24,3,4,74,12822,1.5263157894736843,0.6842105263157895,10.736842105263158,1.263157894736842,641
806,Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework,8,Accelerate CNNs from Three Dimensions A Comprehensive Pruning Framework,43,210,False,90,96,15,11,20,8,11,4,12,71,8181,3.909090909090909,2.4545454545454546,8.727272727272727,1.0,41
807,Accuracy on the Line: on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization,8,Accuracy on the Line on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization,123,155,False,473,31,145,80,47,20,24,19,6,109,32112,1.5375,1.8875,0.3875,0.3,206
808,Active Testing: Sample-Efficient Model Evaluation,8,Active Testing Sample-Efficient Model Evaluation,58,164,False,114,39,47,20,0,11,28,0,2,48,12397,2.9,2.45,1.95,1.4,33
809,Adaptive Estimation of Graphical Models under Total Positivity,8,Adaptive Estimation of Graphical Models under Total Positivity,61,127,False,212,196,36,26,0,9,13,2,8,62,12568,2.3461538461538463,1.6923076923076923,7.538461538461538,0.5,3
810,Adding Seemingly Uninformative Labels Helps in Low Data Regimes,8,Adding Seemingly Uninformative Labels Helps in Low Data Regimes,35,156,False,46,11,96,16,0,13,13,0,8,63,10121,2.1875,6.5,0.6875,0.8125,8
811,Adversarial Masking for Self-Supervised Learning,8,Adversarial Masking for Self-Supervised Learning,42,190,False,201,80,43,15,35,21,21,0,26,48,9530,2.8,4.6,5.333333333333333,1.4,59
812,Adversarially Robust PAC Learnability of Real-Valued Functions,8,Adversarially Robust PAC Learnability of Real-Valued Functions,72,110,True,114,240,0,30,10,11,3,0,0,62,16955,2.4,0.0,8.0,0.1,1
813,Alternating Randomized Block Coordinate Descent,8,Alternating Randomized Block Coordinate Descent,28,156,False,48,118,16,14,5,9,6,0,0,47,9040,2.0,1.1428571428571428,8.428571428571429,0.42857142857142855,26
814,An Information-Geometric Distance on the Space of Tasks,8,An Information-Geometric Distance on the Space of Tasks,70,187,False,233,23,65,18,11,22,27,0,0,55,13122,3.888888888888889,3.611111111111111,1.2777777777777777,1.5,18
815,Analyzing Diffusion as Serial Reproduction,8,Analyzing Diffusion as Serial Reproduction,29,143,False,55,48,12,10,0,6,2,1,0,42,5060,2.9,1.2,4.8,0.2,4
816,Approximate Message Passing for Amplitude Based Optimization,8,Approximate Message Passing for Amplitude Based Optimization,42,133,False,87,38,22,11,0,6,5,0,0,60,7779,3.8181818181818183,2.0,3.4545454545454546,0.45454545454545453,8
817,Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation,8,Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation,26,97,False,48,24,52,15,0,11,5,4,8,73,8878,1.7333333333333334,4.0,1.6,0.3333333333333333,41
818,AutoSampling: Search for Effective Data Sampling Schedules,8,AutoSampling Search for Effective Data Sampling Schedules,33,140,False,73,20,12,11,0,6,10,0,10,57,6832,3.0,2.0,1.8181818181818181,0.9090909090909091,5
819,BOHB: Robust and Efficient Hyperparameter Optimization at Scale,8,BOHB Robust and Efficient Hyperparameter Optimization at Scale,53,145,True,114,11,79,19,1,18,11,2,8,62,10676,2.789473684210526,4.578947368421052,0.5789473684210527,0.5789473684210527,910
823,Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning,8,Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning,59,166,False,104,42,49,20,1,15,13,2,8,71,11830,2.95,2.85,2.1,0.65,16
824,Boosting for Online Convex Optimization,8,Boosting for Online Convex Optimization,34,138,False,20,57,2,14,0,8,7,0,0,39,5955,2.4285714285714284,0.14285714285714285,4.071428571428571,0.5,4
825,Breaking the Softmax Bottleneck via Learnable Monotonic Pointwise Non-linearities,8,Breaking the Softmax Bottleneck via Learnable Monotonic Pointwise Non-linearities,36,161,False,84,74,29,16,17,15,2,0,4,81,8849,2.25,2.0625,4.625,0.125,17
826,CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection,8,CIFS Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection,53,180,True,68,8,35,16,7,11,13,2,30,97,10710,3.3125,4.0625,0.5,0.8125,27
827,Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?,8,Can Subnetwork Structure be the Key to Out-of-Distribution Generalization,91,122,False,170,24,42,18,0,11,11,0,18,73,12491,5.055555555555555,3.3333333333333335,1.3333333333333333,0.6111111111111112,83
829,Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the Orthogonal and Unitary Group,8,Cheap Orthogonal Constraints in Neural Networks A Simple Parametrization of the Orthogonal and Unitary Group,43,1,False,69,78,8,20,14,12,13,0,6,108,12814,2.15,0.7,3.9,0.65,161
830,Co-manifold learning with missing data,8,Co-manifold learning with missing data,40,158,False,34,66,27,16,0,8,7,0,0,38,7365,2.5,1.6875,4.125,0.4375,12
832,Composable Planning with Attributes,8,Composable Planning with Attributes,48,187,False,45,4,15,13,0,9,6,0,12,35,9386,3.6923076923076925,2.076923076923077,0.3076923076923077,0.46153846153846156,57
833,Concept Bottleneck Models,8,Concept Bottleneck Models,42,1,False,106,48,25,19,0,14,12,1,6,25,12591,2.210526315789474,1.631578947368421,2.526315789473684,0.631578947368421,474
834,Connectivity-Optimized Representation Learning via Persistent Homology,8,Connectivity-Optimized Representation Learning via Persistent Homology,52,135,False,69,135,37,15,0,17,8,0,2,70,11220,3.466666666666667,2.6,9.0,0.5333333333333333,65
835,Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks,8,Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks,21,110,False,29,70,9,10,0,7,3,0,0,90,7075,2.1,0.9,7.0,0.3,14
836,Continuous-Time Bayesian Networks with Clocks,8,Continuous-Time Bayesian Networks with Clocks,26,135,False,26,72,9,17,0,10,15,8,0,45,11522,1.5294117647058822,0.5294117647058824,4.235294117647059,0.8823529411764706,1
837,Convergence of Invariant Graph Networks,8,Convergence of Invariant Graph Networks,54,183,False,123,66,39,29,0,16,15,0,8,39,19516,1.8620689655172413,1.6206896551724137,2.2758620689655173,0.5172413793103449,2
838,Coresets for Ordered Weighted Clustering,8,Coresets for Ordered Weighted Clustering,28,258,False,17,46,12,23,10,5,8,0,4,40,11636,1.2173913043478262,0.6956521739130435,2.0,0.34782608695652173,21
839,Cross-domain Imitation from Observations,8,Cross-domain Imitation from Observations,46,204,False,59,23,25,13,0,10,9,0,0,40,8553,3.5384615384615383,1.9230769230769231,1.7692307692307692,0.6923076923076923,28
840,DANCE: Enhancing saliency maps using decoys,8,DANCE Enhancing saliency maps using decoys,61,211,True,100,28,12,10,0,6,9,2,0,42,7394,6.1,1.2,2.8,0.9,10
841,Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP),8,Data Determines Distributional Robustness in Contrastive Language Image Pre-training CLIP,41,131,True,119,1,38,23,2,22,9,0,22,91,9218,1.7826086956521738,2.608695652173913,0.043478260869565216,0.391304347826087,87
842,DeBayes: a Bayesian method for debiasing network embeddings,8,DeBayes a Bayesian method for debiasing network embeddings,25,134,False,39,22,16,10,0,7,12,0,2,58,7171,2.5,1.8,2.2,1.2,62
843,Decoupling Representation Learning from Reinforcement Learning,8,Decoupling Representation Learning from Reinforcement Learning,42,190,False,118,4,48,16,15,12,21,4,18,62,8283,2.625,4.125,0.25,1.3125,261
844,DeepWalking Backwards: From Embeddings Back to Graphs,8,DeepWalking Backwards From Embeddings Back to Graphs,31,159,False,68,17,52,16,0,6,6,0,4,52,7199,1.9375,3.5,1.0625,0.375,10
845,Describing Differences between Text Distributions with Natural Language,8,Describing Differences between Text Distributions with Natural Language,82,147,False,101,14,24,18,0,15,4,0,6,71,11083,4.555555555555555,1.6666666666666667,0.7777777777777778,0.2222222222222222,20
846,Differentiable Linearized ADMM,8,Differentiable Linearized ADMM,40,186,True,47,153,12,16,0,9,17,0,6,30,10087,2.5,1.125,9.5625,1.0625,58
847,Differentially Private Set Union,8,Differentially Private Set Union,23,289,False,30,40,30,27,0,17,16,7,8,32,12208,0.8518518518518519,1.4074074074074074,1.4814814814814814,0.5925925925925926,27
849,Disentangling Sampling and Labeling Bias for Learning in Large-Output Spaces,8,Disentangling Sampling and Labeling Bias for Learning in Large-Output Spaces,44,100,False,109,48,70,26,0,15,15,0,8,76,10498,1.6923076923076923,3.0,1.8461538461538463,0.5769230769230769,9
850,Distributionally Robust Optimization with Markovian Data,8,Distributionally Robust Optimization with Markovian Data,51,155,False,258,332,34,20,4,22,6,0,0,56,14378,2.55,1.7,16.6,0.3,5
851,Does the Markov Decision Process Fit the Data: Testing for the Markov Property in Sequential Decision Making,8,Does the Markov Decision Process Fit the Data Testing for the Markov Property in Sequential Decision Making,41,87,False,76,234,15,25,0,8,20,12,2,107,13648,1.64,0.68,9.36,0.8,26
852,DynaMixer: A Vision MLP Architecture with Dynamic Mixing,8,DynaMixer A Vision MLP Architecture with Dynamic Mixing,58,148,True,119,10,9,11,14,5,11,0,18,55,8163,5.2727272727272725,2.4545454545454546,0.9090909090909091,1.0,33
853,Efficient Continuous Pareto Exploration in Multi-Task Learning,8,Efficient Continuous Pareto Exploration in Multi-Task Learning,32,179,False,52,64,63,22,9,14,23,2,6,62,13638,1.4545454545454546,3.1363636363636362,2.909090909090909,1.0454545454545454,67
854,Efficient Optimization of Loops and Limits with Randomized Telescoping Sums,8,Efficient Optimization of Loops and Limits with Randomized Telescoping Sums,46,196,False,87,72,9,19,0,12,15,8,0,75,9828,2.4210526315789473,0.47368421052631576,3.789473684210526,0.7894736842105263,20
855,Efficiently Learning Adversarially Robust Halfspaces with Noise,8,Efficiently Learning Adversarially Robust Halfspaces with Noise,33,57,False,28,80,0,18,3,8,4,0,0,63,9182,1.8333333333333333,0.0,4.444444444444445,0.2222222222222222,30
856,Ensemble Bootstrapping for Q-Learning,8,Ensemble Bootstrapping for Q-Learning,38,142,False,94,74,34,19,0,13,11,0,2,37,10271,2.0,1.894736842105263,3.8947368421052633,0.5789473684210527,27
857,Error Estimation for Sketched SVD via the Bootstrap,8,Error Estimation for Sketched SVD via the Bootstrap,53,187,True,65,245,12,33,23,9,13,4,0,51,18039,1.606060606060606,0.36363636363636365,7.424242424242424,0.3939393939393939,11
858,Evaluating Lossy Compression Rates of Deep Generative Models,8,Evaluating Lossy Compression Rates of Deep Generative Models,51,157,False,128,86,66,20,0,12,19,0,0,60,11626,2.55,3.3,4.3,0.95,21
859,Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation,8,Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation,46,120,False,66,22,9,10,0,6,10,0,0,97,7738,4.6,0.9,2.2,1.0,183
860,Expression might be enough: representing pressure and demand for reinforcement learning based traffic signal control,8,Expression might be enough representing pressure and demand for reinforcement learning based traffic signal control,29,154,False,114,36,30,10,6,22,20,16,8,115,6540,2.9,3.8,3.6,2.0,15
861,Fair Online Advertising,8,Fair Online Advertising,31,210,False,44,202,29,37,4,12,14,4,0,23,14861,0.8378378378378378,0.7837837837837838,5.45945945945946,0.3783783783783784,1
862,Fast Finite Width Neural Tangent Kernel,8,Fast Finite Width Neural Tangent Kernel,75,195,False,186,60,23,27,0,9,20,15,10,39,17738,2.7777777777777777,1.2222222222222223,2.2222222222222223,0.7407407407407407,40
864,Feature-Critic Networks for Heterogeneous Domain Generalization,8,Feature-Critic Networks for Heterogeneous Domain Generalization,43,154,False,68,18,15,10,0,6,8,2,12,63,7080,4.3,2.7,1.8,0.8,226
866,Finite mixture models do not reliably learn the number of components,8,Finite mixture models do not reliably learn the number of components,89,1,False,168,31,20,25,7,12,8,0,0,68,11247,3.56,0.8,1.24,0.32,19
868,From ImageNet to Image Classification: Contextualizing Progress on Benchmarks,8,From ImageNet to Image Classification Contextualizing Progress on Benchmarks,44,1,False,125,0,117,33,23,12,16,4,2,76,15482,1.3333333333333333,3.606060606060606,0.0,0.48484848484848486,120
869,Functional Gradient Boosting based on Residual Network Perception,8,Functional Gradient Boosting based on Residual Network Perception,41,158,False,50,174,3,22,10,10,3,0,2,65,12412,1.8636363636363635,0.22727272727272727,7.909090909090909,0.13636363636363635,24
870,GLSearch: Maximum Common Subgraph Detection via Learning to Search,8,GLSearch Maximum Common Subgraph Detection via Learning to Search,64,193,False,154,12,96,37,3,13,28,2,18,65,17702,1.7297297297297298,3.081081081081081,0.32432432432432434,0.7567567567567568,22
871,GenLabel: Mixup Relabeling using Generative Models,8,GenLabel Mixup Relabeling using Generative Models,69,111,False,148,172,50,40,23,15,31,3,28,49,25771,1.725,1.95,4.3,0.775,11
872,Generalized Neural Policies for Relational MDPs,8,Generalized Neural Policies for Relational MDPs,36,260,False,43,0,17,15,0,10,20,0,20,47,10270,2.4,2.466666666666667,0.0,1.3333333333333333,4
873,Generative Flow Networks for Discrete Probabilistic Modeling,8,Generative Flow Networks for Discrete Probabilistic Modeling,61,117,False,276,78,148,17,12,20,24,0,24,60,10906,3.588235294117647,10.117647058823529,4.588235294117647,1.411764705882353,61
874,Global Convergence of Block Coordinate Descent in Deep Learning,8,Global Convergence of Block Coordinate Descent in Deep Learning,61,155,False,228,191,4,27,0,13,13,7,0,63,19001,2.259259259259259,0.14814814814814814,7.074074074074074,0.48148148148148145,59
875,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,8,Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers,38,164,False,124,135,24,32,0,11,6,0,14,116,15358,1.1875,1.1875,4.21875,0.1875,22
876,Graph networks as learnable physics engines for inference and control,8,Graph networks as learnable physics engines for inference and control,53,1,False,43,14,13,21,19,16,16,10,4,69,12435,2.5238095238095237,0.8095238095238095,0.6666666666666666,0.7619047619047619,539
877,Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation,8,Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation,45,173,False,88,200,9,24,11,13,6,4,0,80,15106,1.875,0.375,8.333333333333334,0.25,24
878,Hierarchical Generation of Molecular Graphs using Structural Motifs,8,Hierarchical Generation of Molecular Graphs using Structural Motifs,51,149,False,102,40,30,14,0,8,8,2,8,67,9294,3.642857142857143,2.7142857142857144,2.857142857142857,0.5714285714285714,225
879,History Compression via Language Models in Reinforcement Learning,8,History Compression via Language Models in Reinforcement Learning,115,128,False,212,22,71,32,0,12,8,0,0,65,16418,3.59375,2.21875,0.6875,0.25,31
880,How to Leverage Unlabeled Data in Offline Reinforcement Learning,8,How to Leverage Unlabeled Data in Offline Reinforcement Learning,67,204,False,390,180,18,25,0,32,34,2,52,64,17488,2.68,2.8,7.2,1.36,41
881,"IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages",8,IGLUE A Benchmark for Transfer Learning across Modalities Tasks and Languages,108,168,True,243,2,39,23,0,11,15,0,34,79,16771,4.695652173913044,3.1739130434782608,0.08695652173913043,0.6521739130434783,42
882,Implicit Geometric Regularization for Learning Shapes,8,Implicit Geometric Regularization for Learning Shapes,56,155,False,61,28,52,14,23,12,8,0,2,53,8879,4.0,3.857142857142857,2.0,0.5714285714285714,633
883,Improved Convergence Rates for Sparse Approximation Methods in Kernel-Based Learning,8,Improved Convergence Rates for Sparse Approximation Methods in Kernel-Based Learning,49,146,False,115,187,0,25,12,15,19,0,0,84,13867,1.96,0.0,7.48,0.76,13
884,Improving Generalization in Meta-learning via Task Augmentation,8,Improving Generalization in Meta-learning via Task Augmentation,51,188,False,100,106,34,24,0,15,17,6,30,63,14481,2.125,2.6666666666666665,4.416666666666667,0.7083333333333334,64
885,Improving language models by retrieving from trillions of tokens,8,Improving language models by retrieving from trillions of tokens,65,124,False,326,28,72,43,36,26,56,10,52,64,23656,1.5116279069767442,2.883720930232558,0.6511627906976745,1.302325581395349,606
886,Inductive Matrix Completion: No Bad Local Minima and a Fast Algorithm,8,Inductive Matrix Completion No Bad Local Minima and a Fast Algorithm,47,142,False,77,170,15,24,0,16,11,0,4,68,13009,1.9583333333333333,0.7916666666666666,7.083333333333333,0.4583333333333333,7
887,Input Dependent Sparse Gaussian Processes,8,Input Dependent Sparse Gaussian Processes,37,268,False,74,12,17,14,0,8,8,0,16,41,7436,2.642857142857143,2.357142857142857,0.8571428571428571,0.5714285714285714,3
888,Interpolation between Residual and Non-Residual Networks,8,Interpolation between Residual and Non-Residual Networks,25,143,False,57,52,30,16,0,10,10,0,28,56,7947,1.5625,3.625,3.25,0.625,10
889,Invariance in Policy Optimisation and Partial Identifiability in Reward Learning,8,Invariance in Policy Optimisation and Partial Identifiability in Reward Learning,66,121,False,107,63,8,26,0,12,19,0,4,80,17642,2.5384615384615383,0.46153846153846156,2.423076923076923,0.7307692307692307,24
890,"It's Not What Machines Can Learn, It's What We Cannot Teach",8,Its Not What Machines Can Learn Its What We Cannot Teach,56,1,False,68,13,11,13,9,7,10,0,4,59,10170,4.3076923076923075,1.1538461538461537,1.0,0.7692307692307693,31
894,LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation,8,LeNSE Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation,83,203,False,61,20,14,17,0,11,10,0,10,89,11322,4.882352941176471,1.411764705882353,1.1764705882352942,0.5882352941176471,5
895,Learning Control by Iterative Inversion,8,Learning Control by Iterative Inversion,55,171,False,101,84,48,28,4,10,28,6,16,39,13710,1.9642857142857142,2.2857142857142856,3.0,1.0,1
896,Learning GFlowNets from partial episodes for improved convergence and stability,8,Learning GFlowNets from partial episodes for improved convergence and stability,54,165,False,138,32,45,17,15,12,8,4,4,79,10814,3.176470588235294,2.8823529411764706,1.8823529411764706,0.47058823529411764,48
897,Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits,8,Learning Markov Games with Adversarial Opponents Efficient Algorithms and Fundamental Limits,42,204,False,80,60,6,25,15,11,13,0,2,92,11390,1.68,0.32,2.4,0.52,11
898,Learning Reasoning Strategies in End-to-End Differentiable Proving,8,Learning Reasoning Strategies in End-to-End Differentiable Proving,59,143,False,142,25,6,12,24,7,4,0,0,66,9088,4.916666666666667,0.5,2.0833333333333335,0.3333333333333333,79
899,Learning a Prior over Intent via Meta-Inverse Reinforcement Learning,8,Learning a Prior over Intent via Meta-Inverse Reinforcement Learning,65,170,False,113,34,3,15,9,11,8,1,10,68,10341,4.333333333333333,0.8666666666666667,2.2666666666666666,0.5333333333333333,60
900,Learning selection strategies in Buchberger's algorithm,8,Learning selection strategies in Buchbergers algorithm,49,146,False,46,23,24,14,0,11,19,1,14,55,9568,3.5,2.7142857142857144,1.6428571428571428,1.3571428571428572,26
901,Learning to Learn Kernels with Variational Random Features,8,Learning to Learn Kernels with Variational Random Features,61,163,False,186,48,23,16,0,8,13,4,30,58,9576,3.8125,3.3125,3.0,0.8125,32
903,Leveraging Sparse Linear Layers for Debuggable Deep Networks,8,Leveraging Sparse Linear Layers for Debuggable Deep Networks,64,78,False,145,14,168,44,29,15,27,5,10,60,17028,1.4545454545454546,4.045454545454546,0.3181818181818182,0.6136363636363636,72
904,Link Prediction with Persistent Homology: An Interactive View,8,Link Prediction with Persistent Homology An Interactive View,60,95,False,78,0,37,20,0,11,15,0,10,60,13675,3.0,2.35,0.0,0.75,32
905,Logistic Regression for Massive Data with Rare Events,8,Logistic Regression for Massive Data with Rare Events,19,198,False,26,209,4,28,0,12,7,0,2,53,9399,0.6785714285714286,0.21428571428571427,7.464285714285714,0.25,10
906,Lyapunov Density Models: Constraining Distribution Shift in Learning-Based Control,8,Lyapunov Density Models Constraining Distribution Shift in Learning-Based Control,42,158,False,50,70,33,26,0,15,19,6,0,81,16661,1.6153846153846154,1.2692307692307692,2.6923076923076925,0.7307692307692307,14
907,Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits,8,Make the Minority Great Again First-Order Regret Bound for Contextual Bandits,8,127,False,8,80,0,15,0,8,10,1,0,77,6762,0.5333333333333333,0.0,5.333333333333333,0.6666666666666666,27
908,Maximal Initial Learning Rates in Deep ReLU Networks,8,Maximal Initial Learning Rates in Deep ReLU Networks,44,191,False,99,161,39,31,0,15,11,0,0,52,15134,1.4193548387096775,1.2580645161290323,5.193548387096774,0.3548387096774194,6
910,Metric-Fair Classifier Derandomization,8,Metric-Fair Classifier Derandomization,38,187,False,36,122,0,20,6,7,20,0,0,38,10718,1.9,0.0,6.1,1.0,5
912,Model Transferability with Responsive Decision Subjects,8,Model Transferability with Responsive Decision Subjects,67,205,False,81,173,32,32,19,15,32,2,0,55,17962,2.09375,1.0,5.40625,1.0,9
913,Modeling Structure with Undirected Neural Networks,8,Modeling Structure with Undirected Neural Networks,40,180,False,154,256,78,17,38,28,4,0,32,50,10741,2.3529411764705883,6.470588235294118,15.058823529411764,0.23529411764705882,0
914,More Efficient Sampling for Tensor Decomposition,8,More Efficient Sampling for Tensor Decomposition,92,103,False,254,294,15,31,14,11,23,10,18,48,18544,2.967741935483871,1.064516129032258,9.483870967741936,0.7419354838709677,12
915,Multi-Precision Policy Enforced Training (MuPPET): A precision-switching strategy for quantised fixed-point training of CNNs,8,Multi-Precision Policy Enforced Training MuPPET A precision-switching strategy for quantised fixed-point training of CNNs,43,217,False,57,24,52,21,0,7,7,3,6,123,7012,2.0476190476190474,2.761904761904762,1.1428571428571428,0.3333333333333333,12
916,Multirate Training of Neural Networks,8,Multirate Training of Neural Networks,57,154,False,72,66,43,19,0,14,9,0,12,37,11932,3.0,2.8947368421052633,3.473684210526316,0.47368421052631576,4
917,Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning,8,Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning,48,142,False,67,30,34,14,0,9,9,0,2,70,8155,3.4285714285714284,2.5714285714285716,2.142857142857143,0.6428571428571429,16
918,Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization,8,Nesterov Meets Optimism Rate-Optimal Separable Minimax Optimization,58,130,False,238,386,15,44,21,13,27,0,2,67,20169,1.3181818181818181,0.38636363636363635,8.772727272727273,0.6136363636363636,1
920,Neuro-Symbolic Hierarchical Rule Induction,8,Neuro-Symbolic Hierarchical Rule Induction,48,107,False,120,158,15,36,28,9,11,7,28,42,17290,1.3333333333333333,1.1944444444444444,4.388888888888889,0.3055555555555556,14
921,Non-Parametric Priors For Generative Adversarial Networks,8,Non-Parametric Priors For Generative Adversarial Networks,32,164,False,46,18,21,10,12,6,2,0,12,57,6968,3.2,3.3,1.8,0.2,13
922,Normalized Loss Functions for Deep Learning with Noisy Labels,8,Normalized Loss Functions for Deep Learning with Noisy Labels,39,165,False,64,37,22,13,0,8,10,0,10,61,9666,3.0,2.4615384615384617,2.8461538461538463,0.7692307692307693,331
923,Off-Policy Deep Reinforcement Learning without Exploration,8,Off-Policy Deep Reinforcement Learning without Exploration,88,139,False,130,70,58,23,0,14,11,0,2,58,15012,3.8260869565217392,2.608695652173913,3.0434782608695654,0.4782608695652174,1187
924,On Connected Sublevel Sets in Deep Learning,8,On Connected Sublevel Sets in Deep Learning,46,52,False,21,154,18,16,2,18,3,0,0,43,13783,2.875,1.125,9.625,0.1875,88
925,On Layer Normalization in the Transformer Architecture,8,On Layer Normalization in the Transformer Architecture,57,206,False,126,74,27,17,23,13,9,0,2,54,11827,3.3529411764705883,1.7058823529411764,4.352941176470588,0.5294117647058824,648
926,On Scalable and Efficient Computation of Large Scale Optimal Transport,8,On Scalable and Efficient Computation of Large Scale Optimal Transport,62,132,False,222,100,30,21,0,20,14,0,24,70,8093,2.9523809523809526,2.5714285714285716,4.761904761904762,0.6666666666666666,39
927,On the Difficulty of Defending Self-Supervised Learning against Model Extraction,8,On the Difficulty of Defending Self-Supervised Learning against Model Extraction,32,28,False,12,0,3,20,0,6,12,4,2,80,12154,1.6,0.25,0.0,0.6,13
928,On the Inherent Regularization Effects of Noise Injection During Training,8,On the Inherent Regularization Effects of Noise Injection During Training,43,140,False,63,347,33,31,0,8,16,6,0,73,18193,1.3870967741935485,1.064516129032258,11.193548387096774,0.5161290322580645,15
929,On the Role of Discount Factor in Offline Reinforcement Learning,8,On the Role of Discount Factor in Offline Reinforcement Learning,49,186,False,105,222,93,27,7,10,16,9,12,64,14236,1.8148148148148149,3.888888888888889,8.222222222222221,0.5925925925925926,12
930,One-shot distributed ridge regression in high dimensions,8,One-shot distributed ridge regression in high dimensions,71,200,False,72,98,41,48,0,8,26,0,0,56,19718,1.4791666666666667,0.8541666666666666,2.0416666666666665,0.5416666666666666,48
931,Online Linear Quadratic Control,8,Online Linear Quadratic Control,39,82,False,47,228,6,22,0,10,18,0,0,31,10995,1.7727272727272727,0.2727272727272727,10.363636363636363,0.8181818181818182,128
933,Optimal Robust Learning of Discrete Distributions from Batches,8,Optimal Robust Learning of Discrete Distributions from Batches,16,75,False,25,126,6,22,1,8,16,0,0,62,10375,0.7272727272727273,0.2727272727272727,5.7272727272727275,0.7272727272727273,11
934,Optimizing Black-box Metrics with Iterative Example Weighting,8,Optimizing Black-box Metrics with Iterative Example Weighting,59,142,False,129,158,16,42,0,17,14,0,14,61,19441,1.4047619047619047,0.7142857142857143,3.761904761904762,0.3333333333333333,3
935,Outlier-Robust Optimal Transport,8,Outlier-Robust Optimal Transport,51,135,False,140,227,11,19,19,22,31,0,12,32,13172,2.6842105263157894,1.2105263157894737,11.947368421052632,1.631578947368421,41
936,PC-MLP: Model-based Reinforcement Learning with Policy Cover Guided Exploration,8,PC-MLP Model-based Reinforcement Learning with Policy Cover Guided Exploration,55,138,True,102,176,32,24,3,21,27,8,14,78,13129,2.2916666666666665,1.9166666666666667,7.333333333333333,1.125,17
938,Particle Transformer for Jet Tagging,8,Particle Transformer for Jet Tagging,68,152,False,95,14,9,12,0,7,2,0,12,36,9095,5.666666666666667,1.75,1.1666666666666667,0.16666666666666666,49
939,Perturbation Analysis of Neural Collapse,8,Perturbation Analysis of Neural Collapse,33,215,False,72,198,58,29,0,12,5,0,2,40,16956,1.1379310344827587,2.0689655172413794,6.827586206896552,0.1724137931034483,13
940,Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets,8,Pocket2Mol Efficient Molecular Sampling Based on 3D Protein Pockets,42,0,False,16,10,6,12,0,6,2,0,6,67,7981,3.5,1.0,0.8333333333333334,0.16666666666666666,93
941,Position Prediction as an Effective Pretraining Strategy,8,Position Prediction as an Effective Pretraining Strategy,42,234,False,74,0,52,18,0,11,6,5,16,56,11252,2.3333333333333335,3.7777777777777777,0.0,0.3333333333333333,16
942,Preference Modeling with Context-Dependent Salient Features,8,Preference Modeling with Context-Dependent Salient Features,45,146,False,66,64,40,43,17,45,21,0,8,59,22639,1.0465116279069768,1.1162790697674418,1.4883720930232558,0.4883720930232558,10
943,Private Adaptive Optimization with Side Information,8,Private Adaptive Optimization with Side Information,36,122,False,72,132,18,20,8,11,10,5,20,51,11634,1.8,1.9,6.6,0.5,28
945,Prototype Based Classification from Hierarchy to Fairness,8,Prototype Based Classification from Hierarchy to Fairness,31,132,False,86,10,31,17,0,12,9,0,16,57,9985,1.8235294117647058,2.764705882352941,0.5882352941176471,0.5294117647058824,3
946,Provably Efficient Imitation Learning from Observation Alone,8,Provably Efficient Imitation Learning from Observation Alone,51,169,False,87,184,20,26,10,23,11,0,0,60,16812,1.9615384615384615,0.7692307692307693,7.076923076923077,0.4230769230769231,88
947,Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL,8,Q-learning Decision Transformer Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL,52,177,True,112,24,27,19,3,12,15,1,30,111,11296,2.736842105263158,3.0,1.263157894736842,0.7894736842105263,37
948,Quantum Policy Gradient Algorithm with Optimized Action Decoding,8,Quantum Policy Gradient Algorithm with Optimized Action Decoding,63,102,False,91,74,12,22,0,15,17,2,0,64,14853,2.8636363636363638,0.5454545454545454,3.3636363636363638,0.7727272727272727,12
949,Rademacher Complexity for Adversarially Robust Generalization,8,Rademacher Complexity for Adversarially Robust Generalization,64,198,False,109,104,9,21,4,10,15,2,0,61,10305,3.0476190476190474,0.42857142857142855,4.9523809523809526,0.7142857142857143,231
950,RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank,8,RankMe Assessing the downstream performance of pretrained self-supervised representations by their rank,63,216,False,79,16,59,46,0,18,7,0,56,103,17870,1.3695652173913044,2.5,0.34782608695652173,0.15217391304347827,32
951,Recovery of Sparse Signals from a Mixture of Linear Samples,8,Recovery of Sparse Signals from a Mixture of Linear Samples,27,154,False,57,144,5,26,9,10,9,7,0,59,12154,1.0384615384615385,0.19230769230769232,5.538461538461538,0.34615384615384615,10
953,Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions,8,Repairing without Retraining Avoiding Disparate Impact with Counterfactual Distributions,73,160,False,67,162,9,21,14,9,11,2,6,88,11355,3.4761904761904763,0.7142857142857143,7.714285714285714,0.5238095238095238,70
954,Rethinking Batch Normalization in Transformers,8,Rethinking Batch Normalization in Transformers,52,241,False,95,93,25,18,17,10,14,1,8,46,10258,2.888888888888889,1.8333333333333333,5.166666666666667,0.7777777777777778,16
955,Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline,8,Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline,71,156,False,136,0,15,12,0,6,4,0,14,80,8307,5.916666666666667,2.4166666666666665,0.0,0.3333333333333333,152
956,Robin Hood and Matthew Effects: Differential Privacy Has Disparate Impact on Synthetic Data,8,Robin Hood and Matthew Effects Differential Privacy Has Disparate Impact on Synthetic Data,65,166,False,75,12,81,16,0,6,14,0,0,90,10646,4.0625,5.0625,0.75,0.875,39
957,Robust Outlier Arm Identification,8,Robust Outlier Arm Identification,44,203,False,88,165,17,26,0,15,18,0,0,33,16280,1.6923076923076923,0.6538461538461539,6.346153846153846,0.6923076923076923,2
959,SGD with large step sizes learns sparse features,8,SGD with large step sizes learns sparse features,63,191,True,0,2,0,23,0,5,2,0,0,48,13877,2.739130434782609,0.0,0.08695652173913043,0.08695652173913043,39
960,Safe Reinforcement Learning with Linear Function Approximation,8,Safe Reinforcement Learning with Linear Function Approximation,37,156,False,44,184,8,25,1,10,13,0,0,62,14861,1.48,0.32,7.36,0.52,27
961,Scalable Deep Generative Modeling for Sparse Graphs,8,Scalable Deep Generative Modeling for Sparse Graphs,45,171,False,151,28,20,13,4,8,13,6,14,51,10173,3.4615384615384617,2.6153846153846154,2.1538461538461537,1.0,60
963,SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation,8,SegCLIP Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation,73,151,False,67,14,21,12,2,6,12,0,8,90,7966,6.083333333333333,2.4166666666666665,1.1666666666666667,1.0,77
964,Self-Tuning for Data-Efficient Deep Learning,8,Self-Tuning for Data-Efficient Deep Learning,42,198,False,105,14,28,11,6,7,14,0,10,44,7528,3.8181818181818183,3.4545454545454546,1.2727272727272727,1.2727272727272727,52
965,Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts,8,Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts,74,130,False,146,330,24,21,0,14,14,0,4,76,12445,3.5238095238095237,1.3333333333333333,15.714285714285714,0.6666666666666666,16
966,Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks,8,Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks,58,174,False,154,72,133,30,28,18,33,0,10,72,17104,1.9333333333333333,4.766666666666667,2.4,1.1,2
967,SinIR: Efficient General Image Manipulation with Single Image Reconstruction,8,SinIR Efficient General Image Manipulation with Single Image Reconstruction,58,149,False,84,4,48,20,10,7,4,3,6,75,7436,2.9,2.7,0.2,0.2,17
968,SoQal: Selective Oracle Questioning for Consistency Based Active Learning of Cardiac Signals,8,SoQal Selective Oracle Questioning for Consistency Based Active Learning of Cardiac Signals,36,151,False,88,108,226,39,6,42,66,8,44,91,14179,0.9230769230769231,6.923076923076923,2.769230769230769,1.6923076923076923,0
969,Sparse Mixed Linear Regression with Guarantees: Taming an Intractable Problem with Invex Relaxation,8,Sparse Mixed Linear Regression with Guarantees Taming an Intractable Problem with Invex Relaxation,34,168,False,100,362,5,23,15,17,9,0,0,98,11048,1.4782608695652173,0.21739130434782608,15.73913043478261,0.391304347826087,5
970,SpreadsheetCoder: Formula Prediction from Semi-structured Context,8,SpreadsheetCoder Formula Prediction from Semi-structured Context,55,159,False,160,0,48,14,6,21,10,8,16,64,9871,3.9285714285714284,4.571428571428571,0.0,0.7142857142857143,32
971,State-Reification Networks: Improving Generalization by Modeling the Distribution of Hidden Representations,8,State-Reification Networks Improving Generalization by Modeling the Distribution of Hidden Representations,45,149,False,104,18,26,10,0,7,12,4,4,106,7601,4.5,3.0,1.8,1.2,3
972,Stochastic Gauss-Newton Algorithms for Nonconvex Compositional Optimization,8,Stochastic Gauss-Newton Algorithms for Nonconvex Compositional Optimization,42,137,False,121,310,38,32,0,13,20,0,6,75,19422,1.3125,1.375,9.6875,0.625,18
974,Structural Entropy Guided Graph Hierarchical Pooling,8,Structural Entropy Guided Graph Hierarchical Pooling,36,147,False,170,40,92,14,58,14,20,0,20,52,8670,2.5714285714285716,8.0,2.857142857142857,1.4285714285714286,38
976,Surrogate Likelihoods for Variational Annealed Importance Sampling,8,Surrogate Likelihoods for Variational Annealed Importance Sampling,68,142,False,180,164,18,21,0,10,23,6,14,66,13101,3.238095238095238,1.5238095238095237,7.809523809523809,1.0952380952380953,10
977,TabDDPM: Modelling Tabular Data with Diffusion Models,8,TabDDPM Modelling Tabular Data with Diffusion Models,57,196,False,95,23,12,15,0,9,3,0,18,52,6352,3.8,2.0,1.5333333333333334,0.2,80
978,Temporal Difference Learning as Gradient Splitting,8,Temporal Difference Learning as Gradient Splitting,27,156,False,85,161,0,23,0,9,8,0,0,50,12274,1.173913043478261,0.0,7.0,0.34782608695652173,11
979,The Boomerang Sampler,8,The Boomerang Sampler,25,182,False,34,132,18,15,0,11,12,0,0,21,10061,1.6666666666666667,1.2,8.8,0.8,27
980,The Hierarchical Adaptive Forgetting Variational Filter,8,The Hierarchical Adaptive Forgetting Variational Filter,36,162,False,41,49,18,10,1,6,6,0,0,55,7674,3.6,1.8,4.9,0.6,4
981,The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces,8,The Power of Exploiter Provable Multi-Agent RL in Large State Spaces,69,1,True,119,202,0,38,17,13,19,6,0,68,17251,1.8157894736842106,0.0,5.315789473684211,0.5,42
982,The limits of min-max optimization algorithms: convergence to spurious non-critical sets,8,The limits of min-max optimization algorithms convergence to spurious non-critical sets,111,1,False,181,279,31,36,1,9,18,3,0,87,17733,3.0833333333333335,0.8611111111111112,7.75,0.5,65
983,Tight Kernel Query Complexity of Kernel Ridge Regression and Kernel k-means Clustering,8,Tight Kernel Query Complexity of Kernel Ridge Regression and Kernel k-means Clustering,30,143,False,57,0,4,27,6,6,17,8,0,86,15978,1.1111111111111112,0.14814814814814814,0.0,0.6296296296296297,6
985,Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning,8,Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning,42,138,False,154,44,64,26,0,16,19,3,6,62,18662,1.6153846153846154,2.6923076923076925,1.6923076923076923,0.7307692307692307,43
986,Traditional and Heavy-Tailed Self Regularization in Neural Network Models,8,Traditional and Heavy-Tailed Self Regularization in Neural Network Models,53,195,False,32,8,35,16,6,7,3,0,4,73,7699,3.3125,2.4375,0.5,0.1875,106
988,Two Routes to Scalable Credit Assignment without Weight Symmetry,8,Two Routes to Scalable Credit Assignment without Weight Symmetry,36,220,False,110,12,59,19,0,11,14,4,12,64,13422,1.894736842105263,3.736842105263158,0.631578947368421,0.7368421052631579,27
989,Understanding Geometry of Encoder-Decoder CNNs,8,Understanding Geometry of Encoder-Decoder CNNs,43,129,False,78,176,3,15,0,14,10,2,0,46,9367,2.8666666666666667,0.2,11.733333333333333,0.6666666666666666,63
991,Universal Multi-Party Poisoning Attacks,8,Universal Multi-Party Poisoning Attacks,42,206,False,73,42,0,22,19,5,5,2,0,39,10500,1.9090909090909092,0.0,1.9090909090909092,0.22727272727272727,33
992,Unsupervised label noise modeling and loss correction,8,Unsupervised label noise modeling and loss correction,44,132,False,87,33,20,12,6,8,9,0,12,53,8449,3.6666666666666665,2.6666666666666665,2.75,0.75,497
993,Variable Skipping for Autoregressive Range Density Estimation,8,Variable Skipping for Autoregressive Range Density Estimation,29,1,False,35,23,32,10,0,5,11,0,10,61,6935,2.9,4.2,2.3,1.1,4
994,Vector Quantized Models for Planning,8,Vector Quantized Models for Planning,64,135,False,133,16,44,15,14,7,8,13,2,36,9187,4.266666666666667,3.066666666666667,1.0666666666666667,0.5333333333333333,34
995,Weakly-Supervised Disentanglement Without Compromises,8,Weakly-Supervised Disentanglement Without Compromises,79,152,False,174,26,67,24,6,9,9,4,18,53,12582,3.2916666666666665,3.5416666666666665,1.0833333333333333,0.375,245
996,When Explanations Lie: Why Many Modified BP Attributions Fail,8,When Explanations Lie Why Many Modified BP Attributions Fail,62,148,True,103,86,58,20,29,15,2,0,0,60,11724,3.1,2.9,4.3,0.1,110
997,Wide Bayesian neural networks have a simple weight posterior: theory and accelerated sampling,8,Wide Bayesian neural networks have a simple weight posterior theory and accelerated sampling,65,208,False,131,113,35,20,0,13,16,8,0,92,14456,3.25,1.75,5.65,0.8,3
999,3PC: Three Point Compressors for Communication-Efficient Distributed Training and a Better Theory for Lazy Aggregation,8,3PC Three Point Compressors for Communication-Efficient Distributed Training and a Better Theory for Lazy Aggregation,39,173,False,118,274,78,52,8,11,37,0,12,117,28340,0.75,1.7307692307692308,5.269230769230769,0.7115384615384616,26
1000,A Distribution-dependent Analysis of Meta Learning,8,A Distribution-dependent Analysis of Meta Learning,23,228,False,79,156,31,19,13,14,6,0,0,50,10960,1.2105263157894737,1.631578947368421,8.210526315789474,0.3157894736842105,4
1001,A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton,8,A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton,41,136,False,52,131,24,15,0,12,24,0,8,97,10487,2.7333333333333334,2.1333333333333333,8.733333333333333,1.6,109
1002,A Novel Sequential Coreset Method for Gradient Descent Algorithms,8,A Novel Sequential Coreset Method for Gradient Descent Algorithms,52,172,False,51,98,38,27,0,10,7,0,0,65,9557,1.9259259259259258,1.4074074074074074,3.6296296296296298,0.25925925925925924,11
1003,"A Second look at Exponential and Cosine Step Sizes: Simplicity, Adaptivity, and Performance",8,A Second look at Exponential and Cosine Step Sizes Simplicity Adaptivity and Performance,74,199,False,187,83,16,19,7,16,19,7,6,90,12182,3.8947368421052633,1.1578947368421053,4.368421052631579,1.0,15
1004,A Theoretical Analysis of the Learning Dynamics under Class Imbalance,8,A Theoretical Analysis of the Learning Dynamics under Class Imbalance,56,211,False,62,195,36,39,20,16,21,0,4,69,22250,1.435897435897436,1.0256410256410255,5.0,0.5384615384615384,6
1005,A new regret analysis for Adam-type algorithms,8,A new regret analysis for Adam-type algorithms,19,94,False,138,212,0,21,0,6,17,0,0,46,12870,0.9047619047619048,0.0,10.095238095238095,0.8095238095238095,33
1006,Accelerated Algorithms for Smooth Convex-Concave Minimax Problems with O(1/k^2) Rate on Squared Gradient Norm,8,Accelerated Algorithms for Smooth Convex-Concave Minimax Problems with O1k2 Rate on Squared Gradient Norm,98,68,False,162,371,8,32,11,11,22,0,2,108,18379,3.0625,0.3125,11.59375,0.6875,85
1007,"Accuracy, Interpretability, and Differential Privacy via Explainable Boosting",8,Accuracy Interpretability and Differential Privacy via Explainable Boosting,41,104,False,36,10,18,12,0,8,10,3,6,77,7284,3.4166666666666665,2.0,0.8333333333333334,0.8333333333333334,27
1009,Adaptive Estimator Selection for Off-Policy Evaluation,8,Adaptive Estimator Selection for Off-Policy Evaluation,35,75,False,95,104,12,23,22,10,11,0,4,54,12099,1.5217391304347827,0.6956521739130435,4.521739130434782,0.4782608695652174,30
1010,Additive Gaussian Processes Revisited,8,Additive Gaussian Processes Revisited,34,109,False,115,103,38,26,0,18,21,4,16,37,14074,1.3076923076923077,2.076923076923077,3.9615384615384617,0.8076923076923077,14
1011,Adversarial Mutual Information for Text Generation,8,Adversarial Mutual Information for Text Generation,53,189,False,63,74,9,13,11,10,8,0,14,50,8409,4.076923076923077,1.7692307692307692,5.6923076923076925,0.6153846153846154,4
1012,Adversarially Trained Actor Critic for Offline Reinforcement Learning,8,Adversarially Trained Actor Critic for Offline Reinforcement Learning,58,153,False,244,118,46,27,0,11,14,4,8,69,17026,2.1481481481481484,2.0,4.37037037037037,0.5185185185185185,76
1013,Alternative Microfoundations for Strategic Classification,8,Alternative Microfoundations for Strategic Classification,48,253,False,106,104,13,41,5,15,34,5,0,57,21486,1.170731707317073,0.3170731707317073,2.5365853658536586,0.8292682926829268,38
1014,An Instability in Variational Inference for Topic Models,8,An Instability in Variational Inference for Topic Models,59,174,False,108,536,57,69,0,16,29,0,0,56,27633,0.855072463768116,0.8260869565217391,7.768115942028985,0.42028985507246375,29
1015,Analyzing Federated Learning through an Adversarial Lens,8,Analyzing Federated Learning through an Adversarial Lens,31,205,False,36,14,34,19,0,10,19,3,2,56,9477,1.631578947368421,1.894736842105263,0.7368421052631579,1.0,796
1016,Approximated Oracle Filter Pruning for Destructive CNN Width Optimization,8,Approximated Oracle Filter Pruning for Destructive CNN Width Optimization,47,176,True,58,22,24,11,0,7,9,0,8,73,8661,4.2727272727272725,2.909090909090909,2.0,0.8181818181818182,109
1018,Autoencoding Under Normalization Constraints,8,Autoencoding Under Normalization Constraints,68,129,False,123,44,37,21,0,12,22,0,22,44,13156,3.238095238095238,2.8095238095238093,2.0952380952380953,1.0476190476190477,32
1019,BORE: Bayesian Optimization by Density-Ratio Estimation,8,BORE Bayesian Optimization by Density-Ratio Estimation,95,339,True,180,56,52,26,0,14,12,0,0,54,13401,3.6538461538461537,2.0,2.1538461538461537,0.46153846153846156,22
1020,Bayesian Estimation of Differential Privacy,8,Bayesian Estimation of Differential Privacy,35,214,False,64,46,19,17,10,15,13,1,16,43,9072,2.0588235294117645,2.0588235294117645,2.7058823529411766,0.7647058823529411,23
1021,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,8,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,35,81,False,81,88,83,30,11,7,17,0,22,66,13457,1.1666666666666667,3.5,2.933333333333333,0.5666666666666667,214
1022,Beyond Signal Propagation: Is Feature Diversity Necessary in Deep Neural Network Initialization?,8,Beyond Signal Propagation Is Feature Diversity Necessary in Deep Neural Network Initialization,37,119,False,43,84,26,26,0,14,9,0,8,94,15218,1.4230769230769231,1.3076923076923077,3.230769230769231,0.34615384615384615,10
1023,Bit Allocation using Optimization,8,Bit Allocation using Optimization,77,175,False,226,82,50,23,0,14,18,0,10,33,11852,3.347826086956522,2.608695652173913,3.5652173913043477,0.782608695652174,5
1024,Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning,8,Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning,53,167,False,162,14,40,19,2,8,19,0,20,80,11280,2.789473684210526,3.1578947368421053,0.7368421052631579,1.0,114
1025,Breaking the gridlock in Mixture-of-Experts: Consistent and Efficient Algorithms,8,Breaking the gridlock in Mixture-of-Experts Consistent and Efficient Algorithms,55,220,False,45,290,23,29,0,14,13,2,2,79,15879,1.896551724137931,0.8620689655172413,10.0,0.4482758620689655,16
1027,Canonical Tensor Decomposition for Knowledge Base Completion,8,Canonical Tensor Decomposition for Knowledge Base Completion,37,132,False,161,42,7,12,3,9,16,0,8,60,7811,3.0833333333333335,1.25,3.5,1.3333333333333333,326
1028,Cell-Free Latent Go-Explore,8,Cell-Free Latent Go-Explore,63,143,False,87,18,30,16,25,10,12,3,8,27,10224,3.9375,2.375,1.125,0.75,0
1029,Choice Set Optimization Under Discrete Choice Models of Group Decisions,8,Choice Set Optimization Under Discrete Choice Models of Group Decisions,66,152,False,58,69,21,19,0,12,14,4,4,71,15290,3.473684210526316,1.3157894736842106,3.6315789473684212,0.7368421052631579,5
1030,Co-training Improves Prompt-based Learning for Large Language Models,8,Co-training Improves Prompt-based Learning for Large Language Models,50,158,False,160,12,34,17,20,11,15,0,4,68,12418,2.9411764705882355,2.235294117647059,0.7058823529411765,0.8823529411764706,31
1031,Combining Parametric and Nonparametric Models for Off-Policy Evaluation,8,Combining Parametric and Nonparametric Models for Off-Policy Evaluation,27,96,False,47,112,49,17,11,13,12,0,8,71,11661,1.588235294117647,3.3529411764705883,6.588235294117647,0.7058823529411765,26
1032,Composable Sketches for Functions of Frequencies: Beyond the Worst Case,8,Composable Sketches for Functions of Frequencies Beyond the Worst Case,55,172,False,58,53,52,34,10,8,13,0,6,70,15035,1.6176470588235294,1.7058823529411764,1.5588235294117647,0.38235294117647056,16
1033,Concept-based Explanations for Out-Of-Distribution Detectors,8,Concept-based Explanations for Out-Of-Distribution Detectors,76,28,False,20,0,3,21,0,7,12,4,2,60,13071,3.619047619047619,0.23809523809523808,0.0,0.5714285714285714,6
1034,Consensus Control for Decentralized Deep Learning,8,Consensus Control for Decentralized Deep Learning,65,172,False,128,74,47,24,29,12,23,2,38,49,15727,2.7083333333333335,3.5416666666666665,3.0833333333333335,0.9583333333333334,57
1035,Content addressable memory without catastrophic forgetting by heteroassociation with a fixed scaffold,8,Content addressable memory without catastrophic forgetting by heteroassociation with a fixed scaffold,49,192,False,42,104,45,25,0,14,11,4,0,101,15879,1.96,1.8,4.16,0.44,11
1036,Continuous-Time Model-Based Reinforcement Learning,8,Continuous-Time Model-Based Reinforcement Learning,68,107,False,165,52,53,15,19,10,16,0,2,50,9052,4.533333333333333,3.6666666666666665,3.466666666666667,1.0666666666666667,36
1037,Convergence of Proximal Point and Extragradient-Based Methods Beyond Monotonicity: the Case of Negative Comonotonicity,8,Convergence of Proximal Point and Extragradient-Based Methods Beyond Monotonicity the Case of Negative Comonotonicity,70,126,False,240,229,7,28,7,9,5,6,4,117,16285,2.5,0.39285714285714285,8.178571428571429,0.17857142857142858,16
1038,Correct-N-Contrast: A Contrastive Approach for Improving Robustness to Spurious Correlations,8,Correct-N-Contrast A Contrastive Approach for Improving Robustness to Spurious Correlations,88,187,False,281,49,38,38,0,15,20,6,30,91,20336,2.3157894736842106,1.7894736842105263,1.2894736842105263,0.5263157894736842,103
1039,Cross-model Back-translated Distillation for Unsupervised Machine Translation,8,Cross-model Back-translated Distillation for Unsupervised Machine Translation,55,150,False,612,88,54,15,8,12,26,0,48,77,10106,3.6666666666666665,6.8,5.866666666666666,1.7333333333333334,13
1040,DAdaQuant: Doubly-adaptive quantization for communication-efficient Federated Learning,8,DAdaQuant Doubly-adaptive quantization for communication-efficient Federated Learning,34,166,False,63,10,10,16,6,9,12,0,6,85,7877,2.125,1.0,0.625,0.75,26
1043,Decoupling Value and Policy for Generalization in Reinforcement Learning,8,Decoupling Value and Policy for Generalization in Reinforcement Learning,59,1,False,12,0,3,28,0,6,11,4,2,72,15713,2.107142857142857,0.17857142857142858,0.0,0.39285714285714285,75
1044,Deep Probability Estimation,8,Deep Probability Estimation,53,253,False,121,114,76,36,9,24,6,0,24,27,16661,1.4722222222222223,2.7777777777777777,3.1666666666666665,0.16666666666666666,12
1045,Deeply-Debiased Off-Policy Interval Estimation,8,Deeply-Debiased Off-Policy Interval Estimation,62,84,False,129,172,14,24,0,9,24,6,0,46,14029,2.5833333333333335,0.5833333333333334,7.166666666666667,1.0,29
1046,Description Based Text Classification with Reinforcement Learning,8,Description Based Text Classification with Reinforcement Learning,88,178,False,118,28,5,16,10,10,13,0,12,65,12379,5.5,1.0625,1.75,0.8125,60
1047,Differentiable Particle Filtering via Entropy-Regularized Optimal Transport,8,Differentiable Particle Filtering via Entropy-Regularized Optimal Transport,63,95,False,210,314,40,23,0,24,44,0,16,75,13067,2.739130434782609,2.4347826086956523,13.652173913043478,1.9130434782608696,54
1048,Differentially Private Sliced Wasserstein Distance,8,Differentially Private Sliced Wasserstein Distance,32,208,False,109,22,28,15,5,9,15,3,10,50,9225,2.1333333333333333,2.533333333333333,1.4666666666666666,1.0,16
1049,Disambiguation of Weak Supervision leading to Exponential Convergence rates,8,Disambiguation of Weak Supervision leading to Exponential Convergence rates,58,100,False,141,32,13,20,11,9,7,0,0,75,14853,2.9,0.65,1.6,0.35,5
1050,Disentangling by Factorising,8,Disentangling by Factorising,61,81,False,118,40,123,19,0,22,12,4,6,28,11598,3.210526315789474,6.7894736842105265,2.1052631578947367,0.631578947368421,1159
1051,Ditto: Fair and Robust Federated Learning Through Personalization,8,Ditto Fair and Robust Federated Learning Through Personalization,70,128,False,114,176,26,32,19,11,16,2,24,64,19268,2.1875,1.5625,5.5,0.5,533
1052,Domain Adaptation for Time Series Forecasting via Attention Sharing,8,Domain Adaptation for Time Series Forecasting via Attention Sharing,77,222,False,87,30,27,18,7,9,12,0,14,67,10659,4.277777777777778,2.2777777777777777,1.6666666666666667,0.6666666666666666,50
1054,Efficient Dictionary Learning with Gradient Descent,8,Efficient Dictionary Learning with Gradient Descent,41,142,False,100,331,13,49,3,11,22,2,0,51,16104,0.8367346938775511,0.2653061224489796,6.755102040816326,0.4489795918367347,30
1055,Efficient PAC Learning from the Crowd with Pairwise Comparisons,8,Efficient PAC Learning from the Crowd with Pairwise Comparisons,59,126,True,104,93,3,29,0,12,8,3,0,63,15762,2.0344827586206895,0.10344827586206896,3.206896551724138,0.27586206896551724,6
1056,Efficiently Solving MDPs with Stochastic Mirror Descent,8,Efficiently Solving MDPs with Stochastic Mirror Descent,39,152,False,404,720,0,32,6,32,42,4,20,55,14222,1.21875,0.625,22.5,1.3125,59
1057,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning,8,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning,31,174,False,80,2,27,17,0,10,11,0,6,76,9399,1.8235294117647058,1.9411764705882353,0.11764705882352941,0.6470588235294118,2
1058,Error Feedback Fixes SignSGD and other Gradient Compression Schemes,8,Error Feedback Fixes SignSGD and other Gradient Compression Schemes,47,137,False,79,78,47,22,17,9,18,0,8,67,10684,2.1363636363636362,2.5,3.5454545454545454,0.8181818181818182,424
1060,Explaining Groups of Points in Low-Dimensional Representations,8,Explaining Groups of Points in Low-Dimensional Representations,29,147,False,34,22,64,15,0,7,11,0,4,62,9921,1.9333333333333333,4.533333333333333,1.4666666666666666,0.7333333333333333,23
1061,Extended Unconstrained Features Model for Exploring Deep Neural Collapse,8,Extended Unconstrained Features Model for Exploring Deep Neural Collapse,29,202,False,57,148,52,27,0,15,6,0,0,72,15541,1.0740740740740742,1.9259259259259258,5.481481481481482,0.2222222222222222,65
1062,Fair Regression: Quantitative Definitions and Reduction-based Algorithms,8,Fair Regression Quantitative Definitions and Reduction-based Algorithms,37,176,False,116,134,9,18,9,15,9,0,2,71,12700,2.0555555555555554,0.6111111111111112,7.444444444444445,0.5,185
1063,"Fast Incremental von Neumann Graph Entropy Computation: Theory, Algorithm, and Applications",8,Fast Incremental von Neumann Graph Entropy Computation Theory Algorithm and Applications,67,175,False,116,38,38,18,2,21,5,0,10,88,12302,3.7222222222222223,2.6666666666666665,2.111111111111111,0.2777777777777778,21
1064,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,8,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam,62,1,False,153,160,36,26,0,23,22,0,8,71,16218,2.3846153846153846,1.6923076923076923,6.153846153846154,0.8461538461538461,233
1065,Feature-map-level Online Adversarial Knowledge Distillation,8,Feature-map-level Online Adversarial Knowledge Distillation,27,188,False,70,18,18,13,0,10,11,0,14,59,7984,2.076923076923077,2.4615384615384617,1.3846153846153846,0.8461538461538461,106
1067,Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm,8,Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm,85,125,False,131,124,9,29,4,8,25,15,2,67,14319,2.9310344827586206,0.3793103448275862,4.275862068965517,0.8620689655172413,25
1068,Flowformer: Linearizing Transformers with Conservation Flows,8,Flowformer Linearizing Transformers with Conservation Flows,57,201,False,231,36,27,17,5,10,16,0,22,59,10071,3.3529411764705883,2.8823529411764706,2.1176470588235294,0.9411764705882353,45
1069,From Importance Sampling to Doubly Robust Policy Gradient,8,From Importance Sampling to Doubly Robust Policy Gradient,17,111,False,54,50,0,27,10,7,8,0,2,57,13934,0.6296296296296297,0.07407407407407407,1.8518518518518519,0.2962962962962963,17
1070,Functional Output Regression with Infimal Convolution: Exploring the Huber and ε-insensitive Losses,8,Functional Output Regression with Infimal Convolution Exploring the Huber and ε-insensitive Losses,38,103,False,96,143,34,24,14,10,21,3,10,98,13551,1.5833333333333333,1.8333333333333333,5.958333333333333,0.875,2
1071,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,8,GLaM Efficient Scaling of Language Models with Mixture-of-Experts,108,134,False,288,0,76,23,16,32,20,0,56,65,15113,4.695652173913044,5.739130434782608,0.0,0.8695652173913043,447
1072,"General-purpose, long-context autoregressive modeling with Perceiver AR",8,General-purpose long-context autoregressive modeling with Perceiver AR,77,130,True,103,14,171,24,0,16,25,4,26,71,14393,3.2083333333333335,8.208333333333334,0.5833333333333334,1.0416666666666667,55
1073,Generalized Reductions: Making any Hierarchical Clustering Fair and Balanced with Low Cost,8,Generalized Reductions Making any Hierarchical Clustering Fair and Balanced with Low Cost,40,130,False,57,54,102,25,8,14,14,0,4,89,15153,1.6,4.24,2.16,0.56,2
1074,Generative Flows with Matrix Exponential,8,Generative Flows with Matrix Exponential,29,116,False,72,52,16,10,0,8,11,0,12,40,6295,2.9,2.8,5.2,1.1,4
1075,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,8,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator,60,143,False,123,211,3,38,1,11,18,2,0,80,14971,1.5789473684210527,0.07894736842105263,5.552631578947368,0.47368421052631576,511
1076,Gradient Descent on Neurons and its Link to Approximate Second-Order Optimization,8,Gradient Descent on Neurons and its Link to Approximate Second-Order Optimization,78,140,False,154,44,66,37,0,20,31,5,2,81,20124,2.108108108108108,1.837837837837838,1.1891891891891893,0.8378378378378378,13
1077,Graph-Coupled Oscillator Networks,8,Graph-Coupled Oscillator Networks,72,165,False,164,196,9,22,9,9,11,2,18,33,12512,3.272727272727273,1.2272727272727273,8.909090909090908,0.5,63
1078,Guarantees for Spectral Clustering with Fairness Constraints,8,Guarantees for Spectral Clustering with Fairness Constraints,57,115,False,142,242,36,27,1,13,2,0,0,60,19628,2.111111111111111,1.3333333333333333,8.962962962962964,0.07407407407407407,128
1079,Hierarchical Imitation and Reinforcement Learning,8,Hierarchical Imitation and Reinforcement Learning,38,124,False,82,44,43,14,0,3,8,5,6,49,10503,2.7142857142857144,3.5,3.142857142857143,0.5714285714285714,171
1080,Homomorphic Sensing,8,Homomorphic Sensing,36,167,False,62,24,14,8,0,4,10,5,0,19,8196,4.5,1.75,3.0,1.25,42
1081,How to Solve Fair k-Center in Massive Data Models,8,How to Solve Fair k-Center in Massive Data Models,24,174,False,23,13,16,19,8,9,7,0,8,49,10261,1.263157894736842,1.263157894736842,0.6842105263157895,0.3684210526315789,36
1082,ILLUME: Rationalizing Vision-Language Models through Human Interactions,8,ILLUME Rationalizing Vision-Language Models through Human Interactions,46,133,True,55,2,26,17,2,17,8,0,22,70,11730,2.7058823529411766,2.823529411764706,0.11764705882352941,0.47058823529411764,2
1084,Improved Convergence for $\ell_\infty$ and $\ell_1$ Regression via Iteratively Reweighted Least Squares,8,Improved Convergence for ell_infty and ell_1 Regression via Iteratively Reweighted Least Squares,27,156,False,17,90,10,22,9,9,13,0,0,96,9897,1.2272727272727273,0.45454545454545453,4.090909090909091,0.5909090909090909,2
1085,Improving Generative Imagination in Object-Centric World Models,8,Improving Generative Imagination in Object-Centric World Models,52,168,False,104,28,37,21,0,12,22,5,20,63,10916,2.4761904761904763,2.7142857142857144,1.3333333333333333,1.0476190476190477,62
1086,Improving the Gating Mechanism of Recurrent Neural Networks,8,Improving the Gating Mechanism of Recurrent Neural Networks,60,174,False,159,48,49,19,13,11,23,0,10,59,13028,3.1578947368421053,3.1052631578947367,2.526315789473684,1.2105263157894737,2
1087,Inductive Relation Prediction by Subgraph Reasoning,8,Inductive Relation Prediction by Subgraph Reasoning,37,158,False,74,30,6,13,1,12,7,0,26,51,8398,2.8461538461538463,2.4615384615384617,2.3076923076923075,0.5384615384615384,277
1089,Interpretable Neural Networks with Frank-Wolfe: Sparse Relevance Maps and Relevance Orderings,8,Interpretable Neural Networks with Frank-Wolfe Sparse Relevance Maps and Relevance Orderings,58,81,False,0,36,46,18,14,8,5,2,0,92,10835,3.2222222222222223,2.5555555555555554,2.0,0.2777777777777778,8
1090,Invariant Ancestry Search,8,Invariant Ancestry Search,52,122,False,140,66,45,38,4,14,26,0,4,25,16211,1.368421052631579,1.2894736842105263,1.736842105263158,0.6842105263157895,4
1092,Kernel Continual Learning,8,Kernel Continual Learning,59,173,False,79,40,30,14,8,7,10,0,12,25,8485,4.214285714285714,3.0,2.857142857142857,0.7142857142857143,31
1093,LIDL: Local Intrinsic Dimension Estimation Using Approximate Likelihood,8,LIDL Local Intrinsic Dimension Estimation Using Approximate Likelihood,45,143,True,76,100,69,27,7,13,19,0,8,70,12614,1.6666666666666667,2.8518518518518516,3.7037037037037037,0.7037037037037037,16
1094,Large Scale Private Learning via Low-rank Reparametrization,8,Large Scale Private Learning via Low-rank Reparametrization,64,171,False,87,30,18,13,0,11,15,0,10,59,9770,4.923076923076923,2.1538461538461537,2.3076923076923075,1.1538461538461537,71
1095,LeanResNet: A Low-cost yet Effective Convolutional Residual Networks,8,LeanResNet A Low-cost yet Effective Convolutional Residual Networks,36,160,False,21,8,2,5,1,5,1,0,4,67,3292,7.2,1.2,1.6,0.2,3
1096,Learning Curves for Analysis of Deep Networks,8,Learning Curves for Analysis of Deep Networks,40,88,False,127,12,0,14,0,11,10,0,2,45,10211,2.857142857142857,0.14285714285714285,0.8571428571428571,0.7142857142857143,21
1098,Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time,8,Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time,19,92,False,30,74,4,14,3,8,3,0,0,94,6950,1.3571428571428572,0.2857142857142857,5.285714285714286,0.21428571428571427,3
1099,"Learning Representations by Humans, for Humans",8,Learning Representations by Humans for Humans,103,1,False,48,9,38,22,14,12,24,17,6,46,13103,4.681818181818182,2.0,0.4090909090909091,1.0909090909090908,26
1101,Learning the Reward Function for a Misspecified Model,8,Learning the Reward Function for a Misspecified Model,36,138,False,74,68,11,13,0,8,6,3,0,53,9494,2.769230769230769,0.8461538461538461,5.230769230769231,0.46153846153846156,10
1102,Learning to Optimize Multigrid PDE Solvers,8,Learning to Optimize Multigrid PDE Solvers,34,1,True,22,107,22,11,9,6,5,0,8,42,8426,3.090909090909091,2.727272727272727,9.727272727272727,0.45454545454545453,93
1104,Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski p-Norms,8,Leveraging Well-Conditioned Bases Streaming and Distributed Summaries in Minkowski p-Norms,22,115,False,50,76,34,16,0,15,2,0,0,90,12594,1.375,2.125,4.75,0.125,11
1106,Lookahead-Bounded Q-Learning,8,Lookahead-Bounded Q-Learning,36,137,False,88,232,32,29,2,10,17,2,2,28,17287,1.2413793103448276,1.1724137931034482,8.0,0.5862068965517241,7
1107,Lyapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees,8,Lyapunov Functions for First-Order Methods Tight Automated Convergence Guarantees,25,77,False,52,168,8,13,8,13,10,0,0,81,9128,1.9230769230769231,0.6153846153846154,12.923076923076923,0.7692307692307693,41
1109,Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning,8,Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning,81,120,False,202,66,59,24,24,14,12,0,2,83,16067,3.375,2.5416666666666665,2.75,0.5,100
1111,Metric-Optimized Example Weights,8,Metric-Optimized Example Weights,54,110,False,55,70,24,12,2,7,11,0,6,32,8979,4.5,2.5,5.833333333333333,0.9166666666666666,14
1112,Mitigating Neural Network Overconfidence with Logit Normalization,8,Mitigating Neural Network Overconfidence with Logit Normalization,69,140,False,77,24,18,14,1,14,5,0,18,65,9457,4.928571428571429,2.5714285714285716,1.7142857142857142,0.35714285714285715,150
1113,Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time,8,Model soups averaging weights of multiple fine-tuned models improves accuracy without increasing inference time,119,233,False,212,43,68,34,9,19,13,6,20,111,19687,3.5,2.588235294117647,1.2647058823529411,0.38235294117647056,475
1115,More Information Supervised Probabilistic Deep Face Embedding Learning,8,More Information Supervised Probabilistic Deep Face Embedding Learning,52,149,False,81,30,15,11,0,5,7,0,12,70,7123,4.7272727272727275,2.4545454545454546,2.727272727272727,0.6363636363636364,1
1116,Multi-Receiver Online Bayesian Persuasion,8,Multi-Receiver Online Bayesian Persuasion,38,203,False,82,91,0,22,10,12,9,0,0,41,16791,1.7272727272727273,0.0,4.136363636363637,0.4090909090909091,26
1118,Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path,8,Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path,25,151,False,118,58,2,23,0,12,9,0,2,90,18280,1.0869565217391304,0.17391304347826086,2.5217391304347827,0.391304347826087,3
1120,Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions,8,Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions,39,166,False,33,61,81,11,2,8,7,0,0,76,8147,3.5454545454545454,7.363636363636363,5.545454545454546,0.6363636363636364,50
1121,Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval,8,Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval,47,164,False,96,20,32,18,30,20,23,4,6,67,9056,2.611111111111111,2.111111111111111,1.1111111111111112,1.2777777777777777,45
1122,Non-Stationary Bandits with Intermediate Observations,8,Non-Stationary Bandits with Intermediate Observations,33,145,False,70,89,34,18,12,14,5,0,2,53,11563,1.8333333333333333,2.0,4.944444444444445,0.2777777777777778,0
1123,Normalizing Flows for Interventional Density Estimation,8,Normalizing Flows for Interventional Density Estimation,96,171,False,275,134,35,37,0,19,21,0,14,55,19948,2.5945945945945947,1.3243243243243243,3.6216216216216215,0.5675675675675675,12
1124,Off-Policy Evaluation for Large Action Spaces via Embeddings,8,Off-Policy Evaluation for Large Action Spaces via Embeddings,71,157,False,186,110,11,34,21,10,16,2,2,60,16692,2.088235294117647,0.38235294117647056,3.235294117647059,0.47058823529411764,31
1125,On Convergence of Gradient Descent Ascent: A Tight Local Analysis,8,On Convergence of Gradient Descent Ascent A Tight Local Analysis,40,194,False,0,170,20,24,0,14,6,0,0,64,11609,1.6666666666666667,0.8333333333333334,7.083333333333333,0.25,5
1126,On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting,8,On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting,54,131,False,50,52,9,47,10,7,6,0,0,97,25442,1.148936170212766,0.19148936170212766,1.1063829787234043,0.1276595744680851,14
1129,On the Iteration Complexity of Hypergradient Computation,8,On the Iteration Complexity of Hypergradient Computation,36,162,False,76,193,16,19,7,7,8,0,4,56,12095,1.894736842105263,1.0526315789473684,10.157894736842104,0.42105263157894735,156
1130,On the Spectral Bias of Neural Networks,8,On the Spectral Bias of Neural Networks,53,124,False,103,32,102,23,0,12,21,3,0,39,13418,2.3043478260869565,4.434782608695652,1.391304347826087,0.9130434782608695,945
1131,One-sided Frank-Wolfe algorithms for saddle problems,8,One-sided Frank-Wolfe algorithms for saddle problems,55,251,False,66,129,26,26,0,11,13,0,0,52,13188,2.1153846153846154,1.0,4.961538461538462,0.5,4
1132,Online Meta-Learning,8,Online Meta-Learning,0,185,False,64,70,46,19,3,12,13,0,0,20,11059,0.0,2.4210526315789473,3.6842105263157894,0.6842105263157895,136
1133,OptiDICE: Offline Policy Optimization via Stationary Distribution Correction Estimation,8,OptiDICE Offline Policy Optimization via Stationary Distribution Correction Estimation,47,155,False,101,176,39,26,1,14,11,6,8,86,14097,1.8076923076923077,1.8076923076923077,6.769230769230769,0.4230769230769231,61
1134,Optimal Thompson Sampling strategies for support-aware CVaR bandits,8,Optimal Thompson Sampling strategies for support-aware CVaR bandits,56,165,False,270,216,72,45,35,21,30,15,28,67,25931,1.2444444444444445,2.2222222222222223,4.8,0.6666666666666666,28
1135,Optimizing Data Usage via Differentiable Rewards,8,Optimizing Data Usage via Differentiable Rewards,69,221,False,152,114,15,13,14,13,15,0,4,48,8825,5.3076923076923075,1.4615384615384615,8.76923076923077,1.1538461538461537,48
1136,Outside the Echo Chamber: Optimizing the Performative Risk,8,Outside the Echo Chamber Optimizing the Performative Risk,52,127,False,59,155,6,32,8,22,10,0,0,57,13764,1.625,0.1875,4.84375,0.3125,73
1137,PCA-based Multi Task Learning: a Random Matrix Approach,8,PCA-based Multi Task Learning a Random Matrix Approach,65,82,True,41,30,8,11,11,6,4,0,2,54,7424,5.909090909090909,0.9090909090909091,2.727272727272727,0.36363636363636365,4
1138,Parallel and Streaming Algorithms for K-Core Decomposition,8,Parallel and Streaming Algorithms for K-Core Decomposition,34,104,False,43,6,18,13,6,12,2,0,6,58,10386,2.6153846153846154,1.8461538461538463,0.46153846153846156,0.15384615384615385,24
1139,Passed & Spurious: Descent Algorithms and Local Minima in Spiked Matrix-Tensor Models,8,Passed  Spurious Descent Algorithms and Local Minima in Spiked Matrix-Tensor Models,28,161,False,68,110,36,19,0,10,7,0,2,83,8779,1.4736842105263157,2.0,5.7894736842105265,0.3684210526315789,43
1140,Pessimism meets VCG: Learning Dynamic Mechanism Design via Offline Reinforcement Learning,8,Pessimism meets VCG Learning Dynamic Mechanism Design via Offline Reinforcement Learning,60,200,True,378,740,0,52,10,26,16,0,4,88,20733,1.1538461538461537,0.07692307692307693,14.23076923076923,0.3076923076923077,4
1141,Pointwise Binary Classification with Pairwise Confidence Comparisons,8,Pointwise Binary Classification with Pairwise Confidence Comparisons,61,175,False,64,84,6,17,0,15,2,0,6,68,10144,3.588235294117647,0.7058823529411765,4.9411764705882355,0.11764705882352941,14
1142,Position-aware Graph Neural Networks,8,Position-aware Graph Neural Networks,32,1,False,126,28,12,10,0,18,36,8,8,36,7230,3.2,2.0,2.8,3.6,419
1143,Preferential Temporal Difference Learning,8,Preferential Temporal Difference Learning,41,176,False,84,40,75,23,0,9,8,7,2,41,15027,1.7826086956521738,3.347826086956522,1.7391304347826086,0.34782608695652173,6
1144,Private Alternating Least Squares: Practical Private Matrix Completion with Tighter Rates,8,Private Alternating Least Squares Practical Private Matrix Completion with Tighter Rates,57,147,False,112,87,41,29,0,12,21,2,10,88,18464,1.9655172413793103,1.7586206896551724,3.0,0.7241379310344828,17
1145,Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs,8,Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs,22,116,False,78,198,2,32,12,13,13,3,0,91,17413,0.6875,0.0625,6.1875,0.40625,14
1146,Prototype-Anchored Learning for Learning with Imperfect Annotations,8,Prototype-Anchored Learning for Learning with Imperfect Annotations,62,1,False,99,64,27,23,6,9,22,4,14,67,15190,2.6956521739130435,1.7826086956521738,2.782608695652174,0.9565217391304348,1
1147,Provably Efficient Maximum Entropy Exploration,8,Provably Efficient Maximum Entropy Exploration,48,158,False,40,81,13,16,0,8,9,5,0,46,7148,3.0,0.8125,5.0625,0.5625,240
1148,Q-value Path Decomposition for Deep Multiagent Reinforcement Learning,8,Q-value Path Decomposition for Deep Multiagent Reinforcement Learning,31,197,False,39,38,22,11,0,7,11,4,4,69,7693,2.8181818181818183,2.3636363636363638,3.4545454545454546,1.0,43
1149,Quantum algorithms for reinforcement learning with a generative model,8,Quantum algorithms for reinforcement learning with a generative model,48,191,False,63,138,6,26,0,7,10,0,2,69,13435,1.8461538461538463,0.3076923076923077,5.3076923076923075,0.38461538461538464,19
1150,RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks,8,RadialGAN Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks,21,144,False,49,14,33,9,0,6,11,0,4,121,6291,2.3333333333333335,4.111111111111111,1.5555555555555556,1.2222222222222223,36
1154,Replica Conditional Sequential Monte Carlo,8,Replica Conditional Sequential Monte Carlo,13,141,False,25,42,27,10,0,6,7,2,0,42,6906,1.3,2.7,4.2,0.7,3
1156,Revisiting Rainbow: Promoting more insightful and inclusive deep reinforcement learning research,8,Revisiting Rainbow Promoting more insightful and inclusive deep reinforcement learning research,39,133,False,137,19,78,26,0,18,27,0,14,95,11427,1.5,3.5384615384615383,0.7307692307692307,1.0384615384615385,85
1157,Robust Asymmetric Learning in POMDPs,8,Robust Asymmetric Learning in POMDPs,61,129,False,73,36,5,34,0,13,6,0,0,36,21887,1.7941176470588236,0.14705882352941177,1.0588235294117647,0.17647058823529413,20
1159,Robustness to Spurious Correlations via Human Annotations,8,Robustness to Spurious Correlations via Human Annotations,53,1,False,70,48,32,16,11,11,9,0,0,57,9873,3.3125,2.0,3.0,0.5625,73
1160,SGD without Replacement: Sharper Rates for General Smooth Convex Functions,8,SGD without Replacement Sharper Rates for General Smooth Convex Functions,26,195,True,40,76,2,14,0,6,7,0,2,73,7999,1.8571428571428572,0.2857142857142857,5.428571428571429,0.5,76
1161,"Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models",8,Same Pre-training Loss Better Downstream Implicit Bias Matters for Language Models,118,210,False,190,54,43,29,20,12,15,3,4,83,14716,4.068965517241379,1.6206896551724137,1.8620689655172413,0.5172413793103449,23
1162,Scalable Deep Reinforcement Learning Algorithms for Mean Field Games,8,Scalable Deep Reinforcement Learning Algorithms for Mean Field Games,53,176,False,132,60,27,20,5,10,11,0,0,68,10576,2.65,1.35,3.0,0.55,24
1163,Scaling Gaussian Process Optimization by Evaluating a Few Unique Candidates Multiple Times,8,Scaling Gaussian Process Optimization by Evaluating a Few Unique Candidates Multiple Times,30,190,False,63,71,22,23,2,8,13,0,2,90,10398,1.3043478260869565,1.0434782608695652,3.0869565217391304,0.5652173913043478,10
1164,Segmenting Hybrid Trajectories using Latent ODEs,8,Segmenting Hybrid Trajectories using Latent ODEs,52,151,False,62,42,29,21,0,19,10,2,14,48,13404,2.4761904761904763,2.0476190476190474,2.0,0.47619047619047616,4
1165,Self-concordant analysis of Frank-Wolfe algorithms,8,Self-concordant analysis of Frank-Wolfe algorithms,52,127,False,143,267,43,21,0,14,13,0,0,50,13282,2.4761904761904763,2.0476190476190474,12.714285714285714,0.6190476190476191,22
1166,Sequential Kernelized Independence Testing,8,Sequential Kernelized Independence Testing,42,170,False,98,417,62,44,21,11,15,2,0,42,19037,0.9545454545454546,1.4090909090909092,9.477272727272727,0.3409090909090909,13
1167,Shuffle Private Linear Contextual Bandits,8,Shuffle Private Linear Contextual Bandits,59,295,False,210,276,18,32,2,26,32,0,0,41,15572,1.84375,0.5625,8.625,1.0,15
1168,Single Pass Entrywise-Transformed Low Rank Approximation,8,Single Pass Entrywise-Transformed Low Rank Approximation,16,286,False,32,103,4,23,4,10,8,0,0,56,10970,0.6956521739130435,0.17391304347826086,4.478260869565218,0.34782608695652173,2
1169,Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning,8,Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning,62,163,False,42,0,39,20,0,15,8,0,0,102,11315,3.1,1.95,0.0,0.4,0
1170,Sparse Sinkhorn Attention,8,Sparse Sinkhorn Attention,30,136,False,44,34,10,10,11,7,11,8,16,25,6268,3.0,2.6,3.4,1.1,266
1172,Statistical Estimation from Dependent Data,8,Statistical Estimation from Dependent Data,48,166,False,83,292,5,42,10,8,19,3,4,42,20976,1.1428571428571428,0.21428571428571427,6.9523809523809526,0.4523809523809524,8
1173,Stochastic Gradient Push for Distributed Deep Learning,8,Stochastic Gradient Push for Distributed Deep Learning,42,121,False,89,111,36,33,10,12,9,3,10,54,17944,1.2727272727272727,1.393939393939394,3.3636363636363638,0.2727272727272727,295
1174,StochasticRank: Global Optimization of Scale-Free Discrete Functions,8,StochasticRank Global Optimization of Scale-Free Discrete Functions,35,119,False,70,63,0,15,5,15,27,0,8,67,11123,2.3333333333333335,0.5333333333333333,4.2,1.8,13
1175,Structure Adaptive Algorithms for Stochastic Bandits,8,Structure Adaptive Algorithms for Stochastic Bandits,25,166,False,61,53,10,28,5,5,8,2,0,52,17326,0.8928571428571429,0.35714285714285715,1.8928571428571428,0.2857142857142857,22
1176,"Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering",8,Submodular Hypergraphs p-Laplacians Cheeger Inequalities and Spectral Clustering,54,76,False,84,194,10,30,0,19,10,0,8,80,14798,1.8,0.6,6.466666666666667,0.3333333333333333,97
1177,Surrogate Losses for Online Learning of Stepsizes in Stochastic Non-Convex Optimization,8,Surrogate Losses for Online Learning of Stepsizes in Stochastic Non-Convex Optimization,25,118,False,40,97,12,12,1,11,2,0,0,87,7091,2.0833333333333335,1.0,8.083333333333334,0.16666666666666666,4
1179,Temporal Difference Learning for Model Predictive Control,8,Temporal Difference Learning for Model Predictive Control,69,130,False,165,18,98,20,0,19,1,0,10,57,13245,3.45,5.4,0.9,0.05,103
1180,The CLRS Algorithmic Reasoning Benchmark,8,The CLRS Algorithmic Reasoning Benchmark,83,148,True,158,4,15,19,5,10,10,0,8,40,11232,4.368421052631579,1.2105263157894737,0.21052631578947367,0.5263157894736842,50
1182,The Price of Differential Privacy under Continual Observation,8,The Price of Differential Privacy under Continual Observation,63,228,False,152,190,8,28,10,20,44,0,12,61,16875,2.25,0.7142857142857143,6.785714285714286,1.5714285714285714,35
1183,The many Shapley values for model explanation,8,The many Shapley values for model explanation,28,178,False,63,26,6,20,0,17,35,5,12,45,8874,1.4,0.9,1.3,1.75,471
1184,Tight Regret Bounds for Bayesian Optimization in One Dimension,8,Tight Regret Bounds for Bayesian Optimization in One Dimension,24,126,False,57,134,9,17,0,9,11,0,0,62,11682,1.411764705882353,0.5294117647058824,7.882352941176471,0.6470588235294118,23
1186,Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach,8,Towards Open-World Recommendation An Inductive Model-based Collaborative Filtering Approach,40,171,False,40,54,24,17,10,13,16,2,12,91,12522,2.3529411764705883,2.1176470588235294,3.176470588235294,0.9411764705882353,34
1187,"Train simultaneously, generalize better: Stability of gradient-based minimax learners",8,Train simultaneously generalize better Stability of gradient-based minimax learners,84,198,False,89,270,26,36,0,9,13,0,0,84,15585,2.3333333333333335,0.7222222222222222,7.5,0.3611111111111111,39
1188,Transfer Learning In Differential Privacy's Hybrid-Model,8,Transfer Learning In Differential Privacys Hybrid-Model,56,184,False,149,178,18,17,16,13,3,0,0,56,13129,3.2941176470588234,1.0588235294117647,10.470588235294118,0.17647058823529413,5
1189,Two Simple Ways to Learn Individual Fairness Metrics from Data,8,Two Simple Ways to Learn Individual Fairness Metrics from Data,62,123,False,210,206,0,23,6,12,18,1,10,62,12349,2.6956521739130435,0.43478260869565216,8.956521739130435,0.782608695652174,78
1190,Understanding Gradient Regularization in Deep Learning: Efficient Finite-Difference Computation and Implicit Bias,8,Understanding Gradient Regularization in Deep Learning Efficient Finite-Difference Computation and Implicit Bias,25,170,False,106,138,36,22,0,10,17,7,4,112,10648,1.1363636363636365,1.8181818181818181,6.2727272727272725,0.7727272727272727,7
1191,Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling,8,Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling,42,170,False,83,132,5,21,0,14,13,0,4,95,12064,2.0,0.42857142857142855,6.285714285714286,0.6190476190476191,40
1192,Universal Planning Networks,8,Universal Planning Networks,69,160,False,218,0,124,21,0,32,60,6,40,27,13976,3.2857142857142856,7.809523809523809,0.0,2.857142857142857,143
1193,Unsupervised part representation by Flow Capsules,8,Unsupervised part representation by Flow Capsules,46,116,False,80,22,0,11,16,9,6,0,0,49,6572,4.181818181818182,0.0,2.0,0.5454545454545454,32
1194,Variable-Bitrate Neural Compression via Bayesian Arithmetic Coding,8,Variable-Bitrate Neural Compression via Bayesian Arithmetic Coding,41,146,False,0,2,63,24,0,3,8,0,0,66,10922,1.7083333333333333,2.625,0.08333333333333333,0.3333333333333333,5
1195,Vector-Valued Control Variates,8,Vector-Valued Control Variates,70,160,False,111,0,25,28,19,12,23,3,10,30,18474,2.5,1.25,0.0,0.8214285714285714,6
1196,Weakly-Supervised Temporal Localization via Occurrence Count Learning,8,Weakly-Supervised Temporal Localization via Occurrence Count Learning,67,119,False,39,43,9,11,7,10,17,0,4,69,7645,6.090909090909091,1.1818181818181819,3.909090909090909,1.5454545454545454,11
1197,When Personalization Harms Performance: Reconsidering the Use of Group Attributes in Prediction,8,When Personalization Harms Performance Reconsidering the Use of Group Attributes in Prediction,120,131,False,139,42,15,30,27,11,8,0,8,94,17122,4.0,0.7666666666666667,1.4,0.26666666666666666,1
1198,Width Provably Matters in Optimization for Deep Linear Neural Networks,8,Width Provably Matters in Optimization for Deep Linear Neural Networks,41,1,False,62,169,0,15,4,17,8,0,0,70,9157,2.7333333333333334,0.0,11.266666666666667,0.5333333333333333,84
1199,Zeroth-Order Non-Convex Learning via Hierarchical Dual Averaging,8,Zeroth-Order Non-Convex Learning via Hierarchical Dual Averaging,57,1,False,187,346,44,40,7,9,15,0,0,64,19515,1.425,1.1,8.65,0.375,8
1201,A Distributional Framework for Data Valuation,8,A Distributional Framework for Data Valuation,28,184,False,30,116,18,31,7,11,12,0,0,45,12151,0.9032258064516129,0.5806451612903226,3.7419354838709675,0.3870967741935484,95
1202,"A Gradual, Semi-Discrete Approach to Generative Network Training via Explicit Wasserstein Minimization",8,A Gradual Semi-Discrete Approach to Generative Network Training via Explicit Wasserstein Minimization,42,167,False,99,32,58,19,16,12,12,2,6,101,7476,2.210526315789474,3.3684210526315788,1.6842105263157894,0.631578947368421,14
1203,A Pairwise Fair and Community-preserving Approach to k-Center Clustering,8,A Pairwise Fair and Community-preserving Approach to k-Center Clustering,57,1,False,47,4,13,12,9,6,7,0,0,72,8699,4.75,1.0833333333333333,0.3333333333333333,0.5833333333333334,30
1204,A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games,8,A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games,52,148,False,115,252,0,29,0,13,14,0,0,66,16563,1.793103448275862,0.0,8.689655172413794,0.4827586206896552,13
1206,A new similarity measure for covariate shift with applications to nonparametric regression,8,A new similarity measure for covariate shift with applications to nonparametric regression,31,139,False,27,149,5,22,17,6,15,3,2,90,11885,1.4090909090909092,0.3181818181818182,6.7727272727272725,0.6818181818181818,21
1207,Accelerated Federated Learning with Decoupled Adaptive Optimization,8,Accelerated Federated Learning with Decoupled Adaptive Optimization,101,182,False,99,165,24,26,0,7,5,0,24,67,16395,3.8846153846153846,1.8461538461538463,6.346153846153846,0.19230769230769232,31
1209,Active learning for distributionally robust level-set estimation,8,Active learning for distributionally robust level-set estimation,35,0,False,36,146,38,23,1,8,14,0,10,64,15155,1.5217391304347827,2.0869565217391304,6.3478260869565215,0.6086956521739131,11
1210,Adaptive Identification of Populations with Treatment Benefit in Clinical Trials: Machine Learning Challenges and Solutions,8,Adaptive Identification of Populations with Treatment Benefit in Clinical Trials Machine Learning Challenges and Solutions,76,178,False,107,28,32,20,5,11,13,3,6,122,14484,3.8,1.9,1.4,0.65,0
1211,Addressing Catastrophic Forgetting in Few-Shot Problems,8,Addressing Catastrophic Forgetting in Few-Shot Problems,48,131,False,151,68,30,20,15,11,19,4,6,55,10497,2.4,1.8,3.4,0.95,17
1212,Adversarial Online Learning with noise,8,Adversarial Online Learning with noise,23,73,False,22,257,2,29,0,20,9,6,0,38,11030,0.7931034482758621,0.06896551724137931,8.862068965517242,0.3103448275862069,14
1213,Affine Invariant Analysis of Frank-Wolfe on Strongly Convex Sets,8,Affine Invariant Analysis of Frank-Wolfe on Strongly Convex Sets,56,127,False,116,161,7,18,9,15,3,0,2,64,9872,3.111111111111111,0.5,8.944444444444445,0.16666666666666666,15
1214,Amortised Learning by Wake-Sleep,8,Amortised Learning by Wake-Sleep,77,130,False,149,82,73,31,4,10,31,10,0,32,15477,2.4838709677419355,2.3548387096774195,2.6451612903225805,1.0,7
1215,An Instrumental Variable Approach to Confounded Off-Policy Evaluation,8,An Instrumental Variable Approach to Confounded Off-Policy Evaluation,90,260,False,105,300,16,67,0,15,16,0,0,69,17790,1.3432835820895523,0.23880597014925373,4.477611940298507,0.23880597014925373,5
1218,Asynchronous Coagent Networks: Stochastic Networks for Reinforcement Learning without Backpropagation or a Clock,8,Asynchronous Coagent Networks Stochastic Networks for Reinforcement Learning without Backpropagation or a Clock,25,71,False,68,108,18,24,0,14,8,3,0,111,14860,1.0416666666666667,0.75,4.5,0.3333333333333333,9
1219,Automated Model Selection with Bayesian Quadrature,8,Automated Model Selection with Bayesian Quadrature,38,1,False,84,39,20,10,0,7,6,0,0,50,6222,3.8,2.0,3.9,0.6,11
1220,Backpropagated Neighborhood Aggregation for Accurate Training of Spiking Neural Networks,8,Backpropagated Neighborhood Aggregation for Accurate Training of Spiking Neural Networks,33,135,False,64,44,22,12,3,6,17,4,8,88,8648,2.75,2.5,3.6666666666666665,1.4166666666666667,20
1221,Bayesian Experimental Design for Implicit Models by Mutual Information Neural Estimation,8,Bayesian Experimental Design for Implicit Models by Mutual Information Neural Estimation,39,182,False,110,44,54,17,1,9,16,0,0,88,12154,2.2941176470588234,3.176470588235294,2.588235294117647,0.9411764705882353,55
1222,Bayesian leave-one-out cross-validation for large data,8,Bayesian leave-one-out cross-validation for large data,39,75,False,63,218,3,20,0,14,32,0,10,54,10751,1.95,0.65,10.9,1.6,22
1223,Beyond UCB: Optimal and Efficient Contextual Bandits with Regression Oracles,8,Beyond UCB Optimal and Efficient Contextual Bandits with Regression Oracles,67,136,True,155,232,0,39,21,11,18,1,0,75,16180,1.7179487179487178,0.0,5.948717948717949,0.46153846153846156,179
1224,Bit-Swap: Recursive Bits-Back Coding for Lossless Compression with Hierarchical Latent Variables,8,Bit-Swap Recursive Bits-Back Coding for Lossless Compression with Hierarchical Latent Variables,38,121,False,56,43,41,16,0,15,5,0,14,95,10925,2.375,3.4375,2.6875,0.3125,82
1225,Bootstrap in High Dimension with Low Computation,8,Bootstrap in High Dimension with Low Computation,42,114,False,105,186,37,35,0,10,11,0,16,48,20252,1.2,1.5142857142857142,5.314285714285714,0.3142857142857143,4
1226,Breaking the √T Barrier: Instance-Independent Logarithmic Regret in Stochastic Contextual Linear Bandits,8,Breaking the T Barrier Instance-Independent Logarithmic Regret in Stochastic Contextual Linear Bandits,29,160,False,97,134,15,23,7,12,2,9,0,103,9892,1.2608695652173914,0.6521739130434783,5.826086956521739,0.08695652173913043,2
1227,CLOCS: Contrastive Learning of Cardiac Signals,8,CLOCS Contrastive Learning of Cardiac Signals,38,90,True,154,16,78,39,0,30,58,44,96,45,16919,0.9743589743589743,4.461538461538462,0.41025641025641024,1.4871794871794872,113
1228,Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization,8,Catastrophic Fisher Explosion Early Phase Fisher Matrix Impacts Generalization,87,194,False,156,16,93,26,20,19,9,0,18,78,15541,3.3461538461538463,4.269230769230769,0.6153846153846154,0.34615384615384615,49
1231,CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions,8,CoVeR Learning Covariate-Specific Vector Representations with Tensor Decompositions,18,229,False,61,24,32,12,10,14,12,0,16,83,7274,1.5,4.0,2.0,1.0,0
1232,Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning,8,Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning,53,0,False,9,0,5,20,0,8,8,3,2,98,11686,2.65,0.35,0.0,0.4,13
1233,Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization,8,Composed Fine-Tuning Freezing Pre-Trained Denoising Autoencoders for Improved Generalization,81,140,False,97,62,40,28,42,16,10,8,14,92,15434,2.892857142857143,1.9285714285714286,2.2142857142857144,0.35714285714285715,9
1234,Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression,8,Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression,83,133,False,170,142,9,22,1,11,12,0,2,110,13851,3.772727272727273,0.5,6.454545454545454,0.5454545454545454,25
1235,Consensus Multiplicative Weights Update: Learning to Learn using Projector-based Game Signatures,8,Consensus Multiplicative Weights Update Learning to Learn using Projector-based Game Signatures,39,203,False,82,78,43,26,2,9,5,0,8,95,14874,1.5,1.9615384615384615,3.0,0.19230769230769232,4
1238,Convergence of Uncertainty Sampling for Active Learning,8,Convergence of Uncertainty Sampling for Active Learning,34,131,False,34,224,10,29,7,9,7,1,0,55,12393,1.1724137931034482,0.3448275862068966,7.724137931034483,0.2413793103448276,17
1241,DBSCAN++: Towards fast and scalable density clustering,8,DBSCAN Towards fast and scalable density clustering,59,143,True,60,26,24,12,0,7,13,0,0,51,6991,4.916666666666667,2.0,2.1666666666666665,1.0833333333333333,53
1242,Data Poisoning Attacks Against Multimodal Encoders,8,Data Poisoning Attacks Against Multimodal Encoders,42,188,False,41,4,34,12,0,10,16,7,32,50,9750,3.5,5.5,0.3333333333333333,1.3333333333333333,17
1245,Deep Reference Priors: What is the best way to pretrain a model?,8,Deep Reference Priors What is the best way to pretrain a model,68,210,False,107,14,27,24,23,10,16,0,14,62,11458,2.8333333333333335,1.7083333333333333,0.5833333333333334,0.6666666666666666,3
1246,Defects of Convolutional Decoder Networks in Frequency Representation,8,Defects of Convolutional Decoder Networks in Frequency Representation,33,176,False,37,282,43,34,0,9,30,0,4,69,17362,0.9705882352941176,1.3823529411764706,8.294117647058824,0.8823529411764706,7
1247,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,8,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,47,138,False,133,57,9,11,5,11,5,0,6,96,7816,4.2727272727272725,1.3636363636363635,5.181818181818182,0.45454545454545453,10
1248,Differentiable Product Quantization for End-to-End Embedding Compression,8,Differentiable Product Quantization for End-to-End Embedding Compression,27,117,False,65,14,22,14,8,9,12,0,24,72,7851,1.9285714285714286,3.2857142857142856,1.0,0.8571428571428571,47
1249,Differentially-Private Clustering of Easy Instances,8,Differentially-Private Clustering of Easy Instances,60,284,False,148,300,16,56,16,31,45,23,0,51,28485,1.0714285714285714,0.2857142857142857,5.357142857142857,0.8035714285714286,18
1250,Discount Factor as a Regularizer in Reinforcement Learning,8,Discount Factor as a Regularizer in Reinforcement Learning,59,137,False,102,16,15,16,6,7,13,5,2,58,10034,3.6875,1.0625,1.0,0.8125,50
1251,Disentangling syntax and semantics in the brain with deep networks,8,Disentangling syntax and semantics in the brain with deep networks,67,168,False,103,80,22,16,19,14,9,0,0,66,10044,4.1875,1.375,5.0,0.5625,47
1252,Divergence-Regularized Multi-Agent Actor-Critic,8,Divergence-Regularized Multi-Agent Actor-Critic,35,155,False,132,173,31,24,0,11,21,2,0,47,13283,1.4583333333333333,1.2916666666666667,7.208333333333333,0.875,18
1254,Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising,8,Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising,31,164,False,29,58,65,23,0,12,20,4,14,84,13287,1.3478260869565217,3.4347826086956523,2.5217391304347827,0.8695652173913043,15
1256,Efficient Performance Bounds for Primal-Dual Reinforcement Learning from Demonstrations,8,Efficient Performance Bounds for Primal-Dual Reinforcement Learning from Demonstrations,81,144,False,92,181,4,30,0,12,20,0,0,87,18477,2.7,0.13333333333333333,6.033333333333333,0.6666666666666666,6
1257,Efficiently sampling functions from Gaussian process posteriors,8,Efficiently sampling functions from Gaussian process posteriors,58,178,False,41,45,24,18,3,9,8,0,0,63,10312,3.2222222222222223,1.3333333333333333,2.5,0.4444444444444444,130
1258,Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs,8,Entropic GANs meet VAEs A Statistical Approach to Compute Sample Likelihoods in GANs,37,210,False,130,72,26,15,0,12,7,2,14,84,8341,2.466666666666667,2.6666666666666665,4.8,0.4666666666666667,20
1259,Error-Bounded Correction of Noisy Labels,8,Error-Bounded Correction of Noisy Labels,46,153,False,91,85,42,20,0,10,8,2,8,40,11712,2.3,2.5,4.25,0.4,85
1260,Evaluating Unsupervised Denoising Requires Unsupervised Metrics,8,Evaluating Unsupervised Denoising Requires Unsupervised Metrics,59,151,False,80,90,138,21,0,19,8,5,18,63,12887,2.8095238095238093,7.428571428571429,4.285714285714286,0.38095238095238093,0
1262,Extending Conformal Prediction to Hidden Markov Models with Exact Validity via de Finetti's Theorem for Markov Chains,8,Extending Conformal Prediction to Hidden Markov Models with Exact Validity via de Finettis Theorem for Markov Chains,33,172,False,37,46,9,14,0,10,9,0,2,117,10781,2.357142857142857,0.7857142857142857,3.2857142857142856,0.6428571428571429,5
1263,Fair Representation Learning through Implicit Path Alignment,8,Fair Representation Learning through Implicit Path Alignment,49,159,False,104,93,29,20,21,16,15,0,10,60,12000,2.45,1.95,4.65,0.75,20
1264,Fast Inference from Transformers via Speculative Decoding,8,Fast Inference from Transformers via Speculative Decoding,31,142,False,132,4,36,13,8,28,56,8,24,57,7907,2.3846153846153846,4.615384615384615,0.3076923076923077,4.3076923076923075,186
1265,Fast and Simple Natural-Gradient Variational Inference with Mixture of Exponential-family Approximations,8,Fast and Simple Natural-Gradient Variational Inference with Mixture of Exponential-family Approximations,75,1,False,167,406,23,42,1,20,29,0,2,104,21206,1.7857142857142858,0.5952380952380952,9.666666666666666,0.6904761904761905,49
1266,Fed-CBS: A Heterogeneity-Aware Client Sampling Mechanism for Federated Learning via Class-Imbalance Reduction,8,Fed-CBS A Heterogeneity-Aware Client Sampling Mechanism for Federated Learning via Class-Imbalance Reduction,45,198,True,72,96,44,28,7,11,23,5,14,108,16968,1.6071428571428572,2.0714285714285716,3.4285714285714284,0.8214285714285714,12
1267,Few-shot Domain Adaptation by Causal Mechanism Transfer,8,Few-shot Domain Adaptation by Causal Mechanism Transfer,69,149,False,253,370,13,33,42,13,27,0,6,55,18863,2.090909090909091,0.5757575757575758,11.212121212121213,0.8181818181818182,75
1268,Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications,8,Finite-Sum Coupled Compositional Stochastic Optimization Theory and Applications,30,177,False,152,254,35,47,0,15,16,0,8,80,20023,0.6382978723404256,0.9148936170212766,5.404255319148936,0.3404255319148936,18
1269,"Fluctuations, Bias, Variance & Ensemble of Learners: Exact Asymptotics for Convex Losses in High-Dimension",8,Fluctuations Bias Variance  Ensemble of Learners Exact Asymptotics for Convex Losses in High-Dimension,62,171,False,160,406,19,40,16,7,15,0,0,105,18425,1.55,0.475,10.15,0.375,23
1270,From Local SGD to Local Fixed Point Methods for Federated Learning,8,From Local SGD to Local Fixed Point Methods for Federated Learning,22,134,True,19,227,22,25,0,10,18,0,0,66,11765,0.88,0.88,9.08,0.72,96
1271,Functional Space Analysis of Local GAN Convergence,8,Functional Space Analysis of Local GAN Convergence,34,139,True,97,110,9,11,16,8,2,2,2,50,7599,3.090909090909091,1.0,10.0,0.18181818181818182,3
1272,GMNN: Graph Markov Neural Networks,8,GMNN Graph Markov Neural Networks,43,169,True,81,82,7,13,0,10,18,0,22,33,8739,3.3076923076923075,2.230769230769231,6.3076923076923075,1.3846153846153846,269
1276,Global Convergence of Policy Gradient for Linear-Quadratic Mean-Field Control/Game in Continuous Time,8,Global Convergence of Policy Gradient for Linear-Quadratic Mean-Field ControlGame in Continuous Time,58,164,False,36,5,7,28,0,11,7,0,0,100,9631,2.0714285714285716,0.25,0.17857142857142858,0.25,23
1277,Gradient Disaggregation: Breaking Privacy in Federated Learning by Reconstructing the User Participant Matrix,8,Gradient Disaggregation Breaking Privacy in Federated Learning by Reconstructing the User Participant Matrix,32,155,False,48,34,36,14,0,18,12,0,34,108,8873,2.2857142857142856,5.0,2.4285714285714284,0.8571428571428571,43
1278,Graph-based Nearest Neighbor Search: From Practice to Theory,8,Graph-based Nearest Neighbor Search From Practice to Theory,54,111,False,99,121,35,31,5,13,22,3,6,59,18961,1.7419354838709677,1.3225806451612903,3.903225806451613,0.7096774193548387,40
1279,Guarantees for Tuning the Step Size using a Learning-to-Learn Approach,8,Guarantees for Tuning the Step Size using a Learning-to-Learn Approach,41,180,False,56,293,31,73,28,13,23,12,4,70,40390,0.5616438356164384,0.4794520547945205,4.013698630136986,0.3150684931506849,12
1280,Hierarchical Importance Weighted Autoencoders,8,Hierarchical Importance Weighted Autoencoders,38,125,False,96,26,27,17,6,12,8,0,22,45,8657,2.235294117647059,2.8823529411764706,1.5294117647058822,0.47058823529411764,14
1281,Homomorphism Autoencoder - Learning Group Structured Representations from Observed Transitions,8,Homomorphism Autoencoder - Learning Group Structured Representations from Observed Transitions,50,184,False,94,64,56,26,13,14,23,6,10,94,14249,1.9230769230769231,2.5384615384615383,2.4615384615384617,0.8846153846153846,8
1283,IMEXnet: A Forward Stable Deep Neural Network,8,IMEXnet A Forward Stable Deep Neural Network,39,153,False,27,26,24,10,0,6,5,0,2,44,6317,3.9,2.6,2.6,0.5,34
1284,Implicit Quantile Networks for Distributional Reinforcement Learning,8,Implicit Quantile Networks for Distributional Reinforcement Learning,48,97,False,103,42,20,14,0,7,7,0,4,68,8399,3.4285714285714284,1.7142857142857142,3.0,0.5,439
1285,Improved Corruption Robust Algorithms for Episodic Reinforcement Learning,8,Improved Corruption Robust Algorithms for Episodic Reinforcement Learning,26,174,False,89,196,6,27,19,9,18,2,0,73,14636,0.9629629629629629,0.2222222222222222,7.2592592592592595,0.6666666666666666,20
1286,Improving Graph Neural Networks with Learnable Propagation Operators,8,Improving Graph Neural Networks with Learnable Propagation Operators,91,158,False,252,52,23,20,3,16,19,0,36,68,12027,4.55,2.95,2.6,0.95,6
1287,Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising,8,Improving the Gaussian Mechanism for Differential Privacy Analytical Calibration and Optimal Denoising,34,163,False,61,66,35,23,4,9,11,0,0,102,10024,1.4782608695652173,1.5217391304347827,2.869565217391304,0.4782608695652174,294
1288,Inexact Tensor Methods with Dynamic Accuracies,8,Inexact Tensor Methods with Dynamic Accuracies,49,134,False,42,13,57,23,0,14,11,0,2,46,12174,2.130434782608696,2.5652173913043477,0.5652173913043478,0.4782608695652174,19
1289,Input-agnostic Certified Group Fairness via Gaussian Parameter Smoothing,8,Input-agnostic Certified Group Fairness via Gaussian Parameter Smoothing,102,176,False,50,144,10,23,0,7,7,0,8,72,15028,4.434782608695652,0.782608695652174,6.260869565217392,0.30434782608695654,11
1290,Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transitions,8,Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transitions,30,173,False,57,78,35,19,21,13,19,0,2,101,11498,1.5789473684210527,1.9473684210526316,4.105263157894737,1.0,41
1291,Invariant Causal Prediction for Block MDPs,8,Invariant Causal Prediction for Block MDPs,44,161,False,90,68,26,17,0,14,15,2,2,42,9852,2.588235294117647,1.6470588235294117,4.0,0.8823529411764706,113
1292,Iterative Amortized Inference,8,Iterative Amortized Inference,34,143,False,45,136,34,20,2,10,28,3,4,29,10242,1.7,1.9,6.8,1.4,147
1293,Kernel Mean Matching for Content Addressability of GANs,8,Kernel Mean Matching for Content Addressability of GANs,72,137,False,180,21,260,25,1,17,8,0,2,55,11533,2.88,10.48,0.84,0.32,8
1295,Large-Scale Cox Process Inference using Variational Fourier Features,8,Large-Scale Cox Process Inference using Variational Fourier Features,20,186,False,54,93,18,28,4,11,18,0,0,68,9905,0.7142857142857143,0.6428571428571429,3.3214285714285716,0.6428571428571429,28
1297,Learning De-biased Representations with Biased Representations,8,Learning De-biased Representations with Biased Representations,55,210,False,147,20,38,17,34,14,9,6,16,62,10843,3.235294117647059,3.176470588235294,1.1764705882352942,0.5294117647058824,210
1298,Learning Globally Smooth Functions on Manifolds,8,Learning Globally Smooth Functions on Manifolds,80,128,False,168,528,92,38,0,32,26,4,12,47,19045,2.1052631578947367,2.736842105263158,13.894736842105264,0.6842105263157895,2
1300,Learning and Planning in Average-Reward Markov Decision Processes,8,Learning and Planning in Average-Reward Markov Decision Processes,62,126,False,1,225,42,41,0,14,13,4,2,65,24090,1.5121951219512195,1.0731707317073171,5.487804878048781,0.3170731707317073,42
1301,Learning to Branch for Multi-Task Learning,8,Learning to Branch for Multi-Task Learning,52,144,False,76,22,28,12,0,9,7,0,6,42,8548,4.333333333333333,2.8333333333333335,1.8333333333333333,0.5833333333333334,123
1302,Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters,8,Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters,73,143,False,0,0,0,15,0,8,1,0,0,68,9519,4.866666666666666,0.0,0.0,0.06666666666666667,12
1304,Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models,8,Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models,30,130,False,88,156,0,18,5,12,15,0,0,88,10319,1.6666666666666667,0.0,8.666666666666666,0.8333333333333334,80
1305,Lipschitz Continuity in Model-based Reinforcement Learning,8,Lipschitz Continuity in Model-based Reinforcement Learning,64,80,False,80,144,34,16,7,13,2,0,2,58,8468,4.0,2.25,9.0,0.125,125
1308,Making Deep Q-learning methods robust to time discretization,8,Making Deep Q-learning methods robust to time discretization,16,109,False,47,168,18,18,9,11,8,0,0,60,10378,0.8888888888888888,1.0,9.333333333333334,0.4444444444444444,71
1309,Maximum Entropy-Regularized Multi-Goal Reinforcement Learning,8,Maximum Entropy-Regularized Multi-Goal Reinforcement Learning,58,166,False,81,94,18,15,0,9,12,0,2,61,8370,3.8666666666666667,1.3333333333333333,6.266666666666667,0.8,75
1310,Message Passing Adaptive Resonance Theory for Online Active Semi-supervised Learning,8,Message Passing Adaptive Resonance Theory for Online Active Semi-supervised Learning,46,149,False,50,36,34,19,1,9,14,0,24,84,10153,2.4210526315789473,3.0526315789473686,1.894736842105263,0.7368421052631579,6
1311,MetricGAN: Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement,8,MetricGAN Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement,53,130,False,38,16,18,11,0,5,6,5,4,107,7114,4.818181818181818,2.0,1.4545454545454546,0.5454545454545454,254
1312,Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release (R3) Sampling,8,Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release R3 Sampling,28,191,False,62,4,33,39,0,7,2,0,2,111,19671,0.717948717948718,0.8974358974358975,0.10256410256410256,0.05128205128205128,15
1313,Model-Agnostic Characterization of Fairness Trade-offs,8,Model-Agnostic Characterization of Fairness Trade-offs,31,147,False,69,52,15,15,0,15,10,0,8,54,9995,2.066666666666667,1.5333333333333334,3.466666666666667,0.6666666666666666,14
1314,Modelling Behavioural Diversity for Learning in Open-Ended Games,8,Modelling Behavioural Diversity for Learning in Open-Ended Games,67,183,False,140,0,12,28,0,6,9,0,2,64,16133,2.392857142857143,0.5,0.0,0.32142857142857145,52
1315,More Robust Doubly Robust Off-policy Evaluation,8,More Robust Doubly Robust Off-policy Evaluation,33,223,False,88,194,3,30,0,13,21,2,50,47,16305,1.1,1.7666666666666666,6.466666666666667,0.7,233
1316,Multi-Task Learning as a Bargaining Game,8,Multi-Task Learning as a Bargaining Game,65,157,False,134,34,31,19,0,19,26,4,16,40,11202,3.4210526315789473,2.473684210526316,1.7894736842105263,1.368421052631579,71
1317,Multiscale Invertible Generative Networks for High-Dimensional Bayesian Inference,8,Multiscale Invertible Generative Networks for High-Dimensional Bayesian Inference,46,119,False,117,82,83,23,0,14,6,6,14,81,14965,2.0,4.217391304347826,3.5652173913043477,0.2608695652173913,2
1318,Near-Optimal Confidence Sequences for Bounded Random Variables,8,Near-Optimal Confidence Sequences for Bounded Random Variables,48,107,False,174,221,48,39,1,12,13,0,0,62,15808,1.2307692307692308,1.2307692307692308,5.666666666666667,0.3333333333333333,6
1320,Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization Formulations for Two-Layer Networks,8,Neural Networks are Convex Regularizers Exact Polynomial-time Convex Optimization Formulations for Two-Layer Networks,47,95,False,45,154,46,20,0,9,18,0,2,117,11193,2.35,2.4,7.7,0.9,91
1322,Non-Vacuous Generalisation Bounds for Shallow Neural Networks,8,Non-Vacuous Generalisation Bounds for Shallow Neural Networks,49,91,False,124,41,36,19,22,8,4,0,2,61,12214,2.5789473684210527,2.0,2.1578947368421053,0.21052631578947367,22
1323,Normalizing Flows on Tori and Spheres,8,Normalizing Flows on Tori and Spheres,47,83,False,100,94,33,16,0,16,6,5,4,37,11136,2.9375,2.3125,5.875,0.375,136
1324,Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators: Z-Estimation and Inference Theory,8,Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators Z-Estimation and Inference Theory,48,208,False,170,404,0,39,17,14,19,5,2,107,20625,1.2307692307692308,0.05128205128205128,10.35897435897436,0.48717948717948717,15
1325,On Convergence-Diagnostic based Step Sizes for Stochastic Gradient Descent,8,On Convergence-Diagnostic based Step Sizes for Stochastic Gradient Descent,55,123,False,98,177,34,35,38,13,9,3,0,74,19360,1.5714285714285714,0.9714285714285714,5.057142857142857,0.2571428571428571,12
1326,On Learning Language-Invariant Representations for Universal Machine Translation,8,On Learning Language-Invariant Representations for Universal Machine Translation,63,242,False,64,98,9,23,10,6,6,0,0,80,12162,2.739130434782609,0.391304347826087,4.260869565217392,0.2608695652173913,7
1327,On Symmetric Losses for Learning from Corrupted Labels,8,On Symmetric Losses for Learning from Corrupted Labels,55,104,False,211,140,21,28,0,11,30,0,42,54,14066,1.9642857142857142,2.25,5.0,1.0714285714285714,96
1328,On the Effects of Artificial Data Modification,8,On the Effects of Artificial Data Modification,44,149,False,60,4,55,20,0,9,19,1,32,46,11704,2.2,4.35,0.2,0.95,2
1329,On the Learning of Non-Autoregressive Transformers,8,On the Learning of Non-Autoregressive Transformers,47,156,False,110,52,25,21,0,14,18,0,20,50,13717,2.238095238095238,2.142857142857143,2.4761904761904763,0.8571428571428571,15
1330,On the Spectrum of Random Features Maps of High Dimensional Data,8,On the Spectrum of Random Features Maps of High Dimensional Data,27,94,False,34,43,20,13,0,7,2,0,10,64,7979,2.076923076923077,2.3076923076923075,3.3076923076923075,0.15384615384615385,47
1331,One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training,8,One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training,48,236,False,234,114,111,26,0,13,38,3,14,74,15494,1.8461538461538463,4.8076923076923075,4.384615384615385,1.4615384615384615,2
1332,Online Metric Algorithms with Untrusted Predictions,8,Online Metric Algorithms with Untrusted Predictions,64,150,False,238,63,10,34,18,10,18,2,4,51,19945,1.8823529411764706,0.4117647058823529,1.8529411764705883,0.5294117647058824,117
1333,Optimal Algorithms for Mean Estimation under Local Differential Privacy,8,Optimal Algorithms for Mean Estimation under Local Differential Privacy,32,197,False,80,351,18,27,1,12,22,0,0,71,10881,1.1851851851851851,0.6666666666666666,13.0,0.8148148148148148,23
1334,Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search,8,Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search,77,160,False,158,128,82,23,53,23,27,0,10,80,14297,3.347826086956522,4.0,5.565217391304348,1.173913043478261,28
1335,Optimizing Long-term Social Welfare in Recommender Systems: A Constrained Matching Approach,8,Optimizing Long-term Social Welfare in Recommender Systems A Constrained Matching Approach,52,174,False,57,35,32,23,15,13,12,7,6,90,15075,2.260869565217391,1.6521739130434783,1.5217391304347827,0.5217391304347826,53
1336,Overcoming Catastrophic Forgetting by Bayesian Generative Regularization,8,Overcoming Catastrophic Forgetting by Bayesian Generative Regularization,39,111,False,51,46,31,15,0,10,13,0,6,72,8271,2.6,2.466666666666667,3.066666666666667,0.8666666666666667,11
1337,PDE-Based Optimal Strategy for Unconstrained Online Learning,8,PDE-Based Optimal Strategy for Unconstrained Online Learning,63,135,True,92,264,40,35,13,12,26,0,0,60,18342,1.8,1.1428571428571428,7.542857142857143,0.7428571428571429,18
1338,Parallel tempering on optimized paths,8,Parallel tempering on optimized paths,27,1,False,72,153,25,17,8,13,13,0,0,37,11878,1.588235294117647,1.4705882352941178,9.0,0.7647058823529411,15
1339,Path Consistency Learning in Tsallis Entropy Regularized MDPs,8,Path Consistency Learning in Tsallis Entropy Regularized MDPs,39,235,False,72,102,32,15,0,10,5,0,0,61,10002,2.6,2.1333333333333333,6.8,0.3333333333333333,38
1340,Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets,8,Pessimistic Minimax Value Iteration Provably Efficient Equilibrium Learning from Offline Datasets,47,218,False,121,273,2,43,0,17,22,0,0,97,13604,1.0930232558139534,0.046511627906976744,6.348837209302325,0.5116279069767442,32
1341,Poisson Learning: Graph Based Semi-Supervised Learning At Very Low Label Rates,8,Poisson Learning Graph Based Semi-Supervised Learning At Very Low Label Rates,53,137,False,113,160,7,22,2,8,7,0,6,77,12944,2.409090909090909,0.5909090909090909,7.2727272727272725,0.3181818181818182,66
1342,Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization,8,Positive-Negative Momentum Manipulating Stochastic Gradient Noise to Improve Generalization,61,169,False,132,115,65,20,0,11,8,0,6,91,10345,3.05,3.55,5.75,0.4,22
1344,Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead,8,Private Counting from Anonymous Messages Near-Optimal Accuracy with Vanishing Communication Overhead,60,167,False,111,105,28,26,18,14,20,4,0,100,19392,2.3076923076923075,1.0769230769230769,4.038461538461538,0.7692307692307693,37
1346,Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out,8,Provable Acceleration of Heavy Ball beyond Quadratics for a Class of Polyak-Łojasiewicz Functions when the Non-Convexity is Averaged-Out,50,208,False,137,391,11,28,0,17,15,0,2,136,16990,1.7857142857142858,0.4642857142857143,13.964285714285714,0.5357142857142857,15
1347,Provably Efficient Model-based Policy Adaptation,8,Provably Efficient Model-based Policy Adaptation,47,149,False,51,70,70,21,0,11,23,7,10,48,12090,2.238095238095238,3.8095238095238093,3.3333333333333335,1.0952380952380953,8
1348,QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,8,QMIX Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,77,174,True,65,12,43,14,0,13,16,0,14,87,8208,5.5,4.071428571428571,0.8571428571428571,1.1428571428571428,1406
1349,Quantum-Inspired Algorithms from Randomized Numerical Linear Algebra,8,Quantum-Inspired Algorithms from Randomized Numerical Linear Algebra,74,123,False,76,96,0,29,4,11,5,0,10,68,13947,2.5517241379310347,0.3448275862068966,3.310344827586207,0.1724137931034483,22
1350,Radioactive data: tracing through training,8,Radioactive data tracing through training,47,135,False,41,20,38,11,16,7,11,0,10,41,7408,4.2727272727272725,4.363636363636363,1.8181818181818181,1.0,57
1351,Rao-Blackwellized Stochastic Gradients for Discrete Distributions,8,Rao-Blackwellized Stochastic Gradients for Discrete Distributions,29,99,False,47,88,43,11,0,9,6,4,4,65,6831,2.6363636363636362,4.2727272727272725,8.0,0.5454545454545454,29
1354,Repository-Level Prompt Generation for Large Language Models of Code,8,Repository-Level Prompt Generation for Large Language Models of Code,73,143,False,116,12,14,22,0,11,25,0,30,68,14126,3.3181818181818183,2.0,0.5454545454545454,1.1363636363636365,57
1355,Rethinking Fano's Inequality in Ensemble Learning,8,Rethinking Fanos Inequality in Ensemble Learning,57,139,False,88,60,170,41,7,20,28,0,40,49,20104,1.3902439024390243,5.121951219512195,1.4634146341463414,0.6829268292682927,0
1356,Revisiting Simple Regret: Fast Rates for Returning a Good Arm,8,Revisiting Simple Regret Fast Rates for Returning a Good Arm,50,196,False,236,456,8,49,0,10,23,0,4,60,25416,1.0204081632653061,0.24489795918367346,9.306122448979592,0.46938775510204084,6
1357,Robust Bayesian Classification Using an Optimistic Score Ratio,8,Robust Bayesian Classification Using an Optimistic Score Ratio,53,116,False,61,158,20,20,2,13,3,1,2,62,12277,2.65,1.1,7.9,0.15,13
1358,Robust Policy Gradient against Strong Data Corruption,8,Robust Policy Gradient against Strong Data Corruption,73,168,False,99,225,45,32,9,17,5,0,2,53,18880,2.28125,1.46875,7.03125,0.15625,31
1359,Rotation Invariant Householder Parameterization for Bayesian PCA,8,Rotation Invariant Householder Parameterization for Bayesian PCA,24,179,True,70,48,15,9,0,6,11,2,0,64,6990,2.6666666666666665,1.6666666666666667,5.333333333333333,1.2222222222222223,5
1360,SGLB: Stochastic Gradient Langevin Boosting,8,SGLB Stochastic Gradient Langevin Boosting,44,95,True,89,39,0,13,2,11,13,0,10,42,8751,3.3846153846153846,0.7692307692307693,3.0,1.0,17
1361,Sample Amplification: Increasing Dataset Size even when Learning is Impossible,8,Sample Amplification Increasing Dataset Size even when Learning is Impossible,31,316,False,28,316,4,35,11,4,12,6,0,77,23081,0.8857142857142857,0.11428571428571428,9.028571428571428,0.34285714285714286,12
1362,Scalable Differentiable Physics for Learning and Control,8,Scalable Differentiable Physics for Learning and Control,30,156,False,12,0,3,12,0,12,11,4,2,56,8161,2.5,0.4166666666666667,0.0,0.9166666666666666,98
1363,Scaling Laws for Reward Model Overoptimization,8,Scaling Laws for Reward Model Overoptimization,60,202,False,98,12,82,28,3,9,13,4,4,46,8695,2.142857142857143,3.0714285714285716,0.42857142857142855,0.4642857142857143,174
1364,Selective Dyna-style Planning Under Limited Model Capacity,8,Selective Dyna-style Planning Under Limited Model Capacity,48,163,False,55,8,60,17,0,12,9,6,8,58,9440,2.823529411764706,4.0,0.47058823529411764,0.5294117647058824,23
1366,Sequential Predictive Conformal Inference for Time Series,8,Sequential Predictive Conformal Inference for Time Series,38,129,False,128,92,30,21,0,10,13,2,10,57,12601,1.8095238095238095,1.9047619047619047,4.380952380952381,0.6190476190476191,10
1367,SigGPDE: Scaling Sparse Gaussian Processes on Sequential Data,8,SigGPDE Scaling Sparse Gaussian Processes on Sequential Data,27,130,False,80,110,19,13,4,16,26,4,12,60,8708,2.076923076923077,2.3846153846153846,8.461538461538462,2.0,18
1368,Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training,8,Sinkhorn Label Allocation Semi-Supervised Classification via Annealed Self-Training,54,129,False,107,26,9,12,0,7,5,0,6,83,8202,4.5,1.25,2.1666666666666665,0.4166666666666667,33
1369,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,8,Soft Actor-Critic Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,42,170,False,121,42,24,14,4,13,10,0,4,96,8269,3.0,2.0,3.0,0.7142857142857143,6075
1370,Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm,8,Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm,34,199,False,70,38,40,10,0,4,14,0,12,68,7732,3.4,5.2,3.8,1.4,13
1371,Stability and Convergence of Stochastic Gradient Clipping: Beyond Lipschitz Continuity and Smoothness,8,Stability and Convergence of Stochastic Gradient Clipping Beyond Lipschitz Continuity and Smoothness,44,170,False,62,234,26,29,4,16,7,0,0,100,12279,1.5172413793103448,0.896551724137931,8.068965517241379,0.2413793103448276,29
1372,Statistical inference with implicit SGD: proximal Robbins-Monro vs. Polyak-Ruppert,8,Statistical inference with implicit SGD proximal Robbins-Monro vs Polyak-Ruppert,25,146,True,175,341,6,32,5,9,15,4,6,65,17313,0.78125,0.375,10.65625,0.46875,3
1373,Stochastic Hamiltonian Gradient Methods for Smooth Games,8,Stochastic Hamiltonian Gradient Methods for Smooth Games,76,168,False,222,132,24,31,10,16,31,9,8,56,17442,2.4516129032258065,1.032258064516129,4.258064516129032,1.0,44
1374,Stochastically Dominant Distributional Reinforcement Learning,8,Stochastically Dominant Distributional Reinforcement Learning,56,128,False,71,82,39,19,5,12,23,0,0,61,10167,2.9473684210526314,2.0526315789473686,4.315789473684211,1.2105263157894737,19
1375,Structure Learning of Latent Factors via Clique Search on Correlation Thresholded Graphs,8,Structure Learning of Latent Factors via Clique Search on Correlation Thresholded Graphs,52,173,False,77,118,15,19,0,11,20,0,2,88,11243,2.736842105263158,0.8947368421052632,6.2105263157894735,1.0526315789473684,0
1376,"Submodular Maximization Beyond Non-negativity: Guarantees, Fast Algorithms, and Applications",8,Submodular Maximization Beyond Non-negativity Guarantees Fast Algorithms and Applications,35,226,False,52,111,14,30,3,7,7,0,0,89,13709,1.1666666666666667,0.4666666666666667,3.7,0.23333333333333334,88
1379,Temporal Gaussian Mixture Layer for Videos,8,Temporal Gaussian Mixture Layer for Videos,42,89,False,122,20,39,15,9,10,8,7,26,42,9690,2.8,4.333333333333333,1.3333333333333333,0.5333333333333333,77
1381,The Impact of Neural Network Overparameterization on Gradient Confusion and Stochastic Gradient Descent,8,The Impact of Neural Network Overparameterization on Gradient Confusion and Stochastic Gradient Descent,86,1,False,184,177,83,28,0,23,18,5,0,103,17719,3.0714285714285716,2.9642857142857144,6.321428571428571,0.6428571428571429,95
1382,The Primacy Bias in Deep Reinforcement Learning,8,The Primacy Bias in Deep Reinforcement Learning,72,119,False,148,0,63,20,14,12,7,0,12,47,12706,3.6,3.75,0.0,0.35,98
1383,The power of first-order smooth optimization for black-box non-smooth problems,8,The power of first-order smooth optimization for black-box non-smooth problems,81,110,False,92,152,7,33,0,8,19,0,0,78,11585,2.4545454545454546,0.21212121212121213,4.606060606060606,0.5757575757575758,27
1384,Tightening Exploration in Upper Confidence Reinforcement Learning,8,Tightening Exploration in Upper Confidence Reinforcement Learning,39,207,False,107,44,48,27,10,11,8,0,4,65,14871,1.4444444444444444,1.9259259259259258,1.6296296296296295,0.2962962962962963,21
1385,Total Variation Graph Neural Networks,8,Total Variation Graph Neural Networks,52,161,False,110,122,153,24,3,8,20,1,14,37,11668,2.1666666666666665,6.958333333333333,5.083333333333333,0.8333333333333334,4
1386,Towards Practical Mean Bounds for Small Samples,8,Towards Practical Mean Bounds for Small Samples,25,146,False,88,226,52,32,0,10,10,2,0,47,13677,0.78125,1.625,7.0625,0.3125,4
1387,Training Binary Neural Networks through Learning with Noisy Supervision,8,Training Binary Neural Networks through Learning with Noisy Supervision,55,131,False,102,44,17,10,8,6,7,0,10,71,7375,5.5,2.7,4.4,0.7,47
1388,Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation,8,Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation,40,165,False,54,0,52,12,3,11,6,0,12,89,7752,3.3333333333333335,5.333333333333333,0.0,0.5,89
1389,Two-Scale Gradient Descent Ascent Dynamics Finds Mixed Nash Equilibria of Continuous Games: A Mean-Field Perspective,8,Two-Scale Gradient Descent Ascent Dynamics Finds Mixed Nash Equilibria of Continuous Games A Mean-Field Perspective,64,198,False,66,246,0,25,0,10,11,3,0,115,11083,2.56,0.0,9.84,0.44,13
1390,"Understanding Gradual Domain Adaptation: Improved Analysis, Optimal Path and Beyond",8,Understanding Gradual Domain Adaptation Improved Analysis Optimal Path and Beyond,78,0,False,94,38,9,18,2,4,5,1,0,82,11166,4.333333333333333,0.5,2.111111111111111,0.2777777777777778,25
1391,Understanding the Impact of Adversarial Robustness on Accuracy Disparity,8,Understanding the Impact of Adversarial Robustness on Accuracy Disparity,54,228,False,144,340,0,31,18,13,24,0,0,72,20397,1.7419354838709677,0.0,10.96774193548387,0.7741935483870968,7
1392,Universal and data-adaptive algorithms for model selection in linear contextual bandits,8,Universal and data-adaptive algorithms for model selection in linear contextual bandits,54,157,False,190,303,0,30,12,13,17,0,6,87,15485,1.8,0.2,10.1,0.5666666666666667,5
1393,Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features,8,Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features,34,138,False,48,20,2,18,2,16,26,0,0,85,8222,1.8888888888888888,0.1111111111111111,1.1111111111111112,1.4444444444444444,2
1394,Variance Reduced Coordinate Descent with Acceleration: New Method With a Surprising Application to Finite-Sum Problems,8,Variance Reduced Coordinate Descent with Acceleration New Method With a Surprising Application to Finite-Sum Problems,41,96,False,62,158,12,30,5,13,17,0,2,117,10759,1.3666666666666667,0.4666666666666667,5.266666666666667,0.5666666666666667,14
1395,VectorMapNet: End-to-end Vectorized HD Map Learning,8,VectorMapNet End-to-end Vectorized HD Map Learning,71,199,True,161,16,42,18,0,15,26,0,0,50,10962,3.9444444444444446,2.3333333333333335,0.8888888888888888,1.4444444444444444,86
1396,Weight-covariance alignment for adversarially robust neural networks,8,Weight-covariance alignment for adversarially robust neural networks,42,126,False,98,64,12,12,0,10,11,4,18,68,8388,3.5,2.5,5.333333333333333,0.9166666666666666,18
1397,When and How Mixup Improves Calibration,8,When and How Mixup Improves Calibration,54,169,False,252,216,112,26,14,34,72,8,4,39,13761,2.076923076923077,4.461538461538462,8.307692307692308,2.769230769230769,50
1399,Zoo-Tuning: Adaptive Transfer from a Zoo of Models,8,Zoo-Tuning Adaptive Transfer from a Zoo of Models,60,182,False,70,14,24,13,0,8,14,0,12,49,9504,4.615384615384615,2.769230769230769,1.0769230769230769,1.0769230769230769,38
1400,A Boo(n) for Evaluating Architecture Performance,8,A Boon for Evaluating Architecture Performance,41,85,False,39,22,12,13,12,12,14,3,0,46,9135,3.1538461538461537,0.9230769230769231,1.6923076923076923,1.0769230769230769,2
1401,A Distributional View on Multi-Objective Policy Optimization,8,A Distributional View on Multi-Objective Policy Optimization,70,119,False,122,80,38,22,0,13,27,6,10,60,16191,3.1818181818181817,2.1818181818181817,3.6363636363636362,1.2272727272727273,66
1402,A Graph to Graphs Framework for Retrosynthesis Prediction,8,A Graph to Graphs Framework for Retrosynthesis Prediction,43,424,False,240,140,38,10,14,12,18,14,20,57,7694,4.3,5.8,14.0,1.8,128
1404,A Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition,8,A Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition,48,104,False,58,44,19,14,7,10,7,3,16,91,10186,3.4285714285714284,2.5,3.142857142857143,0.5,32
1405,A Theoretical Comparison of Graph Neural Network Extensions,8,A Theoretical Comparison of Graph Neural Network Extensions,37,152,False,32,7,8,33,0,14,19,0,0,59,18084,1.121212121212121,0.24242424242424243,0.21212121212121213,0.5757575757575758,32
1406,A picture of the space of typical learnable tasks,8,A picture of the space of typical learnable tasks,88,160,False,138,16,33,29,21,13,3,0,0,49,14584,3.0344827586206895,1.1379310344827587,0.5517241379310345,0.10344827586206896,2
1407,Accelerated Flow for Probability Distributions,8,Accelerated Flow for Probability Distributions,34,142,False,41,127,14,21,0,9,8,0,2,46,6732,1.619047619047619,0.7619047619047619,6.0476190476190474,0.38095238095238093,25
1408,Achieving Fairness at No Utility Cost via Data Reweighing,8,Achieving Fairness at No Utility Cost via Data Reweighing,59,155,False,73,36,12,14,0,11,4,0,2,57,8784,4.214285714285714,1.0,2.5714285714285716,0.2857142857142857,29
1409,Active learning of continuous-time Bayesian networks through interventions,8,Active learning of continuous-time Bayesian networks through interventions,47,175,False,45,186,26,19,1,18,17,7,2,74,11880,2.473684210526316,1.4736842105263157,9.789473684210526,0.8947368421052632,0
1410,Adaptive Inertia: Disentangling the Effects of Adaptive Learning Rate and Momentum,8,Adaptive Inertia Disentangling the Effects of Adaptive Learning Rate and Momentum,92,195,False,200,194,67,30,0,16,10,0,6,81,15190,3.066666666666667,2.433333333333333,6.466666666666667,0.3333333333333333,28
1411,Addressing Function Approximation Error in Actor-Critic Methods,8,Addressing Function Approximation Error in Actor-Critic Methods,50,112,False,69,66,28,15,0,13,7,0,6,63,9207,3.3333333333333335,2.2666666666666666,4.4,0.4666666666666667,3773
1412,Adversarial Option-Aware Hierarchical Imitation Learning,8,Adversarial Option-Aware Hierarchical Imitation Learning,32,1,False,218,100,60,16,0,16,22,10,16,56,9146,2.0,4.75,6.25,1.375,19
1413,Agent57: Outperforming the Atari Human Benchmark,8,Agent57 Outperforming the Atari Human Benchmark,51,128,False,61,6,24,30,0,6,6,0,2,47,15093,1.7,0.8666666666666667,0.2,0.2,441
1414,Amortized Conditional Normalized Maximum Likelihood,8,Amortized Conditional Normalized Maximum Likelihood,44,146,False,112,68,76,20,0,11,4,0,8,51,10825,2.2,4.2,3.4,0.2,17
1415,An Integer Linear Programming Framework for Mining Constraints from Data,8,An Integer Linear Programming Framework for Mining Constraints from Data,52,228,False,107,36,18,13,16,12,8,0,8,72,9217,4.0,2.0,2.769230769230769,0.6153846153846154,6
1416,Analyzing Uncertainty in Neural Machine Translation,8,Analyzing Uncertainty in Neural Machine Translation,35,164,False,63,1,37,12,0,11,10,0,4,51,8116,2.9166666666666665,3.4166666666666665,0.08333333333333333,0.8333333333333334,239
1417,Approximating Orthogonal Matrices with Effective Givens Factorization,8,Approximating Orthogonal Matrices with Effective Givens Factorization,24,130,False,36,36,12,9,0,9,2,0,4,69,6399,2.6666666666666665,1.7777777777777777,4.0,0.2222222222222222,14
1418,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,8,Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization,49,131,True,76,104,25,18,0,15,6,0,6,69,11143,2.7222222222222223,1.7222222222222223,5.777777777777778,0.3333333333333333,22
1419,Balancing Competing Objectives with Noisy Data: Score-Based Classifiers for Welfare-Aware Machine Learning,8,Balancing Competing Objectives with Noisy Data Score-Based Classifiers for Welfare-Aware Machine Learning,67,2,False,111,115,77,29,0,11,20,0,4,105,15059,2.310344827586207,2.793103448275862,3.9655172413793105,0.6896551724137931,19
1420,Bayesian Generative Active Deep Learning,8,Bayesian Generative Active Deep Learning,37,204,False,79,18,31,10,0,7,7,0,2,40,6742,3.7,3.3,1.8,0.7,115
1421,Beating Stochastic and Adversarial Semi-bandits Optimally and Simultaneously,8,Beating Stochastic and Adversarial Semi-bandits Optimally and Simultaneously,39,110,False,92,171,2,22,8,9,11,0,0,76,11971,1.7727272727272727,0.09090909090909091,7.7727272727272725,0.5,67
1422,Beyond Uniform Lipschitz Condition in Differentially Private Optimization,8,Beyond Uniform Lipschitz Condition in Differentially Private Optimization,70,154,False,135,229,16,36,0,23,7,0,14,73,20579,1.9444444444444444,0.8333333333333334,6.361111111111111,0.19444444444444445,10
1424,Bootstrapping Fitted Q-Evaluation for Off-Policy Inference,8,Bootstrapping Fitted Q-Evaluation for Off-Policy Inference,47,137,False,119,244,44,25,8,12,16,0,2,58,13456,1.88,1.84,9.76,0.64,27
1426,CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information,8,CLUB A Contrastive Log-ratio Upper Bound of Mutual Information,48,138,True,116,68,14,14,0,12,7,0,4,62,8790,3.4285714285714284,1.2857142857142858,4.857142857142857,0.5,217
1427,Categorical Feature Compression via Submodular Optimization,8,Categorical Feature Compression via Submodular Optimization,26,75,False,56,66,12,17,2,5,10,0,0,59,8527,1.5294117647058822,0.7058823529411765,3.8823529411764706,0.5882352941176471,16
1428,Certified Adversarial Robustness via Randomized Smoothing,8,Certified Adversarial Robustness via Randomized Smoothing,96,126,False,194,166,98,36,15,17,15,3,8,57,18792,2.6666666666666665,2.9444444444444446,4.611111111111111,0.4166666666666667,1647
1429,Class-Weighted Classification: Trade-offs and Robust Approaches,8,Class-Weighted Classification Trade-offs and Robust Approaches,61,163,False,77,262,18,31,7,15,14,2,4,62,13030,1.967741935483871,0.7096774193548387,8.451612903225806,0.45161290322580644,31
1431,Communicating via Markov Decision Processes,8,Communicating via Markov Decision Processes,34,183,False,69,5,28,15,15,10,8,0,2,43,8916,2.2666666666666666,2.0,0.3333333333333333,0.5333333333333333,4
1432,Composing Molecules with Multiple Property Constraints,8,Composing Molecules with Multiple Property Constraints,43,142,False,94,42,23,11,0,8,6,2,8,54,7349,3.909090909090909,2.8181818181818183,3.8181818181818183,0.5454545454545454,20
1433,Conditional GANs with Auxiliary Discriminative Classifier,8,Conditional GANs with Auxiliary Discriminative Classifier,54,190,False,67,18,32,15,0,12,12,0,0,57,8862,3.6,2.1333333333333333,1.2,0.8,20
1434,Conservative Objective Models for Effective Offline Model-Based Optimization,8,Conservative Objective Models for Effective Offline Model-Based Optimization,46,192,False,124,26,17,19,0,13,21,0,8,76,13374,2.4210526315789473,1.3157894736842106,1.368421052631579,1.105263157894737,59
1436,Continuous-time Lower Bounds for Gradient-based Algorithms,8,Continuous-time Lower Bounds for Gradient-based Algorithms,30,85,False,54,114,14,13,0,12,8,0,2,58,9356,2.3076923076923075,1.2307692307692308,8.76923076923077,0.6153846153846154,9
1437,Convergence of a Stochastic Gradient Method with Momentum for Nonsmooth Nonconvex Optimization,8,Convergence of a Stochastic Gradient Method with Momentum for Nonsmooth Nonconvex Optimization,55,129,False,63,254,14,27,0,12,2,0,0,94,11276,2.037037037037037,0.5185185185185185,9.407407407407407,0.07407407407407407,44
1438,Correlated Variational Auto-Encoders,8,Correlated Variational Auto-Encoders,36,139,False,62,69,3,13,6,13,11,3,6,36,9345,2.769230769230769,0.6923076923076923,5.3076923076923075,0.8461538461538461,19
1439,Crowdsourcing via Annotator Co-occurrence Imputation and Provable Symmetric Nonnegative Matrix Factorization,8,Crowdsourcing via Annotator Co-occurrence Imputation and Provable Symmetric Nonnegative Matrix Factorization,57,1,False,83,263,16,43,19,16,14,2,20,108,17447,1.3255813953488371,0.8372093023255814,6.116279069767442,0.32558139534883723,7
1440,DCFNet: Deep Neural Network with Decomposed Convolutional Filters,8,DCFNet Deep Neural Network with Decomposed Convolutional Filters,36,131,False,31,77,22,14,0,9,10,0,10,64,8300,2.5714285714285716,2.2857142857142856,5.5,0.7142857142857143,60
1441,Data Poisoning Attacks on Stochastic Bandits,8,Data Poisoning Attacks on Stochastic Bandits,19,166,False,25,80,19,13,0,9,16,0,0,44,8254,1.4615384615384615,1.4615384615384615,6.153846153846154,1.2307692307692308,89
1442,Debiasing a First-order Heuristic for Approximate Bi-level Optimization,8,Debiasing a First-order Heuristic for Approximate Bi-level Optimization,43,160,False,111,236,20,26,0,13,13,0,4,71,15691,1.6538461538461537,0.9230769230769231,9.076923076923077,0.5,4
1443,Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design,8,Deep Adaptive Design Amortizing Sequential Bayesian Experimental Design,66,158,False,166,142,25,28,4,12,13,1,10,71,16496,2.357142857142857,1.25,5.071428571428571,0.4642857142857143,50
1444,Deep Regression Unlearning,8,Deep Regression Unlearning,53,28,False,12,0,3,19,0,6,12,4,2,26,12092,2.789473684210526,0.2631578947368421,0.0,0.631578947368421,16
1445,Defending Against Saddle Point Attack in Byzantine-Robust Distributed Learning,8,Defending Against Saddle Point Attack in Byzantine-Robust Distributed Learning,77,150,False,97,177,2,28,11,13,13,0,6,78,15007,2.75,0.2857142857142857,6.321428571428571,0.4642857142857143,86
1447,Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision,8,Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision,27,110,False,91,20,25,13,10,10,13,2,18,76,9588,2.076923076923077,3.3076923076923075,1.5384615384615385,1.0,18
1448,Discovering Conditionally Salient Features with Statistical Guarantees,8,Discovering Conditionally Salient Features with Statistical Guarantees,27,217,False,28,91,6,13,9,10,6,1,0,70,10936,2.076923076923077,0.46153846153846156,7.0,0.46153846153846156,12
1449,Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation,8,Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation,66,95,False,83,152,28,22,0,13,5,0,0,82,11198,3.0,1.2727272727272727,6.909090909090909,0.22727272727272727,7
1450,Diversified Adversarial Attacks based on Conjugate Gradient Method,8,Diversified Adversarial Attacks based on Conjugate Gradient Method,54,165,False,23,14,20,23,3,7,12,0,2,66,12858,2.347826086956522,0.9565217391304348,0.6086956521739131,0.5217391304347826,6
1452,Dynamic Learning with Frequent New Product Launches: A Sequential Multinomial Logit Bandit Problem,8,Dynamic Learning with Frequent New Product Launches A Sequential Multinomial Logit Bandit Problem,13,160,False,27,16,12,21,3,8,8,0,0,97,6975,0.6190476190476191,0.5714285714285714,0.7619047619047619,0.38095238095238093,2
1453,Efficient Domain Generalization via Common-Specific Low-Rank Decomposition,8,Efficient Domain Generalization via Common-Specific Low-Rank Decomposition,26,1,False,143,20,23,12,10,22,34,4,36,74,7571,2.1666666666666665,4.916666666666667,1.6666666666666667,2.8333333333333335,176
1454,Efficient Policy Learning from Surrogate-Loss Classification Reductions,8,Efficient Policy Learning from Surrogate-Loss Classification Reductions,38,158,False,85,66,36,26,2,8,15,0,2,71,8518,1.4615384615384615,1.4615384615384615,2.5384615384615383,0.5769230769230769,14
1455,EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis,8,EigenDamage Structured Pruning in the Kronecker-Factored Eigenbasis,49,136,False,123,82,58,15,0,10,11,0,14,67,12469,3.2666666666666666,4.8,5.466666666666667,0.7333333333333333,91
1456,Entropic Gromov-Wasserstein between Gaussian Distributions,8,Entropic Gromov-Wasserstein between Gaussian Distributions,42,111,False,158,1032,20,52,30,26,28,0,0,58,21348,0.8076923076923077,0.38461538461538464,19.846153846153847,0.5384615384615384,15
1457,Error-driven Input Modulation: Solving the Credit Assignment Problem without a Backward Pass,8,Error-driven Input Modulation Solving the Credit Assignment Problem without a Backward Pass,46,180,False,46,48,30,19,0,14,9,0,8,91,9168,2.4210526315789473,2.0,2.526315789473684,0.47368421052631576,29
1458,Evaluating the Adversarial Robustness of Adaptive Test-time Defenses,8,Evaluating the Adversarial Robustness of Adaptive Test-time Defenses,66,99,False,292,20,3,15,18,10,24,1,10,68,11040,4.4,0.8666666666666667,1.3333333333333333,1.6,43
1459,Explanations for Monotonic Classifiers,8,Explanations for Monotonic Classifiers,57,120,False,64,9,0,10,10,8,8,2,2,38,8445,5.7,0.2,0.9,0.8,36
1460,Extracting Latent State Representations with Linear Dynamics from Rich Observations,8,Extracting Latent State Representations with Linear Dynamics from Rich Observations,42,140,False,66,64,13,20,8,10,12,0,0,83,11133,2.1,0.65,3.2,0.6,2
1461,Fair and Diverse DPP-based Data Summarization,8,Fair and Diverse DPP-based Data Summarization,37,181,True,34,76,13,25,0,7,14,8,4,45,11004,1.48,0.68,3.04,0.56,108
1462,Fast Learning of Graph Neural Networks with Guaranteed Generalizability: One-hidden-layer Case,8,Fast Learning of Graph Neural Networks with Guaranteed Generalizability One-hidden-layer Case,37,193,False,63,494,32,30,0,10,10,7,0,93,16022,1.2333333333333334,1.0666666666666667,16.466666666666665,0.3333333333333333,28
1464,FedBR: Improving Federated Learning on Heterogeneous Data via Local Learning Bias Reduction,8,FedBR Improving Federated Learning on Heterogeneous Data via Local Learning Bias Reduction,52,180,False,149,12,107,21,28,10,11,0,28,90,12529,2.4761904761904763,6.428571428571429,0.5714285714285714,0.5238095238095238,8
1465,Few-shot Neural Architecture Search,8,Few-shot Neural Architecture Search,64,158,False,83,0,24,14,18,12,7,2,12,35,9195,4.571428571428571,2.5714285714285716,0.0,0.5,73
1467,Focused Hierarchical RNNs for Conditional Sequence Processing,8,Focused Hierarchical RNNs for Conditional Sequence Processing,42,223,False,62,16,18,10,17,7,8,0,8,61,7134,4.2,2.6,1.6,0.8,23
1468,From Local Structures to Size Generalization in Graph Neural Networks,8,From Local Structures to Size Generalization in Graph Neural Networks,59,180,False,81,18,38,23,0,16,14,0,16,69,16348,2.5652173913043477,2.347826086956522,0.782608695652174,0.6086956521739131,99
1469,Functional Transparency for Structured Data: a Game-Theoretic Approach,8,Functional Transparency for Structured Data a Game-Theoretic Approach,50,150,False,71,100,25,14,0,10,8,0,10,69,9672,3.5714285714285716,2.5,7.142857142857143,0.5714285714285714,17
1471,Generalised Policy Improvement with Geometric Policy Composition,8,Generalised Policy Improvement with Geometric Policy Composition,94,191,False,212,148,61,36,0,17,25,0,2,64,21461,2.611111111111111,1.75,4.111111111111111,0.6944444444444444,4
1472,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,8,Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression,39,113,False,46,110,21,13,0,11,8,0,4,89,9355,3.0,1.9230769230769231,8.461538461538462,0.6153846153846154,69
1473,Generative Particle Variational Inference via Estimation of Functional Gradients,8,Generative Particle Variational Inference via Estimation of Functional Gradients,43,165,False,58,54,66,22,0,12,19,2,10,80,11319,1.9545454545454546,3.4545454545454546,2.4545454545454546,0.8636363636363636,0
1474,Global Optimality Beyond Two Layers: Training Deep ReLU Networks via Convex Programs,8,Global Optimality Beyond Two Layers Training Deep ReLU Networks via Convex Programs,53,163,False,54,118,24,18,0,6,14,0,2,83,11370,2.9444444444444446,1.4444444444444444,6.555555555555555,0.7777777777777778,30
1475,Gradient Temporal-Difference Learning with Regularized Corrections,8,Gradient Temporal-Difference Learning with Regularized Corrections,37,165,False,0,92,66,23,0,17,19,2,6,66,17682,1.608695652173913,3.130434782608696,4.0,0.8260869565217391,39
1476,"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback",8,Graph-based Self-Supervised Program Repair from Diagnostic Feedback,42,154,False,136,25,12,10,3,9,7,5,16,68,9453,4.2,2.8,2.5,0.7,153
1477,Guided Exploration with Proximal Policy Optimization using a Single Demonstration,8,Guided Exploration with Proximal Policy Optimization using a Single Demonstration,44,150,False,89,22,24,13,0,10,5,0,8,81,8114,3.3846153846153846,2.4615384615384617,1.6923076923076923,0.38461538461538464,19
1478,Hierarchical Long-term Video Prediction without Supervision,8,Hierarchical Long-term Video Prediction without Supervision,26,177,False,127,16,147,9,4,6,5,6,4,59,5642,2.888888888888889,16.77777777777778,1.7777777777777777,0.5555555555555556,124
1479,Horizon-Free and Variance-Dependent Reinforcement Learning for Latent Markov Decision Processes,8,Horizon-Free and Variance-Dependent Reinforcement Learning for Latent Markov Decision Processes,58,1,False,118,170,3,26,16,9,12,6,0,95,15523,2.230769230769231,0.11538461538461539,6.538461538461538,0.46153846153846156,1
1480,How to Train Your Wide Neural Network Without Backprop: An Input-Weight Alignment Perspective,8,How to Train Your Wide Neural Network Without Backprop An Input-Weight Alignment Perspective,47,146,False,74,112,31,28,30,9,20,0,20,92,14783,1.6785714285714286,1.8214285714285714,4.0,0.7142857142857143,6
1481,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,8,IMPALA Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,42,168,True,45,18,44,22,0,14,14,6,10,88,11457,1.9090909090909092,2.4545454545454546,0.8181818181818182,0.6363636363636364,1377
1482,Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks,8,Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks,106,148,False,139,202,37,42,9,16,22,6,2,99,28375,2.5238095238095237,0.9285714285714286,4.809523809523809,0.5238095238095238,24
1483,Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP,8,Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP,45,171,True,192,285,0,42,22,9,20,0,0,74,27556,1.0714285714285714,0.0,6.785714285714286,0.47619047619047616,14
1484,Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding,8,Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding,67,140,False,176,100,59,32,28,10,21,0,20,69,19356,2.09375,2.46875,3.125,0.65625,21
1485,Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms,8,Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms,30,185,True,33,286,20,18,0,13,12,0,0,71,11038,1.6666666666666667,1.1111111111111112,15.88888888888889,0.6666666666666666,75
1486,Inference Suboptimality in Variational Autoencoders,8,Inference Suboptimality in Variational Autoencoders,39,131,False,69,24,15,12,0,6,19,6,10,51,7808,3.25,2.0833333333333335,2.0,1.5833333333333333,251
1487,Insertion Transformer: Flexible Sequence Generation via Insertion Operations,8,Insertion Transformer Flexible Sequence Generation via Insertion Operations,34,178,False,58,26,9,10,5,9,13,0,8,75,8120,3.4,1.7,2.6,1.3,233
1488,Interpretable Off-Policy Learning via Hyperbox Search,8,Interpretable Off-Policy Learning via Hyperbox Search,60,170,False,72,124,71,33,0,22,23,5,10,53,16762,1.8181818181818181,2.4545454545454546,3.757575757575758,0.696969696969697,3
1490,Iterative Hard Thresholding with Adaptive Regularization: Sparser Solutions Without Sacrificing Runtime,8,Iterative Hard Thresholding with Adaptive Regularization Sparser Solutions Without Sacrificing Runtime,34,159,False,39,398,14,35,24,10,11,0,0,102,14799,0.9714285714285714,0.4,11.371428571428572,0.3142857142857143,4
1491,Kernel Methods for Cooperative Multi-Agent Contextual Bandits,8,Kernel Methods for Cooperative Multi-Agent Contextual Bandits,60,143,False,103,88,3,19,0,12,7,0,0,61,12473,3.1578947368421053,0.15789473684210525,4.631578947368421,0.3684210526315789,27
1494,Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting,8,Learn to Grow A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting,31,147,False,110,8,24,12,0,10,7,0,8,93,8419,2.5833333333333335,2.6666666666666665,0.6666666666666666,0.5833333333333334,312
1495,Learning Deep Kernels for Non-Parametric Two-Sample Tests,8,Learning Deep Kernels for Non-Parametric Two-Sample Tests,56,161,False,172,174,75,29,14,12,14,3,16,57,17186,1.9310344827586208,3.1379310344827585,6.0,0.4827586206896552,143
1497,Learning Mixtures of Graphs from Epidemic Cascades,8,Learning Mixtures of Graphs from Epidemic Cascades,57,171,False,7,136,4,29,14,15,23,0,0,50,14751,1.9655172413793103,0.13793103448275862,4.689655172413793,0.7931034482758621,5
1498,Learning Representations that Support Extrapolation,8,Learning Representations that Support Extrapolation,33,123,False,35,8,29,20,0,13,12,4,10,51,9962,1.65,1.95,0.4,0.6,40
1499,Learning and Planning in Complex Action Spaces,8,Learning and Planning in Complex Action Spaces,52,130,False,77,12,39,18,0,14,19,0,4,46,10117,2.888888888888889,2.388888888888889,0.6666666666666666,1.0555555555555556,47
1500,Learning to Clear the Market,8,Learning to Clear the Market,21,152,False,33,14,16,17,0,5,7,0,0,28,6858,1.2352941176470589,0.9411764705882353,0.8235294117647058,0.4117647058823529,13
1502,Learning-augmented private algorithms for multiple quantile release,8,Learning-augmented private algorithms for multiple quantile release,67,159,False,151,292,36,33,0,12,19,10,0,67,21758,2.0303030303030303,1.0909090909090908,8.848484848484848,0.5757575757575758,1
1503,Lie Point Symmetry Data Augmentation for Neural PDE Solvers,8,Lie Point Symmetry Data Augmentation for Neural PDE Solvers,63,141,True,150,46,46,15,15,12,9,0,12,59,11152,4.2,3.8666666666666667,3.066666666666667,0.6,31
1504,Lipschitz Generative Adversarial Nets,8,Lipschitz Generative Adversarial Nets,46,176,False,97,124,84,26,0,15,25,0,4,37,13376,1.7692307692307692,3.3846153846153846,4.769230769230769,0.9615384615384616,73
1505,Loss Function Search for Face Recognition,8,Loss Function Search for Face Recognition,47,149,False,66,42,15,10,0,5,10,0,20,41,7357,4.7,3.5,4.2,1.0,44
1506,MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection,8,MAE-DET Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection,63,161,True,126,10,38,17,0,14,8,0,30,92,10378,3.7058823529411766,4.0,0.5882352941176471,0.47058823529411764,22
1509,Message Passing Least Squares Framework and its Application to Rotation Synchronization,8,Message Passing Least Squares Framework and its Application to Rotation Synchronization,39,89,False,88,42,9,11,0,7,9,4,2,87,8925,3.5454545454545454,1.0,3.8181818181818183,0.8181818181818182,27
1510,Metropolis-Hastings Generative Adversarial Networks,8,Metropolis-Hastings Generative Adversarial Networks,26,106,False,66,12,99,15,12,8,6,0,4,51,5365,1.7333333333333334,6.866666666666666,0.8,0.4,86
1511,Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning,8,Mix-n-Match Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning,63,164,False,19,32,29,23,0,14,4,0,4,91,11303,2.739130434782609,1.434782608695652,1.391304347826087,0.17391304347826086,159
1512,Model-Aware Contrastive Learning: Towards Escaping the Dilemmas,8,Model-Aware Contrastive Learning Towards Escaping the Dilemmas,63,178,False,109,78,13,17,0,11,26,3,28,62,10479,3.7058823529411766,2.411764705882353,4.588235294117647,1.5294117647058822,3
1514,More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize,8,More Than a Toy Random Matrix Models Predict How Real-World Neural Representations Generalize,69,1,False,144,183,43,38,4,16,27,9,6,93,21330,1.8157894736842106,1.2894736842105263,4.815789473684211,0.7105263157894737,47
1515,Multi-Task Off-Policy Learning from Bandit Feedback,8,Multi-Task Off-Policy Learning from Bandit Feedback,55,169,False,65,120,10,14,3,9,8,1,0,51,9332,3.9285714285714284,0.7142857142857143,8.571428571428571,0.5714285714285714,5
1516,Multivariate-Information Adversarial Ensemble for Scalable Joint Distribution Matching,8,Multivariate-Information Adversarial Ensemble for Scalable Joint Distribution Matching,45,132,False,45,62,33,10,0,5,9,0,8,86,6857,4.5,4.1,6.2,0.9,6
1518,Network Inference and Influence Maximization from Samples,8,Network Inference and Influence Maximization from Samples,31,200,False,85,68,0,27,6,6,6,2,0,57,13211,1.1481481481481481,0.0,2.5185185185185186,0.2222222222222222,12
1519,Neural Pharmacodynamic State Space Modeling,8,Neural Pharmacodynamic State Space Modeling,61,97,False,82,40,42,23,4,14,16,3,8,43,16553,2.652173913043478,2.1739130434782608,1.7391304347826086,0.6956521739130435,8
1520,Neuro-algorithmic Policies enable Fast Combinatorial Generalization,8,Neuro-algorithmic Policies enable Fast Combinatorial Generalization,61,140,False,147,23,79,15,8,23,14,0,12,67,9742,4.066666666666666,6.066666666666666,1.5333333333333334,0.9333333333333333,12
1521,Non-convex Learning via Replica Exchange Stochastic Gradient MCMC,8,Non-convex Learning via Replica Exchange Stochastic Gradient MCMC,52,152,True,258,428,36,19,0,18,20,4,16,65,12262,2.736842105263158,2.736842105263158,22.526315789473685,1.0526315789473684,34
1522,Not All Memories are Created Equal: Learning to Forget by Expiring,8,Not All Memories are Created Equal Learning to Forget by Expiring,53,175,False,149,16,41,14,34,10,17,4,20,65,9015,3.7857142857142856,4.357142857142857,1.1428571428571428,1.2142857142857142,28
1523,Off-Policy Reinforcement Learning with Delayed Rewards,8,Off-Policy Reinforcement Learning with Delayed Rewards,42,133,False,184,172,62,24,0,18,42,0,4,54,11627,1.75,2.75,7.166666666666667,1.75,19
1525,On Learning Mixture of Linear Regressions in the Non-Realizable Setting,8,On Learning Mixture of Linear Regressions in the Non-Realizable Setting,45,247,False,109,124,3,25,3,10,7,2,12,71,11703,1.8,0.6,4.96,0.28,8
1526,On The Power of Curriculum Learning in Training Deep Networks,8,On The Power of Curriculum Learning in Training Deep Networks,33,197,False,65,49,44,13,20,9,10,0,0,61,9386,2.5384615384615383,3.3846153846153846,3.769230769230769,0.7692307692307693,352
1527,"On the Feasibility of Learning, Rather than Assuming, Human Biases for Reward Inference",8,On the Feasibility of Learning Rather than Assuming Human Biases for Reward Inference,35,226,False,52,8,16,12,0,7,7,1,4,85,7663,2.9166666666666665,1.6666666666666667,0.6666666666666666,0.5833333333333334,59
1528,On the Limitations of Representing Functions on Sets,8,On the Limitations of Representing Functions on Sets,35,135,False,109,56,10,14,0,11,13,2,0,52,10035,2.5,0.7142857142857143,4.0,0.9285714285714286,150
1529,On the Statistical Benefits of Curriculum Learning,8,On the Statistical Benefits of Curriculum Learning,31,143,False,96,204,6,28,38,34,24,2,0,50,11016,1.1071428571428572,0.21428571428571427,7.285714285714286,0.8571428571428571,6
1530,Oneshot Differentially Private Top-k Selection,8,Oneshot Differentially Private Top-k Selection,38,134,False,54,115,0,13,0,7,6,0,0,46,8946,2.923076923076923,0.0,8.846153846153847,0.46153846153846156,26
1532,Optimal Algorithms for Stochastic Multi-Level Compositional Optimization,8,Optimal Algorithms for Stochastic Multi-Level Compositional Optimization,43,183,False,142,142,40,22,0,12,9,0,4,72,12766,1.9545454545454546,2.0,6.454545454545454,0.4090909090909091,12
1533,Optimal Transport for structured data with application on graphs,8,Optimal Transport for structured data with application on graphs,60,138,False,100,140,14,16,9,7,8,3,16,64,10141,3.75,1.875,8.75,0.5,203
1534,Optimizing Sequential Experimental Design with Deep Reinforcement Learning,8,Optimizing Sequential Experimental Design with Deep Reinforcement Learning,50,135,False,88,124,27,22,0,12,19,4,16,74,11838,2.272727272727273,1.9545454545454546,5.636363636363637,0.8636363636363636,20
1535,Overcoming Mean-Field Approximations in Recurrent Gaussian Process Models,8,Overcoming Mean-Field Approximations in Recurrent Gaussian Process Models,37,136,False,104,32,12,10,0,8,18,0,6,73,7101,3.7,1.8,3.2,1.8,28
1536,PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions,8,PDO-eConvs Partial Differential Operator Based Equivariant Convolutions,42,171,True,40,72,9,11,0,9,12,2,6,71,7743,3.8181818181818183,1.3636363636363635,6.545454545454546,1.0909090909090908,36
1537,Parallelizing Legendre Memory Unit Training,8,Parallelizing Legendre Memory Unit Training,38,28,False,116,36,9,11,24,12,20,6,12,43,7570,3.4545454545454546,1.9090909090909092,3.272727272727273,1.8181818181818181,25
1538,Path Planning using Neural A* Search,8,Path Planning using Neural A Search,65,160,False,137,14,28,16,21,9,12,0,16,35,10769,4.0625,2.75,0.875,0.75,64
1539,Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity,8,Pessimistic Q-Learning for Offline Reinforcement Learning Towards Optimal Sample Complexity,66,163,False,120,573,3,64,58,9,20,12,2,91,35654,1.03125,0.078125,8.953125,0.3125,65
1540,Policy Analysis using Synthetic Controls in Continuous-Time,8,Policy Analysis using Synthetic Controls in Continuous-Time,42,92,False,60,40,19,17,0,11,20,0,4,59,8696,2.4705882352941178,1.3529411764705883,2.3529411764705883,1.1764705882352942,16
1541,Post-selection inference with HSIC-Lasso,8,Post-selection inference with HSIC-Lasso,54,120,True,167,142,6,22,0,11,14,9,8,40,13555,2.4545454545454546,0.6363636363636364,6.454545454545454,0.6363636363636364,11
1543,Private Frequency Estimation via Projective Geometry,8,Private Frequency Estimation via Projective Geometry,23,248,False,44,58,14,21,1,8,1,0,4,52,9948,1.0952380952380953,0.8571428571428571,2.761904761904762,0.047619047619047616,13
1544,Problems with Shapley-value-based explanations as feature importance measures,8,Problems with Shapley-value-based explanations as feature importance measures,32,118,False,79,25,3,10,1,5,7,6,2,77,7556,3.2,0.5,2.5,0.7,272
1545,Provable Domain Generalization via Invariant-Feature Subspace Recovery,8,Provable Domain Generalization via Invariant-Feature Subspace Recovery,80,214,False,199,60,18,16,18,10,10,3,0,70,10898,5.0,1.125,3.75,0.625,23
1546,Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping,8,Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping,41,172,False,132,196,2,31,0,13,11,0,0,82,13196,1.3225806451612903,0.06451612903225806,6.32258064516129,0.3548387096774194,120
1547,QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning,8,QTRAN Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning,33,161,True,92,72,109,18,17,13,23,1,16,98,11562,1.8333333333333333,6.944444444444445,4.0,1.2777777777777777,596
1548,Quasi-Global Momentum: Accelerating Decentralized Deep Learning on Heterogeneous Data,8,Quasi-Global Momentum Accelerating Decentralized Deep Learning on Heterogeneous Data,92,115,False,189,157,111,38,24,11,22,3,16,84,20170,2.4210526315789473,3.3421052631578947,4.131578947368421,0.5789473684210527,85
1549,Random Expert Distillation: Imitation Learning via Expert Policy Support Estimation,8,Random Expert Distillation Imitation Learning via Expert Policy Support Estimation,30,125,False,42,24,26,14,0,5,10,0,2,82,6195,2.142857142857143,2.0,1.7142857142857142,0.7142857142857143,61
1550,Rate Distortion For Model Compression: From Theory To Practice,8,Rate Distortion For Model Compression From Theory To Practice,42,202,False,89,96,58,23,0,11,16,3,4,61,10195,1.826086956521739,2.6956521739130435,4.173913043478261,0.6956521739130435,26
1551,Recurrent Predictive State Policy Networks,8,Recurrent Predictive State Policy Networks,38,240,False,119,36,72,15,0,13,7,3,0,42,8401,2.533333333333333,4.8,2.4,0.4666666666666667,18
1552,Reinforcement Learning Under Moral Uncertainty,8,Reinforcement Learning Under Moral Uncertainty,72,212,False,80,19,83,28,0,20,11,0,2,46,16300,2.5714285714285716,3.0357142857142856,0.6785714285714286,0.39285714285714285,24
1554,Rethinking Graph Neural Networks for Anomaly Detection,8,Rethinking Graph Neural Networks for Anomaly Detection,58,123,False,64,30,18,14,1,10,11,0,8,54,8636,4.142857142857143,1.8571428571428572,2.142857142857143,0.7857142857142857,96
1555,Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning,8,Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning,71,1,False,83,27,24,16,0,10,20,0,14,82,9999,4.4375,2.375,1.6875,1.25,29
1556,Robust Collaborative Learning with Linear Gradient Overhead,8,Robust Collaborative Learning with Linear Gradient Overhead,35,0,False,74,37,6,53,7,6,11,0,2,59,26751,0.660377358490566,0.1509433962264151,0.6981132075471698,0.20754716981132076,6
1557,Robust Policy Learning over Multiple Uncertainty Sets,8,Robust Policy Learning over Multiple Uncertainty Sets,62,159,False,81,8,31,15,0,8,12,10,14,53,10672,4.133333333333334,3.0,0.5333333333333333,0.8,11
1558,Rotting infinitely many-armed bandits,8,Rotting infinitely many-armed bandits,37,149,False,45,453,12,36,3,7,14,2,0,37,17008,1.0277777777777777,0.3333333333333333,12.583333333333334,0.3888888888888889,2
1559,SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice for Scalable Gaussian Processes,8,SKIing on Simplices Kernel Interpolation on the Permutohedral Lattice for Scalable Gaussian Processes,44,115,False,144,30,29,13,3,10,9,0,10,101,9071,3.3846153846153846,3.0,2.3076923076923075,0.6923076923076923,8
1560,Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable Embeddings with Generative Priors,8,Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable Embeddings with Generative Priors,52,152,False,70,144,20,23,0,9,11,1,0,106,11650,2.260869565217391,0.8695652173913043,6.260869565217392,0.4782608695652174,25
1561,Scalable Exact Inference in Multi-Output Gaussian Processes,8,Scalable Exact Inference in Multi-Output Gaussian Processes,72,194,False,71,146,35,31,12,29,25,0,10,59,18330,2.3225806451612905,1.4516129032258065,4.709677419354839,0.8064516129032258,29
1562,Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing,8,Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing,26,141,False,35,12,32,10,0,8,9,0,4,75,7004,2.6,3.6,1.2,0.9,74
1563,Selective Network Linearization for Efficient Private Inference,8,Selective Network Linearization for Efficient Private Inference,30,111,False,55,26,22,15,7,9,10,0,20,63,8795,2.0,2.8,1.7333333333333334,0.6666666666666666,28
1564,Self-supervised Graph-level Representation Learning with Local and Global Structure,8,Self-supervised Graph-level Representation Learning with Local and Global Structure,68,132,False,168,58,9,14,0,9,9,0,8,83,9176,4.857142857142857,1.2142857142857142,4.142857142857143,0.6428571428571429,146
1565,Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound,8,Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound,67,192,False,185,144,18,39,4,19,22,0,2,90,16812,1.7179487179487178,0.5128205128205128,3.6923076923076925,0.5641025641025641,12
1566,Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit,8,Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit,36,123,False,84,74,52,20,0,10,20,3,2,65,13891,1.8,2.7,3.7,1.0,16
1568,Soft Threshold Weight Reparameterization for Learnable Sparsity,8,Soft Threshold Weight Reparameterization for Learnable Sparsity,66,109,False,153,12,0,19,0,7,15,8,0,63,13564,3.473684210526316,0.0,0.631578947368421,0.7894736842105263,189
1569,Sparse within Sparse Gaussian Processes using Neighbor Information,8,Sparse within Sparse Gaussian Processes using Neighbor Information,29,1,False,71,36,23,10,5,5,9,0,10,66,7594,2.9,3.3,3.6,0.9,10
1570,Stability and Generalization of Stochastic Gradient Methods for Minimax Problems,8,Stability and Generalization of Stochastic Gradient Methods for Minimax Problems,68,163,False,240,411,6,40,0,17,20,0,6,80,23752,1.7,0.3,10.275,0.5,40
1571,Statistically Efficient Off-Policy Policy Gradients,8,Statistically Efficient Off-Policy Policy Gradients,73,132,False,144,220,8,41,8,9,7,4,4,51,14358,1.7804878048780488,0.2926829268292683,5.365853658536586,0.17073170731707318,34
1572,Stochastic Iterative Graph Matching,8,Stochastic Iterative Graph Matching,43,1,False,120,34,23,11,2,7,6,0,10,35,7916,3.909090909090909,3.0,3.090909090909091,0.5454545454545454,12
1573,Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation,8,Straight to the Gradient Learning to Use Novel Tokens for Neural Text Generation,43,28,False,152,44,25,23,21,22,26,6,58,80,14083,1.8695652173913044,3.608695652173913,1.9130434782608696,1.1304347826086956,22
1574,Structure-Aware Transformer for Graph Representation Learning,8,Structure-Aware Transformer for Graph Representation Learning,63,186,False,209,86,20,21,22,18,33,7,16,61,12175,3.0,1.7142857142857142,4.095238095238095,1.5714285714285714,133
1575,Submodular Maximization subject to a Knapsack Constraint: Combinatorial Algorithms with Near-optimal Adaptive Complexity,8,Submodular Maximization subject to a Knapsack Constraint Combinatorial Algorithms with Near-optimal Adaptive Complexity,53,178,False,121,79,0,29,13,7,6,0,2,119,15541,1.8275862068965518,0.06896551724137931,2.7241379310344827,0.20689655172413793,8
1576,Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach,8,Symmetric Spaces for Graph Embeddings A Finsler-Riemannian Approach,61,126,False,92,18,109,28,17,15,27,3,30,67,19009,2.1785714285714284,4.964285714285714,0.6428571428571429,0.9642857142857143,20
1577,Tackling covariate shift with node-based Bayesian neural networks,8,Tackling covariate shift with node-based Bayesian neural networks,47,157,False,88,50,93,25,11,17,10,0,4,65,11827,1.88,3.88,2.0,0.4,5
1578,Temporal Label Smoothing for Early Event Prediction,8,Temporal Label Smoothing for Early Event Prediction,55,151,False,211,52,68,26,45,11,28,0,22,51,14538,2.1153846153846154,3.4615384615384617,2.0,1.0769230769230769,1
1579,The Complexity of Finding Stationary Points with Stochastic Gradient Descent,8,The Complexity of Finding Stationary Points with Stochastic Gradient Descent,29,90,False,32,170,9,27,0,6,7,0,0,76,11267,1.0740740740740742,0.3333333333333333,6.296296296296297,0.25925925925925924,58
1580,The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous Neural Networks,8,The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous Neural Networks,46,209,False,85,512,33,57,0,13,28,8,0,85,25797,0.8070175438596491,0.5789473684210527,8.982456140350877,0.49122807017543857,25
1581,The Sample Complexity of Best-k Items Selection from Pairwise Comparisons,8,The Sample Complexity of Best-k Items Selection from Pairwise Comparisons,48,214,False,116,72,32,22,0,9,19,5,0,73,19222,2.1818181818181817,1.4545454545454546,3.272727272727273,0.8636363636363636,11
1582,The role of regularization in classification of high-dimensional noisy Gaussian mixture,8,The role of regularization in classification of high-dimensional noisy Gaussian mixture,38,113,False,43,268,21,21,6,11,16,0,0,87,11962,1.8095238095238095,1.0,12.761904761904763,0.7619047619047619,68
1583,Tighter Bounds on the Log Marginal Likelihood of Gaussian Process Regression Using Conjugate Gradients,8,Tighter Bounds on the Log Marginal Likelihood of Gaussian Process Regression Using Conjugate Gradients,31,151,False,104,50,33,17,3,8,16,1,2,102,9039,1.8235294117647058,2.0588235294117645,2.9411764705882355,0.9411764705882353,12
1584,Toward Better Generalization Bounds with Locally Elastic Stability,8,Toward Better Generalization Bounds with Locally Elastic Stability,43,614,False,212,104,71,25,11,12,15,0,4,66,14037,1.72,3.0,4.16,0.6,37
1585,Towards Reliable Neural Specifications,8,Towards Reliable Neural Specifications,29,197,False,51,29,28,19,0,9,11,0,14,38,9808,1.5263157894736843,2.210526315789474,1.5263157894736843,0.5789473684210527,3
1586,Training CNNs with Selective Allocation of Channels,8,Training CNNs with Selective Allocation of Channels,64,127,False,102,26,30,15,0,8,9,0,0,51,9459,4.266666666666667,2.0,1.7333333333333334,0.6,13
1588,Two-way kernel matrix puncturing: towards resource-efficient PCA and spectral clustering,8,Two-way kernel matrix puncturing towards resource-efficient PCA and spectral clustering,27,174,True,29,192,34,24,3,9,17,2,0,87,11760,1.125,1.4166666666666667,8.0,0.7083333333333334,7
1589,Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation,8,Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation,36,182,False,92,108,50,20,0,15,15,0,6,100,9588,1.8,2.8,5.4,0.75,53
1590,Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle,8,Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle,30,178,True,33,114,14,16,1,19,14,0,0,101,9651,1.875,0.875,7.125,0.875,3
1591,Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift,8,Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift,46,186,False,58,26,15,12,11,8,10,0,4,79,8229,3.8333333333333335,1.5833333333333333,2.1666666666666665,0.8333333333333334,27
1592,Unveiling the Latent Space Geometry of Push-Forward Generative Models,8,Unveiling the Latent Space Geometry of Push-Forward Generative Models,56,157,False,433,259,111,22,43,50,42,0,32,69,12241,2.5454545454545454,6.5,11.772727272727273,1.9090909090909092,1
1593,Variance Reduced Training with Stratified Sampling for Forecasting Models,8,Variance Reduced Training with Stratified Sampling for Forecasting Models,65,28,False,12,0,3,21,0,5,11,4,2,73,12851,3.0952380952380953,0.23809523809523808,0.0,0.5238095238095238,14
1594,Versatile Offline Imitation from Observations and Examples via Regularized State-Occupancy Matching,8,Versatile Offline Imitation from Observations and Examples via Regularized State-Occupancy Matching,47,127,False,70,158,46,25,0,17,22,0,10,99,12655,1.88,2.24,6.32,0.88,14
1595,Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks,8,Weisfeiler and Lehman Go Topological Message Passing Simplicial Networks,92,190,False,207,114,30,27,33,14,8,0,6,72,22040,3.4074074074074074,1.3333333333333333,4.222222222222222,0.2962962962962963,177
1596,When are Non-Parametric Methods Robust?,8,When are Non-Parametric Methods Robust,36,122,False,36,48,16,19,8,10,10,0,0,38,11639,1.894736842105263,0.8421052631578947,2.526315789473684,0.5263157894736842,25
1597,Winograd Algorithm for AdderNet,8,Winograd Algorithm for AdderNet,27,176,False,32,58,25,9,3,6,9,0,12,31,6576,3.0,4.111111111111111,6.444444444444445,1.0,8
1598,"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language",8,data2vec A General Framework for Self-supervised Learning in Speech Vision and Language,87,147,False,305,2,7,15,12,11,11,0,18,88,10054,5.8,1.6666666666666667,0.13333333333333333,0.7333333333333333,577
1599,A Closer Look at Self-supervised Lightweight Vision Transformers,8,A Closer Look at Self-supervised Lightweight Vision Transformers,87,170,False,133,8,35,18,19,10,17,0,26,64,10500,4.833333333333333,3.388888888888889,0.4444444444444444,0.9444444444444444,23
1601,A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines,8,A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines,49,134,False,50,14,48,19,0,7,8,3,8,96,12198,2.5789473684210527,2.9473684210526314,0.7368421052631579,0.42105263157894735,5
1602,A Personalized Affective Memory Neural Model for Improving Emotion Recognition,8,A Personalized Affective Memory Neural Model for Improving Emotion Recognition,49,107,False,46,28,9,10,0,7,9,5,6,78,7202,4.9,1.5,2.8,0.9,14
1603,A Sharp Analysis of Model-based Reinforcement Learning with Self-Play,8,A Sharp Analysis of Model-based Reinforcement Learning with Self-Play,42,236,False,154,280,0,46,41,16,21,12,2,69,21789,0.9130434782608695,0.043478260869565216,6.086956521739131,0.45652173913043476,109
1604,A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations,8,A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations,30,97,False,21,168,224,21,0,15,9,5,0,90,10527,1.4285714285714286,10.666666666666666,8.0,0.42857142857142855,137
1605,A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks,8,A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks,54,155,False,163,73,9,16,0,10,17,0,4,108,10542,3.375,0.8125,4.5625,1.0625,13
1606,Accelerated Linear Convergence of Stochastic Momentum Methods in Wasserstein Distances,8,Accelerated Linear Convergence of Stochastic Momentum Methods in Wasserstein Distances,75,214,False,94,712,5,72,0,12,10,0,0,86,23931,1.0416666666666667,0.06944444444444445,9.88888888888889,0.1388888888888889,42
1607,ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training,8,ActNN Reducing Training Memory Footprint via 2-Bit Activation Compressed Training,54,185,False,76,102,41,27,0,11,24,0,18,81,11864,2.0,2.185185185185185,3.7777777777777777,0.8888888888888888,55
1608,Actor-Attention-Critic for Multi-Agent Reinforcement Learning,8,Actor-Attention-Critic for Multi-Agent Reinforcement Learning,43,124,False,109,39,36,14,10,6,8,0,2,61,7648,3.0714285714285716,2.7142857142857144,2.7857142857142856,0.5714285714285714,593
1609,Adaptive Monte Carlo Multiple Testing via Multi-Armed Bandits,8,Adaptive Monte Carlo Multiple Testing via Multi-Armed Bandits,56,172,False,43,184,19,18,0,13,12,0,8,61,13170,3.111111111111111,1.5,10.222222222222221,0.6666666666666666,13
1610,Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning,8,Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning,38,159,False,48,44,9,14,0,11,14,6,10,72,9097,2.7142857142857144,1.3571428571428572,3.142857142857143,1.0,19
1611,Adversarial Parameter Attack on Deep Neural Networks,8,Adversarial Parameter Attack on Deep Neural Networks,58,180,False,85,102,4,29,0,7,14,3,22,52,12566,2.0,0.896551724137931,3.5172413793103448,0.4827586206896552,4
1612,Aggregating From Multiple Target-Shifted Sources,8,Aggregating From Multiple Target-Shifted Sources,87,127,False,143,160,82,32,22,22,16,0,10,48,16939,2.71875,2.875,5.0,0.5,22
1613,Amortized Monte Carlo Integration,8,Amortized Monte Carlo Integration,35,1,False,55,101,28,18,1,12,12,2,0,33,11535,1.9444444444444444,1.5555555555555556,5.611111111111111,0.6666666666666666,3
1614,An Intriguing Property of Geophysics Inversion,8,An Intriguing Property of Geophysics Inversion,23,235,False,59,24,27,13,0,7,13,3,22,46,7226,1.7692307692307692,3.769230769230769,1.8461538461538463,1.0,7
1615,Analyzing and Improving Representations with the Soft Nearest Neighbor Loss,8,Analyzing and Improving Representations with the Soft Nearest Neighbor Loss,22,151,False,31,8,76,16,8,15,7,1,4,75,8129,1.375,5.0,0.5,0.4375,133
1616,Approximation Algorithms for Cascading Prediction Models,8,Approximation Algorithms for Cascading Prediction Models,23,71,False,18,17,9,9,0,6,10,0,2,56,6675,2.5555555555555554,1.2222222222222223,1.8888888888888888,1.1111111111111112,18
1617,Atari-5: Distilling the Arcade Learning Environment down to Five Games,8,Atari-5 Distilling the Arcade Learning Environment down to Five Games,33,90,False,48,16,16,21,3,16,14,0,24,69,9326,1.5714285714285714,1.9047619047619047,0.7619047619047619,0.6666666666666666,6
1618,Automated Synthetic-to-Real Generalization,8,Automated Synthetic-to-Real Generalization,56,138,False,57,8,44,11,0,6,11,0,8,42,7573,5.090909090909091,4.7272727272727275,0.7272727272727273,1.0,61
1619,Balancing Discriminability and Transferability for Source-Free Domain Adaptation,8,Balancing Discriminability and Transferability for Source-Free Domain Adaptation,97,139,False,206,50,18,19,3,8,8,0,26,80,12607,5.105263157894737,2.3157894736842106,2.6315789473684212,0.42105263157894735,67
1620,Bayesian Graph Neural Networks with Adaptive Connection Sampling,8,Bayesian Graph Neural Networks with Adaptive Connection Sampling,49,145,False,120,48,17,15,0,12,10,6,8,64,9269,3.2666666666666666,1.6666666666666667,3.2,0.6666666666666666,83
1621,"Been There, Done That: Meta-Learning with Episodic Recall",8,Been There Done That Meta-Learning with Episodic Recall,32,110,False,124,28,54,10,0,12,10,2,0,55,7152,3.2,5.4,2.8,1.0,76
1622,Beyond log2(T) Regret for Decentralized Bandits in Matching Markets,8,Beyond log2T Regret for Decentralized Bandits in Matching Markets,30,28,False,72,82,27,40,0,16,25,4,2,67,18996,0.75,0.725,2.05,0.625,21
1623,Black Box FDR,8,Black Box FDR,31,1,True,36,22,30,12,0,8,9,0,2,13,6689,2.5833333333333335,2.6666666666666665,1.8333333333333333,0.75,18
1625,Bregman Proximal Langevin Monte Carlo via Bregman-Moreau Envelopes,8,Bregman Proximal Langevin Monte Carlo via Bregman-Moreau Envelopes,86,151,False,212,173,104,33,1,11,17,3,0,66,15160,2.606060606060606,3.1515151515151514,5.242424242424242,0.5151515151515151,5
1627,Causal Bandits with Propagating Inference,8,Causal Bandits with Propagating Inference,22,230,False,48,293,5,38,3,6,11,0,0,41,14683,0.5789473684210527,0.13157894736842105,7.7105263157894735,0.2894736842105263,27
1628,Certified Data Removal from Machine Learning Models,8,Certified Data Removal from Machine Learning Models,36,105,False,66,52,13,15,16,8,6,0,2,51,9481,2.4,1.0,3.466666666666667,0.4,257
1629,Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels,8,Class2Simi A Noise Reduction Perspective on Learning with Noisy Labels,73,172,False,85,12,13,11,0,6,4,0,8,70,7481,6.636363636363637,1.9090909090909092,1.0909090909090908,0.36363636363636365,46
1630,Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets,8,Coarsening the Granularity Towards Structurally Sparse Lottery Tickets,70,225,False,157,0,36,15,24,9,3,0,14,70,9881,4.666666666666667,3.3333333333333335,0.0,0.2,28
1631,Communication Complexity in Locally Private Distribution Estimation and Heavy Hitters,8,Communication Complexity in Locally Private Distribution Estimation and Heavy Hitters,45,112,False,47,78,8,17,1,7,3,0,4,85,7068,2.6470588235294117,0.7058823529411765,4.588235294117647,0.17647058823529413,48
1632,Composing Normalizing Flows for Inverse Problems,8,Composing Normalizing Flows for Inverse Problems,68,124,False,99,23,0,16,0,11,19,0,0,48,9596,4.25,0.0,1.4375,1.1875,42
1633,Conditional Neural Processes,8,Conditional Neural Processes,34,140,False,52,6,22,10,0,6,8,3,4,28,6980,3.4,2.6,0.6,0.8,559
1634,Consistent Estimators for Learning to Defer to an Expert,8,Consistent Estimators for Learning to Defer to an Expert,58,113,False,119,118,68,43,2,12,23,9,30,56,17924,1.3488372093023255,2.2790697674418605,2.744186046511628,0.5348837209302325,149
1635,Context-Aware Local Differential Privacy,8,Context-Aware Local Differential Privacy,43,161,False,52,136,13,24,1,13,21,1,2,40,9903,1.7916666666666667,0.625,5.666666666666667,0.875,31
1637,Convergence of policy gradient for entropy regularized MDPs with neural network approximation in the mean-field regime,8,Convergence of policy gradient for entropy regularized MDPs with neural network approximation in the mean-field regime,68,163,False,93,279,0,32,0,6,11,9,0,118,19654,2.125,0.0,8.71875,0.34375,9
1638,Correlated bandits or: How to minimize mean-squared error online,8,Correlated bandits or How to minimize mean-squared error online,20,166,False,46,166,6,21,0,9,7,6,0,63,10845,0.9523809523809523,0.2857142857142857,7.904761904761905,0.3333333333333333,4
1641,Data Scaling Laws in NMT: The Effect of Noise and Architecture,8,Data Scaling Laws in NMT The Effect of Noise and Architecture,49,162,True,114,8,37,17,0,13,10,2,2,61,9959,2.8823529411764706,2.2941176470588234,0.47058823529411764,0.5882352941176471,31
1642,Decentralised Learning with Random Features and Distributed Gradient Descent,8,Decentralised Learning with Random Features and Distributed Gradient Descent,51,187,False,72,282,12,42,6,13,30,0,0,76,17100,1.2142857142857142,0.2857142857142857,6.714285714285714,0.7142857142857143,14
1643,Deep Compressed Sensing,8,Deep Compressed Sensing,53,157,False,97,50,17,11,0,7,13,4,8,23,7599,4.818181818181818,2.272727272727273,4.545454545454546,1.1818181818181819,140
1644,Deep Reinforcement Learning Architecture for Continuous Power Allocation in High Throughput Satellites,8,Deep Reinforcement Learning Architecture for Continuous Power Allocation in High Throughput Satellites,15,143,False,24,20,15,8,0,6,9,0,8,102,5374,1.875,2.875,2.5,1.125,16
1645,Defense Through Diverse Directions,8,Defense Through Diverse Directions,45,102,False,54,46,12,11,0,10,13,4,8,34,7168,4.090909090909091,1.8181818181818181,4.181818181818182,1.1818181818181819,4
1646,DessiLBI: Exploring Structural Sparsity of Deep Networks via Differential Inclusion Paths,8,DessiLBI Exploring Structural Sparsity of Deep Networks via Differential Inclusion Paths,91,190,False,138,99,33,23,0,14,12,1,22,88,14513,3.9565217391304346,2.391304347826087,4.304347826086956,0.5217391304347826,6
1647,Differentiable Top-k Classification Learning,8,Differentiable Top-k Classification Learning,43,135,False,161,11,16,13,1,8,16,0,14,44,10154,3.3076923076923075,2.3076923076923075,0.8461538461538461,1.2307692307692308,17
1648,Diffusion Based Representation Learning,8,Diffusion Based Representation Learning,65,176,False,55,48,87,26,8,15,10,3,14,39,10773,2.5,3.8846153846153846,1.8461538461538463,0.38461538461538464,25
1649,Discovering Context Effects from Raw Choice Data,8,Discovering Context Effects from Raw Choice Data,47,152,False,73,118,15,24,1,9,13,7,2,48,15161,1.9583333333333333,0.7083333333333334,4.916666666666667,0.5416666666666666,22
1650,Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs,8,Dissipativity Theory for Accelerating Stochastic Variance Reduction A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs,38,135,True,83,150,0,14,0,11,8,0,0,135,9458,2.7142857142857144,0.0,10.714285714285714,0.5714285714285714,20
1651,Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration,8,Diversity Actor-Critic Sample-Aware Entropy Regularization for Sample-Efficient Exploration,64,99,False,124,101,87,28,0,14,14,0,12,91,13922,2.2857142857142856,3.5357142857142856,3.607142857142857,0.5,18
1652,Domain Agnostic Learning with Disentangled Representations,8,Domain Agnostic Learning with Disentangled Representations,57,107,False,70,18,3,12,0,8,3,0,0,58,7980,4.75,0.25,1.5,0.25,224
1653,Dynamic Measurement Scheduling for Event Forecasting using Deep RL,8,Dynamic Measurement Scheduling for Event Forecasting using Deep RL,48,109,True,74,6,21,14,2,7,9,1,10,66,8191,3.4285714285714284,2.2142857142857144,0.42857142857142855,0.6428571428571429,16
1654,Efficient Evaluation-Time Uncertainty Estimation by Improved Distillation,8,Efficient Evaluation-Time Uncertainty Estimation by Improved Distillation,19,73,False,38,8,31,8,0,9,7,0,6,73,4790,2.375,4.625,1.0,0.875,7
1656,Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits,8,Einsum Networks Fast and Scalable Learning of Tractable Probabilistic Circuits,57,149,False,100,16,29,11,0,8,7,0,2,78,8738,5.181818181818182,2.8181818181818183,1.4545454545454546,0.6363636363636364,99
1658,Escaping Saddle Points with Adaptive Gradient Methods,8,Escaping Saddle Points with Adaptive Gradient Methods,39,145,False,156,392,7,45,8,13,25,7,0,53,16005,0.8666666666666667,0.15555555555555556,8.71111111111111,0.5555555555555556,65
1659,Evaluating the Performance of Reinforcement Learning Algorithms,8,Evaluating the Performance of Reinforcement Learning Algorithms,68,99,False,136,70,27,30,0,19,11,2,26,63,17501,2.2666666666666666,1.7666666666666666,2.3333333333333335,0.36666666666666664,37
1660,Explicit Gradient Learning,8,Explicit Gradient Learning,60,163,False,55,162,90,49,2,15,14,3,4,26,20518,1.2244897959183674,1.9183673469387754,3.306122448979592,0.2857142857142857,8
1661,Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations,8,Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations,61,1,False,101,6,80,23,3,14,11,8,10,99,10701,2.652173913043478,3.9130434782608696,0.2608695652173913,0.4782608695652174,285
1662,Fair and Optimal Classification via Post-Processing,8,Fair and Optimal Classification via Post-Processing,89,151,False,136,261,21,47,21,13,14,0,4,51,20988,1.8936170212765957,0.5319148936170213,5.553191489361702,0.2978723404255319,15
1663,Fast Lossless Neural Compression with Integer-Only Discrete Flows,8,Fast Lossless Neural Compression with Integer-Only Discrete Flows,57,125,False,63,54,19,14,6,9,11,0,12,65,8920,4.071428571428571,2.2142857142857144,3.857142857142857,0.7857142857142857,7
1665,FedNL: Making Newton-Type Methods Applicable to Federated Learning,8,FedNL Making Newton-Type Methods Applicable to Federated Learning,43,229,False,135,301,111,65,0,15,59,4,22,65,31260,0.6615384615384615,2.046153846153846,4.630769230769231,0.9076923076923077,56
1666,Few-shot Relation Extraction via Bayesian Meta-learning on Relation Graphs,8,Few-shot Relation Extraction via Bayesian Meta-learning on Relation Graphs,40,167,False,65,70,11,13,0,10,9,0,12,74,8838,3.076923076923077,1.7692307692307692,5.384615384615385,0.6923076923076923,88
1667,First Order Generative Adversarial Networks,8,First Order Generative Adversarial Networks,37,151,False,74,116,20,25,0,10,6,0,4,43,11758,1.48,0.96,4.64,0.24,8
1668,Fold2Seq: A Joint Sequence(1D)-Fold(3D) Embedding-based Generative Model for Protein Design,8,Fold2Seq A Joint Sequence1D-Fold3D Embedding-based Generative Model for Protein Design,50,189,False,104,20,38,17,13,16,6,0,12,90,9897,2.9411764705882355,2.9411764705882355,1.1764705882352942,0.35294117647058826,44
1669,From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model,8,From Noisy Prediction to True Label Noisy Prediction Calibration via Generative Model,50,199,False,99,60,37,21,0,10,23,18,22,85,13157,2.380952380952381,2.8095238095238093,2.857142857142857,1.0952380952380953,17
1670,"Fundamental Limits of Two-layer Autoencoders, and Achieving Them with Gradient Methods",8,Fundamental Limits of Two-layer Autoencoders and Achieving Them with Gradient Methods,76,170,False,69,619,43,67,25,14,4,4,0,86,30061,1.1343283582089552,0.6417910447761194,9.238805970149254,0.05970149253731343,2
1671,GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings,8,GNNAutoScale Scalable and Expressive Graph Neural Networks via Historical Embeddings,62,143,False,210,64,19,18,13,14,3,0,16,84,11599,3.4444444444444446,1.9444444444444444,3.5555555555555554,0.16666666666666666,101
1672,Generalizable Episodic Memory for Deep Reinforcement Learning,8,Generalizable Episodic Memory for Deep Reinforcement Learning,47,1,False,142,80,36,18,4,12,13,0,4,61,9405,2.611111111111111,2.2222222222222223,4.444444444444445,0.7222222222222222,31
1673,Generalized Strategic Classification and the Case of Aligned Incentives,8,Generalized Strategic Classification and the Case of Aligned Incentives,37,1,False,54,159,24,26,14,11,27,0,0,71,14338,1.4230769230769231,0.9230769230769231,6.115384615384615,1.0384615384615385,15
1674,Generative Pretraining for Black-Box Optimization,8,Generative Pretraining for Black-Box Optimization,60,1,False,109,16,19,25,1,10,6,0,6,49,13598,2.4,1.0,0.64,0.24,12
1675,Global Optimization Networks,8,Global Optimization Networks,69,124,False,94,68,38,46,0,16,31,0,36,28,16985,1.5,1.608695652173913,1.4782608695652173,0.6739130434782609,5
1676,GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values,8,GradientDICE Rethinking Generalized Offline Estimation of Stationary Values,43,137,False,186,76,15,14,0,11,12,0,0,75,8812,3.0714285714285716,1.0714285714285714,5.428571428571429,0.8571428571428571,88
1677,GraphDF: A Discrete Flow Model for Molecular Graph Generation,8,GraphDF A Discrete Flow Model for Molecular Graph Generation,50,104,False,83,54,13,14,0,10,10,0,18,60,9279,3.5714285714285716,2.2142857142857144,3.857142857142857,0.7142857142857143,127
1678,Guided Learning of Nonconvex Models through Successive Functional Gradient Optimization,8,Guided Learning of Nonconvex Models through Successive Functional Gradient Optimization,29,63,False,35,67,30,16,7,8,15,3,12,87,10523,1.8125,2.625,4.1875,0.9375,7
1679,Hierarchical Shrinkage: improving the accuracy and interpretability of tree-based methods,8,Hierarchical Shrinkage improving the accuracy and interpretability of tree-based methods,61,234,False,55,26,92,22,0,13,14,0,6,88,11702,2.772727272727273,4.454545454545454,1.1818181818181819,0.6363636363636364,19
1680,HoroPCA: Hyperbolic Dimensionality Reduction via Horospherical Projections,8,HoroPCA Hyperbolic Dimensionality Reduction via Horospherical Projections,37,1,False,49,26,0,31,15,11,11,2,0,73,15523,1.1935483870967742,0.0,0.8387096774193549,0.3548387096774194,31
1681,How to train your neural ODE,8,How to train your neural ODE,40,127,True,82,66,41,14,0,13,4,0,4,28,7419,2.857142857142857,3.2142857142857144,4.714285714285714,0.2857142857142857,228
1682,INSPECTRE: Privately Estimating the Unseen,8,INSPECTRE Privately Estimating the Unseen,71,1,True,69,72,83,23,11,6,8,12,0,41,11176,3.0869565217391304,3.608695652173913,3.130434782608696,0.34782608695652173,22
1683,Implicit Regularization in Tensor Factorization,8,Implicit Regularization in Tensor Factorization,82,161,False,93,170,33,30,4,12,12,7,2,47,20643,2.7333333333333334,1.1666666666666667,5.666666666666667,0.4,42
1684,Improved OOD Generalization via Adversarial Training and Pre-training,8,Improved OOD Generalization via Adversarial Training and Pre-training,62,132,True,388,320,186,24,30,20,22,12,20,69,12554,2.5833333333333335,8.583333333333334,13.333333333333334,0.9166666666666666,61
1685,Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling,8,Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling,61,168,False,207,14,12,14,0,11,13,2,14,88,9059,4.357142857142857,1.8571428571428572,1.0,0.9285714285714286,10
1686,Improving the Sample and Communication Complexity for Decentralized Non-Convex Optimization: A Joint Gradient Estimation and Tracking Approach,8,Improving the Sample and Communication Complexity for Decentralized Non-Convex Optimization A Joint Gradient Estimation and Tracking Approach,70,250,False,81,202,4,32,0,11,6,3,2,141,13039,2.1875,0.1875,6.3125,0.1875,46
1687,Inference and Sampling of K33-free Ising Models,8,Inference and Sampling of K33-free Ising Models,36,145,False,52,72,30,20,1,14,16,0,0,47,11186,1.8,1.5,3.6,0.8,4
1688,InstaHide: Instance-hiding Schemes for Private Distributed Learning,8,InstaHide Instance-hiding Schemes for Private Distributed Learning,81,1,False,95,80,35,36,28,17,25,0,8,66,15671,2.25,1.1944444444444444,2.2222222222222223,0.6944444444444444,125
1689,Interpretable Stability Bounds for Spectral Graph Filters,8,Interpretable Stability Bounds for Spectral Graph Filters,40,169,False,92,58,41,29,8,11,15,0,4,57,10949,1.3793103448275863,1.5517241379310345,2.0,0.5172413793103449,33
1690,Invariant Risk Minimization Games,8,Invariant Risk Minimization Games,54,188,False,57,72,120,44,0,7,18,7,8,33,13905,1.2272727272727273,2.909090909090909,1.6363636363636365,0.4090909090909091,204
1692,Kernel Recursive ABC: Point Estimation with Intractable Likelihood,8,Kernel Recursive ABC Point Estimation with Intractable Likelihood,49,92,True,136,76,18,18,2,12,17,0,20,65,11217,2.7222222222222223,2.111111111111111,4.222222222222222,0.9444444444444444,12
1693,LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured Prediction,8,LP-SparseMAP Differentiable Relaxed Optimization for Sparse Structured Prediction,73,156,True,162,415,10,34,27,14,21,13,12,81,17702,2.1470588235294117,0.6470588235294118,12.205882352941176,0.6176470588235294,17
1694,Large-Scale Multi-Agent Deep FBSDEs,8,Large-Scale Multi-Agent Deep FBSDEs,21,139,False,240,472,90,23,0,34,54,0,12,35,13025,0.9130434782608695,4.434782608695652,20.52173913043478,2.347826086956522,4
1695,Learn2Hop: Learned Optimization on Rough Landscapes,8,Learn2Hop Learned Optimization on Rough Landscapes,60,137,False,75,22,30,16,3,14,21,0,12,50,10129,3.75,2.625,1.375,1.3125,13
1696,Learning Deep Neural Networks under Agnostic Corrupted Supervision,8,Learning Deep Neural Networks under Agnostic Corrupted Supervision,46,147,False,109,46,40,23,0,12,16,0,10,66,10908,2.0,2.1739130434782608,2.0,0.6956521739130435,3
1697,Learning Hidden Markov Models When the Locations of Missing Observations are Unknown,8,Learning Hidden Markov Models When the Locations of Missing Observations are Unknown,39,214,False,56,150,42,26,0,14,11,8,4,84,14207,1.5,1.7692307692307692,5.769230769230769,0.4230769230769231,0
1698,Learning Mixtures of Linear Dynamical Systems,8,Learning Mixtures of Linear Dynamical Systems,101,132,False,69,407,14,55,43,11,17,12,2,45,28804,1.8363636363636364,0.2909090909090909,7.4,0.3090909090909091,12
1699,Learning Robot Skills with Temporal Variational Inference,8,Learning Robot Skills with Temporal Variational Inference,53,104,False,114,28,8,13,0,7,10,4,4,57,9038,4.076923076923077,0.9230769230769231,2.1538461538461537,0.7692307692307693,60
1700,Learning by Playing - Solving Sparse Reward Tasks from Scratch,8,Learning by Playing - Solving Sparse Reward Tasks from Scratch,55,116,False,72,70,73,18,2,11,12,3,6,62,11985,3.0555555555555554,4.388888888888889,3.888888888888889,0.6666666666666666,399
1701,Learning to Collaborate in Markov Decision Processes,8,Learning to Collaborate in Markov Decision Processes,47,170,False,123,276,0,36,2,17,21,0,0,52,17713,1.3055555555555556,0.0,7.666666666666667,0.5833333333333334,33
1702,Learning to Prove Theorems via Interacting with Proof Assistants,8,Learning to Prove Theorems via Interacting with Proof Assistants,53,134,False,108,7,19,15,1,10,3,0,4,64,10016,3.533333333333333,1.5333333333333334,0.4666666666666667,0.2,100
1703,Learning-to-Learn Stochastic Gradient Descent with Biased Regularization,8,Learning-to-Learn Stochastic Gradient Descent with Biased Regularization,34,177,False,43,392,16,37,0,19,13,0,0,72,17388,0.918918918918919,0.43243243243243246,10.594594594594595,0.35135135135135137,98
1704,LieTransformer: Equivariant self-attention for Lie Groups,8,LieTransformer Equivariant self-attention for Lie Groups,64,133,False,159,52,35,22,1,16,13,1,4,56,13017,2.909090909090909,1.7727272727272727,2.3636363636363638,0.5909090909090909,89
1705,Lipschitz Normalization for Self-Attention Layers with Application to Graph Neural Networks,8,Lipschitz Normalization for Self-Attention Layers with Application to Graph Neural Networks,43,167,False,506,148,66,18,110,40,68,0,24,91,10503,2.388888888888889,5.0,8.222222222222221,3.7777777777777777,26
1706,Loss Landscapes of Regularized Linear Autoencoders,8,Loss Landscapes of Regularized Linear Autoencoders,37,103,False,79,36,40,14,1,8,13,0,14,50,8988,2.642857142857143,3.857142857142857,2.5714285714285716,0.9285714285714286,81
1707,MAGAN: Aligning Biological Manifolds,8,MAGAN Aligning Biological Manifolds,30,174,True,17,8,22,8,0,5,8,2,2,35,5523,3.75,3.0,1.0,1.0,61
1709,Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching,8,Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching,35,185,False,304,640,64,32,8,38,48,0,12,97,18823,1.09375,2.375,20.0,1.5,45
1710,MetAug: Contrastive Learning via Meta Feature Augmentation,8,MetAug Contrastive Learning via Meta Feature Augmentation,54,210,False,76,34,21,15,0,8,15,0,12,57,10055,3.6,2.2,2.2666666666666666,1.0,15
1711,Mind the box: l1-APGD for sparse adversarial attacks on image classifiers,8,Mind the box l1-APGD for sparse adversarial attacks on image classifiers,42,149,True,198,83,21,21,0,13,13,0,20,72,15058,2.0,1.9523809523809523,3.9523809523809526,0.6190476190476191,40
1712,MixFlows: principled variational inference via mixed flows,8,MixFlows principled variational inference via mixed flows,89,116,False,154,64,180,35,9,13,20,5,10,57,17067,2.5428571428571427,5.428571428571429,1.8285714285714285,0.5714285714285714,6
1713,Model-Based Active Exploration,8,Model-Based Active Exploration,46,140,False,112,61,38,17,2,11,13,0,8,30,9206,2.7058823529411766,2.7058823529411766,3.588235294117647,0.7647058823529411,155
1715,Moreau-Yosida f-divergences,8,Moreau-Yosida f-divergences,41,175,False,94,391,95,38,0,9,9,14,2,27,17189,1.0789473684210527,2.5526315789473686,10.289473684210526,0.23684210526315788,4
1716,Multi-Task Reinforcement Learning with Context-based Representations,8,Multi-Task Reinforcement Learning with Context-based Representations,86,0,False,17,12,0,17,0,6,5,0,16,68,11452,5.0588235294117645,0.9411764705882353,0.7058823529411765,0.29411764705882354,116
1717,Mutual Information Neural Estimation,8,Mutual Information Neural Estimation,61,102,False,202,49,37,18,9,8,13,11,30,36,10222,3.388888888888889,3.7222222222222223,2.7222222222222223,0.7222222222222222,1016
1718,Near-Optimal Linear Regression under Distribution Shift,8,Near-Optimal Linear Regression under Distribution Shift,70,85,False,80,146,12,37,17,13,12,0,0,55,13966,1.8918918918918919,0.32432432432432434,3.945945945945946,0.32432432432432434,29
1719,Neural Architecture Search without Training,8,Neural Architecture Search without Training,44,168,False,145,4,53,13,1,7,6,0,4,43,7691,3.3846153846153846,4.384615384615385,0.3076923076923077,0.46153846153846156,274
1720,Neural Relational Inference for Interacting Systems,8,Neural Relational Inference for Interacting Systems,83,138,False,43,30,48,17,5,11,24,1,4,51,10941,4.882352941176471,3.0588235294117645,1.7647058823529411,1.411764705882353,707
1721,NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural Radiance Fields,8,NeuroFluid Fluid Dynamics Grounding with Particle-Driven Neural Radiance Fields,51,148,False,48,30,15,11,5,7,8,0,12,79,7715,4.636363636363637,2.4545454545454546,2.727272727272727,0.7272727272727273,18
1722,Non-exponentially weighted aggregation: regret bounds for unbounded loss functions,8,Non-exponentially weighted aggregation regret bounds for unbounded loss functions,70,112,False,128,196,0,16,0,9,7,0,0,81,9986,4.375,0.0,12.25,0.4375,13
1723,Not All Poisons are Created Equal: Robust Training against Data Poisoning,8,Not All Poisons are Created Equal Robust Training against Data Poisoning,40,28,False,106,30,89,12,21,23,36,15,48,72,8594,3.3333333333333335,11.416666666666666,2.5,3.0,23
1724,Off-policy Confidence Sequences,8,Off-policy Confidence Sequences,36,80,False,45,113,12,30,2,14,25,0,2,31,10911,1.2,0.4666666666666667,3.7666666666666666,0.8333333333333334,13
1726,On Learning Sets of Symmetric Elements,8,On Learning Sets of Symmetric Elements,71,178,False,135,26,23,20,30,15,25,0,8,38,14367,3.55,1.55,1.3,1.25,111
1727,On Thompson Sampling with Langevin Algorithms,8,On Thompson Sampling with Langevin Algorithms,48,164,False,104,328,3,47,1,12,9,1,0,45,22416,1.0212765957446808,0.06382978723404255,6.9787234042553195,0.19148936170212766,12
1728,On the Finite-Time Complexity and Practical Computation of Approximate Stationarity Concepts of Lipschitz Functions,8,On the Finite-Time Complexity and Practical Computation of Approximate Stationarity Concepts of Lipschitz Functions,59,161,False,157,114,8,20,4,12,10,6,0,115,11996,2.95,0.4,5.7,0.5,16
1729,On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization,8,On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization,43,168,True,53,242,35,37,0,6,10,11,2,110,19751,1.162162162162162,1.0,6.54054054054054,0.2702702702702703,326
1730,On the Statistical Efficiency of Optimal Kernel Sum Classifiers,8,On the Statistical Efficiency of Optimal Kernel Sum Classifiers,24,1,False,29,118,7,22,1,17,3,0,0,63,8326,1.0909090909090908,0.3181818181818182,5.363636363636363,0.13636363636363635,0
1731,Online Active Regression,8,Online Active Regression,20,158,False,94,149,14,33,4,10,10,0,0,24,17443,0.6060606060606061,0.42424242424242425,4.515151515151516,0.30303030303030304,4
1732,Optimal approximation for unconstrained non-submodular minimization,8,Optimal approximation for unconstrained non-submodular minimization,70,112,False,94,66,19,21,3,10,14,0,0,67,13437,3.3333333333333335,0.9047619047619048,3.142857142857143,0.6666666666666666,19
1733,Optimizing Tensor Network Contraction Using Reinforcement Learning,8,Optimizing Tensor Network Contraction Using Reinforcement Learning,46,147,False,62,14,19,18,25,9,12,0,20,66,9534,2.5555555555555554,2.1666666666666665,0.7777777777777778,0.6666666666666666,9
1734,Overcoming Multi-Model Forgetting,8,Overcoming Multi-Model Forgetting,34,111,False,113,69,21,13,0,8,5,1,2,33,8429,2.6153846153846154,1.7692307692307692,5.3076923076923075,0.38461538461538464,31
1735,PDO-s3DCNNs: Partial Differential Operator Based Steerable 3D CNNs,8,PDO-s3DCNNs Partial Differential Operator Based Steerable 3D CNNs,45,177,True,145,156,9,20,0,13,17,0,38,65,13888,2.25,2.35,7.8,0.85,4
1737,Path-Gradient Estimators for Continuous Normalizing Flows,8,Path-Gradient Estimators for Continuous Normalizing Flows,30,89,False,131,94,23,15,6,18,20,4,12,57,8266,2.0,2.3333333333333335,6.266666666666667,1.3333333333333333,10
1738,"Phase Transitions, Distance Functions, and Implicit Neural Representations",8,Phase Transitions Distance Functions and Implicit Neural Representations,36,135,False,72,102,50,17,4,10,17,0,8,74,10912,2.1176470588235294,3.411764705882353,6.0,1.0,28
1739,Policy Certificates: Towards Accountable Reinforcement Learning,8,Policy Certificates Towards Accountable Reinforcement Learning,51,155,False,114,325,17,42,4,13,18,0,2,62,24254,1.2142857142857142,0.4523809523809524,7.738095238095238,0.42857142857142855,133
1740,Pow-Wow: A Dataset and Study on Collaborative Communication in Pommerman,8,Pow-Wow A Dataset and Study on Collaborative Communication in Pommerman,13,150,False,28,0,12,9,10,10,7,4,2,71,4912,1.4444444444444444,1.5555555555555556,0.0,0.7777777777777778,1
1741,Pretrained Generalized Autoregressive Model with Adaptive Probabilistic Label Clusters for Extreme Multi-label Text Classification,8,Pretrained Generalized Autoregressive Model with Adaptive Probabilistic Label Clusters for Extreme Multi-label Text Classification,44,108,False,58,36,15,11,0,7,5,0,8,130,7571,4.0,2.090909090909091,3.272727272727273,0.45454545454545453,46
1742,Private Outsourced Bayesian Optimization,8,Private Outsourced Bayesian Optimization,63,160,False,163,144,11,27,0,8,10,2,24,40,18389,2.3333333333333335,1.2962962962962963,5.333333333333333,0.37037037037037035,19
1743,Processing Megapixel Images with Deep Attention-Sampling Models,8,Processing Megapixel Images with Deep Attention-Sampling Models,26,229,False,53,38,137,17,0,14,17,11,4,63,8853,1.5294117647058822,8.294117647058824,2.235294117647059,1.0,56
1744,Provable Generalization of SGD-trained Neural Networks of Any Width in the Presence of Adversarial Label Noise,8,Provable Generalization of SGD-trained Neural Networks of Any Width in the Presence of Adversarial Label Noise,61,118,True,92,93,41,30,0,8,5,0,0,110,14281,2.033333333333333,1.3666666666666667,3.1,0.16666666666666666,14
1745,Provably End-to-end Label-Noise Learning without Anchor Points,8,Provably End-to-end Label-Noise Learning without Anchor Points,56,143,False,50,48,37,15,0,10,4,0,6,62,9619,3.7333333333333334,2.8666666666666667,3.2,0.26666666666666666,84
1746,Quadratically Regularized Subgradient Methods for Weakly Convex Optimization with Weakly Convex Constraints,8,Quadratically Regularized Subgradient Methods for Weakly Convex Optimization with Weakly Convex Constraints,63,133,False,82,132,8,15,0,7,8,1,0,107,10477,4.2,0.5333333333333333,8.8,0.5333333333333333,18
1747,Quasi-Monte Carlo Variational Inference,8,Quasi-Monte Carlo Variational Inference,62,174,False,167,89,14,14,19,9,20,0,2,39,10520,4.428571428571429,1.1428571428571428,6.357142857142857,1.4285714285714286,55
1748,Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,8,Random Fourier Features for Kernel Ridge Regression Approximation Bounds and Statistical Guarantees,26,183,False,44,346,23,56,4,16,18,3,2,99,21668,0.4642857142857143,0.44642857142857145,6.178571428571429,0.32142857142857145,142
1749,Rate-Distortion Analysis of Minimum Excess Risk in Bayesian Learning,8,Rate-Distortion Analysis of Minimum Excess Risk in Bayesian Learning,31,208,False,54,158,6,19,0,18,12,0,0,68,12856,1.631578947368421,0.3157894736842105,8.31578947368421,0.631578947368421,8
1750,Recursive Sketches for Modular Deep Learning,8,Recursive Sketches for Modular Deep Learning,41,185,False,28,233,22,52,6,13,33,1,2,44,28879,0.7884615384615384,0.46153846153846156,4.480769230769231,0.6346153846153846,19
1751,Reinforcement Learning for Integer Programming: Learning to Cut,8,Reinforcement Learning for Integer Programming Learning to Cut,32,213,False,73,36,29,18,28,12,8,0,14,62,12028,1.7777777777777777,2.388888888888889,2.0,0.4444444444444444,119
1752,Representation Learning via Adversarially-Contrastive Optimal Transport,8,Representation Learning via Adversarially-Contrastive Optimal Transport,45,180,False,56,39,25,13,0,8,10,1,6,71,9253,3.4615384615384617,2.3846153846153846,3.0,0.7692307692307693,6
1754,Revisiting Spatial Invariance with Low-Rank Local Connectivity,8,Revisiting Spatial Invariance with Low-Rank Local Connectivity,66,187,False,51,12,36,19,1,10,5,2,16,62,10415,3.473684210526316,2.736842105263158,0.631578947368421,0.2631578947368421,37
1755,Robust Counterfactual Explanations for Tree-Based Ensembles,8,Robust Counterfactual Explanations for Tree-Based Ensembles,30,202,False,46,14,16,18,1,8,12,0,22,59,9033,1.6666666666666667,2.111111111111111,0.7777777777777778,0.6666666666666666,29
1757,S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning,8,S2SD Simultaneous Similarity-based Self-Distillation for Deep Metric Learning,80,1,False,532,90,3,21,0,34,44,4,4,77,13171,3.8095238095238093,0.3333333333333333,4.285714285714286,2.0952380952380953,17
1759,Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes,8,Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes,25,196,False,42,201,0,27,2,8,6,0,0,81,15443,0.9259259259259259,0.0,7.444444444444445,0.2222222222222222,1
1760,Scalable Fair Clustering,8,Scalable Fair Clustering,15,200,False,69,30,19,17,21,7,1,0,6,24,8188,0.8823529411764706,1.4705882352941178,1.7647058823529411,0.058823529411764705,170
1763,Self-supervised Learning with Random-projection Quantizer for Speech Recognition,8,Self-supervised Learning with Random-projection Quantizer for Speech Recognition,30,139,False,72,4,9,10,4,12,20,11,14,80,6847,3.0,2.3,0.4,2.0,90
1765,Signatured Deep Fictitious Play for Mean Field Games with Common Noise,8,Signatured Deep Fictitious Play for Mean Field Games with Common Noise,56,1,False,93,176,38,20,3,13,2,0,20,70,13352,2.8,2.9,8.8,0.1,24
1767,Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation,8,Soft Truncation A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation,46,131,False,143,112,52,28,0,12,18,0,18,113,13774,1.6428571428571428,2.5,4.0,0.6428571428571429,63
1768,SparseBERT: Rethinking the Importance Analysis in Self-attention,8,SparseBERT Rethinking the Importance Analysis in Self-attention,41,143,False,245,82,186,15,0,22,26,13,30,63,9242,2.7333333333333334,14.4,5.466666666666667,1.7333333333333334,39
1769,Stabilizing Differentiable Architecture Search via Perturbation-based Regularization,8,Stabilizing Differentiable Architecture Search via Perturbation-based Regularization,58,166,False,121,16,26,14,16,8,15,2,14,84,8655,4.142857142857143,2.857142857142857,1.1428571428571428,1.0714285714285714,168
1770,Statistics and Samples in Distributional Reinforcement Learning,8,Statistics and Samples in Distributional Reinforcement Learning,23,125,False,67,112,44,25,0,12,24,0,2,63,13790,0.92,1.84,4.48,0.96,73
1771,Stochastic Iterative Hard Thresholding for Graph-structured Sparsity Optimization,8,Stochastic Iterative Hard Thresholding for Graph-structured Sparsity Optimization,66,129,False,116,140,22,22,0,10,2,0,10,81,13844,3.0,1.4545454545454546,6.363636363636363,0.09090909090909091,5
1772,Strategic Classification Made Practical,8,Strategic Classification Made Practical,50,1,False,112,35,19,13,12,7,14,4,0,39,9208,3.8461538461538463,1.4615384615384615,2.6923076923076925,1.0769230769230769,35
1773,Structure-preserving GANs,8,Structure-preserving GANs,80,227,False,102,210,76,39,2,11,19,2,18,25,18414,2.051282051282051,2.41025641025641,5.384615384615385,0.48717948717948717,11
1774,Submodular Observation Selection and Information Gathering for Quadratic Models,8,Submodular Observation Selection and Information Gathering for Quadratic Models,35,157,False,148,320,30,14,0,32,6,4,0,79,8990,2.5,2.142857142857143,22.857142857142858,0.42857142857142855,23
1776,TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning,8,TapNet Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning,23,130,False,62,18,16,13,0,7,9,0,6,83,8180,1.7692307692307692,1.6923076923076923,1.3846153846153846,0.6923076923076923,248
1777,Temporal Phenotyping using Deep Predictive Clustering of Disease Progression,8,Temporal Phenotyping using Deep Predictive Clustering of Disease Progression,28,140,False,105,34,30,19,0,13,13,3,12,76,11267,1.4736842105263157,2.210526315789474,1.7894736842105263,0.6842105263157895,45
1778,The Cost-free Nature of Optimally Tuning Tikhonov Regularizers and Other Ordered Smoothers,8,The Cost-free Nature of Optimally Tuning Tikhonov Regularizers and Other Ordered Smoothers,51,233,False,41,53,0,13,1,5,4,0,0,90,6294,3.923076923076923,0.0,4.076923076923077,0.3076923076923077,7
1779,The Implicit Regularization of Stochastic Gradient Flow for Least Squares,8,The Implicit Regularization of Stochastic Gradient Flow for Least Squares,98,148,False,91,189,34,24,3,18,7,0,0,73,12840,4.083333333333333,1.4166666666666667,7.875,0.2916666666666667,70
1780,The Shapley Taylor Interaction Index,8,The Shapley Taylor Interaction Index,34,203,False,36,179,14,21,6,9,23,7,2,36,7890,1.619047619047619,0.7619047619047619,8.523809523809524,1.0952380952380953,105
1781,Theoretical Analysis of Image-to-Image Translation with Adversarial Learning,8,Theoretical Analysis of Image-to-Image Translation with Adversarial Learning,42,0,False,16,48,0,20,0,6,1,0,0,76,10211,2.1,0.0,2.4,0.05,6
1782,Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds,8,Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds,26,139,False,81,396,2,40,10,16,26,0,0,118,22732,0.65,0.05,9.9,0.65,253
1784,Towards Rigorous Interpretations: a Formalisation of Feature Attribution,8,Towards Rigorous Interpretations a Formalisation of Feature Attribution,47,141,False,64,62,43,20,0,11,17,0,12,71,13536,2.35,2.75,3.1,0.85,14
1785,Training Characteristic Functions with Reinforcement Learning: XAI-methods play Connect Four,8,Training Characteristic Functions with Reinforcement Learning XAI-methods play Connect Four,61,157,True,94,17,23,19,18,12,12,1,2,91,9901,3.210526315789474,1.3157894736842106,0.8947368421052632,0.631578947368421,8
1786,Transfer and Marginalize: Explaining Away Label Noise with Privileged Information,8,Transfer and Marginalize Explaining Away Label Noise with Privileged Information,36,120,False,126,46,20,19,11,15,15,5,18,80,10572,1.894736842105263,2.0,2.4210526315789473,0.7894736842105263,6
1789,Understanding the Loss Surface of Neural Networks for Binary Classification,8,Understanding the Loss Surface of Neural Networks for Binary Classification,38,136,False,21,376,4,82,0,7,27,0,2,75,35143,0.4634146341463415,0.07317073170731707,4.585365853658536,0.32926829268292684,79
1790,Unraveling Attention via Convex Duality: Analysis and Interpretations of Vision Transformers,8,Unraveling Attention via Convex Duality Analysis and Interpretations of Vision Transformers,65,147,False,77,432,6,38,0,9,19,6,6,91,17280,1.7105263157894737,0.3157894736842105,11.368421052631579,0.5,25
1792,Variance Reduction in Stochastic Particle-Optimization Sampling,8,Variance Reduction in Stochastic Particle-Optimization Sampling,31,158,False,59,116,26,32,0,12,8,3,4,63,10044,0.96875,0.9375,3.625,0.25,10
1793,Versatile Verification of Tree Ensembles,8,Versatile Verification of Tree Ensembles,36,224,False,43,34,18,12,1,10,21,3,10,40,9113,3.0,2.3333333333333335,2.8333333333333335,1.75,9
1794,Weisfeiler-Lehman meets Gromov-Wasserstein,8,Weisfeiler-Lehman meets Gromov-Wasserstein,46,222,False,54,238,15,60,12,9,19,22,8,42,24766,0.7666666666666667,0.38333333333333336,3.966666666666667,0.31666666666666665,8
1795,When deep denoising meets iterative phase retrieval,8,When deep denoising meets iterative phase retrieval,61,108,False,136,146,12,14,0,8,11,0,4,51,7203,4.357142857142857,1.1428571428571428,10.428571428571429,0.7857142857142857,14
1796,Working Memory Graphs,8,Working Memory Graphs,41,138,False,166,22,44,18,0,16,10,6,60,21,9863,2.2777777777777777,5.777777777777778,1.2222222222222223,0.5555555555555556,34
1797,f-Domain-Adversarial Learning: Theory and Algorithms,8,f-Domain-Adversarial Learning Theory and Algorithms,43,174,False,246,66,21,18,2,12,13,0,26,51,12382,2.388888888888889,2.611111111111111,3.6666666666666665,0.7222222222222222,49
1798,A Closer Look at Smoothness in Domain Adversarial Training,8,A Closer Look at Smoothness in Domain Adversarial Training,66,170,False,215,64,29,22,0,21,12,1,34,58,13686,3.0,2.8636363636363638,2.909090909090909,0.5454545454545454,66
1799,A Dynamical Systems Perspective on Nesterov Acceleration,8,A Dynamical Systems Perspective on Nesterov Acceleration,16,92,False,42,126,8,11,0,7,6,0,0,56,6450,1.4545454545454546,0.7272727272727273,11.454545454545455,0.5454545454545454,106
1800,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,8,A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music,43,130,False,47,14,45,16,0,12,16,2,4,76,8947,2.6875,3.0625,0.875,1.0,399
1801,A Practical Method for Constructing Equivariant Multilayer Perceptrons for Arbitrary Matrix Groups,8,A Practical Method for Constructing Equivariant Multilayer Perceptrons for Arbitrary Matrix Groups,48,121,False,138,74,30,18,0,19,14,0,18,98,13468,2.6666666666666665,2.6666666666666665,4.111111111111111,0.7777777777777778,147
1802,A Simple Framework for Contrastive Learning of Visual Representations,8,A Simple Framework for Contrastive Learning of Visual Representations,67,138,False,96,2,61,20,13,12,19,2,28,69,12108,3.35,4.45,0.1,0.95,13676
1803,A Theory of Label Propagation for Subpopulation Shift,8,A Theory of Label Propagation for Subpopulation Shift,85,146,False,184,53,6,28,5,10,15,2,4,53,12927,3.0357142857142856,0.35714285714285715,1.8928571428571428,0.5357142857142857,41
1804,A psychological theory of explainability,8,A psychological theory of explainability,43,157,False,48,20,9,15,0,10,10,12,8,40,9980,2.8666666666666667,1.1333333333333333,1.3333333333333333,0.6666666666666666,12
1805,Accelerated Message Passing for Entropy-Regularized MAP Inference,8,Accelerated Message Passing for Entropy-Regularized MAP Inference,46,173,True,141,259,14,26,4,13,19,5,0,65,14663,1.7692307692307692,0.5384615384615384,9.961538461538462,0.7307692307692307,0
1806,Action Matching: Learning Stochastic Dynamics from Samples,8,Action Matching Learning Stochastic Dynamics from Samples,70,190,False,2,10,0,32,1,4,4,0,0,57,17653,2.1875,0.0,0.3125,0.125,14
1807,Actor-Critic based Improper Reinforcement Learning,8,Actor-Critic based Improper Reinforcement Learning,53,197,False,159,512,64,53,0,32,28,1,12,50,26310,1.0,1.4339622641509433,9.660377358490566,0.5283018867924528,2
1808,Adaptive Neural Trees,8,Adaptive Neural Trees,83,134,False,227,6,19,15,3,14,9,0,18,21,11017,5.533333333333333,2.466666666666667,0.4,0.6,142
1809,Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment,8,Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment,45,130,False,75,24,24,13,0,12,6,0,18,64,10301,3.4615384615384617,3.230769230769231,1.8461538461538463,0.46153846153846156,63
1810,Adversarial Policies Beat Superhuman Go AIs,8,Adversarial Policies Beat Superhuman Go AIs,83,123,False,204,26,50,87,0,18,32,4,10,43,31589,0.9540229885057471,0.6896551724137931,0.2988505747126437,0.367816091954023,7
1811,Aggregation of Multiple Knockoffs,8,Aggregation of Multiple Knockoffs,34,108,False,70,124,28,35,0,10,15,0,2,33,11035,0.9714285714285714,0.8571428571428571,3.5428571428571427,0.42857142857142855,17
1812,Amortized Population Gibbs Samplers with Neural Sufficient Statistics,8,Amortized Population Gibbs Samplers with Neural Sufficient Statistics,43,102,False,53,192,37,27,1,17,12,0,24,69,13498,1.5925925925925926,2.259259259259259,7.111111111111111,0.4444444444444444,6
1813,An Investigation into Neural Net Optimization via Hessian Eigenvalue Density,8,An Investigation into Neural Net Optimization via Hessian Eigenvalue Density,36,148,False,41,58,57,21,0,12,9,0,0,76,9348,1.7142857142857142,2.7142857142857144,2.761904761904762,0.42857142857142855,254
1814,Analyzing and Mitigating Interference in Neural Architecture Search,8,Analyzing and Mitigating Interference in Neural Architecture Search,77,261,False,164,10,37,17,18,10,11,0,12,67,11509,4.529411764705882,2.8823529411764706,0.5882352941176471,0.6470588235294118,26
1815,Approximation Capabilities of Neural ODEs and Invertible Residual Networks,8,Approximation Capabilities of Neural ODEs and Invertible Residual Networks,27,126,False,53,18,8,14,2,8,11,0,0,74,7494,1.9285714285714286,0.5714285714285714,1.2857142857142858,0.7857142857142857,81
1816,Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,8,Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,54,165,False,103,50,166,27,9,15,28,0,8,69,14604,2.0,6.444444444444445,1.8518518518518519,1.037037037037037,334
1817,Automatic Classifiers as Scientific Instruments: One Step Further Away from Ground-Truth,8,Automatic Classifiers as Scientific Instruments One Step Further Away from Ground-Truth,29,212,False,45,40,30,10,0,9,10,0,0,87,7358,2.9,3.0,4.0,1.0,1
1818,Band-limited Training and Inference for Convolutional Neural Networks,8,Band-limited Training and Inference for Convolutional Neural Networks,42,125,False,47,5,176,16,0,12,27,17,6,69,11023,2.625,11.375,0.3125,1.6875,44
1819,Bayesian Imitation Learning for End-to-End Mobile Manipulation,8,Bayesian Imitation Learning for End-to-End Mobile Manipulation,54,185,False,51,8,34,15,0,10,3,0,8,62,8025,3.6,2.8,0.5333333333333333,0.2,7
1820,Being Bayesian about Categorical Probability,8,Being Bayesian about Categorical Probability,66,108,False,142,32,25,12,4,7,8,0,8,44,8501,5.5,2.75,2.6666666666666665,0.6666666666666666,46
1821,Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical Models with Double Power-law Behavior,8,Beyond the Chinese Restaurant and Pitman-Yor processes Statistical Models with Double Power-law Behavior,49,180,False,100,131,78,28,15,12,20,0,4,104,9416,1.75,2.9285714285714284,4.678571428571429,0.7142857142857143,12
1822,Black-Box Tuning for Language-Model-as-a-Service,8,Black-Box Tuning for Language-Model-as-a-Service,68,150,False,98,8,41,15,20,9,7,0,8,48,10033,4.533333333333333,3.2666666666666666,0.5333333333333333,0.4666666666666667,166
1823,Born-Again Tree Ensembles,8,Born-Again Tree Ensembles,56,154,False,149,18,27,17,7,11,7,0,22,25,11168,3.2941176470588234,2.8823529411764706,1.0588235294117647,0.4117647058823529,41
1824,Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation,8,Bridging Multi-Task Learning and Meta-Learning Towards Efficient Training and Effective Adaptation,68,247,False,168,186,7,26,5,11,20,2,8,98,15898,2.6153846153846154,0.5769230769230769,7.153846153846154,0.7692307692307693,64
1825,COLA: Consistent Learning with Opponent-Learning Awareness,8,COLA Consistent Learning with Opponent-Learning Awareness,43,239,True,141,96,72,28,15,18,15,0,22,57,12724,1.5357142857142858,3.357142857142857,3.4285714285714284,0.5357142857142857,28
1826,Causal Conceptions of Fairness and their Consequences,8,Causal Conceptions of Fairness and their Consequences,73,222,False,111,538,5,40,6,13,14,4,0,53,31039,1.825,0.125,13.45,0.35,38
1827,Certified Neural Network Watermarks with Randomized Smoothing,8,Certified Neural Network Watermarks with Randomized Smoothing,34,154,False,92,6,29,16,12,7,13,0,14,61,8645,2.125,2.6875,0.375,0.8125,24
1828,Classification from Pairwise Similarity and Unlabeled Data,8,Classification from Pairwise Similarity and Unlabeled Data,56,106,False,41,148,26,19,0,13,14,0,8,58,9854,2.9473684210526314,1.7894736842105263,7.7894736842105265,0.7368421052631579,75
1829,Cocktail Party Attack: Breaking Aggregation-Based Privacy in Federated Learning using Independent Component Analysis,8,Cocktail Party Attack Breaking Aggregation-Based Privacy in Federated Learning using Independent Component Analysis,26,191,False,32,42,30,14,0,11,13,2,12,115,7206,1.8571428571428572,3.0,3.0,0.9285714285714286,15
1830,Communication-Computation Efficient Gradient Coding,8,Communication-Computation Efficient Gradient Coding,39,109,False,74,82,10,20,0,10,7,0,4,51,12574,1.95,0.7,4.1,0.35,148
1831,Composing Partial Differential Equations with Physics-Aware Neural Networks,8,Composing Partial Differential Equations with Physics-Aware Neural Networks,36,136,False,107,36,107,29,31,11,15,3,38,75,18548,1.2413793103448276,5.0,1.2413793103448276,0.5172413793103449,13
1833,Consistent Polyhedral Surrogates for Top-k Classification and Variants,8,Consistent Polyhedral Surrogates for Top-k Classification and Variants,28,133,False,94,170,10,31,1,11,24,1,2,70,18077,0.9032258064516129,0.3870967741935484,5.483870967741935,0.7741935483870968,7
1834,Context-Aware Zero-Shot Learning for Object Recognition,8,Context-Aware Zero-Shot Learning for Object Recognition,62,121,False,57,24,18,13,7,10,11,0,20,55,10253,4.769230769230769,2.923076923076923,1.8461538461538463,0.8461538461538461,27
1835,Contrastive Explanations with Local Foil Trees,8,Contrastive Explanations with Local Foil Trees,43,123,False,52,0,6,7,0,4,1,0,2,46,4634,6.142857142857143,1.1428571428571428,0.0,0.14285714285714285,75
1836,Convex Calibrated Surrogates for the Multi-Label F-Measure,8,Convex Calibrated Surrogates for the Multi-Label F-Measure,27,236,False,94,64,3,11,0,10,4,0,4,58,8082,2.4545454545454546,0.6363636363636364,5.818181818181818,0.36363636363636365,16
1837,Correlated quantization for distributed mean estimation and optimization,8,Correlated quantization for distributed mean estimation and optimization,40,113,False,105,150,9,30,5,13,2,0,4,72,11450,1.3333333333333333,0.43333333333333335,5.0,0.06666666666666667,9
1839,DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm,8,DG-LMC A Turn-key and Scalable Synchronous Distributed MCMC Algorithm,48,124,True,144,591,21,77,6,13,20,10,4,69,29310,0.6233766233766234,0.3246753246753247,7.675324675324675,0.2597402597402597,17
1840,Data Shapley: Equitable Valuation of Data for Machine Learning,8,Data Shapley Equitable Valuation of Data for Machine Learning,50,0,False,46,2,27,23,18,9,3,0,2,61,9658,2.1739130434782608,1.2608695652173914,0.08695652173913043,0.13043478260869565,536
1841,Decentralized Exploration in Multi-Armed Bandits,8,Decentralized Exploration in Multi-Armed Bandits,31,0,False,69,6,26,15,15,7,9,0,0,48,9021,2.066666666666667,1.7333333333333334,0.4,0.6,19
1843,Deep Reinforcement Learning with Smooth Policy,8,Deep Reinforcement Learning with Smooth Policy,34,150,False,43,34,15,16,0,7,5,0,0,46,6053,2.125,0.9375,2.125,0.3125,5
1844,Defining Locality for Surrogates in Post-hoc Interpretablity,8,Defining Locality for Surrogates in Post-hoc Interpretablity,11,172,False,12,2,15,7,0,6,7,3,2,60,4710,1.5714285714285714,2.4285714285714284,0.2857142857142857,1.0,67
1845,Detached Error Feedback for Distributed SGD with Random Sparsification,8,Detached Error Feedback for Distributed SGD with Random Sparsification,58,149,True,101,896,20,26,0,15,38,0,8,70,14161,2.230769230769231,1.0769230769230769,34.46153846153846,1.4615384615384615,6
1846,Differentiable and Transportable Structure Learning,8,Differentiable and Transportable Structure Learning,94,169,False,191,42,56,28,0,13,17,0,20,51,17361,3.357142857142857,2.7142857142857144,1.5,0.6071428571428571,1
1847,Diffusion Earth Mover's Distance and Distribution Embeddings,8,Diffusion Earth Movers Distance and Distribution Embeddings,55,210,False,148,100,0,23,14,12,16,0,2,60,15512,2.391304347826087,0.08695652173913043,4.3478260869565215,0.6956521739130435,24
1848,Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning,8,Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning,48,193,False,86,44,66,16,0,18,36,4,4,93,10916,3.0,4.375,2.75,2.25,5
1850,"Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic Programs with Stochastic Support",8,Divide Conquer and Combine a New Inference Strategy for Probabilistic Programs with Stochastic Support,58,1,False,86,30,30,21,6,16,12,0,4,104,14304,2.761904761904762,1.619047619047619,1.4285714285714286,0.5714285714285714,17
1851,Domain Generalization using Causal Matching,8,Domain Generalization using Causal Matching,68,178,False,202,78,20,28,9,12,32,2,36,43,19434,2.4285714285714284,2.0,2.7857142857142856,1.1428571428571428,247
1852,Dynamic Regret of Online Markov Decision Processes,8,Dynamic Regret of Online Markov Decision Processes,70,151,False,206,299,15,60,40,11,33,0,2,50,28662,1.1666666666666667,0.2833333333333333,4.983333333333333,0.55,13
1853,Efficient First-Order Algorithms for Adaptive Signal Denoising,8,Efficient First-Order Algorithms for Adaptive Signal Denoising,34,100,False,59,247,25,27,28,5,10,0,0,62,11340,1.2592592592592593,0.9259259259259259,9.148148148148149,0.37037037037037035,5
1854,Efficient Reinforcement Learning in Block MDPs: A Model-free Representation Learning Approach,8,Efficient Reinforcement Learning in Block MDPs A Model-free Representation Learning Approach,43,105,False,110,214,13,40,26,12,5,0,14,92,18331,1.075,0.675,5.35,0.125,42
1856,Environment Inference for Invariant Learning,8,Environment Inference for Invariant Learning,60,144,False,248,30,24,23,31,13,12,0,18,44,15578,2.608695652173913,1.826086956521739,1.3043478260869565,0.5217391304347826,260
1857,Escaping Saddles with Stochastic Gradients,8,Escaping Saddles with Stochastic Gradients,34,131,False,57,336,30,27,45,14,9,0,14,42,12574,1.2592592592592593,1.6296296296296295,12.444444444444445,0.3333333333333333,148
1858,Event Outlier Detection in Continuous Time,8,Event Outlier Detection in Continuous Time,38,155,False,52,101,21,17,18,15,11,0,14,42,11279,2.235294117647059,2.0588235294117645,5.9411764705882355,0.6470588235294118,6
1859,Explicit Inductive Bias for Transfer Learning with Convolutional Networks,8,Explicit Inductive Bias for Transfer Learning with Convolutional Networks,47,137,False,110,24,8,12,8,9,6,9,10,73,8111,3.9166666666666665,1.5,2.0,0.5,282
1860,Extrapolation for Large-batch Training in Deep Learning,8,Extrapolation for Large-batch Training in Deep Learning,74,193,False,243,224,33,30,15,11,16,0,6,55,17223,2.466666666666667,1.3,7.466666666666667,0.5333333333333333,33
1861,Fair k-Center Clustering for Data Summarization,8,Fair k-Center Clustering for Data Summarization,48,170,False,142,74,53,20,0,10,6,0,0,47,13294,2.4,2.65,3.7,0.3,145
1862,Fast Margin Maximization via Dual Acceleration,8,Fast Margin Maximization via Dual Acceleration,35,98,False,84,219,14,21,1,14,6,0,0,46,10760,1.6666666666666667,0.6666666666666666,10.428571428571429,0.2857142857142857,26
1863,Faster Algorithms for Learning Convex Functions,8,Faster Algorithms for Learning Convex Functions,25,205,False,80,148,9,19,0,13,10,9,10,47,10732,1.3157894736842106,1.0,7.7894736842105265,0.5263157894736842,4
1864,FedNew: A Communication-Efficient and Privacy-Preserving Newton-Type Method for Federated Learning,8,FedNew A Communication-Efficient and Privacy-Preserving Newton-Type Method for Federated Learning,35,195,False,74,402,40,25,0,26,12,0,8,97,10576,1.4,1.92,16.08,0.48,14
1865,Fictitious Play and Best-Response Dynamics in Identical Interest and Zero-Sum Stochastic Games,8,Fictitious Play and Best-Response Dynamics in Identical Interest and Zero-Sum Stochastic Games,61,1,False,20,38,0,27,2,14,6,0,0,94,15982,2.259259259259259,0.0,1.4074074074074074,0.2222222222222222,11
1866,First-Order Algorithms Converge Faster than $O(1/k)$ on Convex Problems,8,First-Order Algorithms Converge Faster than O1k on Convex Problems,17,115,False,20,151,0,14,1,5,5,0,0,66,6691,1.2142857142857142,0.0,10.785714285714286,0.35714285714285715,10
1867,Follow-the-Regularized-Leader Routes to Chaos in Routing Games,8,Follow-the-Regularized-Leader Routes to Chaos in Routing Games,60,184,False,46,103,30,30,0,12,4,0,2,62,12171,2.0,1.0666666666666667,3.433333333333333,0.13333333333333333,19
1868,From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model,8,From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model,41,201,True,84,175,45,56,0,14,25,0,2,73,26159,0.7321428571428571,0.8392857142857143,3.125,0.44642857142857145,14
1869,Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations,8,Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations,32,139,False,80,15,33,15,16,13,7,0,8,85,10255,2.1333333333333333,2.7333333333333334,1.0,0.4666666666666667,84
1870,GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks,8,GNNRank Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks,0,136,False,94,26,3,32,4,13,17,0,52,93,31263,0.0,1.71875,0.8125,0.53125,15
1871,Generalization Bounds using Lower Tail Exponents in Stochastic Optimizers,8,Generalization Bounds using Lower Tail Exponents in Stochastic Optimizers,76,170,False,242,96,57,22,5,14,14,0,0,73,13880,3.4545454545454546,2.590909090909091,4.363636363636363,0.6363636363636364,14
1872,Generalized and Scalable Optimal Sparse Decision Trees,8,Generalized and Scalable Optimal Sparse Decision Trees,43,177,False,34,0,3,42,0,5,14,4,2,54,25155,1.0238095238095237,0.11904761904761904,0.0,0.3333333333333333,104
1873,Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data,8,Generative Teaching Networks Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data,51,270,False,158,2,52,26,0,16,6,0,8,116,13557,1.9615384615384615,2.3076923076923075,0.07692307692307693,0.23076923076923078,127
1874,Global Optimization with Parametric Function Approximation,8,Global Optimization with Parametric Function Approximation,77,134,False,104,166,23,24,0,11,16,0,2,58,13475,3.2083333333333335,1.0416666666666667,6.916666666666667,0.6666666666666666,4
1875,Graph Contrastive Learning Automated,8,Graph Contrastive Learning Automated,69,225,False,62,20,12,12,0,5,7,4,14,36,7859,5.75,2.1666666666666665,1.6666666666666667,0.5833333333333334,302
1876,GraphFM: Improving Large-Scale GNN Training via Feature Momentum,8,GraphFM Improving Large-Scale GNN Training via Feature Momentum,44,126,True,56,100,8,18,1,10,8,0,8,63,11085,2.4444444444444446,0.8888888888888888,5.555555555555555,0.4444444444444444,27
1878,Hierarchical VAEs Know What They Don't Know,8,Hierarchical VAEs Know What They Dont Know,64,116,False,153,62,23,18,0,16,14,0,16,43,12153,3.5555555555555554,2.1666666666666665,3.4444444444444446,0.7777777777777778,58
1879,HousE: Knowledge Graph Embedding with Householder Parameterization,8,HousE Knowledge Graph Embedding with Householder Parameterization,28,121,False,84,90,16,16,0,14,20,0,22,65,9164,1.75,2.375,5.625,1.25,26
1880,Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation,8,Human-in-the-loop Provably Efficient Preference-based Reinforcement Learning with General Function Approximation,54,211,False,100,204,0,21,0,13,14,0,0,112,11568,2.5714285714285716,0.0,9.714285714285714,0.6666666666666666,27
1881,IPBoost - Non-Convex Boosting via Integer Programming,8,IPBoost - Non-Convex Boosting via Integer Programming,33,60,False,40,16,15,27,6,6,4,0,0,53,14214,1.2222222222222223,0.5555555555555556,0.5925925925925926,0.14814814814814814,5
1882,Implicit Regularization of Random Feature Models,8,Implicit Regularization of Random Feature Models,38,137,False,49,243,64,36,0,10,19,5,0,48,19206,1.0555555555555556,1.7777777777777777,6.75,0.5277777777777778,75
1883,Improved Optimistic Algorithms for Logistic Bandits,8,Improved Optimistic Algorithms for Logistic Bandits,20,156,False,68,250,6,28,14,12,19,0,2,51,12874,0.7142857142857143,0.2857142857142857,8.928571428571429,0.6785714285714286,60
1884,Improving Mini-batch Optimal Transport via Partial Transportation,8,Improving Mini-batch Optimal Transport via Partial Transportation,68,157,False,180,152,74,35,2,18,54,0,68,65,22541,1.9428571428571428,4.057142857142857,4.3428571428571425,1.542857142857143,30
1885,Imputer: Sequence Modelling via Imputation and Dynamic Programming,8,Imputer Sequence Modelling via Imputation and Dynamic Programming,61,118,False,140,24,12,11,0,7,13,0,6,65,7790,5.545454545454546,1.6363636363636365,2.1818181818181817,1.1818181818181819,102
1886,Inference for Network Regression Models with Community Structure,8,Inference for Network Regression Models with Community Structure,36,103,False,104,82,62,43,0,14,3,0,4,64,11749,0.8372093023255814,1.5348837209302326,1.9069767441860466,0.06976744186046512,0
1887,Instabilities of Offline RL with Pre-Trained Neural Representation,8,Instabilities of Offline RL with Pre-Trained Neural Representation,79,1,True,130,79,80,36,39,11,9,0,16,66,15228,2.1944444444444446,2.6666666666666665,2.1944444444444446,0.25,32
1888,Interpretable Stein Goodness-of-fit Tests on Riemannian Manifold,8,Interpretable Stein Goodness-of-fit Tests on Riemannian Manifold,72,102,False,96,83,20,29,11,12,19,0,2,64,9943,2.4827586206896552,0.7586206896551724,2.8620689655172415,0.6551724137931034,7
1889,Invariant-equivariant representation learning for multi-class data,8,Invariant-equivariant representation learning for multi-class data,33,160,False,84,24,16,12,0,7,5,0,4,66,7199,2.75,1.6666666666666667,2.0,0.4166666666666667,9
1890,"Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks",8,Ithemal Accurate Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks,57,175,False,44,2,43,14,11,15,11,1,8,95,7629,4.071428571428571,3.642857142857143,0.14285714285714285,0.7857142857142857,129
1891,Kernel interpolation with continuous volume sampling,8,Kernel interpolation with continuous volume sampling,65,163,False,166,346,23,41,1,9,29,13,0,52,15353,1.5853658536585367,0.5609756097560976,8.439024390243903,0.7073170731707317,16
1892,LR-GLM: High-Dimensional Bayesian Inference Using Low-Rank Data Approximations,8,LR-GLM High-Dimensional Bayesian Inference Using Low-Rank Data Approximations,52,187,True,116,132,35,33,0,17,27,1,2,77,17835,1.5757575757575757,1.121212121212121,4.0,0.8181818181818182,8
1893,Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,8,Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion,45,133,False,61,130,6,23,0,7,14,0,2,95,11157,1.9565217391304348,0.34782608695652173,5.6521739130434785,0.6086956521739131,30
1894,Learning Action Representations for Reinforcement Learning,8,Learning Action Representations for Reinforcement Learning,50,1,False,67,86,21,18,2,12,11,4,0,58,11361,2.7777777777777777,1.1666666666666667,4.777777777777778,0.6111111111111112,135
1896,Learning Hidden Markov Models from Pairwise Co-occurrences with Applications to Topic Modeling,8,Learning Hidden Markov Models from Pairwise Co-occurrences with Applications to Topic Modeling,40,141,False,65,77,24,21,0,15,2,0,0,94,10077,1.9047619047619047,1.1428571428571428,3.6666666666666665,0.09523809523809523,20
1897,Learning Mixtures of Markov Chains and MDPs,8,Learning Mixtures of Markov Chains and MDPs,28,119,False,91,144,31,51,0,16,24,15,0,43,21234,0.5490196078431373,0.6078431372549019,2.823529411764706,0.47058823529411764,4
1898,Learning Routines for Effective Off-Policy Reinforcement Learning,8,Learning Routines for Effective Off-Policy Reinforcement Learning,47,136,False,12,0,3,18,0,6,11,4,2,65,10408,2.611111111111111,0.2777777777777778,0.0,0.6111111111111112,1
1900,Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules,8,Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules,34,177,False,97,14,18,15,17,10,21,0,14,107,9747,2.2666666666666666,2.1333333333333333,0.9333333333333333,1.4,53
1901,Learning to Rank Learning Curves,8,Learning to Rank Learning Curves,24,148,False,120,8,62,14,5,8,9,0,2,32,8143,1.7142857142857142,4.571428571428571,0.5714285714285714,0.6428571428571429,20
1902,Least Squares Estimation using Sketched Data with Heteroskedastic Errors,8,Least Squares Estimation using Sketched Data with Heteroskedastic Errors,30,204,False,70,235,0,42,0,9,6,0,10,72,12623,0.7142857142857143,0.23809523809523808,5.595238095238095,0.14285714285714285,3
1903,Lifted Disjoint Paths with Application in Multiple Object Tracking,8,Lifted Disjoint Paths with Application in Multiple Object Tracking,60,85,False,87,70,23,22,33,10,15,0,10,66,15546,2.727272727272727,1.5,3.1818181818181817,0.6818181818181818,106
1905,Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling,8,Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling,28,115,False,120,26,115,26,5,12,21,0,0,70,13092,1.0769230769230769,4.423076923076923,1.0,0.8076923076923077,44
1906,MAML and ANIL Provably Learn Representations,8,MAML and ANIL Provably Learn Representations,0,166,True,166,1610,129,98,0,34,37,1,18,44,35316,0.0,1.5,16.428571428571427,0.37755102040816324,23
1907,Making transport more robust and interpretable by moving data through a small number of anchor points,8,Making transport more robust and interpretable by moving data through a small number of anchor points,55,165,False,95,108,66,25,23,22,27,6,6,101,14824,2.2,2.88,4.32,1.08,14
1908,Maximum Mean Discrepancy Test is Aware of Adversarial Attacks,8,Maximum Mean Discrepancy Test is Aware of Adversarial Attacks,77,153,False,150,70,96,20,24,15,4,0,6,61,13256,3.85,5.1,3.5,0.2,36
1909,Meta Learning for Support Recovery in High-dimensional Precision Matrix Estimation,8,Meta Learning for Support Recovery in High-dimensional Precision Matrix Estimation,42,269,False,60,422,10,37,0,18,21,2,4,82,16612,1.135135135135135,0.3783783783783784,11.405405405405405,0.5675675675675675,4
1910,Minibatch Gibbs Sampling on Large Graphical Models,8,Minibatch Gibbs Sampling on Large Graphical Models,21,126,False,25,85,8,24,2,7,2,0,2,50,11653,0.875,0.4166666666666667,3.5416666666666665,0.08333333333333333,19
1911,MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing,8,MixHop Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing,28,92,False,81,24,16,9,0,11,15,0,8,88,6390,3.111111111111111,2.6666666666666665,2.6666666666666665,1.6666666666666667,668
1913,Molecular Hypergraph Grammar with its Application to Molecular Optimization,8,Molecular Hypergraph Grammar with its Application to Molecular Optimization,24,188,False,58,22,74,19,3,16,10,0,6,75,9624,1.263157894736842,4.2105263157894735,1.1578947368421053,0.5263157894736842,91
1914,"Mu2SLAM: Multitask, Multilingual Speech and Language Models",8,Mu2SLAM Multitask Multilingual Speech and Language Models,66,161,False,87,18,6,17,0,8,11,0,0,58,10370,3.8823529411764706,0.35294117647058826,1.0588235294117647,0.6470588235294118,7
1915,Multi-User Reinforcement Learning with Low Rank Rewards,8,Multi-User Reinforcement Learning with Low Rank Rewards,53,179,False,58,132,0,33,4,14,17,0,0,55,19210,1.606060606060606,0.0,4.0,0.5151515151515151,0
1916,My Fair Bandit: Distributed Learning of Max-Min Fairness with Multi-player Bandits,8,My Fair Bandit Distributed Learning of Max-Min Fairness with Multi-player Bandits,41,132,False,20,66,6,11,0,9,1,0,0,81,9110,3.727272727272727,0.5454545454545454,6.0,0.09090909090909091,30
1918,Neural Autoregressive Flows,8,Neural Autoregressive Flows,46,122,False,173,76,39,16,0,20,22,8,8,27,10919,2.875,2.9375,4.75,1.375,406
1921,Non-monotone Submodular Maximization with Nearly Optimal Adaptivity and Query Complexity,8,Non-monotone Submodular Maximization with Nearly Optimal Adaptivity and Query Complexity,54,151,False,112,105,10,19,6,11,5,0,2,88,10788,2.8421052631578947,0.631578947368421,5.526315789473684,0.2631578947368421,41
1922,Not All Samples Are Created Equal: Deep Learning with Importance Sampling,8,Not All Samples Are Created Equal Deep Learning with Importance Sampling,33,139,False,69,58,30,13,0,11,11,0,0,72,8036,2.5384615384615383,2.3076923076923075,4.461538461538462,0.8461538461538461,421
1923,Offline Contextual Bandits with Overparameterized Models,8,Offline Contextual Bandits with Overparameterized Models,37,167,False,94,108,18,20,21,14,16,0,0,56,12446,1.85,0.9,5.4,0.8,7
1924,On Disentangled Representations Learned from Correlated Data,8,On Disentangled Representations Learned from Correlated Data,70,117,False,137,22,153,19,8,12,7,0,12,60,12616,3.6842105263157894,8.68421052631579,1.1578947368421053,0.3684210526315789,92
1925,On Learning Sparsely Used Dictionaries from Incomplete Samples,8,On Learning Sparsely Used Dictionaries from Incomplete Samples,36,138,False,117,114,2,24,0,8,11,4,4,62,13035,1.5,0.25,4.75,0.4583333333333333,2
1926,On Transportation of Mini-batches: A Hierarchical Approach,8,On Transportation of Mini-batches A Hierarchical Approach,88,185,False,94,60,33,34,22,10,23,0,16,57,20913,2.588235294117647,1.4411764705882353,1.7647058823529411,0.6764705882352942,15
1927,On the Finite-Time Performance of the Knowledge Gradient Algorithm,8,On the Finite-Time Performance of the Knowledge Gradient Algorithm,44,161,False,66,198,21,34,0,15,7,0,0,66,15354,1.2941176470588236,0.6176470588235294,5.823529411764706,0.20588235294117646,3
1928,On the Long-term Impact of Algorithmic Decision Policies: Effort Unfairness and Feature Segregation through Social Learning,8,On the Long-term Impact of Algorithmic Decision Policies Effort Unfairness and Feature Segregation through Social Learning,37,159,False,86,14,30,12,5,12,5,0,0,122,8659,3.0833333333333335,2.5,1.1666666666666667,0.4166666666666667,53
1929,On the Surrogate Gap between Contrastive and Supervised Losses,8,On the Surrogate Gap between Contrastive and Supervised Losses,70,204,False,280,86,29,22,22,13,15,1,2,62,13501,3.1818181818181817,1.4090909090909092,3.909090909090909,0.6818181818181818,14
1930,Online Adaptive Principal Component Analysis and Its extensions,8,Online Adaptive Principal Component Analysis and Its extensions,28,85,False,61,152,7,17,0,11,5,0,0,63,8914,1.6470588235294117,0.4117647058823529,8.941176470588236,0.29411764705882354,8
1931,Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with √T Regret,8,Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with T Regret,32,96,False,71,192,0,19,2,8,12,0,0,92,9579,1.6842105263157894,0.0,10.105263157894736,0.631578947368421,12
1932,Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training,8,Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training,46,167,False,56,52,21,16,0,13,13,0,12,93,11690,2.875,2.0625,3.25,0.8125,23
1934,Optimizing for the Future in Non-Stationary MDPs,8,Optimizing for the Future in Non-Stationary MDPs,78,152,False,250,148,102,23,6,32,16,0,4,48,13880,3.391304347826087,4.608695652173913,6.434782608695652,0.6956521739130435,52
1936,PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization,8,PEGASUS Pre-training with Extracted Gap-sentences for Abstractive Summarization,58,166,True,130,0,33,55,9,18,8,3,0,79,54930,1.0545454545454545,0.6,0.0,0.14545454545454545,1616
1938,Path-Level Network Transformation for Efficient Architecture Search,8,Path-Level Network Transformation for Efficient Architecture Search,44,156,False,121,8,30,12,0,9,12,0,6,67,8005,3.6666666666666665,3.0,0.6666666666666666,1.0,196
1939,"Phase transition in PCA with missing data: Reduced signal-to-noise ratio, not sample size!",8,Phase transition in PCA with missing data Reduced signal-to-noise ratio not sample size,31,126,True,38,85,19,9,0,8,1,0,0,89,6516,3.4444444444444446,2.111111111111111,9.444444444444445,0.1111111111111111,3
1940,Policy Consolidation for Continual Reinforcement Learning,8,Policy Consolidation for Continual Reinforcement Learning,35,109,False,56,26,33,13,0,10,11,7,2,57,8188,2.6923076923076925,2.6923076923076925,2.0,0.8461538461538461,39
1941,Power-Law Escape Rate of SGD,8,Power-Law Escape Rate of SGD,47,126,True,102,91,28,25,0,11,7,2,0,28,9986,1.88,1.12,3.64,0.28,11
1942,Principal Bit Analysis: Autoencoding with Schur-Concave Loss,8,Principal Bit Analysis Autoencoding with Schur-Concave Loss,62,201,False,74,238,116,24,0,10,12,0,4,59,9725,2.5833333333333335,5.0,9.916666666666666,0.5,1
1943,Private Query Release Assisted by Public Data,8,Private Query Release Assisted by Public Data,24,574,False,44,21,3,13,6,6,6,0,0,45,6894,1.8461538461538463,0.23076923076923078,1.6153846153846154,0.46153846153846156,40
1944,"ProgFed: Effective, Communication, and Computation Efficient Federated Learning by Progressive Training",8,ProgFed Effective Communication and Computation Efficient Federated Learning by Progressive Training,64,142,False,12,0,3,21,0,7,12,4,2,102,10701,3.0476190476190474,0.23809523809523808,0.0,0.5714285714285714,29
1945,Provable Guarantees for Gradient-Based Meta-Learning,8,Provable Guarantees for Gradient-Based Meta-Learning,56,109,False,114,46,45,25,0,10,18,0,0,52,15365,2.24,1.8,1.84,0.72,135
1946,Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup,8,Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup,53,171,False,92,216,8,37,0,10,12,0,2,73,22327,1.4324324324324325,0.2702702702702703,5.837837837837838,0.32432432432432434,5
1947,Quant-BnB: A Scalable Branch-and-Bound Method for Optimal Decision Trees with Continuous Features,8,Quant-BnB A Scalable Branch-and-Bound Method for Optimal Decision Trees with Continuous Features,31,178,False,52,208,10,31,0,12,26,0,14,96,13721,1.0,0.7741935483870968,6.709677419354839,0.8387096774193549,9
1948,Query complexity of adversarial attacks,8,Query complexity of adversarial attacks,44,125,False,79,346,10,32,19,15,4,2,2,39,19075,1.375,0.375,10.8125,0.125,4
1949,Random Function Priors for Correlation Modeling,8,Random Function Priors for Correlation Modeling,59,299,False,103,70,25,13,0,9,16,7,12,47,8592,4.538461538461538,2.8461538461538463,5.384615384615385,1.2307692307692308,1
1950,Rates of Convergence for Sparse Variational Gaussian Process Regression,8,Rates of Convergence for Sparse Variational Gaussian Process Regression,43,137,False,103,118,12,15,1,14,27,0,2,71,10044,2.8666666666666667,0.9333333333333333,7.866666666666666,1.8,137
1951,Reducing Sampling Error in Batch Temporal Difference Learning,8,Reducing Sampling Error in Batch Temporal Difference Learning,46,195,False,105,86,58,29,1,15,20,19,0,61,16174,1.5862068965517242,2.0,2.9655172413793105,0.6896551724137931,12
1952,Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism,8,Reinforcement Learning for Non-Stationary Markov Decision Processes The Blessing of More Optimism,75,141,False,184,148,12,28,0,14,25,3,2,99,17175,2.6785714285714284,0.5,5.285714285714286,0.8928571428571429,76
1953,Representation Matters: Assessing the Importance of Subgroup Allocations in Training Data,8,Representation Matters Assessing the Importance of Subgroup Allocations in Training Data,54,1,False,165,107,48,31,0,11,27,0,10,88,18424,1.7419354838709677,1.8709677419354838,3.4516129032258065,0.8709677419354839,20
1954,Rethinking Lossy Compression: The Rate-Distortion-Perception Tradeoff,8,Rethinking Lossy Compression The Rate-Distortion-Perception Tradeoff,58,177,False,107,106,39,21,10,12,8,0,6,68,11995,2.761904761904762,2.142857142857143,5.0476190476190474,0.38095238095238093,200
1955,Revisiting Training Strategies and Generalization Performance in Deep Metric Learning,8,Revisiting Training Strategies and Generalization Performance in Deep Metric Learning,76,150,False,152,52,0,26,23,17,11,0,2,85,16457,2.923076923076923,0.07692307692307693,2.0,0.4230769230769231,147
1956,Robust Decision Trees Against Adversarial Examples,8,Robust Decision Trees Against Adversarial Examples,50,189,False,101,48,49,16,0,14,9,0,14,50,11766,3.125,3.9375,3.0,0.5625,99
1957,Robust SDE-Based Variational Formulations for Solving Linear PDEs via Deep Learning,8,Robust SDE-Based Variational Formulations for Solving Linear PDEs via Deep Learning,49,133,True,112,222,45,18,0,12,8,0,2,83,13104,2.7222222222222223,2.611111111111111,12.333333333333334,0.4444444444444444,10
1958,SAFFRON: an adaptive algorithm for online control of the false discovery rate,8,SAFFRON an adaptive algorithm for online control of the false discovery rate,15,258,True,48,62,65,19,0,6,14,0,0,76,9523,0.7894736842105263,3.4210526315789473,3.263157894736842,0.7368421052631579,48
1960,Sample Complexity of Adversarially Robust Linear Classification on Separated Data,8,Sample Complexity of Adversarially Robust Linear Classification on Separated Data,33,179,False,46,90,10,34,18,9,13,7,0,81,20252,0.9705882352941176,0.29411764705882354,2.6470588235294117,0.38235294117647056,7
1961,Scalable First-Order Bayesian Optimization via Structured Automatic Differentiation,8,Scalable First-Order Bayesian Optimization via Structured Automatic Differentiation,77,176,False,189,60,17,17,30,12,7,0,2,83,11311,4.529411764705882,1.1176470588235294,3.5294117647058822,0.4117647058823529,5
1963,SelectiveNet: A Deep Neural Network with an Integrated Reject Option,8,SelectiveNet A Deep Neural Network with an Integrated Reject Option,30,103,False,38,8,12,10,0,10,9,0,12,67,5973,3.0,2.4,0.8,0.9,261
1964,Self-supervised and Supervised Joint Training for Resource-rich Machine Translation,8,Self-supervised and Supervised Joint Training for Resource-rich Machine Translation,49,138,False,127,24,13,12,0,10,10,0,14,83,8103,4.083333333333333,2.25,2.0,0.8333333333333334,12
1965,Set Functions for Time Series,8,Set Functions for Time Series,48,111,False,130,14,11,15,24,6,12,1,14,29,11403,3.2,1.6666666666666667,0.9333333333333333,0.8,101
1966,SimGANs: Simulator-Based Generative Adversarial Networks for ECG Synthesis to Improve Deep ECG Classification,8,SimGANs Simulator-Based Generative Adversarial Networks for ECG Synthesis to Improve Deep ECG Classification,43,150,True,64,42,15,10,0,8,5,0,4,108,7624,4.3,1.9,4.2,0.5,53
1967,Sketching Algorithms and Lower Bounds for Ridge Regression,8,Sketching Algorithms and Lower Bounds for Ridge Regression,22,228,False,62,169,5,21,0,12,10,0,0,58,12295,1.0476190476190477,0.23809523809523808,8.047619047619047,0.47619047619047616,6
1968,Soft then Hard: Rethinking the Quantization in Neural Image Compression,8,Soft then Hard Rethinking the Quantization in Neural Image Compression,48,158,False,102,43,66,16,0,12,13,0,6,70,8579,3.0,4.5,2.6875,0.8125,56
1969,SparseMAP: Differentiable Sparse Structured Inference,8,SparseMAP Differentiable Sparse Structured Inference,74,124,False,182,96,15,14,9,11,9,0,4,52,8830,5.285714285714286,1.3571428571428572,6.857142857142857,0.6428571428571429,111
1970,Stabilizing Equilibrium Models by Jacobian Regularization,8,Stabilizing Equilibrium Models by Jacobian Regularization,60,171,False,235,13,37,16,0,8,22,0,10,57,11353,3.75,2.9375,0.8125,1.375,44
1971,Steerable 3D Spherical Neurons,8,Steerable 3D Spherical Neurons,36,153,False,126,49,23,10,2,7,13,0,4,30,7503,3.6,2.7,4.9,1.3,3
1973,Strategic Classification in the Dark,8,Strategic Classification in the Dark,21,133,False,55,50,32,24,8,9,13,5,0,36,11907,0.875,1.3333333333333333,2.0833333333333335,0.5416666666666666,40
1974,Structured Control Nets for Deep Reinforcement Learning,8,Structured Control Nets for Deep Reinforcement Learning,32,226,False,79,14,34,12,0,10,9,1,6,55,5713,2.6666666666666665,3.3333333333333335,1.1666666666666667,0.75,42
1975,Submodular Order Functions and Assortment Optimization,8,Submodular Order Functions and Assortment Optimization,69,0,False,80,162,0,49,0,11,15,11,4,54,23020,1.4081632653061225,0.08163265306122448,3.306122448979592,0.30612244897959184,9
1976,"Synergy and Symmetry in Deep Learning: Interactions between the Data, Model, and Inference Algorithm",8,Synergy and Symmetry in Deep Learning Interactions between the Data Model and Inference Algorithm,86,175,False,199,50,54,23,15,14,16,0,0,99,12866,3.739130434782609,2.347826086956522,2.1739130434782608,0.6956521739130435,9
1978,Temporal Poisson Square Root Graphical Models,8,Temporal Poisson Square Root Graphical Models,40,162,False,168,260,26,17,0,16,32,16,0,45,10857,2.3529411764705883,1.5294117647058822,15.294117647058824,1.8823529411764706,13
1979,The Differentiable Cross-Entropy Method,8,The Differentiable Cross-Entropy Method,111,112,False,172,33,34,17,0,10,8,2,0,39,11513,6.529411764705882,2.0,1.9411764705882353,0.47058823529411764,49
1980,The Implicit and Explicit Regularization Effects of Dropout,8,The Implicit and Explicit Regularization Effects of Dropout,77,149,False,111,170,27,32,0,12,18,2,10,59,14779,2.40625,1.15625,5.3125,0.5625,102
1981,The State of Sparse Training in Deep Reinforcement Learning,8,The State of Sparse Training in Deep Reinforcement Learning,77,161,False,160,4,134,27,20,16,6,0,18,59,13436,2.8518518518518516,5.62962962962963,0.14814814814814814,0.2222222222222222,18
1982,Theoretical Analysis of Sparse Subspace Clustering with Missing Entries,8,Theoretical Analysis of Sparse Subspace Clustering with Missing Entries,44,164,False,56,188,3,11,0,8,13,0,0,71,10086,4.0,0.2727272727272727,17.09090909090909,1.1818181818181819,25
1983,Tighter Variational Bounds are Not Necessarily Better,8,Tighter Variational Bounds are Not Necessarily Better,36,130,False,75,86,65,17,0,18,9,2,2,53,10386,2.1176470588235294,3.9411764705882355,5.0588235294117645,0.5294117647058824,180
1984,Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning,8,Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning,61,245,False,46,377,12,67,16,11,20,0,0,89,28875,0.9104477611940298,0.1791044776119403,5.626865671641791,0.29850746268656714,101
1985,Towards Scaling Difference Target Propagation by Learning Backprop Targets,8,Towards Scaling Difference Target Propagation by Learning Backprop Targets,30,183,False,53,80,15,18,18,10,10,0,18,74,8906,1.6666666666666667,1.8333333333333333,4.444444444444445,0.5555555555555556,18
1986,Training Data Subset Selection for Regression with Controlled Generalization Error,8,Training Data Subset Selection for Regression with Controlled Generalization Error,51,1,False,128,508,106,27,0,40,74,0,8,82,12733,1.8888888888888888,4.222222222222222,18.814814814814813,2.740740740740741,18
1987,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,8,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement,38,238,False,46,50,57,19,0,11,12,0,0,99,11356,2.0,3.0,2.6315789473684212,0.631578947368421,141
1988,UnICORNN: A recurrent model for learning very long time dependencies,8,UnICORNN A recurrent model for learning very long time dependencies,50,117,False,83,256,19,25,10,11,8,0,16,67,15367,2.0,1.4,10.24,0.32,41
1989,Understanding Instance-Level Label Noise: Disparate Impacts and Treatments,8,Understanding Instance-Level Label Noise Disparate Impacts and Treatments,40,142,False,124,272,38,20,8,48,28,0,0,73,12662,2.0,1.9,13.6,1.4,25
1990,Understanding the Origins of Bias in Word Embeddings,8,Understanding the Origins of Bias in Word Embeddings,29,116,False,35,70,37,18,1,13,10,0,10,52,9422,1.6111111111111112,2.611111111111111,3.888888888888889,0.5555555555555556,162
1991,Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks,8,Unraveling Meta-Learning Understanding Feature Representations for Few-Shot Tasks,26,108,False,28,2,12,13,0,7,11,0,14,81,7844,2.0,2.0,0.15384615384615385,0.8461538461538461,64
1994,Video Prediction via Example Guidance,8,Video Prediction via Example Guidance,44,130,False,212,26,30,10,0,5,8,2,6,37,7167,4.4,3.6,2.6,0.8,17
1995,What Are Bayesian Neural Network Posteriors Really Like?,8,What Are Bayesian Neural Network Posteriors Really Like,83,194,False,196,64,148,24,1,20,19,0,14,55,17401,3.4583333333333335,6.75,2.6666666666666665,0.7916666666666666,264
1996,When is Realizability Sufficient for Off-Policy Reinforcement Learning?,8,When is Realizability Sufficient for Off-Policy Reinforcement Learning,63,1,False,75,246,6,32,22,12,16,8,0,70,15603,1.96875,0.1875,7.6875,0.5,12
1997,World Model as a Graph: Learning Latent Landmarks for Planning,8,World Model as a Graph Learning Latent Landmarks for Planning,53,222,False,65,22,54,12,0,17,7,0,0,61,8022,4.416666666666667,4.5,1.8333333333333333,0.5833333333333334,57
1999,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,8,A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming,59,106,False,95,146,15,16,6,12,14,0,0,112,9370,3.6875,0.9375,9.125,0.875,34
2000,A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,8,A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models,49,245,False,95,183,52,27,33,15,28,11,4,134,18028,1.8148148148148149,2.074074074074074,6.777777777777778,1.037037037037037,6
2001,A Hierarchical Transitive-Aligned Graph Kernel for Un-attributed Graphs,8,A Hierarchical Transitive-Aligned Graph Kernel for Un-attributed Graphs,45,141,False,40,28,6,8,0,6,7,0,6,71,7090,5.625,1.5,3.5,0.875,6
2002,A Precise Performance Analysis of Support Vector Regression,8,A Precise Performance Analysis of Support Vector Regression,36,186,False,39,186,17,32,0,9,8,4,0,59,14418,1.125,0.53125,5.8125,0.25,2
2003,A Simple Guard for Learned Optimizers,8,A Simple Guard for Learned Optimizers,31,216,False,53,44,57,17,0,14,7,0,4,37,11005,1.8235294117647058,3.588235294117647,2.588235294117647,0.4117647058823529,4
2004,A Theory of Regularized Markov Decision Processes,8,A Theory of Regularized Markov Decision Processes,46,130,False,113,258,0,25,0,10,14,0,0,49,14217,1.84,0.0,10.32,0.56,248
2005,A query-optimal algorithm for finding counterfactuals,8,A query-optimal algorithm for finding counterfactuals,54,124,False,32,40,11,22,13,9,14,1,0,53,9790,2.4545454545454546,0.5,1.8181818181818181,0.6363636363636364,3
2006,Accelerated Primal-Dual Methods for Convex-Strongly-Concave Saddle Point Problems,8,Accelerated Primal-Dual Methods for Convex-Strongly-Concave Saddle Point Problems,30,145,False,79,338,13,30,0,14,15,2,2,81,13215,1.0,0.5,11.266666666666667,0.5,5
2007,Action Robust Reinforcement Learning and Applications in Continuous Control,8,Action Robust Reinforcement Learning and Applications in Continuous Control,45,169,False,87,100,108,29,2,13,20,0,2,75,12871,1.5517241379310345,3.793103448275862,3.4482758620689653,0.6896551724137931,177
2008,AdAUC: End-to-end Adversarial AUC Optimization Against Long-tail Problems,8,AdAUC End-to-end Adversarial AUC Optimization Against Long-tail Problems,65,222,True,58,312,80,23,0,10,18,0,4,72,12157,2.8260869565217392,3.652173913043478,13.565217391304348,0.782608695652174,4
2009,Adaptive Newton Sketch: Linear-time Optimization with Quadratic Convergence and Effective Hessian Dimensionality,8,Adaptive Newton Sketch Linear-time Optimization with Quadratic Convergence and Effective Hessian Dimensionality,44,247,False,86,190,58,24,0,9,15,1,10,111,12739,1.8333333333333333,2.8333333333333335,7.916666666666667,0.625,13
2010,Adversarial Attack and Defense for Non-Parametric Two-Sample Tests,8,Adversarial Attack and Defense for Non-Parametric Two-Sample Tests,126,178,False,136,92,21,27,29,13,26,0,22,66,17610,4.666666666666667,1.5925925925925926,3.4074074074074074,0.9629629629629629,1
2012,Agnostic Federated Learning,8,Agnostic Federated Learning,69,200,False,97,95,11,30,0,15,17,0,6,27,12169,2.3,0.5666666666666667,3.1666666666666665,0.5666666666666667,757
2013,An Accelerated DFO Algorithm for Finite-sum Convex Functions,8,An Accelerated DFO Algorithm for Finite-sum Convex Functions,35,133,True,123,416,64,48,14,11,16,0,0,60,25764,0.7291666666666666,1.3333333333333333,8.666666666666666,0.3333333333333333,12
2014,An Investigation of Why Overparameterization Exacerbates Spurious Correlations,8,An Investigation of Why Overparameterization Exacerbates Spurious Correlations,43,1,False,94,206,53,36,11,11,19,9,0,78,19757,1.1944444444444444,1.4722222222222223,5.722222222222222,0.5277777777777778,292
2015,Analyzing the tree-layer structure of Deep Forests,8,Analyzing the tree-layer structure of Deep Forests,31,174,False,39,362,138,55,13,13,21,4,6,50,27374,0.5636363636363636,2.618181818181818,6.581818181818182,0.38181818181818183,9
2016,Approximation Guarantees of Local Search Algorithms via Localizability of Set Functions,8,Approximation Guarantees of Local Search Algorithms via Localizability of Set Functions,41,133,False,108,160,8,23,14,12,16,0,2,87,13009,1.7826086956521738,0.43478260869565216,6.956521739130435,0.6956521739130435,0
2017,Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth,8,Attention is Not All You Need Pure Attention Loses Rank Doubly Exponentially with Depth,56,117,False,63,98,22,22,2,8,18,0,0,87,9643,2.5454545454545454,1.0,4.454545454545454,0.8181818181818182,261
2018,Automatic Data Augmentation via Invariance-Constrained Learning,8,Automatic Data Augmentation via Invariance-Constrained Learning,89,204,False,247,84,39,24,0,20,40,12,32,63,14345,3.7083333333333335,2.9583333333333335,3.5,1.6666666666666667,8
2019,Bandit Multiclass Linear Classification: Efficient Algorithms for the Separable Case,8,Bandit Multiclass Linear Classification Efficient Algorithms for the Separable Case,40,136,False,104,157,30,37,4,16,3,0,0,83,19761,1.0810810810810811,0.8108108108108109,4.243243243243243,0.08108108108108109,10
2020,Bayesian Joint Spike-and-Slab Graphical Lasso,8,Bayesian Joint Spike-and-Slab Graphical Lasso,37,101,False,97,56,40,22,5,15,5,0,4,45,13034,1.6818181818181819,2.0,2.5454545454545454,0.22727272727272727,31
2022,Beyond the One Step Greedy Approach in Reinforcement Learning,8,Beyond the One Step Greedy Approach in Reinforcement Learning,37,123,False,32,104,5,15,0,16,2,0,0,61,9373,2.466666666666667,0.3333333333333333,6.933333333333334,0.13333333333333333,42
2023,Black-Box Variational Inference for Stochastic Differential Equations,8,Black-Box Variational Inference for Stochastic Differential Equations,40,118,False,54,52,18,10,11,7,10,0,2,69,6516,4.0,2.0,5.2,1.0,51
2024,Born-Infeld (BI) for AI: Energy-Conserving Descent (ECD) for Optimization,8,Born-Infeld BI for AI Energy-Conserving Descent ECD for Optimization,56,119,True,53,114,26,19,0,8,12,2,4,72,12239,2.9473684210526314,1.5789473684210527,6.0,0.631578947368421,8
2025,Bridging Theory and Algorithm for Domain Adaptation,8,Bridging Theory and Algorithm for Domain Adaptation,46,148,False,128,309,14,10,2,13,9,0,10,51,7322,4.6,2.4,30.9,0.9,589
2026,CRFL: Certifiably Robust Federated Learning against Backdoor Attacks,8,CRFL Certifiably Robust Federated Learning against Backdoor Attacks,44,167,True,65,194,54,25,23,12,20,0,4,67,15912,1.76,2.32,7.76,0.8,117
2027,Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning,8,Causal Curiosity RL Agents Discovering Self-supervised Experiments for Causal Representation Learning,42,206,True,36,30,33,14,0,11,11,4,0,101,9077,3.0,2.357142857142857,2.142857142857143,0.7857142857142857,42
2028,Certified Robustness Against Natural Language Attacks by Causal Intervention,8,Certified Robustness Against Natural Language Attacks by Causal Intervention,73,116,False,144,38,12,13,0,13,12,0,14,76,8684,5.615384615384615,2.0,2.923076923076923,0.9230769230769231,23
2029,"Classification from Positive, Unlabeled and Biased Negative Data",8,Classification from Positive Unlabeled and Biased Negative Data,51,181,False,98,106,25,20,0,11,23,0,12,63,12456,2.55,1.85,5.3,1.15,61
2030,Coded Sparse Matrix Multiplication,8,Coded Sparse Matrix Multiplication,23,114,False,76,268,42,25,0,12,24,0,20,34,11234,0.92,2.48,10.72,0.96,115
2031,Communication-Efficient Adaptive Federated Learning,8,Communication-Efficient Adaptive Federated Learning,57,151,False,173,244,40,38,0,12,17,0,6,51,21245,1.5,1.2105263157894737,6.421052631578948,0.4473684210526316,38
2032,Composite Functional Gradient Learning of Generative Adversarial Models,8,Composite Functional Gradient Learning of Generative Adversarial Models,28,95,False,36,70,104,19,3,8,13,2,2,71,10501,1.4736842105263157,5.578947368421052,3.6842105263157894,0.6842105263157895,13
2035,Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning,8,Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning,47,124,False,95,4,115,23,0,14,12,0,6,85,11711,2.0434782608695654,5.260869565217392,0.17391304347826086,0.5217391304347826,85
2036,Contrastive Learning Inverts the Data Generating Process,8,Contrastive Learning Inverts the Data Generating Process,64,128,False,168,74,9,21,8,7,12,9,10,56,14870,3.0476190476190474,0.9047619047619048,3.5238095238095237,0.5714285714285714,154
2037,Convex Regularization in Monte-Carlo Tree Search,8,Convex Regularization in Monte-Carlo Tree Search,56,216,False,162,140,8,18,1,8,9,0,4,48,10282,3.111111111111111,0.6666666666666666,7.777777777777778,0.5,7
2038,Correlation Clustering in Constant Many Parallel Rounds,8,Correlation Clustering in Constant Many Parallel Rounds,30,137,False,39,32,7,17,7,6,7,5,4,55,11435,1.7647058823529411,0.6470588235294118,1.8823529411764706,0.4117647058823529,29
2039,Curiosity in hindsight,8,Curiosity in hindsight,107,206,False,77,147,149,37,0,10,32,0,2,22,22369,2.891891891891892,4.081081081081081,3.972972972972973,0.8648648648648649,4
2042,Decentralized Online Convex Optimization in Networked Systems,8,Decentralized Online Convex Optimization in Networked Systems,64,1,False,86,137,4,43,0,11,16,8,4,61,25139,1.4883720930232558,0.18604651162790697,3.186046511627907,0.37209302325581395,3
2043,Deep Counterfactual Regret Minimization,8,Deep Counterfactual Regret Minimization,53,161,False,72,78,15,19,0,10,10,0,2,39,11032,2.789473684210526,0.8947368421052632,4.105263157894737,0.5263157894736842,185
2044,Deep Residual Output Layers for Neural Language Generation,8,Deep Residual Output Layers for Neural Language Generation,57,154,False,165,22,9,12,0,7,11,6,10,58,8740,4.75,1.5833333333333333,1.8333333333333333,0.9166666666666666,6
2045,Delay-adaptive step-sizes for asynchronous learning,8,Delay-adaptive step-sizes for asynchronous learning,30,130,False,64,468,25,22,0,12,22,7,2,51,9473,1.3636363636363635,1.2272727272727273,21.272727272727273,1.0,8
2046,Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them,8,Detecting Adversarial Examples Is Nearly As Hard As Classifying Them,47,151,False,129,8,3,11,1,6,7,0,4,70,7908,4.2727272727272725,0.6363636363636364,0.7272727272727273,0.6363636363636364,43
2047,Differentiable plasticity: training plastic neural networks with backpropagation,8,Differentiable plasticity training plastic neural networks with backpropagation,34,185,False,52,6,22,12,0,9,5,0,2,79,7941,2.8333333333333335,2.0,0.5,0.4166666666666667,137
2048,Diffusion Models for Adversarial Purification,8,Diffusion Models for Adversarial Purification,70,163,False,195,129,23,22,19,9,22,0,30,45,13812,3.1818181818181817,2.409090909090909,5.863636363636363,1.0,214
2049,Discovering Options for Exploration by Minimizing Cover Time,8,Discovering Options for Exploration by Minimizing Cover Time,39,130,False,35,32,38,10,0,7,7,0,2,60,6376,3.9,4.0,3.2,0.7,48
2050,Distributed Contextual Linear Bandits with Minimax Optimal Communication Cost,8,Distributed Contextual Linear Bandits with Minimax Optimal Communication Cost,40,198,False,73,164,5,32,13,11,13,0,2,77,15254,1.25,0.21875,5.125,0.40625,8
2053,Dynamic Weights in Multi-Objective Deep Reinforcement Learning,8,Dynamic Weights in Multi-Objective Deep Reinforcement Learning,38,141,False,71,4,36,19,1,11,21,2,18,62,12449,2.0,2.8421052631578947,0.21052631578947367,1.105263157894737,112
2054,Efficient Intervention Design for Causal Discovery with Latents,8,Efficient Intervention Design for Causal Discovery with Latents,56,218,False,139,76,11,34,1,8,12,0,0,63,19342,1.6470588235294117,0.3235294117647059,2.235294117647059,0.35294117647058826,23
2055,Efficient Representation Learning via Adaptive Context Pooling,8,Efficient Representation Learning via Adaptive Context Pooling,45,181,False,79,12,18,13,0,9,7,0,14,62,8650,3.4615384615384617,2.4615384615384617,0.9230769230769231,0.5384615384615384,5
2057,EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction,8,EquiBind Geometric Deep Learning for Drug Binding Structure Prediction,70,164,False,126,18,59,19,0,21,17,6,14,70,10593,3.6842105263157894,3.8421052631578947,0.9473684210526315,0.8947368421052632,179
2058,Escaping saddle points in zeroth-order optimization: the power of two-point estimators,8,Escaping saddle points in zeroth-order optimization the power of two-point estimators,63,162,False,348,1134,14,62,6,25,20,0,4,85,30988,1.0161290322580645,0.2903225806451613,18.29032258064516,0.3225806451612903,2
2059,Everyone's Preference Changes Differently: A Weighted Multi-Interest Model For Retrieval,8,Everyones Preference Changes Differently A Weighted Multi-Interest Model For Retrieval,42,202,False,114,28,28,15,0,22,27,6,28,87,10088,2.8,3.7333333333333334,1.8666666666666667,1.8,1
2060,Exploiting Independent Instruments: Identification and Distribution Generalization,8,Exploiting Independent Instruments Identification and Distribution Generalization,54,182,False,99,147,22,24,6,11,17,0,4,81,14801,2.25,1.0833333333333333,6.125,0.7083333333333334,11
2061,Extreme Multi-label Classification from Aggregated Labels,8,Extreme Multi-label Classification from Aggregated Labels,47,135,False,33,68,51,23,17,11,6,0,12,57,11505,2.0434782608695654,2.739130434782609,2.9565217391304346,0.2608695652173913,8
2062,Fairness Without Demographics in Repeated Loss Minimization,8,Fairness Without Demographics in Repeated Loss Minimization,33,2,False,60,63,33,18,0,8,14,0,0,59,9183,1.8333333333333333,1.8333333333333333,3.5,0.7777777777777778,483
2063,"Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",8,Fast Maximization of Non-Submodular Monotonic Functions on the Integer Lattice,28,96,False,92,57,28,30,29,15,7,0,0,78,11594,0.9333333333333333,0.9333333333333333,1.9,0.23333333333333334,37
2064,Faster Fundamental Graph Algorithms via Learned Predictions,8,Faster Fundamental Graph Algorithms via Learned Predictions,87,183,False,44,13,10,25,16,8,16,0,0,59,13851,3.48,0.4,0.52,0.64,31
2067,First-Order Methods for Wasserstein Distributionally Robust MDP,8,First-Order Methods for Wasserstein Distributionally Robust MDP,58,147,True,133,118,22,20,25,13,1,0,0,63,11557,2.9,1.1,5.9,0.05,21
2068,"For Learning in Symmetric Teams, Local Optima are Global Nash Equilibria",8,For Learning in Symmetric Teams Local Optima are Global Nash Equilibria,55,153,False,106,26,11,20,0,15,18,0,16,72,13376,2.75,1.35,1.3,0.9,4
2069,From Poincaré Recurrence to Convergence in Imperfect Information Games: Finding Equilibrium via Regularization,8,From Poincaré Recurrence to Convergence in Imperfect Information Games Finding Equilibrium via Regularization,61,105,False,77,114,100,43,16,19,15,3,0,109,12913,1.4186046511627908,2.3255813953488373,2.6511627906976742,0.3488372093023256,67
2070,Fundamental Tradeoffs in Distributionally Adversarial Training,8,Fundamental Tradeoffs in Distributionally Adversarial Training,38,290,False,26,123,13,23,0,5,12,2,0,62,9764,1.6521739130434783,0.5652173913043478,5.3478260869565215,0.5217391304347826,14
2071,GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning,8,GP-Tree A Gaussian Process Classifier for Few-Shot Incremental Learning,69,139,True,121,82,21,16,0,11,19,0,8,71,11930,4.3125,1.8125,5.125,1.1875,24
2072,Generalization Error Bound for Hyperbolic Ordinal Embedding,8,Generalization Error Bound for Hyperbolic Ordinal Embedding,45,188,False,121,274,0,16,1,11,14,0,0,59,11555,2.8125,0.0,17.125,0.875,8
2073,Generalized approximate survey propagation for high-dimensional estimation,8,Generalized approximate survey propagation for high-dimensional estimation,48,150,False,57,118,18,21,0,11,8,0,0,74,11926,2.2857142857142856,0.8571428571428571,5.619047619047619,0.38095238095238093,7
2074,Generative Temporal Models with Spatial Memory for Partially Observed Environments,8,Generative Temporal Models with Spatial Memory for Partially Observed Environments,44,151,False,78,22,22,13,0,11,9,2,0,82,9613,3.3846153846153846,1.6923076923076923,1.6923076923076923,0.6923076923076923,28
2075,Global Selection of Contrastive Batches via Optimization on Sample Permutations,8,Global Selection of Contrastive Batches via Optimization on Sample Permutations,54,170,False,74,42,21,21,0,21,19,3,26,79,11044,2.5714285714285716,2.238095238095238,2.0,0.9047619047619048,1
2076,Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization,8,Graph Convolution for Semi-Supervised Classification Improved Linear Separability and Out-of-Distribution Generalization,48,145,False,35,223,61,33,0,10,21,0,4,120,15452,1.4545454545454546,1.9696969696969697,6.757575757575758,0.6363636363636364,59
2077,GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training,8,GraphNorm A Principled Approach to Accelerating Graph Neural Network Training,81,144,False,350,187,77,25,38,28,39,6,14,77,14622,3.24,3.64,7.48,1.56,112
2078,HAWQV3: Dyadic Neural Network Quantization,8,HAWQV3 Dyadic Neural Network Quantization,64,183,False,88,48,24,17,6,16,8,0,4,41,11963,3.764705882352941,1.6470588235294117,2.823529411764706,0.47058823529411764,82
2079,Hierarchical Verification for Adversarial Robustness,8,Hierarchical Verification for Adversarial Robustness,39,177,False,88,34,90,19,14,13,10,0,6,52,11177,2.0526315789473686,5.052631578947368,1.7894736842105263,0.5263157894736842,5
2080,How Do Adam and Training Strategies Help BNNs Optimization?,8,How Do Adam and Training Strategies Help BNNs Optimization,44,175,False,88,8,31,11,0,5,6,10,10,58,8189,4.0,3.727272727272727,0.7272727272727273,0.5454545454545454,59
2081,Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops,8,Humor in Word Embeddings Cockamamie Gobbledegook for Nincompoops,43,1,False,52,2,6,13,0,10,5,0,14,64,8233,3.3076923076923075,1.5384615384615385,0.15384615384615385,0.38461538461538464,11
2082,Identifiability of Label Noise Transition Matrix,8,Identifiability of Label Noise Transition Matrix,70,183,False,178,152,12,17,2,36,22,0,12,48,10873,4.117647058823529,1.411764705882353,8.941176470588236,1.2941176470588236,21
2083,Implicit Regularization with Polynomial Growth in Deep Tensor Factorization,8,Implicit Regularization with Polynomial Growth in Deep Tensor Factorization,22,89,False,79,84,27,18,6,9,7,5,2,75,9874,1.2222222222222223,1.6111111111111112,4.666666666666667,0.3888888888888889,2
2084,Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data,8,Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data,53,121,False,75,184,0,35,0,9,20,0,0,95,15045,1.5142857142857142,0.0,5.257142857142857,0.5714285714285714,40
2085,Improving Molecular Design by Stochastic Iterative Target Augmentation,8,Improving Molecular Design by Stochastic Iterative Target Augmentation,54,156,False,132,40,38,18,0,16,23,9,22,70,11880,3.0,3.3333333333333335,2.2222222222222223,1.2777777777777777,21
2086,Imputing Missing Events in Continuous-Time Event Streams,8,Imputing Missing Events in Continuous-Time Event Streams,63,155,False,136,74,38,25,8,15,29,1,4,56,19449,2.52,1.68,2.96,1.16,30
2087,Inferring Heterogeneous Causal Effects in Presence of Spatial Confounding,8,Inferring Heterogeneous Causal Effects in Presence of Spatial Confounding,24,92,False,33,62,44,9,0,6,11,0,2,73,5428,2.6666666666666665,5.111111111111111,6.888888888888889,1.2222222222222223,8
2088,Instance Specific Approximations for Submodular Maximization,8,Instance Specific Approximations for Submodular Maximization,63,268,False,79,22,26,27,10,8,16,5,4,60,12266,2.3333333333333335,1.1111111111111112,0.8148148148148148,0.5925925925925926,7
2089,Interpretable VAEs for nonlinear group factor analysis,8,Interpretable VAEs for nonlinear group factor analysis,29,152,False,50,20,27,20,3,8,5,0,4,54,7792,1.45,1.55,1.0,0.25,19
2090,Inverse Active Sensing: Modeling and Understanding Timely Decision-Making,8,Inverse Active Sensing Modeling and Understanding Timely Decision-Making,71,144,False,186,166,27,21,0,8,4,0,10,72,17658,3.380952380952381,1.7619047619047619,7.904761904761905,0.19047619047619047,16
2091,Joining datasets via data augmentation in the label space for neural networks,8,Joining datasets via data augmentation in the label space for neural networks,43,134,False,67,10,18,13,0,7,15,8,14,77,8056,3.3076923076923075,2.4615384615384617,0.7692307692307693,1.1538461538461537,1
2094,Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence,8,Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence,61,185,True,145,507,52,44,0,16,13,14,16,98,24156,1.3863636363636365,1.5454545454545454,11.522727272727273,0.29545454545454547,13
2095,Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition,8,Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition,35,114,False,129,194,0,21,8,12,11,0,0,90,12499,1.6666666666666667,0.0,9.238095238095237,0.5238095238095238,84
2096,Learning Dependency Structures for Weak Supervision Models,8,Learning Dependency Structures for Weak Supervision Models,50,1,False,166,109,8,23,16,10,7,0,8,58,13175,2.1739130434782608,0.6956521739130435,4.739130434782608,0.30434782608695654,61
2097,Learning Human Objectives by Evaluating Hypothetical Behavior,8,Learning Human Objectives by Evaluating Hypothetical Behavior,54,193,False,90,14,57,18,0,7,13,0,0,61,11766,3.0,3.1666666666666665,0.7777777777777778,0.7222222222222222,71
2098,Learning Models from Data with Measurement Error: Tackling Underreporting,8,Learning Models from Data with Measurement Error Tackling Underreporting,33,225,False,51,36,10,11,7,13,5,0,0,72,7565,3.0,0.9090909090909091,3.272727272727273,0.45454545454545453,9
2099,Learning Self-Modulating Attention in Continuous Time Space with Applications to Sequential Recommendation,8,Learning Self-Modulating Attention in Continuous Time Space with Applications to Sequential Recommendation,74,174,False,72,56,3,13,2,9,10,0,6,106,8934,5.6923076923076925,0.6923076923076923,4.3076923076923075,0.7692307692307693,11
2101,Learning to Convolve: A Generalized Weight-Tying Approach,8,Learning to Convolve A Generalized Weight-Tying Approach,27,127,False,94,64,27,13,12,10,9,0,4,56,7623,2.076923076923077,2.3846153846153846,4.923076923076923,0.6923076923076923,18
2102,Learning to Rehearse in Long Sequence Memorization,8,Learning to Rehearse in Long Sequence Memorization,39,192,False,104,24,10,13,0,8,10,5,14,50,8770,3.0,1.8461538461538463,1.8461538461538463,0.7692307692307693,8
2104,Lightweight Projective Derivative Codes for Compressed Asynchronous Gradient Descent,8,Lightweight Projective Derivative Codes for Compressed Asynchronous Gradient Descent,57,210,False,32,38,39,15,0,7,10,4,2,84,8762,3.8,2.7333333333333334,2.533333333333333,0.6666666666666666,2
2105,Local Algorithms for Finding Densely Connected Clusters,8,Local Algorithms for Finding Densely Connected Clusters,34,152,False,49,99,32,25,17,8,9,2,6,55,14202,1.36,1.52,3.96,0.36,7
2106,Lossless Compression of Efficient Private Local Randomizers,8,Lossless Compression of Efficient Private Local Randomizers,53,223,False,160,67,4,27,1,5,6,0,0,59,15578,1.962962962962963,0.14814814814814814,2.4814814814814814,0.2222222222222222,29
2107,MARINA: Faster Non-Convex Distributed Learning with Compression,8,MARINA Faster Non-Convex Distributed Learning with Compression,47,191,True,94,336,74,42,0,11,19,8,12,62,22589,1.119047619047619,2.0476190476190474,8.0,0.4523809523809524,90
2109,Maximum-and-Concatenation Networks,8,Maximum-and-Concatenation Networks,67,181,False,61,256,6,33,2,9,19,0,6,34,19130,2.0303030303030303,0.36363636363636365,7.757575757575758,0.5757575757575758,2
2110,Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks,8,Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks,77,238,False,96,106,205,38,0,16,12,0,14,87,12935,2.026315789473684,5.7631578947368425,2.789473684210526,0.3157894736842105,4
2111,Minimal Achievable Sufficient Statistic Learning,8,Minimal Achievable Sufficient Statistic Learning,44,98,False,33,33,6,23,1,8,13,5,28,48,13351,1.9130434782608696,1.4782608695652173,1.434782608695652,0.5652173913043478,11
2112,Mix&Match - Agent Curricula for Reinforcement Learning,8,MixMatch - Agent Curricula for Reinforcement Learning,25,198,False,43,8,45,12,2,15,14,0,0,53,8148,2.0833333333333335,3.75,0.6666666666666666,1.1666666666666667,68
2113,Model-Free Opponent Shaping,8,Model-Free Opponent Shaping,36,216,False,84,6,27,14,0,11,9,0,40,27,7125,2.5714285714285716,4.785714285714286,0.42857142857142855,0.6428571428571429,21
2114,Molecular Representation Learning via Heterogeneous Motif Graph Neural Networks,8,Molecular Representation Learning via Heterogeneous Motif Graph Neural Networks,66,194,False,112,10,18,14,0,10,12,0,10,79,8859,4.714285714285714,2.0,0.7142857142857143,0.8571428571428571,18
2115,Muesli: Combining Improvements in Policy Optimization,8,Muesli Combining Improvements in Policy Optimization,102,70,False,265,88,54,28,0,14,19,0,22,52,16158,3.642857142857143,2.7142857142857144,3.142857142857143,0.6785714285714286,53
2116,Multi-fidelity Bayesian Optimization with Max-value Entropy Search,8,Multi-fidelity Bayesian Optimization with Max-value Entropy Search,47,189,False,120,129,10,31,4,15,12,4,2,66,11801,1.5161290322580645,0.3870967741935484,4.161290322580645,0.3870967741935484,42
2117,NADS: Neural Architecture Distribution Search for Uncertainty Awareness,8,NADS Neural Architecture Distribution Search for Uncertainty Awareness,63,170,True,282,40,198,21,0,26,16,0,12,70,9355,3.0,10.0,1.9047619047619047,0.7619047619047619,17
2118,Neural Collaborative Subspace Clustering,8,Neural Collaborative Subspace Clustering,58,125,False,56,34,15,10,0,6,10,0,6,40,7023,5.8,2.1,3.4,1.0,65
2119,Neural SDEs as Infinite-Dimensional GANs,8,Neural SDEs as Infinite-Dimensional GANs,69,177,False,145,44,14,14,33,6,16,1,6,40,8672,4.928571428571429,1.4285714285714286,3.142857142857143,1.1428571428571428,92
2121,Nonconvex Variance Reduced Optimization with Arbitrary Sampling,8,Nonconvex Variance Reduced Optimization with Arbitrary Sampling,36,167,False,85,284,23,31,3,19,32,16,4,63,14708,1.1612903225806452,0.8709677419354839,9.161290322580646,1.032258064516129,38
2122,Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care,8,Not to Cry Wolf Distantly Supervised Multitask Learning in Critical Care,62,180,False,57,10,10,14,0,8,4,0,2,72,9198,4.428571428571429,0.8571428571428571,0.7142857142857143,0.2857142857142857,20
2123,Offline Meta-Reinforcement Learning with Advantage Weighting,8,Offline Meta-Reinforcement Learning with Advantage Weighting,51,227,False,136,34,43,23,6,14,13,0,10,60,13362,2.217391304347826,2.3043478260869565,1.4782608695652173,0.5652173913043478,77
2124,On Distribution Shift in Learning-based Bug Detectors,8,On Distribution Shift in Learning-based Bug Detectors,51,40,False,110,20,20,22,33,13,16,0,0,53,12218,2.3181818181818183,0.9090909090909091,0.9090909090909091,0.7272727272727273,16
2125,On Leveraging Pretrained GANs for Limited-Data Generation,8,On Leveraging Pretrained GANs for Limited-Data Generation,64,175,False,75,12,82,23,0,12,17,2,6,57,10878,2.782608695652174,3.8260869565217392,0.5217391304347826,0.7391304347826086,20
2126,On Unbalanced Optimal Transport: An Analysis of Sinkhorn Algorithm,8,On Unbalanced Optimal Transport An Analysis of Sinkhorn Algorithm,27,159,False,32,172,10,14,4,6,10,0,0,65,8978,1.9285714285714286,0.7142857142857143,12.285714285714286,0.7142857142857143,63
2127,On the Forward Invariance of Neural ODEs,8,On the Forward Invariance of Neural ODEs,63,125,False,126,98,40,25,0,14,19,0,8,40,14344,2.52,1.92,3.92,0.76,6
2128,On the Number of Linear Regions of Convolutional Neural Networks,8,On the Number of Linear Regions of Convolutional Neural Networks,42,138,False,43,151,0,23,0,13,4,0,14,64,14976,1.826086956521739,0.6086956521739131,6.565217391304348,0.17391304347826086,55
2129,On the Theoretical Properties of the Network Jackknife,8,On the Theoretical Properties of the Network Jackknife,48,116,False,114,250,23,34,3,12,10,0,8,54,12864,1.411764705882353,0.9117647058823529,7.352941176470588,0.29411764705882354,9
2130,Online Algorithms with Multiple Predictions,8,Online Algorithms with Multiple Predictions,60,294,False,60,95,0,22,6,8,10,0,0,43,11734,2.727272727272727,0.0,4.318181818181818,0.45454545454545453,18
2131,Online Pricing with Offline Data: Phase Transition and Inverse Square Law,8,Online Pricing with Offline Data Phase Transition and Inverse Square Law,54,0,False,125,330,34,72,0,15,23,0,12,72,32016,0.75,0.6388888888888888,4.583333333333333,0.3194444444444444,23
2132,Optimal Clustering with Noisy Queries via Multi-Armed Bandit,8,Optimal Clustering with Noisy Queries via Multi-Armed Bandit,27,203,False,50,34,0,17,11,11,16,0,0,60,12282,1.588235294117647,0.0,2.0,0.9411764705882353,5
2133,Optimal transport mapping via input convex neural networks,8,Optimal transport mapping via input convex neural networks,49,217,False,172,96,68,14,2,18,16,0,4,58,9451,3.5,5.142857142857143,6.857142857142857,1.1428571428571428,159
2134,Option Discovery in the Absence of Rewards with Manifold Analysis,8,Option Discovery in the Absence of Rewards with Manifold Analysis,54,115,False,127,64,77,22,2,14,16,0,4,65,13033,2.4545454545454546,3.6818181818181817,2.909090909090909,0.7272727272727273,4
2135,Overcoming catastrophic forgetting with hard attention to the task,8,Overcoming catastrophic forgetting with hard attention to the task,49,94,False,120,36,30,17,0,11,24,0,16,66,11010,2.8823529411764706,2.7058823529411766,2.1176470588235294,1.411764705882353,816
2136,PENNI: Pruned Kernel Sharing for Efficient CNN Inference,8,PENNI Pruned Kernel Sharing for Efficient CNN Inference,46,148,True,44,12,31,15,6,10,13,0,10,55,8370,3.066666666666667,2.7333333333333334,0.8,0.8666666666666667,9
2137,Parameter-free Locally Accelerated Conditional Gradients,8,Parameter-free Locally Accelerated Conditional Gradients,44,146,False,310,256,74,36,22,20,34,4,0,56,20481,1.2222222222222223,2.0555555555555554,7.111111111111111,0.9444444444444444,7
2138,Pathwise Derivatives Beyond the Reparameterization Trick,8,Pathwise Derivatives Beyond the Reparameterization Trick,48,114,False,50,202,36,17,0,10,25,13,0,56,11879,2.823529411764706,2.1176470588235294,11.882352941176471,1.4705882352941178,100
2139,Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL,8,Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL,65,185,True,88,31,120,30,0,16,17,0,14,75,16282,2.1666666666666665,4.466666666666667,1.0333333333333334,0.5666666666666667,14
2140,Practical Contextual Bandits with Regression Oracles,8,Practical Contextual Bandits with Regression Oracles,30,106,False,86,200,99,35,23,8,13,0,18,52,19156,0.8571428571428571,3.342857142857143,5.714285714285714,0.37142857142857144,109
2141,Principal Component Hierarchy for Sparse Quadratic Programs,8,Principal Component Hierarchy for Sparse Quadratic Programs,71,120,False,76,79,16,14,0,8,8,0,16,59,9267,5.071428571428571,2.2857142857142856,5.642857142857143,0.5714285714285714,2
2143,Programmatically Interpretable Reinforcement Learning,8,Programmatically Interpretable Reinforcement Learning,41,213,False,46,18,14,14,23,12,6,0,10,53,9429,2.9285714285714284,1.7142857142857142,1.2857142857142858,0.42857142857142855,290
2144,Provable Lipschitz Certification for Generative Models,8,Provable Lipschitz Certification for Generative Models,20,88,False,19,85,32,23,39,17,15,0,40,54,13182,0.8695652173913043,3.130434782608696,3.6956521739130435,0.6521739130434783,12
2145,Provably Strict Generalisation Benefit for Equivariant Models,8,Provably Strict Generalisation Benefit for Equivariant Models,40,154,False,85,146,3,24,14,10,17,1,0,61,13709,1.6666666666666667,0.125,6.083333333333333,0.7083333333333334,60
2146,Quantification and Analysis of Layer-wise and Pixel-wise Information Discarding,8,Quantification and Analysis of Layer-wise and Pixel-wise Information Discarding,59,159,False,73,50,76,35,0,18,14,0,6,79,14135,1.6857142857142857,2.342857142857143,1.4285714285714286,0.4,0
2147,Query-Efficient and Scalable Black-Box Adversarial Attacks on Discrete Sequential Data via Bayesian Optimization,8,Query-Efficient and Scalable Black-Box Adversarial Attacks on Discrete Sequential Data via Bayesian Optimization,54,156,False,104,14,19,20,0,12,24,19,44,112,12658,2.7,3.15,0.7,1.2,24
2148,Random Gegenbauer Features for Scalable Kernel Methods,8,Random Gegenbauer Features for Scalable Kernel Methods,46,142,False,99,232,4,39,7,18,21,0,6,54,16305,1.1794871794871795,0.2564102564102564,5.948717948717949,0.5384615384615384,3
2149,Re-evaluating Word Mover's Distance,8,Re-evaluating Word Movers Distance,101,140,False,162,23,22,19,0,16,3,0,18,35,13350,5.315789473684211,2.1052631578947367,1.2105263157894737,0.15789473684210525,17
2150,Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks,8,Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks,65,160,False,438,16,226,17,10,22,20,0,12,87,8970,3.823529411764706,14.0,0.9411764705882353,1.1764705882352942,9
2151,Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency,8,Reinforcement Learning from Partial Observation Linear Function Approximation with Provable Sample Efficiency,41,173,False,65,8,4,55,0,10,26,0,0,109,19566,0.7454545454545455,0.07272727272727272,0.14545454545454545,0.4727272727272727,12
2152,Representation Matters: Offline Pretraining for Sequential Decision Making,8,Representation Matters Offline Pretraining for Sequential Decision Making,57,189,False,180,22,54,20,24,20,34,0,8,73,8581,2.85,3.1,1.1,1.7,104
2153,Rethinking Neural vs. Matrix-Factorization Collaborative Filtering: the Theoretical Perspectives,8,Rethinking Neural vs Matrix-Factorization Collaborative Filtering the Theoretical Perspectives,66,178,False,151,332,15,27,0,17,3,0,0,20,17127,2.4444444444444446,0.5555555555555556,12.296296296296296,0.1111111111111111,14
2154,Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization,8,Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization,58,235,False,161,106,12,20,31,12,4,0,14,92,11846,2.9,1.3,5.3,0.2,57
2155,Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum,8,Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum,46,148,False,97,22,0,35,12,12,7,0,66,80,18980,1.3142857142857143,1.8857142857142857,0.6285714285714286,0.2,12
2156,Robust Speech Recognition via Large-Scale Weak Supervision,8,Robust Speech Recognition via Large-Scale Weak Supervision,100,90,False,123,0,33,28,8,13,25,9,20,58,17596,3.5714285714285716,1.8928571428571428,0.0,0.8928571428571429,1255
2157,SAGA with Arbitrary Sampling,8,SAGA with Arbitrary Sampling,36,180,True,102,140,39,26,0,10,31,0,2,28,12994,1.3846153846153846,1.5769230769230769,5.384615384615385,1.1923076923076923,23
2158,SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation,8,SPADE A Spectral Method for Black-Box Adversarial Robustness Evaluation,56,151,True,52,88,30,18,3,8,24,2,0,71,11347,3.111111111111111,1.6666666666666667,4.888888888888889,1.3333333333333333,7
2159,Sample Efficient Learning of Predictors that Complement Humans,8,Sample Efficient Learning of Predictors that Complement Humans,46,137,False,58,44,11,47,15,19,6,0,0,62,17718,0.9787234042553191,0.23404255319148937,0.9361702127659575,0.1276595744680851,18
2160,Scalable Gaussian Process Regression for Kernels with a Non-Stationary Phase,8,Scalable Gaussian Process Regression for Kernels with a Non-Stationary Phase,26,147,False,56,28,8,12,0,6,12,0,8,76,6776,2.1666666666666665,1.3333333333333333,2.3333333333333335,1.0,3
2161,Scaling Structured Inference with Randomization,8,Scaling Structured Inference with Randomization,52,226,False,114,140,6,18,0,9,7,4,10,47,9726,2.888888888888889,0.8888888888888888,7.777777777777778,0.3888888888888889,2
2163,Self-supervised models of audio effectively explain human cortical responses to speech,8,Self-supervised models of audio effectively explain human cortical responses to speech,51,166,False,46,0,34,16,2,9,13,0,2,86,8364,3.1875,2.25,0.0,0.8125,30
2165,Similarity of Neural Network Representations Revisited,8,Similarity of Neural Network Representations Revisited,61,131,False,81,76,42,20,10,14,18,0,10,54,10970,3.05,2.6,3.8,0.9,963
2166,Sketching Meets Differential Privacy: Fast Algorithm for Dynamic Kronecker Projection Maintenance,8,Sketching Meets Differential Privacy Fast Algorithm for Dynamic Kronecker Projection Maintenance,111,1,False,102,308,12,57,12,12,21,5,2,96,23547,1.9473684210526316,0.24561403508771928,5.4035087719298245,0.3684210526315789,16
2167,SoftSort: A Continuous Relaxation for the argsort Operator,8,SoftSort A Continuous Relaxation for the argsort Operator,16,140,False,60,28,14,18,0,7,11,0,6,57,11358,0.8888888888888888,1.1111111111111112,1.5555555555555556,0.6111111111111112,41
2168,Sparsified Linear Programming for Zero-Sum Equilibrium Finding,8,Sparsified Linear Programming for Zero-Sum Equilibrium Finding,25,195,False,68,18,9,12,0,11,7,0,4,62,9059,2.0833333333333335,1.0833333333333333,1.5,0.5833333333333334,9
2170,Stein Point Markov Chain Monte Carlo,8,Stein Point Markov Chain Monte Carlo,62,130,False,204,167,23,31,9,8,14,6,0,36,19077,2.0,0.7419354838709677,5.387096774193548,0.45161290322580644,51
2171,Stochastic Optimization for DC Functions and Non-smooth Non-convex Regularizers with Non-asymptotic Convergence,8,Stochastic Optimization for DC Functions and Non-smooth Non-convex Regularizers with Non-asymptotic Convergence,56,231,True,160,530,14,60,10,17,8,0,4,111,23440,0.9333333333333333,0.3,8.833333333333334,0.13333333333333333,35
2172,Strategic Classification is Causal Modeling in Disguise,8,Strategic Classification is Causal Modeling in Disguise,36,138,False,98,34,7,16,0,7,10,0,0,55,7393,2.25,0.4375,2.125,0.625,96
2173,Structured Convolutional Kernel Networks for Airline Crew Scheduling,8,Structured Convolutional Kernel Networks for Airline Crew Scheduling,49,141,False,206,49,20,22,7,12,15,5,18,68,15644,2.227272727272727,1.7272727272727273,2.227272727272727,0.6818181818181818,8
2175,Synthesizer: Rethinking Self-Attention for Transformer Models,8,Synthesizer Rethinking Self-Attention for Transformer Models,24,153,False,57,18,32,10,22,6,6,0,12,60,5832,2.4,4.4,1.8,0.6,281
2176,Target Tracking for Contextual Bandits: Application to Demand Side Management,8,Target Tracking for Contextual Bandits Application to Demand Side Management,36,125,False,97,233,12,20,1,11,15,0,0,76,12996,1.8,0.6,11.65,0.75,9
2177,Temporal Predictive Coding For Model-Based Planning In Latent Space,8,Temporal Predictive Coding For Model-Based Planning In Latent Space,35,172,False,113,62,34,18,17,16,26,4,2,67,8678,1.9444444444444444,2.0,3.4444444444444446,1.4444444444444444,42
2178,The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation,8,The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation,75,1,False,101,210,28,54,11,10,9,4,0,90,22633,1.3888888888888888,0.5185185185185185,3.888888888888889,0.16666666666666666,168
2180,The Symmetry between Arms and Knapsacks: A Primal-Dual Approach for Bandits with Knapsacks,8,The Symmetry between Arms and Knapsacks A Primal-Dual Approach for Bandits with Knapsacks,25,206,False,72,196,0,39,8,11,18,0,0,89,17138,0.6410256410256411,0.0,5.0256410256410255,0.46153846153846156,16
2181,Theoretically Principled Trade-off between Robustness and Accuracy,8,Theoretically Principled Trade-off between Robustness and Accuracy,73,154,False,118,136,41,31,0,14,23,5,22,66,12429,2.3548387096774195,2.032258064516129,4.387096774193548,0.7419354838709677,2030
2182,Tilting the playing field: Dynamical loss functions for machine learning,8,Tilting the playing field Dynamical loss functions for machine learning,82,181,False,42,28,28,16,0,9,4,0,0,71,8555,5.125,1.75,1.75,0.25,9
2183,Towards Better Laplacian Representation in Reinforcement Learning with Generalized Graph Drawing,8,Towards Better Laplacian Representation in Reinforcement Learning with Generalized Graph Drawing,28,174,False,75,170,60,20,0,13,14,2,12,96,10028,1.4,3.6,8.5,0.7,14
2184,Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs,8,Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs,64,132,False,78,136,43,23,0,12,15,0,6,70,15548,2.782608695652174,2.130434782608696,5.913043478260869,0.6521739130434783,2
2185,Training Deep Energy-Based Models with f-Divergence Minimization,8,Training Deep Energy-Based Models with f-Divergence Minimization,58,304,False,102,232,69,38,7,15,31,2,10,64,15369,1.5263157894736843,2.0789473684210527,6.105263157894737,0.8157894736842105,40
2187,Unaligned Supervision For Automatic Music Transcription in The Wild,8,Unaligned Supervision For Automatic Music Transcription in The Wild,19,198,False,47,13,3,16,2,6,9,14,24,67,10507,1.1875,1.6875,0.8125,0.5625,14
2188,Understanding MCMC Dynamics as Flows on the Wasserstein Space,8,Understanding MCMC Dynamics as Flows on the Wasserstein Space,69,143,True,159,90,22,15,0,9,12,10,0,61,10882,4.6,1.4666666666666666,6.0,0.8,21
2189,Understanding the impact of entropy on policy optimization,8,Understanding the impact of entropy on policy optimization,40,130,False,89,42,108,25,0,7,8,15,0,58,13227,1.6,4.32,1.68,0.32,186
2190,Unsupervised Co-part Segmentation through Assembly,8,Unsupervised Co-part Segmentation through Assembly,38,105,False,51,28,45,11,16,7,7,0,8,50,6927,3.4545454545454546,4.818181818181818,2.5454545454545454,0.6363636363636364,11
2191,Using Inherent Structures to design Lean 2-layer RBMs,8,Using Inherent Structures to design Lean 2-layer RBMs,23,222,False,24,62,16,16,0,20,8,0,10,53,10062,1.4375,1.625,3.875,0.5,0
2192,Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models,8,Variational Gradient Estimate of the Score Function in Energy-based Latent Variable Models,76,145,False,155,122,60,27,0,18,13,4,8,92,13621,2.814814814814815,2.5185185185185186,4.518518518518518,0.48148148148148145,7
2193,Video Prediction with Appearance and Motion Conditions,8,Video Prediction with Appearance and Motion Conditions,45,134,False,100,16,29,14,0,9,13,0,12,54,9949,3.2142857142857144,2.9285714285714284,1.1428571428571428,0.9285714285714286,41
2194,What Can Be Learnt With Wide Convolutional Neural Networks?,8,What Can Be Learnt With Wide Convolutional Neural Networks,71,220,False,132,246,47,33,12,14,17,0,0,58,19440,2.1515151515151514,1.4242424242424243,7.454545454545454,0.5151515151515151,7
2196,X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion,8,X-Paste Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion,64,220,True,113,0,26,12,0,6,8,0,22,95,8878,5.333333333333333,4.0,0.0,0.6666666666666666,14
2197,p-Norm Flow Diffusion for Local Graph Clustering,8,p-Norm Flow Diffusion for Local Graph Clustering,42,221,False,64,121,17,28,2,4,6,4,6,48,13897,1.5,0.8214285714285714,4.321428571428571,0.21428571428571427,21
2198,A Conditional-Gradient-Based Augmented Lagrangian Framework,8,A Conditional-Gradient-Based Augmented Lagrangian Framework,33,135,False,75,160,36,19,11,8,11,2,0,59,10961,1.736842105263158,1.894736842105263,8.421052631578947,0.5789473684210527,23
2199,"A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel",8,A Fast Well-Founded Approximation to the Empirical Neural Tangent Kernel,51,132,False,133,155,104,21,0,14,6,0,0,73,13774,2.4285714285714284,4.9523809523809526,7.380952380952381,0.2857142857142857,9
2200,A Joint Exponential Mechanism For Differentially Private Top-k,8,A Joint Exponential Mechanism For Differentially Private Top-k,35,85,False,80,25,100,22,2,9,12,9,0,62,8801,1.5909090909090908,4.545454545454546,1.1363636363636365,0.5454545454545454,7
2203,"A Tighter Analysis of Spectral Clustering, and Beyond",8,A Tighter Analysis of Spectral Clustering and Beyond,31,153,False,30,167,52,31,1,8,7,0,2,53,12218,1.0,1.7419354838709677,5.387096774193548,0.22580645161290322,9
2204,A theory of representation learning gives a deep generalisation of kernel methods,8,A theory of representation learning gives a deep generalisation of kernel methods,55,1,False,74,256,41,36,0,18,15,0,2,81,17764,1.5277777777777777,1.1944444444444444,7.111111111111111,0.4166666666666667,3
2205,Accelerated Stochastic Gradient-free and Projection-free Methods,8,Accelerated Stochastic Gradient-free and Projection-free Methods,62,180,False,75,210,46,34,0,9,15,10,4,64,17276,1.8235294117647058,1.4705882352941178,6.176470588235294,0.4411764705882353,15
2206,Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills,8,Actionable Models Unsupervised Offline Reinforcement Learning of Robotic Skills,51,156,False,65,15,72,11,0,9,13,1,2,79,8370,4.636363636363637,6.7272727272727275,1.3636363636363635,1.1818181818181819,125
2207,"AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization",8,AdaGrad stepsizes Sharp convergence over nonconvex landscapes from any initialization,53,199,False,111,99,24,30,3,9,11,2,4,85,11912,1.7666666666666666,0.9333333333333333,3.3,0.36666666666666664,297
2208,Adaptive Region-Based Active Learning,8,Adaptive Region-Based Active Learning,36,100,False,71,131,104,23,1,10,4,0,2,37,14739,1.565217391304348,4.608695652173913,5.695652173913044,0.17391304347826086,16
2209,Adversarial Attack on Graph Structured Data,8,Adversarial Attack on Graph Structured Data,24,144,False,84,42,24,10,0,7,6,4,10,43,7050,2.4,3.4,4.2,0.6,641
2211,Agnostic Learnability of Halfspaces via Logistic Loss,8,Agnostic Learnability of Halfspaces via Logistic Loss,34,199,False,95,484,0,38,5,9,11,0,0,53,16621,0.8947368421052632,0.0,12.736842105263158,0.2894736842105263,3
2212,An Algorithm for Stochastic and Adversarial Bandits with Switching Costs,8,An Algorithm for Stochastic and Adversarial Bandits with Switching Costs,18,184,False,66,152,21,20,10,14,3,0,0,72,11219,0.9,1.05,7.6,0.15,15
2213,An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks,8,An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks,59,125,False,77,120,6,20,0,10,8,3,0,96,13130,2.95,0.3,6.0,0.4,60
2214,Anarchic Federated Learning,8,Anarchic Federated Learning,50,233,False,121,94,33,33,0,12,7,0,6,27,17856,1.5151515151515151,1.1818181818181819,2.8484848484848486,0.21212121212121213,44
2215,Approximation Theory Based Methods for RKHS Bandits,8,Approximation Theory Based Methods for RKHS Bandits,31,117,True,125,134,18,34,0,14,17,0,12,51,13391,0.9117647058823529,0.8823529411764706,3.9411764705882355,0.5,3
2216,Attention-based Deep Multiple Instance Learning,8,Attention-based Deep Multiple Instance Learning,50,121,False,120,18,36,16,6,7,12,0,34,47,9066,3.125,4.375,1.125,0.75,1274
2217,Automatic Posterior Transformation for Likelihood-Free Inference,8,Automatic Posterior Transformation for Likelihood-Free Inference,52,117,False,70,30,22,17,0,8,18,6,2,64,9191,3.0588235294117645,1.411764705882353,1.7647058823529411,1.0588235294117647,243
2218,Bandits with adversarial scaling,8,Bandits with adversarial scaling,31,1,False,50,38,12,16,5,5,5,0,0,32,7569,1.9375,0.75,2.375,0.3125,13
2219,Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense,8,Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense,48,169,False,125,50,24,15,0,12,8,0,12,93,8801,3.2,2.4,3.3333333333333335,0.5333333333333333,5
2220,Being Properly Improper,8,Being Properly Improper,89,174,False,81,292,78,53,0,9,15,0,10,23,19432,1.679245283018868,1.6603773584905661,5.509433962264151,0.2830188679245283,9
2221,Bias-Free Scalable Gaussian Processes via Randomized Truncations,8,Bias-Free Scalable Gaussian Processes via Randomized Truncations,41,108,False,113,242,31,19,17,16,21,0,4,64,13003,2.1578947368421053,1.8421052631578947,12.736842105263158,1.105263157894737,17
2222,Black-box Adversarial Attacks with Limited Queries and Information,8,Black-box Adversarial Attacks with Limited Queries and Information,34,1,False,68,6,14,10,4,6,11,4,4,66,6242,3.4,1.8,0.6,1.1,1004
2225,CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family,8,CRISP Curriculum based Sequential Neural Decoders for Polar Code Family,101,172,True,141,20,94,23,1,19,25,13,6,71,14035,4.391304347826087,4.3478260869565215,0.8695652173913043,1.0869565217391304,3
2226,Causal Discovery and Forecasting in Nonstationary Environments with State-Space Models,8,Causal Discovery and Forecasting in Nonstationary Environments with State-Space Models,45,162,False,47,195,10,24,4,14,6,0,2,86,13611,1.875,0.5,8.125,0.25,49
2227,Certified Robustness to Label-Flipping Attacks via Randomized Smoothing,8,Certified Robustness to Label-Flipping Attacks via Randomized Smoothing,67,205,False,112,66,26,19,16,12,6,0,10,71,11874,3.526315789473684,1.894736842105263,3.473684210526316,0.3157894736842105,115
2228,Classification with Rejection Based on Cost-sensitive Classification,8,Classification with Rejection Based on Cost-sensitive Classification,70,123,False,229,115,33,40,5,12,20,3,46,68,20070,1.75,1.975,2.875,0.5,49
2229,Coded-InvNet for Resilient Prediction Serving Systems,8,Coded-InvNet for Resilient Prediction Serving Systems,44,108,False,136,14,39,14,12,9,16,0,2,53,11210,3.142857142857143,2.9285714285714284,1.0,1.1428571428571428,3
2230,Communication-Efficient Distributed Optimization with Quantized Preconditioners,8,Communication-Efficient Distributed Optimization with Quantized Preconditioners,38,144,False,58,382,19,28,11,12,14,0,0,79,14503,1.3571428571428572,0.6785714285714286,13.642857142857142,0.5,14
2232,Conditional gradient methods for stochastically constrained convex minimization,8,Conditional gradient methods for stochastically constrained convex minimization,53,1,False,102,283,24,32,10,8,14,4,4,79,14737,1.65625,0.875,8.84375,0.4375,3
2234,Contextual Bandits with Large Action Spaces: Made Practical,8,Contextual Bandits with Large Action Spaces Made Practical,76,149,False,178,120,3,30,26,11,16,4,8,58,16115,2.533333333333333,0.36666666666666664,4.0,0.5333333333333333,15
2235,Contrastive Learning with Boosted Memorization,8,Contrastive Learning with Boosted Memorization,49,174,False,148,24,19,11,1,6,9,0,10,46,8185,4.454545454545454,2.6363636363636362,2.1818181818181817,0.8181818181818182,14
2236,Convex Representation Learning for Generalized Invariance in Semi-Inner-Product Space,8,Convex Representation Learning for Generalized Invariance in Semi-Inner-Product Space,57,109,False,129,313,38,21,19,17,10,0,4,85,13498,2.7142857142857144,2.0,14.904761904761905,0.47619047619047616,1
2237,Correlation Clustering via Strong Triadic Closure Labeling: Fast Approximation Algorithms and Practical Lower Bounds,8,Correlation Clustering via Strong Triadic Closure Labeling Fast Approximation Algorithms and Practical Lower Bounds,51,116,False,77,46,27,24,5,8,24,0,12,115,15909,2.125,1.625,1.9166666666666667,1.0,16
2238,Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks,8,Curriculum Learning by Transfer Learning Theory and Experiments with Deep Networks,26,157,False,34,78,22,9,1,7,5,7,0,82,6672,2.888888888888889,2.4444444444444446,8.666666666666666,0.5555555555555556,201
2239,DIVISION: Memory Efficient Training via Dual Activation Precision,8,DIVISION Memory Efficient Training via Dual Activation Precision,47,168,True,63,135,28,22,6,24,21,0,20,64,14472,2.1363636363636362,2.1818181818181817,6.136363636363637,0.9545454545454546,1
2240,Data Valuation using Reinforcement Learning,8,Data Valuation using Reinforcement Learning,36,177,False,117,14,55,17,0,13,9,0,12,43,7956,2.1176470588235294,3.9411764705882355,0.8235294117647058,0.5294117647058824,126
2242,Deep Divergence Learning,8,Deep Divergence Learning,44,166,False,69,26,26,14,0,10,13,0,12,24,9907,3.142857142857143,2.7142857142857144,1.8571428571428572,0.9285714285714286,11
2243,Deep Squared Euclidean Approximation to the Levenshtein Distance for DNA Storage,8,Deep Squared Euclidean Approximation to the Levenshtein Distance for DNA Storage,42,132,True,39,63,16,14,0,10,5,0,2,80,10330,3.0,1.2857142857142858,4.5,0.35714285714285715,2
2244,Delayed Impact of Fair Machine Learning,8,Delayed Impact of Fair Machine Learning,36,1,False,32,162,20,37,0,12,27,1,0,39,16645,0.972972972972973,0.5405405405405406,4.378378378378378,0.7297297297297297,417
2246,Differential Privacy has Bounded Impact on Fairness in Classification,8,Differential Privacy has Bounded Impact on Fairness in Classification,51,118,False,122,199,29,25,7,14,12,0,2,69,15258,2.04,1.24,7.96,0.48,6
2247,Diffusion Source Identification on Networks with Statistical Confidence,8,Diffusion Source Identification on Networks with Statistical Confidence,31,165,False,57,40,6,21,0,12,11,0,8,71,9173,1.4761904761904763,0.6666666666666666,1.9047619047619047,0.5238095238095238,9
2248,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning,8,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning,18,127,False,16,54,24,12,0,8,8,0,0,89,8173,1.5,2.0,4.5,0.6666666666666666,28
2249,"Distributed, Egocentric Representations of Graphs for Detecting Critical Structures",8,Distributed Egocentric Representations of Graphs for Detecting Critical Structures,28,132,False,71,6,40,12,0,10,6,0,8,82,8357,2.3333333333333335,4.0,0.5,0.5,13
2250,DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning,8,DouZero Mastering DouDizhu with Self-Play Deep Reinforcement Learning,60,206,False,69,0,136,34,0,14,32,0,40,69,19073,1.7647058823529411,5.176470588235294,0.0,0.9411764705882353,82
2251,"Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10, 000-Layer Vanilla Convolutional Neural Networks",8,Dynamical Isometry and a Mean Field Theory of CNNs How to Train 10 000-Layer Vanilla Convolutional Neural Networks,27,155,False,198,368,100,16,0,40,46,32,0,114,9976,1.6875,6.25,23.0,2.875,314
2253,"Efficient Robustness Certificates for Discrete Data: Sparsity-Aware Randomized Smoothing for Graphs, Images and More",8,Efficient Robustness Certificates for Discrete Data Sparsity-Aware Randomized Smoothing for Graphs Images and More,46,173,False,117,48,22,18,0,26,12,0,4,115,14771,2.5555555555555554,1.4444444444444444,2.6666666666666665,0.6666666666666666,67
2254,Emergence of Separable Manifolds in Deep Language Representations,8,Emergence of Separable Manifolds in Deep Language Representations,50,189,False,70,2,51,19,19,7,11,13,4,65,10053,2.6315789473684212,2.8947368421052633,0.10526315789473684,0.5789473684210527,30
2255,Equivalence Analysis between Counterfactual Regret Minimization and Online Mirror Descent,8,Equivalence Analysis between Counterfactual Regret Minimization and Online Mirror Descent,45,164,False,79,284,33,32,0,12,21,0,6,89,15473,1.40625,1.21875,8.875,0.65625,5
2256,Essentially No Barriers in Neural Network Energy Landscape,8,Essentially No Barriers in Neural Network Energy Landscape,40,67,False,46,28,29,12,6,13,13,0,4,58,7805,3.3333333333333335,2.75,2.3333333333333335,1.0833333333333333,346
2257,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination,8,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination,49,190,False,77,0,47,13,2,11,2,0,4,80,8285,3.769230769230769,3.923076923076923,0.0,0.15384615384615385,45
2258,Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups,8,Exploiting Redundancy Separable Group Convolutional Networks on Lie Groups,44,179,False,140,45,69,28,0,9,14,0,12,74,14555,1.5714285714285714,2.892857142857143,1.6071428571428572,0.5,20
2260,Fairness for Image Generation with Uncertain Sensitive Attributes,8,Fairness for Image Generation with Uncertain Sensitive Attributes,60,240,False,60,119,39,24,12,17,15,0,4,65,11797,2.5,1.7916666666666667,4.958333333333333,0.625,32
2261,Fast OSCAR and OWL Regression via Safe Screening Rules,8,Fast OSCAR and OWL Regression via Safe Screening Rules,37,175,True,41,52,16,11,0,6,9,6,6,54,7372,3.3636363636363638,2.0,4.7272727272727275,0.8181818181818182,32
2262,Faster Graph Embeddings via Coarsening,8,Faster Graph Embeddings via Coarsening,44,148,False,99,34,6,18,7,8,4,0,8,38,8107,2.4444444444444446,0.7777777777777778,1.8888888888888888,0.2222222222222222,22
2263,Federated Adversarial Learning: A Framework with Convergence Analysis,8,Federated Adversarial Learning A Framework with Convergence Analysis,70,1,False,49,204,7,34,13,17,22,0,4,68,13747,2.0588235294117645,0.3235294117647059,6.0,0.6470588235294118,8
2264,Fiedler Regularization: Learning Neural Networks with Graph Sparsity,8,Fiedler Regularization Learning Neural Networks with Graph Sparsity,32,147,False,66,4,0,10,0,8,12,0,6,67,7583,3.2,0.6,0.4,1.2,11
2266,Forecasting Sequential Data using Consistent Koopman Autoencoders,8,Forecasting Sequential Data using Consistent Koopman Autoencoders,46,134,False,90,36,22,12,3,11,10,0,12,65,8770,3.8333333333333335,2.8333333333333335,3.0,0.8333333333333334,98
2267,From Sets to Multisets: Provable Variational Inference for Probabilistic Integer Submodular Models,8,From Sets to Multisets Provable Variational Inference for Probabilistic Integer Submodular Models,47,147,False,105,54,29,13,2,12,4,0,2,97,8128,3.6153846153846154,2.3846153846153846,4.153846153846154,0.3076923076923077,5
2268,Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining and Speech Translation,8,Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining and Speech Translation,36,160,False,85,30,27,11,0,7,12,8,16,92,6860,3.272727272727273,3.909090909090909,2.727272727272727,1.0909090909090908,55
2269,GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training,8,GRAD-MATCH Gradient Matching based Data Subset Selection for Efficient Deep Model Training,41,129,True,65,388,32,33,6,10,17,3,16,90,18779,1.2424242424242424,1.4545454545454546,11.757575757575758,0.5151515151515151,113
2270,Generalization Error of Generalized Linear Models in High Dimensions,8,Generalization Error of Generalized Linear Models in High Dimensions,42,150,False,49,213,11,20,13,14,6,0,0,68,14671,2.1,0.55,10.65,0.3,30
2271,Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data,8,Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data,54,126,False,125,90,88,21,0,10,28,0,12,102,14263,2.5714285714285716,4.761904761904762,4.285714285714286,1.3333333333333333,260
2273,Global convergence of neuron birth-death dynamics,8,Global convergence of neuron birth-death dynamics,32,173,False,32,404,7,31,1,15,11,1,0,49,14479,1.032258064516129,0.22580645161290322,13.03225806451613,0.3548387096774194,42
2274,Graph Convolutional Gaussian Processes,8,Graph Convolutional Gaussian Processes,27,89,False,71,28,17,10,0,6,4,3,6,38,7629,2.7,2.3,2.8,0.4,32
2275,GraphOpt: Learning Optimization Models of Graph Formation,8,GraphOpt Learning Optimization Models of Graph Formation,84,184,False,102,29,21,18,0,10,13,8,28,56,11341,4.666666666666667,2.7222222222222223,1.6111111111111112,0.7222222222222222,14
2276,HEMET: A Homomorphic-Encryption-Friendly Privacy-Preserving Mobile Neural Network Architecture,8,HEMET A Homomorphic-Encryption-Friendly Privacy-Preserving Mobile Neural Network Architecture,13,107,True,37,14,15,9,0,7,13,0,8,93,6633,1.4444444444444444,2.5555555555555554,1.5555555555555556,1.4444444444444444,42
2277,Hierarchically Decoupled Imitation for Morphological Transfer,8,Hierarchically Decoupled Imitation for Morphological Transfer,82,144,False,83,10,25,18,0,14,18,0,22,61,11357,4.555555555555555,2.611111111111111,0.5555555555555556,1.0,27
2278,How Framelets Enhance Graph Neural Networks,8,How Framelets Enhance Graph Neural Networks,72,171,False,133,102,41,24,16,16,11,0,16,43,13240,3.0,2.375,4.25,0.4583333333333333,56
2279,Hybrid Models with Deep and Invertible Features,8,Hybrid Models with Deep and Invertible Features,56,146,False,136,44,26,11,3,10,12,1,10,47,7571,5.090909090909091,3.272727272727273,4.0,1.0909090909090908,88
2281,Implicit competitive regularization in GANs,8,Implicit competitive regularization in GANs,63,171,False,124,26,50,15,0,8,6,5,10,43,9760,4.2,4.0,1.7333333333333334,0.4,34
2283,Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity,8,Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity,47,154,False,49,6,23,11,0,6,5,5,4,100,6725,4.2727272727272725,2.4545454545454546,0.5454545454545454,0.45454545454545453,22
2284,In Defense of Uniform Convergence: Generalization via derandomization with an application to interpolating predictors,8,In Defense of Uniform Convergence Generalization via derandomization with an application to interpolating predictors,26,164,False,78,36,6,23,0,9,8,1,0,116,8510,1.1304347826086956,0.2608695652173913,1.565217391304348,0.34782608695652173,53
2285,Inferring serial correlation with dynamic backgrounds,8,Inferring serial correlation with dynamic backgrounds,39,144,False,164,304,84,39,0,24,32,0,4,53,19616,1.0,2.2564102564102564,7.794871794871795,0.8205128205128205,5
2286,Instance-Dependent Regret Analysis of Kernelized Bandits,8,Instance-Dependent Regret Analysis of Kernelized Bandits,35,217,False,202,340,22,26,4,31,27,10,2,56,16391,1.3461538461538463,0.9230769230769231,13.076923076923077,1.0384615384615385,2
2287,Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism,8,Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism,64,157,False,117,32,59,20,0,16,27,8,18,81,12879,3.2,3.85,1.6,1.35,102
2288,Inverse Constrained Reinforcement Learning,8,Inverse Constrained Reinforcement Learning,37,148,False,84,82,39,14,0,8,14,3,2,42,7665,2.642857142857143,2.9285714285714284,5.857142857142857,1.0,37
2289,Joint Online Learning and Decision-making via Dual Mirror Descent,8,Joint Online Learning and Decision-making via Dual Mirror Descent,27,150,False,64,97,12,36,0,7,20,0,8,65,17087,0.75,0.5555555555555556,2.6944444444444446,0.5555555555555556,8
2292,Last Iterate Risk Bounds of SGD with Decaying Stepsize for Overparameterized Linear Regression,8,Last Iterate Risk Bounds of SGD with Decaying Stepsize for Overparameterized Linear Regression,36,165,True,136,382,11,35,1,12,17,0,2,94,17994,1.0285714285714285,0.37142857142857144,10.914285714285715,0.4857142857142857,14
2293,Learning Adversarially Fair and Transferable Representations,8,Learning Adversarially Fair and Transferable Representations,38,115,False,75,58,10,11,0,10,11,0,4,60,8410,3.4545454545454546,1.2727272727272727,5.2727272727272725,1.0,577
2294,Learning Discrete Structured Representations by Adversarially Maximizing Mutual Information,8,Learning Discrete Structured Representations by Adversarially Maximizing Mutual Information,45,120,False,100,36,4,11,7,8,4,9,6,91,8323,4.090909090909091,0.9090909090909091,3.272727272727273,0.36363636363636365,7
2296,Learning Multiscale Transformer Models for Sequence Generation,8,Learning Multiscale Transformer Models for Sequence Generation,61,139,False,90,8,0,17,18,11,13,0,16,62,10346,3.588235294117647,0.9411764705882353,0.47058823529411764,0.7647058823529411,7
2297,Learning Similarity Metrics for Numerical Simulations,8,Learning Similarity Metrics for Numerical Simulations,58,162,False,117,36,97,30,0,15,23,7,8,53,18044,1.9333333333333333,3.5,1.2,0.7666666666666667,12
2298,Learning deep kernels for exponential family densities,8,Learning deep kernels for exponential family densities,45,130,False,102,76,18,20,7,10,9,1,0,54,10854,2.25,0.9,3.8,0.45,68
2299,Learning to Encode Position for Transformer with Continuous Dynamical Model,8,Learning to Encode Position for Transformer with Continuous Dynamical Model,29,240,False,45,44,14,17,6,8,12,0,12,75,7304,1.7058823529411764,1.5294117647058822,2.588235294117647,0.7058823529411765,86
2301,Let's Agree to Degree: Comparing Graph Convolutional Networks in the Message-Passing Framework,8,Lets Agree to Degree Comparing Graph Convolutional Networks in the Message-Passing Framework,30,188,False,91,62,12,22,5,7,7,0,2,93,14980,1.3636363636363635,0.6363636363636364,2.8181818181818183,0.3181818181818182,36
2302,Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data,8,Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data,25,148,False,44,193,33,21,0,7,17,7,6,81,11090,1.1904761904761905,1.8571428571428572,9.19047619047619,0.8095238095238095,8
2303,Local Augmentation for Graph Neural Networks,8,Local Augmentation for Graph Neural Networks,101,1,False,187,36,16,18,21,11,17,0,24,44,10713,5.611111111111111,2.2222222222222223,2.0,0.9444444444444444,60
2304,Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?,8,Lottery Ticket Preserves Weight Correlation Is It Desirable or Not,33,0,False,22,2,27,17,0,12,5,0,2,66,11744,1.9411764705882353,1.7058823529411764,0.11764705882352941,0.29411764705882354,28
2305,MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer,8,MASER Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer,36,121,True,61,24,40,12,0,8,4,0,4,94,7409,3.0,3.6666666666666665,2.0,0.3333333333333333,19
2306,Margin-based sampling in high dimensions: When being active is less efficient than staying passive,8,Margin-based sampling in high dimensions When being active is less efficient than staying passive,50,133,False,164,219,82,56,38,15,44,6,2,97,23837,0.8928571428571429,1.5,3.9107142857142856,0.7857142857142857,1
2307,Mean Field Multi-Agent Reinforcement Learning,8,Mean Field Multi-Agent Reinforcement Learning,56,171,False,84,115,26,18,0,13,13,2,0,45,12419,3.111111111111111,1.4444444444444444,6.388888888888889,0.7222222222222222,473
2308,Meta Optimal Transport,8,Meta Optimal Transport,106,105,False,170,55,72,23,0,10,14,5,16,22,11410,4.608695652173913,3.8260869565217392,2.391304347826087,0.6086956521739131,15
2309,Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models,8,Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models,36,188,True,94,41,16,16,0,16,12,0,6,72,9651,2.25,1.375,2.5625,0.75,15
2310,Mixed Cross Entropy Loss for Neural Machine Translation,8,Mixed Cross Entropy Loss for Neural Machine Translation,54,181,False,120,30,15,12,2,7,8,0,14,55,9102,4.5,2.4166666666666665,2.5,0.6666666666666666,13
2311,Model-Free Reinforcement Learning: from Clipped Pseudo-Regret to Sample Complexity,8,Model-Free Reinforcement Learning from Clipped Pseudo-Regret to Sample Complexity,24,127,False,38,337,0,42,10,9,15,5,2,81,17495,0.5714285714285714,0.047619047619047616,8.023809523809524,0.35714285714285715,32
2312,Moment-Based Variational Inference for Markov Jump Processes,8,Moment-Based Variational Inference for Markov Jump Processes,27,101,False,34,226,9,16,9,9,16,0,0,60,9387,1.6875,0.5625,14.125,1.0,9
2314,Multi-group Agnostic PAC Learnability,8,Multi-group Agnostic PAC Learnability,28,174,True,42,56,2,21,5,8,6,0,0,37,10598,1.3333333333333333,0.09523809523809523,2.6666666666666665,0.2857142857142857,33
2315,NAFS: A Simple yet Tough-to-beat Baseline for Graph Representation Learning,8,NAFS A Simple yet Tough-to-beat Baseline for Graph Representation Learning,52,176,True,132,58,39,17,0,13,32,0,16,74,11152,3.0588235294117645,3.235294117647059,3.411764705882353,1.8823529411764706,7
2316,Near-linear Time Gaussian Process Optimization with Adaptive Batching and Resparsification,8,Near-linear Time Gaussian Process Optimization with Adaptive Batching and Resparsification,42,169,False,332,284,80,37,0,18,30,0,4,90,16509,1.135135135135135,2.27027027027027,7.675675675675675,0.8108108108108109,16
2317,Neural Datalog Through Time: Informed Temporal Modeling via Logical Specification,8,Neural Datalog Through Time Informed Temporal Modeling via Logical Specification,70,144,False,99,55,25,29,20,14,26,0,2,80,28943,2.413793103448276,0.9310344827586207,1.896551724137931,0.896551724137931,17
2318,Neural Status Registers,8,Neural Status Registers,57,135,False,168,28,58,13,2,20,28,0,8,23,8079,4.384615384615385,5.076923076923077,2.1538461538461537,2.1538461538461537,8
2319,Newton Method over Networks is Fast up to the Statistical Precision,8,Newton Method over Networks is Fast up to the Statistical Precision,63,178,False,65,414,24,31,0,14,22,0,2,67,18634,2.032258064516129,0.8387096774193549,13.35483870967742,0.7096774193548387,17
2320,Nondeterminism and Instability in Neural Network Optimization,8,Nondeterminism and Instability in Neural Network Optimization,40,129,False,42,2,12,16,23,14,6,0,20,61,9887,2.5,2.0,0.125,0.375,28
2321,NysADMM: faster composite convex optimization via low-rank approximation,8,NysADMM faster composite convex optimization via low-rank approximation,44,167,False,94,111,3,17,0,9,18,6,12,71,9776,2.588235294117647,0.8823529411764706,6.529411764705882,1.0588235294117647,6
2322,Offline Meta-Reinforcement Learning with Online Self-Supervision,8,Offline Meta-Reinforcement Learning with Online Self-Supervision,76,257,False,129,22,38,19,25,11,6,0,4,64,11894,4.0,2.210526315789474,1.1578947368421053,0.3157894736842105,46
2323,On Dropout and Nuclear Norm Regularization,8,On Dropout and Nuclear Norm Regularization,41,84,False,38,112,8,20,5,7,10,0,2,42,11334,2.05,0.5,5.6,0.5,20
2324,On Limited-Memory Subsampling Strategies for Bandits,8,On Limited-Memory Subsampling Strategies for Bandits,36,161,False,132,261,18,38,16,15,19,10,4,52,22170,0.9473684210526315,0.5789473684210527,6.868421052631579,0.5,7
2325,On Variational Bounds of Mutual Information,8,On Variational Bounds of Mutual Information,53,133,False,156,43,22,14,0,9,9,0,6,43,9029,3.7857142857142856,2.0,3.0714285714285716,0.6428571428571429,652
2326,On the Generalization Benefit of Noise in Stochastic Gradient Descent,8,On the Generalization Benefit of Noise in Stochastic Gradient Descent,45,154,False,188,14,52,17,0,14,11,0,14,69,13544,2.6470588235294117,3.8823529411764706,0.8235294117647058,0.6470588235294118,76
2327,On the Optimality of Batch Policy Optimization Algorithms,8,On the Optimality of Batch Policy Optimization Algorithms,37,474,False,74,373,18,29,5,14,14,0,0,57,12510,1.2758620689655173,0.6206896551724138,12.862068965517242,0.4827586206896552,27
2328,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,8,On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo,40,1,False,162,510,22,37,2,20,22,4,4,71,17561,1.0810810810810811,0.7027027027027027,13.783783783783784,0.5945945945945946,81
2329,Online Balanced Experimental Design,8,Online Balanced Experimental Design,38,154,False,155,93,24,21,8,8,15,0,2,35,10572,1.8095238095238095,1.2380952380952381,4.428571428571429,0.7142857142857143,3
2330,Online Variance Reduction with Mixtures,8,Online Variance Reduction with Mixtures,37,102,False,89,96,13,15,2,8,4,0,2,39,9336,2.466666666666667,1.0,6.4,0.26666666666666666,13
2332,Optimally Controllable Perceptual Lossy Compression,8,Optimally Controllable Perceptual Lossy Compression,51,184,False,58,97,73,18,0,11,9,0,4,51,9971,2.8333333333333335,4.277777777777778,5.388888888888889,0.5,7
2333,Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,8,Oracles  Followers Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,45,142,False,124,10,20,32,19,14,6,0,6,85,15885,1.40625,0.8125,0.3125,0.1875,7
2334,Overfitting in adversarially robust deep learning,8,Overfitting in adversarially robust deep learning,85,212,False,167,6,82,25,13,10,15,0,10,49,13577,3.4,3.68,0.24,0.6,640
2336,Parameterized Algorithms for the Matrix Completion Problem,8,Parameterized Algorithms for the Matrix Completion Problem,36,122,False,42,14,8,13,0,5,8,0,2,58,8172,2.769230769230769,0.7692307692307693,1.0769230769230769,0.6153846153846154,28
2337,Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates,8,Peer Loss Functions Learning from Noisy Labels without Knowing Noise Rates,64,171,False,306,440,68,32,32,49,28,0,12,74,18007,2.0,2.5,13.75,0.875,194
2338,Phasic Policy Gradient,8,Phasic Policy Gradient,22,124,False,48,0,30,17,0,9,8,0,0,22,4388,1.2941176470588236,1.7647058823529411,0.0,0.47058823529411764,118
2339,Policy Gradient Bayesian Robust Optimization for Imitation Learning,8,Policy Gradient Bayesian Robust Optimization for Imitation Learning,66,152,False,119,112,59,26,9,10,19,10,8,67,14578,2.5384615384615383,2.576923076923077,4.3076923076923075,0.7307692307692307,14
2340,Practical and Private (Deep) Learning without Sampling or Shuffling,8,Practical and Private Deep Learning without Sampling or Shuffling,76,93,False,146,52,64,37,5,16,28,2,10,67,20419,2.054054054054054,2.0,1.4054054054054055,0.7567567567567568,130
2341,Principled Acceleration of Iterative Numerical Methods Using Machine Learning,8,Principled Acceleration of Iterative Numerical Methods Using Machine Learning,51,139,False,43,74,11,29,9,8,9,4,6,77,11729,1.7586206896551724,0.5862068965517241,2.5517241379310347,0.3103448275862069,5
2342,Private optimization in the interpolation regime: faster rates and hardness results,8,Private optimization in the interpolation regime faster rates and hardness results,32,152,False,57,222,0,26,1,8,16,1,0,82,12297,1.2307692307692308,0.0,8.538461538461538,0.6153846153846154,4
2343,Progress & Compress: A scalable framework for continual learning,8,Progress  Compress A scalable framework for continual learning,42,154,False,62,16,23,13,0,10,7,0,4,62,8535,3.230769230769231,2.076923076923077,1.2307692307692308,0.5384615384615384,727
2344,Provable Meta-Learning of Linear Representations,8,Provable Meta-Learning of Linear Representations,46,159,False,216,520,24,36,0,30,13,4,0,48,22173,1.2777777777777777,0.6666666666666666,14.444444444444445,0.3611111111111111,156
2345,Provably and Practically Efficient Neural Contextual Bandits,8,Provably and Practically Efficient Neural Contextual Bandits,45,115,False,320,584,102,57,12,24,56,8,0,60,22178,0.7894736842105263,1.7894736842105263,10.24561403508772,0.9824561403508771,5
2346,Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability,8,Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability,47,164,False,51,57,55,32,19,11,19,0,10,89,13064,1.46875,2.03125,1.78125,0.59375,5
2347,Quickshift++: Provably Good Initializations for Sample-Based Mean Shift,8,Quickshift Provably Good Initializations for Sample-Based Mean Shift,36,63,False,55,20,29,10,0,9,6,0,0,68,6623,3.6,2.9,2.0,0.6,30
2348,Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization,8,Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization,44,180,False,42,6,14,18,0,8,2,0,0,85,8472,2.4444444444444446,0.7777777777777778,0.3333333333333333,0.1111111111111111,53
2349,Re-understanding Finite-State Representations of Recurrent Policy Networks,8,Re-understanding Finite-State Representations of Recurrent Policy Networks,26,132,False,31,0,84,20,0,14,7,0,4,74,9714,1.3,4.4,0.0,0.35,17
2350,Refined Complexity of PCA with Outliers,8,Refined Complexity of PCA with Outliers,24,194,True,28,64,4,20,0,4,2,0,0,39,12628,1.2,0.2,3.2,0.1,13
2351,"Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound",8,Reinforcement Learning in Feature Space Matrix Bandit Kernels and Regret Bound,50,180,False,44,170,0,26,6,7,11,0,0,78,9814,1.9230769230769231,0.0,6.538461538461538,0.4230769230769231,259
2352,Representation Topology Divergence: A Method for Comparing Neural Network Representations,8,Representation Topology Divergence A Method for Comparing Neural Network Representations,53,134,False,104,34,84,20,0,14,11,5,20,88,10581,2.65,5.2,1.7,0.55,24
2353,Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss,8,Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss,94,146,False,140,88,25,15,0,8,13,0,18,75,11982,6.266666666666667,2.8666666666666667,5.866666666666666,0.8666666666666667,253
2354,Revisiting the Effects of Stochasticity for Hamiltonian Samplers,8,Revisiting the Effects of Stochasticity for Hamiltonian Samplers,72,1,False,253,472,55,33,11,13,35,10,8,64,17968,2.1818181818181817,1.9090909090909092,14.303030303030303,1.0606060606060606,1
2356,Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning,8,Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning,51,139,False,51,36,14,13,0,10,13,0,10,92,8391,3.923076923076923,1.8461538461538463,2.769230769230769,1.0,18
2357,SAINT-ACC: Safety-Aware Intelligent Adaptive Cruise Control for Autonomous Vehicles Using Deep Reinforcement Learning,8,SAINT-ACC Safety-Aware Intelligent Adaptive Cruise Control for Autonomous Vehicles Using Deep Reinforcement Learning,37,121,True,54,0,44,11,0,6,8,0,4,116,8757,3.3636363636363638,4.363636363636363,0.0,0.7272727272727273,11
2358,SPDY: Accurate Pruning with Speedup Guarantees,8,SPDY Accurate Pruning with Speedup Guarantees,56,216,True,151,12,30,18,1,15,7,0,12,45,12941,3.111111111111111,2.3333333333333335,0.6666666666666666,0.3888888888888889,16
2359,Sample Efficient Reinforcement Learning In Continuous State Spaces: A Perspective Beyond Linearity,8,Sample Efficient Reinforcement Learning In Continuous State Spaces A Perspective Beyond Linearity,53,172,False,94,50,29,28,0,8,10,0,0,97,13240,1.8928571428571428,1.0357142857142858,1.7857142857142858,0.35714285714285715,6
2360,Scalable Gaussian Processes with Grid-Structured Eigenfunctions (GP-GRIEF),8,Scalable Gaussian Processes with Grid-Structured Eigenfunctions GP-GRIEF,33,116,True,50,58,9,12,9,11,2,0,2,72,8454,2.75,0.9166666666666666,4.833333333333333,0.16666666666666666,25
2361,Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory,8,Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory,34,190,False,57,18,57,26,3,8,23,0,18,67,8999,1.3076923076923077,2.8846153846153846,0.6923076923076923,0.8846153846153846,53
2362,Self-Attention Generative Adversarial Networks,8,Self-Attention Generative Adversarial Networks,54,166,False,56,12,46,10,0,7,5,0,4,46,5419,5.4,5.0,1.2,0.5,3307
2363,Semi-Amortized Variational Autoencoders,8,Semi-Amortized Variational Autoencoders,69,124,False,85,18,20,13,1,12,11,0,8,39,9748,5.3076923076923075,2.1538461538461537,1.3846153846153846,0.8461538461538461,226
2364,Set Transformer,8,Set Transformer,40,145,False,118,36,36,17,1,8,20,3,34,15,9573,2.3529411764705883,4.117647058823529,2.1176470588235294,1.1764705882352942,300
2365,Simple Black-box Adversarial Attacks,8,Simple Black-box Adversarial Attacks,38,1,False,74,12,43,14,16,8,3,0,4,36,6963,2.7142857142857144,3.357142857142857,0.8571428571428571,0.21428571428571427,449
2366,Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth Channel and Vulnerability,8,Sketching for First Order Method Efficient Algorithm for Low-Bandwidth Channel and Vulnerability,106,1,False,86,564,0,69,8,23,33,0,4,96,26075,1.536231884057971,0.057971014492753624,8.173913043478262,0.4782608695652174,17
2367,Solving Challenging Dexterous Manipulation Tasks With Trajectory Optimisation and Reinforcement Learning,8,Solving Challenging Dexterous Manipulation Tasks With Trajectory Optimisation and Reinforcement Learning,25,143,False,52,0,21,13,0,9,10,0,0,104,8260,1.9230769230769231,1.6153846153846154,0.0,0.7692307692307693,18
2368,Sparsity in Partially Controllable Linear Systems,8,Sparsity in Partially Controllable Linear Systems,42,172,False,110,840,10,54,40,37,18,10,4,49,21429,0.7777777777777778,0.25925925925925924,15.555555555555555,0.3333333333333333,11
2370,Stein Points,8,Stein Points,50,110,False,173,144,61,31,11,10,24,11,0,12,15813,1.6129032258064515,1.967741935483871,4.645161290322581,0.7741935483870968,91
2371,Stochastic Optimization for Non-convex Inf-Projection Problems,8,Stochastic Optimization for Non-convex Inf-Projection Problems,33,165,False,50,188,20,22,2,8,7,0,4,62,12301,1.5,1.0909090909090908,8.545454545454545,0.3181818181818182,3
2372,Strategic Instrumental Variable Regression: Recovering Causal Relationships From Strategic Responses,8,Strategic Instrumental Variable Regression Recovering Causal Relationships From Strategic Responses,52,204,False,130,528,82,21,3,29,33,10,2,99,13384,2.4761904761904763,4.0,25.142857142857142,1.5714285714285714,23
2374,Subspace Embedding and Linear Regression with Orlicz Norm,8,Subspace Embedding and Linear Regression with Orlicz Norm,50,1,False,55,98,10,17,2,26,8,0,8,57,14025,2.9411764705882355,1.0588235294117647,5.764705882352941,0.47058823529411764,34
2375,Synthesizing Programs for Images using Reinforced Adversarial Learning,8,Synthesizing Programs for Images using Reinforced Adversarial Learning,53,215,False,50,26,28,12,0,9,10,0,0,70,7965,4.416666666666667,2.3333333333333335,2.1666666666666665,0.8333333333333334,211
2376,Target-Based Temporal Difference Learning,8,Target-Based Temporal Difference Learning,37,183,False,116,252,27,36,2,14,6,0,0,41,13698,1.0277777777777777,0.75,7.0,0.16666666666666666,26
2377,Temporally Consistent Transformers for Video Generation,8,Temporally Consistent Transformers for Video Generation,67,156,False,171,17,72,37,0,21,22,0,48,55,12268,1.8108108108108107,3.2432432432432434,0.4594594594594595,0.5945945945945946,9
2378,The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention,8,The Dual Form of Neural Networks Revisited Connecting Test Time Predictions to Training Patterns via Spotlights of Attention,36,160,False,96,32,179,21,4,12,11,0,14,124,11304,1.7142857142857142,9.19047619047619,1.5238095238095237,0.5238095238095238,29
2379,The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation,8,The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation,30,207,False,44,184,20,24,0,9,15,0,0,72,15541,1.25,0.8333333333333334,7.666666666666667,0.625,24
2380,The Unsurprising Effectiveness of Pre-Trained Vision Models for Control,8,The Unsurprising Effectiveness of Pre-Trained Vision Models for Control,73,148,False,124,15,41,13,0,6,13,0,0,71,8028,5.615384615384615,3.1538461538461537,1.1538461538461537,1.0,137
2381,Theory of Spectral Method for Union of Subspaces-Based Random Geometry Graph,8,Theory of Spectral Method for Union of Subspaces-Based Random Geometry Graph,39,88,False,48,74,15,22,1,7,4,2,0,76,6964,1.7727272727272727,0.6818181818181818,3.3636363636363638,0.18181818181818182,2
2383,Towards Binary-Valued Gates for Robust LSTM Training,8,Towards Binary-Valued Gates for Robust LSTM Training,50,172,True,112,17,14,10,0,6,8,2,10,52,6804,5.0,2.4,1.7,0.8,46
2384,Towards Tight Bounds on the Sample Complexity of Average-reward MDPs,8,Towards Tight Bounds on the Sample Complexity of Average-reward MDPs,25,105,False,188,84,6,22,6,7,7,0,4,68,11711,1.1363636363636365,0.45454545454545453,3.8181818181818183,0.3181818181818182,21
2385,Training Discrete Deep Generative Models via Gapped Straight-Through Estimator,8,Training Discrete Deep Generative Models via Gapped Straight-Through Estimator,36,117,False,95,100,9,15,0,8,16,5,18,78,9189,2.4,1.8,6.666666666666667,1.0666666666666667,6
2386,Transformation Autoregressive Networks,8,Transformation Autoregressive Networks,34,155,False,78,40,41,16,15,7,8,0,26,38,9062,2.125,4.1875,2.5,0.5,83
2387,Unbalanced minibatch Optimal Transport; applications to Domain Adaptation,8,Unbalanced minibatch Optimal Transport applications to Domain Adaptation,64,128,False,136,129,21,22,4,9,14,6,14,73,15639,2.909090909090909,1.5909090909090908,5.863636363636363,0.6363636363636364,111
2388,Understanding Noise Injection in GANs,8,Understanding Noise Injection in GANs,40,180,False,94,62,55,22,6,14,13,0,16,37,10606,1.8181818181818181,3.227272727272727,2.8181818181818183,0.5909090909090909,24
2389,Understanding the unstable convergence of gradient descent,8,Understanding the unstable convergence of gradient descent,14,91,False,38,64,41,11,1,9,8,3,0,58,7259,1.2727272727272727,3.727272727272727,5.818181818181818,0.7272727272727273,43
2390,Unsupervised Deep Learning by Neighbourhood Discovery,8,Unsupervised Deep Learning by Neighbourhood Discovery,44,131,False,59,22,21,10,0,6,4,0,12,53,6838,4.4,3.3,2.2,0.4,137
2391,Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies,8,Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies,64,167,False,135,0,76,43,41,15,4,0,8,91,20263,1.4883720930232558,1.9534883720930232,0.0,0.09302325581395349,141
2392,Variational Auto-Regressive Gaussian Processes for Continual Learning,8,Variational Auto-Regressive Gaussian Processes for Continual Learning,44,106,False,117,88,35,14,8,11,16,2,4,69,9357,3.142857142857143,2.7857142857142856,6.285714285714286,1.1428571428571428,19
2393,Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning,8,Virtual Homogeneity Learning Defending against Data Heterogeneity in Federated Learning,78,132,False,250,42,125,22,0,11,20,0,24,87,14778,3.5454545454545454,6.7727272727272725,1.9090909090909092,0.9090909090909091,41
2394,What Can Learned Intrinsic Rewards Capture?,8,What Can Learned Intrinsic Rewards Capture,53,142,False,84,15,38,18,8,11,15,3,2,42,10048,2.9444444444444446,2.2222222222222223,0.8333333333333334,0.8333333333333334,66
2395,Which Tasks Should Be Learned Together in Multi-task Learning?,8,Which Tasks Should Be Learned Together in Multi-task Learning,69,143,False,37,0,21,13,0,7,3,2,16,61,9637,5.3076923076923075,2.8461538461538463,0.0,0.23076923076923078,396
2396,XAI for Transformers: Better Explanations through Conservative Propagation,8,XAI for Transformers Better Explanations through Conservative Propagation,60,132,True,156,96,174,17,0,44,50,8,24,73,9626,3.5294117647058822,11.647058823529411,5.647058823529412,2.9411764705882355,45
2397,pathGCN: Learning General Graph Spatial Operators from Paths,8,pathGCN Learning General Graph Spatial Operators from Paths,60,141,False,106,18,13,14,2,8,18,0,32,59,9110,4.285714285714286,3.2142857142857144,1.2857142857142858,1.2857142857142858,19
2398,A Consistent and Efficient Evaluation Strategy for Attribution Methods,8,A Consistent and Efficient Evaluation Strategy for Attribution Methods,53,150,False,152,79,148,26,3,17,28,1,34,70,13293,2.0384615384615383,7.0,3.0384615384615383,1.0769230769230769,46
2399,A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation,8,A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation,65,114,False,113,154,0,22,0,8,9,0,2,79,9525,2.9545454545454546,0.09090909090909091,7.0,0.4090909090909091,55
2400,A Kernel Theory of Modern Data Augmentation,8,A Kernel Theory of Modern Data Augmentation,50,169,False,93,96,57,25,0,11,16,1,2,43,13293,2.0,2.36,3.84,0.64,169
2401,A Probabilistic Approach to Neural Network Pruning,8,A Probabilistic Approach to Neural Network Pruning,51,114,False,113,194,26,29,3,12,15,0,6,50,18340,1.7586206896551724,1.103448275862069,6.689655172413793,0.5172413793103449,14
2402,A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates,8,A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates,32,138,False,93,238,70,29,0,11,15,6,8,74,16240,1.103448275862069,2.689655172413793,8.206896551724139,0.5172413793103449,71
2403,A Tree-based Model Averaging Approach for Personalized Treatment Effect Estimation from Heterogeneous Data Sources,8,A Tree-based Model Averaging Approach for Personalized Treatment Effect Estimation from Heterogeneous Data Sources,92,28,False,124,8,77,24,0,18,16,4,8,114,15151,3.8333333333333335,3.5416666666666665,0.3333333333333333,0.6666666666666666,11
2404,A3T: Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing,8,A3T Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing,40,125,False,180,20,108,13,0,16,26,4,52,82,8171,3.076923076923077,12.307692307692308,1.5384615384615385,2.0,29
2405,"Accelerated, Optimal, and Parallel: Some Results on Model-Based Stochastic Optimization",8,Accelerated Optimal and Parallel Some Results on Model-Based Stochastic Optimization,47,148,False,70,319,14,24,3,10,17,5,0,86,12196,1.9583333333333333,0.5833333333333334,13.291666666666666,0.7083333333333334,12
2406,Active Fairness Auditing,8,Active Fairness Auditing,40,108,False,86,148,8,34,18,10,15,4,0,24,21869,1.1764705882352942,0.23529411764705882,4.352941176470588,0.4411764705882353,15
2407,AdaXpert: Adapting Neural Architecture for Growing Data,8,AdaXpert Adapting Neural Architecture for Growing Data,64,179,False,71,14,35,16,0,10,9,0,12,54,10689,4.0,2.9375,0.875,0.5625,10
2408,Adaptive Regret of Convex and Smooth Functions,8,Adaptive Regret of Convex and Smooth Functions,38,102,False,160,181,6,27,0,7,10,2,0,46,10210,1.4074074074074074,0.2222222222222222,6.703703703703703,0.37037037037037035,42
2409,Adversarial Attacks on Gaussian Process Bandits,8,Adversarial Attacks on Gaussian Process Bandits,32,185,False,85,39,169,26,6,8,25,0,4,47,13543,1.2307692307692308,6.653846153846154,1.5,0.9615384615384616,5
2410,Adversarial Robustness Against the Union of Multiple Perturbation Models,8,Adversarial Robustness Against the Union of Multiple Perturbation Models,40,199,False,172,46,48,18,22,14,13,0,14,72,11738,2.2222222222222223,3.4444444444444446,2.5555555555555554,0.7222222222222222,131
2411,Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins,8,Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins,42,111,False,106,132,0,25,0,12,4,0,2,70,11079,1.68,0.08,5.28,0.16,13
2412,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,8,An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method,53,188,False,98,232,46,28,0,16,3,2,0,94,18635,1.8928571428571428,1.6428571428571428,8.285714285714286,0.10714285714285714,2
2413,An Optimal Private Stochastic-MAB Algorithm Based on an Optimal Private Stopping Rule,8,An Optimal Private Stochastic-MAB Algorithm Based on an Optimal Private Stopping Rule,30,149,True,104,20,64,25,17,7,1,0,0,85,9410,1.2,2.56,0.8,0.04,38
2414,Anchor Sampling for Federated Learning with Partial Client Participation,8,Anchor Sampling for Federated Learning with Partial Client Participation,91,236,False,69,184,86,38,32,13,11,2,8,72,21921,2.3947368421052633,2.473684210526316,4.842105263157895,0.2894736842105263,0
2415,Approximation Theory of Convolutional Architectures for Time Series Modelling,8,Approximation Theory of Convolutional Architectures for Time Series Modelling,33,131,False,51,162,2,18,9,10,5,0,0,77,11011,1.8333333333333333,0.1111111111111111,9.0,0.2777777777777778,11
2416,Attentional Meta-learners for Few-shot Polythetic Classification,8,Attentional Meta-learners for Few-shot Polythetic Classification,35,138,False,79,40,49,23,5,19,1,0,18,64,11589,1.5217391304347827,2.9130434782608696,1.7391304347826086,0.043478260869565216,0
2417,Automatic Reparameterisation of Probabilistic Programs,8,Automatic Reparameterisation of Probabilistic Programs,33,133,False,49,42,22,15,9,11,15,0,0,54,7126,2.2,1.4666666666666666,2.8,1.0,21
2418,Barlow Twins: Self-Supervised Learning via Redundancy Reduction,8,Barlow Twins Self-Supervised Learning via Redundancy Reduction,52,224,False,91,32,24,13,16,15,23,4,12,62,8884,4.0,2.769230769230769,2.4615384615384617,1.7692307692307692,1685
2419,Bayesian Model Selection for Change Point Detection and Clustering,8,Bayesian Model Selection for Change Point Detection and Clustering,36,148,False,60,252,12,37,0,10,3,0,0,66,14542,0.972972972972973,0.32432432432432434,6.8108108108108105,0.08108108108108109,4
2422,Black-box Certification and Learning under Adversarial Perturbations,8,Black-box Certification and Learning under Adversarial Perturbations,55,110,False,79,38,0,17,3,11,9,3,0,68,14917,3.235294117647059,0.0,2.235294117647059,0.5294117647058824,18
2423,Bounding the Width of Neural Networks via Coupled Initialization - A Worst Case Analysis,8,Bounding the Width of Neural Networks via Coupled Initialization - A Worst Case Analysis,54,1,False,111,390,10,42,4,16,27,2,8,88,21658,1.2857142857142858,0.42857142857142855,9.285714285714286,0.6428571428571429,10
2424,Bucket renormalization for approximate inference,8,Bucket renormalization for approximate inference,0,115,False,104,192,58,10,16,18,18,0,0,48,6478,0.0,5.8,19.2,1.8,1
2425,CRPO: A New Approach for Safe Reinforcement Learning with Convergence Guarantee,8,CRPO A New Approach for Safe Reinforcement Learning with Convergence Guarantee,73,196,True,67,304,11,36,0,9,13,0,0,78,19683,2.0277777777777777,0.3055555555555556,8.444444444444445,0.3611111111111111,84
2427,Certifying Out-of-Domain Generalization for Blackbox Functions,8,Certifying Out-of-Domain Generalization for Blackbox Functions,53,198,False,64,202,44,22,6,13,9,5,2,62,12473,2.409090909090909,2.090909090909091,9.181818181818182,0.4090909090909091,10
2428,Classifying Treatment Responders Under Causal Effect Monotonicity,8,Classifying Treatment Responders Under Causal Effect Monotonicity,33,191,False,42,29,19,10,0,6,11,0,2,65,7246,3.3,2.1,2.9,1.1,15
2430,Communication-Efficient Distributed SVD via Local Power Iterations,8,Communication-Efficient Distributed SVD via Local Power Iterations,58,128,True,43,41,14,37,19,8,1,0,4,66,18898,1.5675675675675675,0.4864864864864865,1.1081081081081081,0.02702702702702703,13
2431,Compositional Fairness Constraints for Graph Embeddings,8,Compositional Fairness Constraints for Graph Embeddings,40,141,False,59,28,21,11,0,11,7,7,8,55,7222,3.6363636363636362,2.6363636363636362,2.5454545454545454,0.6363636363636364,209
2432,Conditioning by adaptive sampling for robust design,8,Conditioning by adaptive sampling for robust design,43,111,False,121,40,37,18,21,21,5,0,2,51,10119,2.388888888888889,2.1666666666666665,2.2222222222222223,0.2777777777777778,157
2433,Constant Curvature Graph Convolutional Networks,8,Constant Curvature Graph Convolutional Networks,65,152,False,181,203,43,19,22,17,14,12,8,47,12058,3.4210526315789473,2.6842105263157894,10.68421052631579,0.7368421052631579,99
2434,Contextual Bandits with Smooth Regret: Efficient Learning in Continuous Action Spaces,8,Contextual Bandits with Smooth Regret Efficient Learning in Continuous Action Spaces,30,135,False,122,90,3,20,13,9,11,3,2,84,10354,1.5,0.25,4.5,0.55,15
2435,"Contrastive Mixture of Posteriors for Counterfactual Inference, Data Integration and Fairness",8,Contrastive Mixture of Posteriors for Counterfactual Inference Data Integration and Fairness,78,157,False,178,166,20,44,13,15,23,0,28,93,20565,1.7727272727272727,1.0909090909090908,3.772727272727273,0.5227272727272727,5
2436,Convolutional Kernel Networks for Graph-Structured Data,8,Convolutional Kernel Networks for Graph-Structured Data,39,111,False,152,108,43,19,27,10,14,0,6,55,11502,2.0526315789473686,2.5789473684210527,5.684210526315789,0.7368421052631579,44
2437,Correlation Clustering with Asymmetric Classification Errors,8,Correlation Clustering with Asymmetric Classification Errors,21,115,False,48,124,6,24,3,8,6,0,2,60,10900,0.875,0.3333333333333333,5.166666666666667,0.25,15
2439,DNNR: Differential Nearest Neighbors Regression,8,DNNR Differential Nearest Neighbors Regression,44,160,True,60,111,34,22,1,10,10,0,44,46,11457,2.0,3.5454545454545454,5.045454545454546,0.45454545454545453,5
2440,Data augmentation for deep learning based accelerated MRI reconstruction with limited data,8,Data augmentation for deep learning based accelerated MRI reconstruction with limited data,41,191,True,81,31,156,27,0,12,13,0,4,90,10667,1.5185185185185186,5.925925925925926,1.1481481481481481,0.48148148148148145,37
2442,Deep Factors for Forecasting,8,Deep Factors for Forecasting,59,156,False,86,36,41,16,1,9,14,4,12,28,9716,3.6875,3.3125,2.25,0.875,145
2445,Detecting Rewards Deterioration in Episodic Reinforcement Learning,8,Detecting Rewards Deterioration in Episodic Reinforcement Learning,75,201,False,200,100,78,41,18,19,7,1,4,66,22882,1.829268292682927,2.0,2.4390243902439024,0.17073170731707318,11
2446,Differentially Private Aggregation in the Shuffle Model: Almost Central Accuracy in Almost a Single Message,8,Differentially Private Aggregation in the Shuffle Model Almost Central Accuracy in Almost a Single Message,49,83,False,94,94,32,31,26,17,18,0,0,106,13551,1.5806451612903225,1.032258064516129,3.032258064516129,0.5806451612903226,25
2447,Diffusion bridges vector quantized variational autoencoders,8,Diffusion bridges vector quantized variational autoencoders,26,135,False,32,20,72,23,23,12,8,0,8,59,8126,1.1304347826086956,3.4782608695652173,0.8695652173913043,0.34782608695652173,11
2448,Discrete Key-Value Bottleneck,8,Discrete Key-Value Bottleneck,97,253,False,81,36,54,25,3,19,22,4,4,29,13818,3.88,2.32,1.44,0.88,14
2449,Distributed Learning over Unreliable Networks,8,Distributed Learning over Unreliable Networks,50,203,False,67,225,21,38,27,12,11,0,0,45,15070,1.3157894736842106,0.5526315789473685,5.921052631578948,0.2894736842105263,51
2452,Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks,8,Dynamical Isometry and a Mean Field Theory of RNNs Gating Enables Signal Propagation in Recurrent Neural Networks,54,187,False,96,86,15,13,0,13,4,2,2,113,8815,4.153846153846154,1.3076923076923077,6.615384615384615,0.3076923076923077,111
2453,Efficient Learning of Mesh-Based Physical Simulation with Bi-Stride Multi-Scale Graph Neural Network,8,Efficient Learning of Mesh-Based Physical Simulation with Bi-Stride Multi-Scale Graph Neural Network,52,184,False,86,8,33,18,17,7,13,9,18,100,10296,2.888888888888889,2.8333333333333335,0.4444444444444444,0.7222222222222222,4
2454,"Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language",8,Efficient Self-supervised Learning with Contextualized Target Representations for Vision Speech and Language,65,132,False,228,0,9,14,16,7,9,0,16,109,8459,4.642857142857143,1.7857142857142858,0.0,0.6428571428571429,40
2455,Emergent Social Learning via Multi-agent Reinforcement Learning,8,Emergent Social Learning via Multi-agent Reinforcement Learning,55,187,False,72,12,45,14,0,7,17,0,2,63,9810,3.9285714285714284,3.357142857142857,0.8571428571428571,1.2142857142857142,37
2456,Equivariance versus Augmentation for Spherical Images,8,Equivariance versus Augmentation for Spherical Images,26,186,False,39,116,40,18,0,10,23,0,14,53,10520,1.4444444444444444,3.0,6.444444444444445,1.2777777777777777,12
2457,Estimate Sequences for Variance-Reduced Stochastic Composite Optimization,8,Estimate Sequences for Variance-Reduced Stochastic Composite Optimization,49,1,False,95,182,16,24,10,10,23,0,2,73,14042,2.0416666666666665,0.75,7.583333333333333,0.9583333333333334,26
2458,Evolving Attention with Residual Convolutions,8,Evolving Attention with Residual Convolutions,34,146,False,95,20,65,18,0,9,18,0,22,45,8527,1.8888888888888888,4.833333333333333,1.1111111111111112,1.0,23
2459,Exploiting Shared Representations for Personalized Federated Learning,8,Exploiting Shared Representations for Personalized Federated Learning,55,227,False,109,786,15,39,0,7,9,0,24,69,16362,1.4102564102564104,1.0,20.153846153846153,0.23076923076923078,399
2461,Fairness of Exposure in Stochastic Bandits,8,Fairness of Exposure in Stochastic Bandits,55,149,False,44,153,64,29,0,9,24,2,0,42,14894,1.896551724137931,2.206896551724138,5.275862068965517,0.8275862068965517,34
2462,Fast Parametric Learning with Activation Memorization,8,Fast Parametric Learning with Activation Memorization,54,146,False,162,44,54,16,0,20,28,10,8,53,10200,3.375,3.875,2.75,1.75,46
2463,Faster Kernel Matrix Algebra via Density Estimation,8,Faster Kernel Matrix Algebra via Density Estimation,31,144,False,47,46,8,20,15,8,6,0,2,51,9448,1.55,0.5,2.3,0.3,6
2464,Federated Composite Optimization,8,Federated Composite Optimization,113,146,False,197,260,44,49,31,12,25,15,0,32,23658,2.306122448979592,0.8979591836734694,5.3061224489795915,0.5102040816326531,44
2465,Fighting Fire with Fire: Avoiding DNN Shortcuts through Priming,8,Fighting Fire with Fire Avoiding DNN Shortcuts through Priming,80,165,True,249,138,44,28,0,23,25,8,18,62,15854,2.857142857142857,2.2142857142857144,4.928571428571429,0.8928571428571429,12
2466,Fisher SAM: Information Geometry and Sharpness Aware Minimisation,8,Fisher SAM Information Geometry and Sharpness Aware Minimisation,57,201,True,76,74,20,14,0,14,20,4,10,64,9308,4.071428571428571,2.142857142857143,5.285714285714286,1.4285714285714286,46
2468,From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers,8,From block-Toeplitz matrices to differential equations on graphs towards a general theory for scalable masked Transformers,48,104,False,131,77,39,22,4,9,21,9,20,122,14501,2.1818181818181817,2.6818181818181817,3.5,0.9545454545454546,20
2469,FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning,8,FusionRetro Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning,48,1,False,135,22,30,14,20,10,9,0,8,94,8429,3.4285714285714284,2.7142857142857144,1.5714285714285714,0.6428571428571429,5
2470,GRAND: Graph Neural Diffusion,8,GRAND Graph Neural Diffusion,68,123,True,115,68,16,15,24,19,26,4,10,28,10010,4.533333333333333,1.7333333333333334,4.533333333333333,1.7333333333333334,179
2471,Generalization Guarantee of Training Graph Convolutional Networks with Graph Topology Sampling,8,Generalization Guarantee of Training Graph Convolutional Networks with Graph Topology Sampling,39,162,False,170,1056,30,38,0,12,18,4,6,94,20645,1.0263157894736843,0.9473684210526315,27.789473684210527,0.47368421052631576,19
2473,Generative Video Transformer: Can Objects be the Words?,8,Generative Video Transformer Can Objects be the Words,47,168,False,97,4,27,16,0,9,11,6,8,53,9505,2.9375,2.1875,0.25,0.6875,25
2474,Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes,8,Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes,79,141,False,185,132,29,33,8,21,12,0,20,101,18024,2.393939393939394,1.4848484848484849,4.0,0.36363636363636365,56
2475,Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters,8,Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters,38,123,False,166,40,78,13,0,20,26,0,20,82,9261,2.923076923076923,7.538461538461538,3.076923076923077,2.0,73
2476,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,8,GraphRNN Generating Realistic Graphs with Deep Auto-regressive Models,36,1,False,81,30,23,12,0,8,16,6,4,69,8717,3.0,2.25,2.5,1.3333333333333333,677
2477,Hallucinative Topological Memory for Zero-Shot Visual Planning,8,Hallucinative Topological Memory for Zero-Shot Visual Planning,38,214,False,91,7,27,12,0,11,7,0,8,62,7951,3.1666666666666665,2.9166666666666665,0.5833333333333334,0.5833333333333334,40
2478,Hierarchically Structured Meta-learning,8,Hierarchically Structured Meta-learning,48,150,False,77,40,33,19,3,17,5,0,20,39,10914,2.526315789473684,2.789473684210526,2.1052631578947367,0.2631578947368421,186
2480,Hybrid Stochastic-Deterministic Minibatch Proximal Gradient: Less-Than-Single-Pass Optimization with Nearly Optimal Generalization,8,Hybrid Stochastic-Deterministic Minibatch Proximal Gradient Less-Than-Single-Pass Optimization with Nearly Optimal Generalization,38,237,False,57,194,20,21,0,10,13,2,4,129,12684,1.8095238095238095,1.1428571428571428,9.238095238095237,0.6190476190476191,6
2481,Image Transformer,8,Image Transformer,27,167,False,140,12,524,10,8,14,14,0,24,17,5791,2.7,54.8,1.2,1.4,1385
2485,In-Database Regression in Input Sparsity Time,8,In-Database Regression in Input Sparsity Time,54,243,False,70,48,7,28,2,11,17,2,10,45,15393,1.9285714285714286,0.6071428571428571,1.7142857142857142,0.6071428571428571,7
2486,Infinite Mixture Prototypes for Few-Shot Learning,8,Infinite Mixture Prototypes for Few-Shot Learning,41,115,False,134,22,9,13,0,8,11,0,18,49,8259,3.1538461538461537,2.076923076923077,1.6923076923076923,0.8461538461538461,213
2487,Instance-Level Explanations for Fraud Detection: A Case Study,8,Instance-Level Explanations for Fraud Detection A Case Study,33,98,False,29,4,14,6,11,6,6,1,0,60,4139,5.5,2.3333333333333335,0.6666666666666666,1.0,29
2488,"Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure",8,Interpretable Multidimensional Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure,31,215,False,30,2,8,10,0,7,4,0,4,116,7812,3.1,1.2,0.2,0.4,49
2489,Inverse Contextual Bandits: Learning How Behavior Evolves over Time,8,Inverse Contextual Bandits Learning How Behavior Evolves over Time,81,192,False,87,61,15,19,39,13,2,0,14,66,14862,4.2631578947368425,1.5263157894736843,3.210526315789474,0.10526315789473684,10
2490,JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,8,JointGAN Multi-Domain Joint Distribution Learning with Generative Adversarial Nets,38,124,False,64,28,26,10,11,7,6,2,4,82,6073,3.8,3.0,2.8,0.6,39
2491,Kernelized Stein Discrepancy Tests of Goodness-of-fit for Time-to-Event Data,8,Kernelized Stein Discrepancy Tests of Goodness-of-fit for Time-to-Event Data,43,213,False,82,190,65,31,18,10,17,21,4,76,13891,1.3870967741935485,2.225806451612903,6.129032258064516,0.5483870967741935,12
2492,LaVAN: Localized and Visible Adversarial Noise,8,LaVAN Localized and Visible Adversarial Noise,11,89,False,27,0,72,9,4,6,6,0,2,45,5625,1.2222222222222223,8.222222222222221,0.0,0.6666666666666666,200
2493,Latent Diffusion Energy-Based Model for Interpretable Text Modeling,8,Latent Diffusion Energy-Based Model for Interpretable Text Modeling,80,166,False,226,126,19,19,19,8,15,0,22,67,12532,4.2105263157894735,2.1578947368421053,6.631578947368421,0.7894736842105263,47
2494,Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization,8,Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization,54,124,False,142,90,18,19,0,12,9,0,10,92,12113,2.8421052631578947,1.4736842105263157,4.7368421052631575,0.47368421052631576,26
2495,Learning Discrete Structures for Graph Neural Networks,8,Learning Discrete Structures for Graph Neural Networks,63,153,False,113,34,24,14,0,10,8,0,8,54,9195,4.5,2.2857142857142856,2.4285714285714284,0.5714285714285714,322
2496,Learning Infinite-Horizon Average-Reward Markov Decision Processes with Constraints,8,Learning Infinite-Horizon Average-Reward Markov Decision Processes with Constraints,45,126,False,123,155,0,24,16,9,15,0,0,83,15209,1.875,0.0,6.458333333333333,0.625,20
2499,Learning disconnected manifolds: a no GANs land,8,Learning disconnected manifolds a no GANs land,48,108,False,139,124,96,24,7,16,10,0,14,46,12821,2.0,4.583333333333333,5.166666666666667,0.4166666666666667,34
2500,Learning to Estimate and Refine Fluid Motion with Physical Dynamics,8,Learning to Estimate and Refine Fluid Motion with Physical Dynamics,41,183,False,58,124,44,16,8,11,9,0,4,67,8601,2.5625,3.0,7.75,0.5625,5
2501,Learning to Route in Similarity Graphs,8,Learning to Route in Similarity Graphs,38,145,False,38,12,18,10,0,5,12,0,6,38,6908,3.8,2.4,1.2,1.2,28
2502,Let's Agree to Agree: Neural Networks Share Classification Order on Real Datasets,8,Lets Agree to Agree Neural Networks Share Classification Order on Real Datasets,50,154,False,65,4,409,22,20,14,9,0,0,79,11562,2.272727272727273,18.59090909090909,0.18181818181818182,0.4090909090909091,50
2503,Likelihood adjusted semidefinite programs for clustering heterogeneous data,8,Likelihood adjusted semidefinite programs for clustering heterogeneous data,45,237,False,89,122,28,21,0,7,8,3,0,75,13363,2.142857142857143,1.3333333333333333,5.809523809523809,0.38095238095238093,1
2505,Low Latency Privacy Preserving Inference,8,Low Latency Privacy Preserving Inference,31,140,False,89,5,16,18,11,12,6,3,8,40,8619,1.7222222222222223,1.3333333333333333,0.2777777777777778,0.3333333333333333,176
2506,MASS: Masked Sequence to Sequence Pre-training for Language Generation,8,MASS Masked Sequence to Sequence Pre-training for Language Generation,60,172,True,148,4,27,11,15,6,10,0,20,69,7515,5.454545454545454,4.2727272727272725,0.36363636363636365,0.9090909090909091,876
2507,Marginal Tail-Adaptive Normalizing Flows,8,Marginal Tail-Adaptive Normalizing Flows,57,147,False,140,142,67,29,12,10,18,0,14,40,15867,1.9655172413793103,2.793103448275862,4.896551724137931,0.6206896551724138,6
2508,Meaningfully debugging model mistakes using conceptual counterfactual explanations,8,Meaningfully debugging model mistakes using conceptual counterfactual explanations,45,195,False,69,2,15,23,4,8,14,3,2,82,11870,1.9565217391304348,0.7391304347826086,0.08695652173913043,0.6086956521739131,42
2509,Meta-Cal: Well-controlled Post-hoc Calibration by Ranking,8,Meta-Cal Well-controlled Post-hoc Calibration by Ranking,43,148,False,92,58,15,13,0,9,5,0,4,56,8936,3.3076923076923075,1.4615384615384615,4.461538461538462,0.38461538461538464,23
2510,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,8,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,35,119,False,54,72,93,24,12,9,12,0,32,77,12300,1.4583333333333333,5.208333333333333,3.0,0.5,361
2512,Model-Free and Model-Based Policy Evaluation when Causality is Uncertain,8,Model-Free and Model-Based Policy Evaluation when Causality is Uncertain,49,114,False,31,38,9,11,0,9,10,0,6,72,7649,4.454545454545454,1.3636363636363635,3.4545454545454546,0.9090909090909091,8
2513,Momentum Improves Normalized SGD,8,Momentum Improves Normalized SGD,35,128,True,66,132,4,18,0,7,3,0,0,32,7833,1.9444444444444444,0.2222222222222222,7.333333333333333,0.16666666666666666,88
2514,Multi-Agent Adversarial Inverse Reinforcement Learning,8,Multi-Agent Adversarial Inverse Reinforcement Learning,60,138,False,192,128,6,13,0,16,24,0,16,54,8792,4.615384615384615,1.6923076923076923,9.846153846153847,1.8461538461538463,102
2515,Multi-layered Network Exploration via Random Walks: From Offline Optimization to Online Learning,8,Multi-layered Network Exploration via Random Walks From Offline Optimization to Online Learning,28,177,False,24,0,6,27,0,8,24,8,4,95,19240,1.037037037037037,0.37037037037037035,0.0,0.8888888888888888,7
2516,NAS-Bench-101: Towards Reproducible Neural Architecture Search,8,NAS-Bench-101 Towards Reproducible Neural Architecture Search,54,128,True,65,0,67,15,7,13,15,0,2,61,8695,3.6,4.6,0.0,1.0,574
2518,Neural Diffusion Processes,8,Neural Diffusion Processes,41,129,False,104,88,50,23,10,14,23,6,6,26,12476,1.7826086956521738,2.4347826086956523,3.8260869565217392,1.0,23
2519,Neural Symbolic Regression that Scales,8,Neural Symbolic Regression that Scales,41,121,False,59,0,48,18,25,10,17,0,16,38,10681,2.2777777777777777,3.5555555555555554,0.0,0.9444444444444444,103
2520,No-Regret Exploration in Goal-Oriented Reinforcement Learning,8,No-Regret Exploration in Goal-Oriented Reinforcement Learning,40,210,False,146,317,55,31,8,17,10,0,6,61,18120,1.2903225806451613,1.967741935483871,10.225806451612904,0.3225806451612903,41
2521,Nonlinear Advantage: Trained Networks Might Not Be As Complex as You Think,8,Nonlinear Advantage Trained Networks Might Not Be As Complex as You Think,39,194,False,96,6,63,18,0,9,16,7,0,73,9453,2.1666666666666665,3.5,0.3333333333333333,0.8888888888888888,2
2522,Offline RL Policies Should be Trained to be Adaptive,8,Offline RL Policies Should be Trained to be Adaptive,42,159,True,76,43,23,18,0,14,18,0,0,52,11243,2.3333333333333335,1.2777777777777777,2.388888888888889,1.0,26
2523,On Efficient Constructions of Checkpoints,8,On Efficient Constructions of Checkpoints,37,281,False,42,16,34,10,0,8,7,2,0,41,6648,3.7,3.4,1.6,0.7,9
2524,On Linear Identifiability of Learned Representations,8,On Linear Identifiability of Learned Representations,44,153,False,144,58,10,18,9,13,21,1,0,52,9342,2.4444444444444446,0.5555555555555556,3.2222222222222223,1.1666666666666667,46
2525,On Well-posedness and Minimax Optimal Rates of Nonparametric Q-function Estimation in Off-policy Evaluation,8,On Well-posedness and Minimax Optimal Rates of Nonparametric Q-function Estimation in Off-policy Evaluation,63,190,False,119,143,0,46,0,13,8,0,0,107,14337,1.3695652173913044,0.0,3.108695652173913,0.17391304347826086,21
2526,On the Generalization Effects of Linear Transformations in Data Augmentation,8,On the Generalization Effects of Linear Transformations in Data Augmentation,67,157,False,67,105,16,22,13,12,14,0,10,76,14025,3.0454545454545454,1.1818181818181819,4.7727272727272725,0.6363636363636364,68
2528,On the Universality of Invariant Networks,8,On the Universality of Invariant Networks,29,148,False,36,43,7,10,8,7,4,0,0,41,7466,2.9,0.7,4.3,0.4,211
2529,Online Control of the False Coverage Rate and False Sign Rate,8,Online Control of the False Coverage Rate and False Sign Rate,30,300,False,68,49,15,23,0,9,15,0,2,61,13376,1.3043478260869565,0.7391304347826086,2.130434782608696,0.6521739130434783,19
2530,Online learning with kernel losses,8,Online learning with kernel losses,58,1,False,206,732,16,40,0,30,40,14,0,34,18235,1.45,0.4,18.3,1.0,15
2531,Optimal Continual Learning has Perfect Memory and is NP-hard,8,Optimal Continual Learning has Perfect Memory and is NP-hard,35,107,True,58,0,21,13,0,10,14,2,0,60,9972,2.6923076923076925,1.6153846153846154,0.0,1.0769230769230769,87
2532,Optimisation of Overparametrized Sum-Product Networks,8,Optimisation of Overparametrized Sum-Product Networks,22,82,False,32,49,7,6,0,5,3,0,0,53,3914,3.6666666666666665,1.1666666666666667,8.166666666666666,0.5,3
2533,Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering,8,Orchestra Unsupervised Federated Learning via Globally Consistent Clustering,90,144,False,118,34,50,23,0,14,14,3,12,76,16065,3.9130434782608696,2.6956521739130435,1.4782608695652173,0.6086956521739131,31
2534,Overparameterized Nonlinear Learning: Gradient Descent Takes the Shortest Path?,8,Overparameterized Nonlinear Learning Gradient Descent Takes the Shortest Path,76,265,False,24,361,15,43,5,10,20,12,0,77,20954,1.7674418604651163,0.3488372093023256,8.395348837209303,0.46511627906976744,162
2535,PINs: Progressive Implicit Networks for Multi-Scale Neural Representations,8,PINs Progressive Implicit Networks for Multi-Scale Neural Representations,45,145,False,72,10,67,14,3,11,12,2,4,73,7389,3.2142857142857144,5.071428571428571,0.7142857142857143,0.8571428571428571,9
2536,Pareto GAN: Extending the Representational Power of GANs to Heavy-Tailed Distributions,8,Pareto GAN Extending the Representational Power of GANs to Heavy-Tailed Distributions,29,159,True,40,76,18,15,0,10,11,1,4,85,7874,1.9333333333333333,1.4666666666666666,5.066666666666666,0.7333333333333333,21
2537,Penalizing Gradient Norm for Efficiently Improving Generalization in Deep Learning,8,Penalizing Gradient Norm for Efficiently Improving Generalization in Deep Learning,33,147,False,48,40,9,11,5,7,5,0,8,82,6656,3.0,1.5454545454545454,3.6363636363636362,0.45454545454545453,64
2538,Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning,8,Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning,67,1,False,87,34,61,17,0,15,25,9,4,89,11271,3.9411764705882355,3.823529411764706,2.0,1.4705882352941178,16
2539,Policy Gradient Method For Robust Reinforcement Learning,8,Policy Gradient Method For Robust Reinforcement Learning,94,145,False,68,370,44,44,0,14,19,1,0,56,21177,2.1363636363636362,1.0,8.409090909090908,0.4318181818181818,42
2540,Preconditioning for Scalable Gaussian Process Hyperparameter Optimization,8,Preconditioning for Scalable Gaussian Process Hyperparameter Optimization,59,136,False,118,222,20,30,14,14,28,0,8,73,16829,1.9666666666666666,0.9333333333333333,7.4,0.9333333333333333,15
2541,Principled Exploration via Optimistic Bootstrapping and Backward Induction,8,Principled Exploration via Optimistic Bootstrapping and Backward Induction,60,134,False,231,21,40,24,0,16,14,0,14,74,14553,2.5,2.25,0.875,0.5833333333333334,29
2542,Privately Learning Markov Random Fields,8,Privately Learning Markov Random Fields,80,184,False,80,38,0,29,2,8,11,1,2,39,14371,2.7586206896551726,0.06896551724137931,1.3103448275862069,0.3793103448275862,21
2543,Progressive Graph Learning for Open-Set Domain Adaptation,8,Progressive Graph Learning for Open-Set Domain Adaptation,35,160,False,40,54,22,11,0,7,5,3,12,57,7632,3.1818181818181817,3.090909090909091,4.909090909090909,0.45454545454545453,82
2544,Provable Reinforcement Learning with a Short-Term Memory,8,Provable Reinforcement Learning with a Short-Term Memory,46,1,False,0,1,0,27,0,6,2,0,0,56,12599,1.7037037037037037,0.0,0.037037037037037035,0.07407407407407407,30
2545,Provably efficient RL with Rich Observations via Latent State Decoding,8,Provably efficient RL with Rich Observations via Latent State Decoding,28,1,True,70,245,14,32,12,14,14,1,4,70,19115,0.875,0.5625,7.65625,0.4375,200
2546,Quantifying Generalization in Reinforcement Learning,8,Quantifying Generalization in Reinforcement Learning,20,116,False,37,0,56,14,0,12,13,0,6,52,5735,1.4285714285714286,4.428571428571429,0.0,0.9285714285714286,547
2548,Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,8,Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures,39,114,True,46,80,11,21,0,7,6,0,0,102,7872,1.8571428571428572,0.5238095238095238,3.8095238095238093,0.2857142857142857,58
2549,Reachability Constrained Reinforcement Learning,8,Reachability Constrained Reinforcement Learning,48,210,False,95,128,37,20,0,12,16,4,6,47,13039,2.4,2.15,6.4,0.8,31
2550,Refined Convergence Rates for Maximum Likelihood Estimation under Finite Mixture Models,8,Refined Convergence Rates for Maximum Likelihood Estimation under Finite Mixture Models,42,196,False,135,185,12,41,1,8,13,1,0,87,17222,1.024390243902439,0.2926829268292683,4.512195121951219,0.3170731707317073,7
2551,Reinforcement Learning of Implicit and Explicit Control Flow in Instructions,8,Reinforcement Learning of Implicit and Explicit Control Flow in Instructions,18,192,False,39,4,32,14,17,12,18,4,0,76,9159,1.2857142857142858,2.2857142857142856,0.2857142857142857,1.2857142857142858,10
2552,Representation Tradeoffs for Hyperbolic Embeddings,8,Representation Tradeoffs for Hyperbolic Embeddings,47,1,False,110,112,14,31,25,14,7,0,18,50,16271,1.5161290322580645,1.032258064516129,3.6129032258064515,0.22580645161290322,347
2553,Retrieval-Augmented Reinforcement Learning,8,Retrieval-Augmented Reinforcement Learning,96,262,False,136,18,123,26,3,7,15,10,12,42,15709,3.6923076923076925,5.1923076923076925,0.6923076923076923,0.5769230769230769,40
2554,Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation,8,Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation,55,195,True,178,156,0,35,8,8,22,2,0,94,14286,1.5714285714285714,0.0,4.457142857142857,0.6285714285714286,7
2555,Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees,8,Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees,101,195,False,141,231,22,38,13,7,16,1,12,87,17755,2.6578947368421053,0.8947368421052632,6.078947368421052,0.42105263157894735,19
2556,Robust Testing and Estimation under Manipulation Attacks,8,Robust Testing and Estimation under Manipulation Attacks,36,103,False,49,81,2,18,0,6,5,0,2,56,7708,2.0,0.2222222222222222,4.5,0.2777777777777778,6
2557,SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver,8,SATNet Bridging deep learning and logical reasoning using a differentiable satisfiability solver,33,190,False,39,86,20,14,6,13,7,7,2,96,9007,2.357142857142857,1.5714285714285714,6.142857142857143,0.5,215
2558,SPECTRE : Spectral Conditioning Helps to Overcome the Expressivity Limits of One-shot Graph Generators,8,SPECTRE  Spectral Conditioning Helps to Overcome the Expressivity Limits of One-shot Graph Generators,83,130,True,133,8,31,21,10,14,11,0,12,101,11979,3.9523809523809526,2.0476190476190474,0.38095238095238093,0.5238095238095238,36
2559,Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning,8,Sample Factory Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning,40,150,True,67,0,31,18,0,7,12,5,12,103,11454,2.2222222222222223,2.388888888888889,0.0,0.6666666666666666,70
2560,Scalable Identification of Partially Observed Systems with Certainty-Equivalent EM,8,Scalable Identification of Partially Observed Systems with Certainty-Equivalent EM,61,139,True,111,58,17,14,0,7,9,10,2,82,8568,4.357142857142857,1.3571428571428572,4.142857142857143,0.6428571428571429,6
2561,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,8,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,81,236,False,111,4,15,14,2,13,8,0,26,89,9497,5.785714285714286,2.9285714285714284,0.2857142857142857,0.5714285714285714,2370
2563,Semi-Autoregressive Energy Flows: Exploring Likelihood-Free Training of Normalizing Flows,8,Semi-Autoregressive Energy Flows Exploring Likelihood-Free Training of Normalizing Flows,54,131,False,208,42,34,22,43,17,17,0,24,88,12360,2.4545454545454546,2.6363636363636362,1.9090909090909092,0.7727272727272727,3
2564,Sets Clustering,8,Sets Clustering,67,183,False,51,122,32,20,3,12,15,0,2,15,14831,3.35,1.7,6.1,0.75,21
2565,Simple Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized Optimization,8,Simple Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized Optimization,31,74,False,73,272,4,17,0,12,2,0,2,85,8343,1.8235294117647058,0.35294117647058826,16.0,0.11764705882352941,17
2566,Skew Orthogonal Convolutions,8,Skew Orthogonal Convolutions,43,199,False,44,166,11,18,0,12,18,0,8,28,11229,2.388888888888889,1.0555555555555556,9.222222222222221,1.0,48
2567,Solving Inverse Problems with a Flow-based Noise Model,8,Solving Inverse Problems with a Flow-based Noise Model,58,85,False,143,32,0,15,0,11,12,5,0,54,7575,3.8666666666666667,0.0,2.1333333333333333,0.8,32
2568,Sparsity-Agnostic Lasso Bandit,8,Sparsity-Agnostic Lasso Bandit,41,148,False,168,338,64,51,0,14,24,3,0,30,21538,0.803921568627451,1.2549019607843137,6.627450980392157,0.47058823529411764,36
2569,Stabilizing Q-learning with Linear Architectures for Provably Efficient Learning,8,Stabilizing Q-learning with Linear Architectures for Provably Efficient Learning,91,1,False,64,308,0,45,3,9,28,2,0,80,20621,2.022222222222222,0.0,6.844444444444444,0.6222222222222222,4
2570,Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning,8,Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning,39,145,False,113,20,31,18,25,14,13,0,8,95,10425,2.1666666666666665,2.1666666666666665,1.1111111111111112,0.7222222222222222,1
2572,Strategic Representation,8,Strategic Representation,31,161,False,42,127,7,32,8,18,21,2,0,24,15776,0.96875,0.21875,3.96875,0.65625,5
2573,Structured Linear Contextual Bandits: A Sharp and Geometric Smoothed Analysis,8,Structured Linear Contextual Bandits A Sharp and Geometric Smoothed Analysis,38,1,False,77,121,0,40,0,10,8,2,0,76,20509,0.95,0.0,3.025,0.2,16
2574,Subspace Fitting Meets Regression: The Effects of Supervision and Orthonormality Constraints on Double Descent of Generalization Errors,8,Subspace Fitting Meets Regression The Effects of Supervision and Orthonormality Constraints on Double Descent of Generalization Errors,24,147,False,20,102,51,22,0,12,21,0,0,134,14358,1.0909090909090908,2.3181818181818183,4.636363636363637,0.9545454545454546,13
2575,Synthetic Data for Model Selection,8,Synthetic Data for Model Selection,57,0,False,54,10,0,24,0,5,4,3,0,34,9823,2.375,0.0,0.4166666666666667,0.16666666666666666,4
2577,Temporally Correlated Task Scheduling for Sequence Learning,8,Temporally Correlated Task Scheduling for Sequence Learning,53,191,False,177,14,47,18,0,11,23,0,18,59,11529,2.9444444444444446,3.611111111111111,0.7777777777777778,1.2777777777777777,8
2578,The Dynamics of Learning: A Random Matrix Approach,8,The Dynamics of Learning A Random Matrix Approach,32,110,False,40,75,14,14,0,9,9,0,0,49,8719,2.2857142857142856,1.0,5.357142857142857,0.6428571428571429,41
2579,The Kernel Interaction Trick: Fast Bayesian Discovery of Pairwise Interactions in High Dimensions,8,The Kernel Interaction Trick Fast Bayesian Discovery of Pairwise Interactions in High Dimensions,38,185,False,75,144,18,21,0,15,9,0,8,96,11058,1.8095238095238095,1.2380952380952381,6.857142857142857,0.42857142857142855,20
2580,The Usual Suspects? Reassessing Blame for VAE Posterior Collapse,8,The Usual Suspects Reassessing Blame for VAE Posterior Collapse,45,172,True,70,112,13,25,0,11,4,0,0,63,11010,1.8,0.52,4.48,0.16,61
2581,Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces,8,Think Global and Act Local Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces,68,96,False,178,126,71,26,26,10,22,2,4,106,20177,2.6153846153846154,2.8846153846153846,4.846153846153846,0.8461538461538461,41
2582,Time Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders,8,Time Series Deconfounder Estimating Treatment Effects over Time in the Presence of Hidden Confounders,65,170,False,288,156,36,24,0,30,20,0,32,101,14929,2.7083333333333335,2.8333333333333335,6.5,0.8333333333333334,81
2583,Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons,8,Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons,61,190,False,174,96,3,18,20,17,18,0,18,86,12970,3.388888888888889,1.1666666666666667,5.333333333333333,1.0,40
2584,Towards Understanding Knowledge Distillation,8,Towards Understanding Knowledge Distillation,29,186,False,34,185,15,16,0,10,6,0,0,44,10095,1.8125,0.9375,11.5625,0.375,238
2585,Training Graph Neural Networks with 1000 Layers,8,Training Graph Neural Networks with 1000 Layers,79,183,False,240,16,15,16,0,9,15,0,14,47,11411,4.9375,1.8125,1.0,0.9375,176
2586,Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time,8,Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time,55,157,False,58,234,19,17,0,9,8,0,0,92,10261,3.235294117647059,1.1176470588235294,13.764705882352942,0.47058823529411764,13
2587,Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies,8,Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies,72,132,False,181,214,67,39,40,20,12,2,8,96,19679,1.8461538461538463,1.9230769230769231,5.487179487179487,0.3076923076923077,54
2588,Understanding Robust Generalization in Learning Regular Languages,8,Understanding Robust Generalization in Learning Regular Languages,37,192,False,24,74,30,14,7,9,18,0,4,65,8077,2.642857142857143,2.4285714285714284,5.285714285714286,1.2857142857142858,4
2590,Unsupervised Detection of Contextualized Embedding Bias with Application to Ideology,8,Unsupervised Detection of Contextualized Embedding Bias with Application to Ideology,108,99,False,111,14,40,15,0,10,8,0,16,84,9880,7.2,3.7333333333333334,0.9333333333333333,0.5333333333333333,0
2591,Using Pre-Training Can Improve Model Robustness and Uncertainty,8,Using Pre-Training Can Improve Model Robustness and Uncertainty,56,78,False,130,0,17,12,0,8,5,1,12,63,7634,4.666666666666667,2.4166666666666665,0.0,0.4166666666666667,601
2592,Variational Autoencoders with Riemannian Brownian Motion Priors,8,Variational Autoencoders with Riemannian Brownian Motion Priors,43,138,False,69,42,40,14,2,10,13,0,16,63,7597,3.0714285714285716,4.0,3.0,0.9285714285714286,42
2593,Visual Attention Emerges from Recurrent Sparse Reconstruction,8,Visual Attention Emerges from Recurrent Sparse Reconstruction,91,163,False,114,34,39,19,0,8,13,0,10,61,9372,4.7894736842105265,2.5789473684210527,1.7894736842105263,0.6842105263157895,3
2594,What Dense Graph Do You Need for Self-Attention?,8,What Dense Graph Do You Need for Self-Attention,31,137,False,36,92,22,17,0,13,22,3,36,47,8760,1.8235294117647058,3.411764705882353,5.411764705882353,1.2941176470588236,3
2596,XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization,8,XTREME A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization,63,184,True,71,0,21,20,0,17,8,0,42,96,12271,3.15,3.15,0.0,0.4,816
2597,prDeep: Robust Phase Retrieval with a Flexible Deep Network,8,prDeep Robust Phase Retrieval with a Flexible Deep Network,58,136,False,60,22,42,10,5,5,11,0,4,58,6101,5.8,4.6,2.2,1.1,147
2598,A Context-Integrated Transformer-Based Neural Network for Auction Design,8,A Context-Integrated Transformer-Based Neural Network for Auction Design,60,139,False,105,148,3,21,11,11,11,0,0,72,10783,2.857142857142857,0.14285714285714285,7.0476190476190474,0.5238095238095238,14
2599,A Flexible Diffusion Model,8,A Flexible Diffusion Model,66,138,False,180,60,21,20,2,5,11,5,2,26,9320,3.3,1.15,3.0,0.55,6
2600,A Kernel-Based View of Language Model Fine-Tuning,8,A Kernel-Based View of Language Model Fine-Tuning,90,181,False,187,81,7,32,33,15,23,0,8,49,19279,2.8125,0.46875,2.53125,0.71875,31
2603,A Two-Stage Active Learning Algorithm for k-Nearest Neighbors,8,A Two-Stage Active Learning Algorithm for k-Nearest Neighbors,26,152,False,121,96,3,31,0,11,24,1,0,61,18671,0.8387096774193549,0.0967741935483871,3.096774193548387,0.7741935483870968,0
2604,ADMM and Accelerated ADMM as Continuous Dynamical Systems,8,ADMM and Accelerated ADMM as Continuous Dynamical Systems,26,79,True,67,144,3,22,0,6,7,5,0,57,7006,1.1818181818181819,0.13636363636363635,6.545454545454546,0.3181818181818182,77
2605,Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders,8,Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders,91,141,False,183,6,66,20,5,9,21,0,2,93,12969,4.55,3.4,0.3,1.05,43
2606,Active Feature Acquisition with Generative Surrogate Models,8,Active Feature Acquisition with Generative Surrogate Models,43,207,False,88,54,54,16,0,10,8,2,2,59,10466,2.6875,3.5,3.375,0.5,26
2607,Adafactor: Adaptive Learning Rates with Sublinear Memory Cost,8,Adafactor Adaptive Learning Rates with Sublinear Memory Cost,13,173,False,39,22,3,9,0,11,10,0,6,60,6269,1.4444444444444444,1.0,2.4444444444444446,1.1111111111111112,779
2608,Adaptive Reward-Poisoning Attacks against Reinforcement Learning,8,Adaptive Reward-Poisoning Attacks against Reinforcement Learning,33,170,False,27,98,30,18,8,15,9,0,2,64,11157,1.8333333333333333,1.7777777777777777,5.444444444444445,0.5,105
2609,Adversarial Attacks on Node Embeddings via Graph Poisoning,8,Adversarial Attacks on Node Embeddings via Graph Poisoning,51,28,False,12,0,3,12,0,4,12,4,2,58,9459,4.25,0.4166666666666667,0.0,1.0,256
2610,Adversarial Robustness against Multiple and Single lp-Threat Models via Quick Fine-Tuning of Robust Classifiers,8,Adversarial Robustness against Multiple and Single lp-Threat Models via Quick Fine-Tuning of Robust Classifiers,67,153,False,268,12,19,19,0,11,18,0,32,111,13957,3.526315789473684,2.6842105263157894,0.631578947368421,0.9473684210526315,11
2611,Algorithms for bounding contribution for histogram estimation under user-level privacy,8,Algorithms for bounding contribution for histogram estimation under user-level privacy,50,231,False,104,168,25,32,6,13,14,0,4,86,14075,1.5625,0.90625,5.25,0.4375,0
2612,An Alternative View: When Does SGD Escape Local Minima?,8,An Alternative View When Does SGD Escape Local Minima,32,205,True,31,40,19,17,0,10,5,0,0,53,7245,1.8823529411764706,1.1176470588235294,2.3529411764705883,0.29411764705882354,272
2613,An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm,8,An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm,35,179,False,48,132,9,33,23,21,21,0,8,91,16349,1.0606060606060606,0.5151515151515151,4.0,0.6363636363636364,8
2614,Anderson Acceleration of Proximal Gradient Methods,8,Anderson Acceleration of Proximal Gradient Methods,61,110,False,78,159,38,25,0,10,8,0,0,50,9790,2.44,1.52,6.36,0.32,33
2615,Approximation and Non-parametric Estimation of ResNet-type Convolutional Neural Networks,8,Approximation and Non-parametric Estimation of ResNet-type Convolutional Neural Networks,49,163,False,71,172,12,29,0,18,15,5,2,88,18313,1.6896551724137931,0.4827586206896552,5.931034482758621,0.5172413793103449,49
2616,Attentive Group Equivariant Convolutional Networks,8,Attentive Group Equivariant Convolutional Networks,73,117,False,113,67,57,17,0,11,18,10,6,50,11437,4.294117647058823,3.7058823529411766,3.9411764705882355,1.0588235294117647,76
2618,Batch Policy Learning under Constraints,8,Batch Policy Learning under Constraints,70,155,False,139,204,19,30,0,16,36,0,0,39,19663,2.3333333333333335,0.6333333333333333,6.8,1.2,254
2619,"Bayesian Model Selection, the Marginal Likelihood, and Generalization",8,Bayesian Model Selection the Marginal Likelihood and Generalization,102,194,False,256,78,128,59,11,21,18,0,6,69,27220,1.728813559322034,2.2711864406779663,1.3220338983050848,0.3050847457627119,45
2620,"Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement",8,Benchmarks Algorithms and Metrics for Hierarchical Disentanglement,57,86,False,142,20,99,23,0,11,13,0,2,68,12453,2.4782608695652173,4.391304347826087,0.8695652173913043,0.5652173913043478,9
2621,Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning,8,Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning,37,172,True,34,64,75,19,0,11,15,0,2,73,9929,1.9473684210526316,4.052631578947368,3.3684210526315788,0.7894736842105263,41
2622,Black-box Methods for Restoring Monotonicity,8,Black-box Methods for Restoring Monotonicity,26,135,False,15,23,2,15,8,8,11,0,2,44,9340,1.7333333333333334,0.26666666666666666,1.5333333333333334,0.7333333333333333,2
2623,Bounds on the Approximation Power of Feedforward Neural Networks,8,Bounds on the Approximation Power of Feedforward Neural Networks,14,73,False,62,156,5,9,0,8,15,4,4,64,6148,1.5555555555555556,1.0,17.333333333333332,1.6666666666666667,12
2624,Building Robust Ensembles via Margin Boosting,8,Building Robust Ensembles via Margin Boosting,75,154,False,412,248,16,24,10,24,42,4,24,45,14712,3.125,1.6666666666666667,10.333333333333334,1.75,12
2626,Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health,8,Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health,50,105,False,74,154,0,31,0,6,12,2,28,70,13190,1.6129032258064515,0.9032258064516129,4.967741935483871,0.3870967741935484,15
2627,ChaCha for Online AutoML,8,ChaCha for Online AutoML,34,82,False,25,30,25,16,0,10,9,0,4,24,9714,2.125,1.8125,1.875,0.5625,5
2628,Classifying high-dimensional Gaussian mixtures: Where kernel methods fail and neural networks succeed,8,Classifying high-dimensional Gaussian mixtures Where kernel methods fail and neural networks succeed,68,215,False,32,198,30,26,20,10,14,0,0,100,16050,2.6153846153846154,1.1538461538461537,7.615384615384615,0.5384615384615384,58
2629,Cognitive Model Priors for Predicting Human Decisions,8,Cognitive Model Priors for Predicting Human Decisions,28,230,False,60,2,9,10,0,7,9,0,4,53,6784,2.8,1.3,0.2,0.9,59
2630,Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks,8,Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks,63,217,True,73,380,46,30,4,15,1,0,2,89,16679,2.1,1.6,12.666666666666666,0.03333333333333333,39
2631,Compositional Score Modeling for Simulation-Based Inference,8,Compositional Score Modeling for Simulation-Based Inference,70,140,False,120,56,29,19,13,12,19,0,0,59,11015,3.6842105263157894,1.5263157894736843,2.9473684210526314,1.0,7
2632,Confidence Score for Source-Free Unsupervised Domain Adaptation,8,Confidence Score for Source-Free Unsupervised Domain Adaptation,43,1,False,63,46,32,13,9,14,7,0,0,63,8604,3.3076923076923075,2.4615384615384617,3.5384615384615383,0.5384615384615384,43
2633,Constant Matters: Fine-grained Error Bound on Differentially Private Continual Observation,8,Constant Matters Fine-grained Error Bound on Differentially Private Continual Observation,82,178,False,233,102,22,27,3,14,13,0,4,89,16122,3.037037037037037,0.9629629629629629,3.7777777777777777,0.48148148148148145,7
2634,Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing,8,Contextual Graph Markov Model A Deep and Generative Approach to Graph Processing,30,81,False,43,18,18,10,0,6,6,0,8,80,6885,3.0,2.6,1.8,0.6,67
2635,Contrastive Multi-View Representation Learning on Graphs,8,Contrastive Multi-View Representation Learning on Graphs,73,105,False,144,12,6,13,0,6,16,4,14,56,9245,5.615384615384615,1.5384615384615385,0.9230769230769231,1.2307692307692308,920
2636,Convolutional Poisson Gamma Belief Network,8,Convolutional Poisson Gamma Belief Network,59,165,False,310,152,30,13,0,20,18,0,16,42,8769,4.538461538461538,3.5384615384615383,11.692307692307692,1.3846153846153846,11
2637,Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes,8,Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes,52,193,False,200,64,0,32,0,14,17,0,0,118,18389,1.625,0.0,2.0,0.53125,16
2638,Curvature-Exploiting Acceleration of Elastic Net Computations,8,Curvature-Exploiting Acceleration of Elastic Net Computations,37,108,False,50,262,6,34,0,15,6,3,4,61,12342,1.088235294117647,0.29411764705882354,7.705882352941177,0.17647058823529413,0
2639,DNS: Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning,8,DNS Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning,47,124,True,84,28,38,16,4,7,9,0,4,96,8618,2.9375,2.625,1.75,0.5625,6
2640,Data-Dependent Differentially Private Parameter Learning for Directed Graphical Models,8,Data-Dependent Differentially Private Parameter Learning for Directed Graphical Models,56,132,False,84,148,22,20,0,10,13,17,2,86,14703,2.8,1.2,7.4,0.65,10
2641,Decentralized Stochastic Bilevel Optimization with Improved Per-Iteration Complexity,8,Decentralized Stochastic Bilevel Optimization with Improved Per-Iteration Complexity,56,155,False,192,299,20,31,0,8,13,2,2,84,18366,1.8064516129032258,0.7096774193548387,9.64516129032258,0.41935483870967744,15
2642,Deep Gaussian Markov random fields,8,Deep Gaussian Markov random fields,64,140,False,134,70,19,15,0,13,15,2,4,34,9493,4.266666666666667,1.5333333333333334,4.666666666666667,1.0,20
2643,Deep equilibrium networks are sensitive to initialization statistics,8,Deep equilibrium networks are sensitive to initialization statistics,34,90,False,112,768,40,25,0,18,34,18,4,68,13489,1.36,1.76,30.72,1.36,2
2644,Deletion Robust Submodular Maximization over Matroids,8,Deletion Robust Submodular Maximization over Matroids,44,138,False,116,89,50,28,10,11,4,0,0,53,13759,1.5714285714285714,1.7857142857142858,3.1785714285714284,0.14285714285714285,8
2646,Differentially Private Approximate Quantiles,8,Differentially Private Approximate Quantiles,19,103,False,80,31,20,16,4,5,9,1,0,44,7386,1.1875,1.25,1.9375,0.5625,14
2647,Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient Reinforcement Learning,8,Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient Reinforcement Learning,35,146,False,54,19,61,13,0,10,7,0,8,94,8376,2.6923076923076925,5.3076923076923075,1.4615384615384615,0.5384615384615384,14
2648,Discrete Probabilistic Inverse Optimal Transport,8,Discrete Probabilistic Inverse Optimal Transport,25,105,False,207,120,387,22,0,14,24,0,8,48,13354,1.1363636363636365,17.954545454545453,5.454545454545454,1.0909090909090908,7
2649,Distributed Learning with Sublinear Communication,8,Distributed Learning with Sublinear Communication,52,184,False,91,183,6,33,5,7,16,0,0,49,14472,1.5757575757575757,0.18181818181818182,5.545454545454546,0.48484848484848486,37
2650,Do ImageNet Classifiers Generalize to ImageNet?,8,Do ImageNet Classifiers Generalize to ImageNet,63,1,False,157,23,236,76,33,12,15,26,50,46,30086,0.8289473684210527,3.763157894736842,0.3026315789473684,0.19736842105263158,1258
2651,Double Trouble in Double Descent : Bias and Variance(s) in the Lazy Regime,8,Double Trouble in Double Descent  Bias and Variances in the Lazy Regime,60,235,False,69,212,37,30,16,9,12,16,0,73,14711,2.0,1.2333333333333334,7.066666666666666,0.4,129
2653,Efficient List-Decodable Regression using Batches,8,Efficient List-Decodable Regression using Batches,84,136,False,77,410,0,45,8,17,12,0,0,49,24054,1.8666666666666667,0.0,9.11111111111111,0.26666666666666666,3
2654,Efficient Test-Time Model Adaptation without Forgetting,8,Efficient Test-Time Model Adaptation without Forgetting,59,216,False,73,18,29,17,0,11,8,0,24,55,11508,3.4705882352941178,3.1176470588235294,1.0588235294117647,0.47058823529411764,148
2656,Equivariance with Learned Canonicalization Functions,8,Equivariance with Learned Canonicalization Functions,79,136,False,128,74,32,21,23,16,14,0,14,52,12624,3.761904761904762,2.1904761904761907,3.5238095238095237,0.6666666666666666,21
2657,Estimating Generalization under Distribution Shifts via Domain-Invariant Representations,8,Estimating Generalization under Distribution Shifts via Domain-Invariant Representations,37,132,False,102,86,41,15,11,14,22,0,4,88,11346,2.466666666666667,3.0,5.733333333333333,1.4666666666666666,50
2658,Evolving Curricula with Regret-Based Environment Design,8,Evolving Curricula with Regret-Based Environment Design,101,181,False,268,8,169,26,0,10,16,0,22,55,15527,3.8846153846153846,7.346153846153846,0.3076923076923077,0.6153846153846154,78
2659,Exploiting Structure of Uncertainty for Efficient Combinatorial Semi-Bandits,8,Exploiting Structure of Uncertainty for Efficient Combinatorial Semi-Bandits,44,112,False,134,69,7,16,5,11,7,0,4,76,9967,2.75,0.6875,4.3125,0.4375,1
2660,FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting,8,FEDformer Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting,57,0,False,18,29,20,19,10,5,10,0,0,84,13893,3.0,1.0526315789473684,1.5263157894736843,0.5263157894736842,527
2661,Fairness risk measures,8,Fairness risk measures,92,1,False,256,108,30,23,0,11,24,8,2,22,8772,4.0,1.391304347826087,4.695652173913044,1.0434782608695652,114
2662,Fast Population-Based Reinforcement Learning on a Single Machine,8,Fast Population-Based Reinforcement Learning on a Single Machine,33,150,False,51,0,24,15,1,9,7,0,6,64,9857,2.2,2.0,0.0,0.4666666666666667,6
2663,Faster Privacy Accounting via Evolving Discretization,8,Faster Privacy Accounting via Evolving Discretization,34,110,False,70,107,14,14,21,10,5,0,0,53,8222,2.4285714285714284,1.0,7.642857142857143,0.35714285714285715,12
2665,Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation,8,Fighting Fire with Fire Contrastive Debiasing without Bias-free Data via Generative Bias-transformation,60,191,False,168,4,25,16,11,12,8,0,14,103,8942,3.75,2.4375,0.25,0.5,1
2666,Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification,8,Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification,37,129,False,132,22,43,17,1,11,8,0,6,82,8999,2.176470588235294,2.8823529411764706,1.2941176470588236,0.47058823529411764,55
2667,Formalizing Preferences Over Runtime Distributions,8,Formalizing Preferences Over Runtime Distributions,55,175,False,56,148,11,24,10,11,10,0,0,50,15489,2.2916666666666665,0.4583333333333333,6.166666666666667,0.4166666666666667,4
2668,From data to functa: Your data point is a function and you can treat it like one,8,From data to functa Your data point is a function and you can treat it like one,90,203,False,139,24,118,32,0,12,19,0,12,79,15452,2.8125,4.0625,0.75,0.59375,74
2669,G-Mixup: Graph Data Augmentation for Graph Classification,8,G-Mixup Graph Data Augmentation for Graph Classification,74,162,False,165,65,30,18,0,15,26,2,18,56,11435,4.111111111111111,2.6666666666666665,3.611111111111111,1.4444444444444444,120
2670,GREAD: Graph Neural Reaction-Diffusion Networks,8,GREAD Graph Neural Reaction-Diffusion Networks,74,162,True,86,46,80,26,22,16,18,0,48,46,12053,2.8461538461538463,4.923076923076923,1.7692307692307692,0.6923076923076923,12
2672,Generalizing to Evolving Domains with Latent Structure-Aware Sequential Autoencoder,8,Generalizing to Evolving Domains with Latent Structure-Aware Sequential Autoencoder,49,159,False,53,82,18,21,0,11,12,0,42,83,13290,2.3333333333333335,2.857142857142857,3.9047619047619047,0.5714285714285714,10
2673,"Generic Coreset for Scalable Learning of Monotonic Kernels: Logistic Regression, Sigmoid and more",8,Generic Coreset for Scalable Learning of Monotonic Kernels Logistic Regression Sigmoid and more,51,148,False,92,476,26,27,2,24,20,0,0,95,15409,1.8888888888888888,0.9629629629629629,17.62962962962963,0.7407407407407407,11
2674,Globally-Robust Neural Networks,8,Globally-Robust Neural Networks,53,1,False,98,18,16,19,19,14,12,0,6,31,13659,2.789473684210526,1.1578947368421053,0.9473684210526315,0.631578947368421,99
2675,Graph Cuts Always Find a Global Optimum for Potts Models (With a Catch),8,Graph Cuts Always Find a Global Optimum for Potts Models With a Catch,31,193,False,112,116,19,18,1,11,9,1,2,71,11315,1.7222222222222223,1.1666666666666667,6.444444444444445,0.5,1
2676,Graphical-model based estimation and inference for differential privacy,8,Graphical-model based estimation and inference for differential privacy,45,89,False,80,19,23,14,0,13,22,0,4,71,10823,3.2142857142857144,1.9285714285714286,1.3571428571428572,1.5714285714285714,109
2677,Handling the Positive-Definite Constraint in the Bayesian Learning Rule,8,Handling the Positive-Definite Constraint in the Bayesian Learning Rule,41,1,False,183,350,51,45,1,22,29,0,4,71,22364,0.9111111111111111,1.2222222222222223,7.777777777777778,0.6444444444444445,25
2678,Hierarchies of Reward Machines,8,Hierarchies of Reward Machines,77,148,False,193,76,51,48,7,13,13,10,16,30,35020,1.6041666666666667,1.3958333333333333,1.5833333333333333,0.2708333333333333,5
2679,How Many Perturbations Break This Model? Evaluating Robustness Beyond Adversarial Accuracy,8,How Many Perturbations Break This Model Evaluating Robustness Beyond Adversarial Accuracy,48,167,False,111,74,22,16,3,12,22,3,8,89,9597,3.0,1.875,4.625,1.375,2
2680,"HyperGAN: A Generative Model for Diverse, Performant Neural Networks",8,HyperGAN A Generative Model for Diverse Performant Neural Networks,26,143,False,87,18,37,11,0,8,14,0,14,67,7586,2.3636363636363638,4.636363636363637,1.6363636363636365,1.2727272727272727,49
2681,Image-Level or Object-Level? A Tale of Two Resampling Strategies for Long-Tailed Detection,8,Image-Level or Object-Level A Tale of Two Resampling Strategies for Long-Tailed Detection,35,150,False,49,0,23,10,0,6,5,0,10,89,7311,3.5,3.3,0.0,0.5,23
2682,Implicit rate-constrained optimization of non-decomposable objectives,8,Implicit rate-constrained optimization of non-decomposable objectives,48,134,False,73,47,26,17,0,10,14,0,10,69,11172,2.823529411764706,2.1176470588235294,2.764705882352941,0.8235294117647058,10
2683,Improved Sleeping Bandits with Stochastic Actions Sets and Adversarial Rewards,8,Improved Sleeping Bandits with Stochastic Actions Sets and Adversarial Rewards,15,294,False,27,138,19,19,0,10,17,0,0,78,10580,0.7894736842105263,1.0,7.2631578947368425,0.8947368421052632,16
2684,Improving Neural Network Quantization without Retraining using Outlier Channel Splitting,8,Improving Neural Network Quantization without Retraining using Outlier Channel Splitting,35,142,False,83,18,8,10,0,6,17,0,10,88,6924,3.5,1.8,1.8,1.7,272
2686,Infinite attention: NNGP and NTK for deep attention networks,8,Infinite attention NNGP and NTK for deep attention networks,48,186,True,188,240,14,36,0,11,15,13,16,59,23615,1.3333333333333333,0.8333333333333334,6.666666666666667,0.4166666666666667,99
2687,Instance-Optimal Compressed Sensing via Posterior Sampling,8,Instance-Optimal Compressed Sensing via Posterior Sampling,82,120,False,72,257,19,32,14,10,20,0,0,58,16295,2.5625,0.59375,8.03125,0.625,40
2688,Interpretations are useful: penalizing explanations to align neural networks with prior knowledge,8,Interpretations are useful penalizing explanations to align neural networks with prior knowledge,57,127,False,102,12,39,18,6,11,10,0,10,96,8839,3.1666666666666665,2.7222222222222223,0.6666666666666666,0.5555555555555556,192
2689,Invertible Residual Networks,8,Invertible Residual Networks,55,112,False,165,96,48,18,9,14,13,0,12,28,9597,3.0555555555555554,3.3333333333333335,5.333333333333333,0.7222222222222222,534
2690,Jump-Start Reinforcement Learning,8,Jump-Start Reinforcement Learning,57,1,False,89,17,63,28,4,9,13,8,22,33,12785,2.0357142857142856,3.0357142857142856,0.6071428571428571,0.4642857142857143,52
2692,"Label Distributionally Robust Losses for Multi-class Classification: Consistency, Robustness and Adaptivity",8,Label Distributionally Robust Losses for Multi-class Classification Consistency Robustness and Adaptivity,50,222,False,91,81,106,37,1,18,19,0,34,106,22194,1.3513513513513513,3.7837837837837838,2.189189189189189,0.5135135135135135,3
2693,Latent Normalizing Flows for Discrete Sequences,8,Latent Normalizing Flows for Discrete Sequences,40,151,False,82,76,25,13,11,19,6,0,6,47,8779,3.076923076923077,2.3846153846153846,5.846153846153846,0.46153846153846156,111
2694,Learning Algebraic Multigrid Using Graph Neural Networks,8,Learning Algebraic Multigrid Using Graph Neural Networks,50,1,False,69,20,20,11,10,7,5,0,10,56,8591,4.545454545454546,2.727272727272727,1.8181818181818181,0.45454545454545453,54
2695,Learning Discrete and Continuous Factors of Data via Alternating Disentanglement,8,Learning Discrete and Continuous Factors of Data via Alternating Disentanglement,25,145,False,51,41,34,11,0,13,11,0,12,80,6541,2.272727272727273,4.181818181818182,3.727272727272727,1.0,39
2696,Learning Instance-Specific Augmentations by Capturing Local Invariances,8,Learning Instance-Specific Augmentations by Capturing Local Invariances,56,1,False,120,32,132,17,9,17,29,4,16,71,11802,3.2941176470588234,8.705882352941176,1.8823529411764706,1.7058823529411764,4
2697,Learning Neurosymbolic Generative Models via Program Synthesis,8,Learning Neurosymbolic Generative Models via Program Synthesis,33,123,False,41,38,118,13,23,7,6,0,4,62,6916,2.5384615384615383,9.384615384615385,2.923076923076923,0.46153846153846156,30
2698,Learning Stochastic Behaviour from Aggregate Data,8,Learning Stochastic Behaviour from Aggregate Data,48,145,False,47,79,59,15,0,9,11,0,6,49,8662,3.2,4.333333333333333,5.266666666666667,0.7333333333333333,13
2700,Learning to Explain: An Information-Theoretic Perspective on Model Interpretation,8,Learning to Explain An Information-Theoretic Perspective on Model Interpretation,36,101,False,52,56,34,10,6,7,9,2,8,80,7857,3.6,4.2,5.6,0.9,479
2701,Learning to Score Behaviors for Guided Policy Optimization,8,Learning to Score Behaviors for Guided Policy Optimization,39,136,False,98,97,63,24,12,12,19,3,2,58,11953,1.625,2.7083333333333335,4.041666666666667,0.7916666666666666,35
2702,Let's be honest: An optimal no-regret framework for zero-sum games,8,Lets be honest An optimal no-regret framework for zero-sum games,11,168,False,60,74,8,14,0,9,7,0,2,64,7206,0.7857142857142857,0.7142857142857143,5.285714285714286,0.5,18
2703,Linear Adversarial Concept Erasure,8,Linear Adversarial Concept Erasure,68,150,False,113,48,37,21,17,10,23,1,4,34,11561,3.238095238095238,1.9523809523809523,2.2857142857142856,1.0952380952380953,44
2706,MC-LSTM: Mass-Conserving LSTM,8,MC-LSTM Mass-Conserving LSTM,104,205,True,271,42,31,30,31,11,11,14,42,28,20135,3.466666666666667,2.433333333333333,1.4,0.36666666666666664,43
2708,Measure Estimation in the Barycentric Coding Model,8,Measure Estimation in the Barycentric Coding Model,55,222,False,101,68,19,23,0,13,24,0,8,50,13414,2.391304347826087,1.173913043478261,2.9565217391304346,1.0434782608695652,9
2709,Meta-Learning Bidirectional Update Rules,8,Meta-Learning Bidirectional Update Rules,69,134,False,61,40,79,17,8,8,17,0,2,40,10719,4.0588235294117645,4.764705882352941,2.3529411764705883,1.0,12
2710,Minimax Classification under Concept Drift with Multidimensional Adaptation and Performance Guarantees,8,Minimax Classification under Concept Drift with Multidimensional Adaptation and Performance Guarantees,37,126,False,59,76,22,14,1,11,4,0,8,102,9838,2.642857142857143,2.142857142857143,5.428571428571429,0.2857142857142857,3
2713,Momentum Residual Neural Networks,8,Momentum Residual Neural Networks,63,187,False,167,80,38,24,27,13,23,4,6,33,14443,2.625,1.8333333333333333,3.3333333333333335,0.9583333333333334,44
2714,Multi-Agent Determinantal Q-Learning,8,Multi-Agent Determinantal Q-Learning,41,168,False,91,75,32,17,0,9,12,0,4,36,12129,2.411764705882353,2.1176470588235294,4.411764705882353,0.7058823529411765,61
2715,Multi-objective Bayesian Optimization using Pareto-frontier Entropy,8,Multi-objective Bayesian Optimization using Pareto-frontier Entropy,39,185,False,108,73,12,28,0,13,4,2,10,67,11045,1.3928571428571428,0.7857142857142857,2.607142857142857,0.14285714285714285,50
2716,NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks,8,NATTACK Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks,65,177,True,201,20,6,13,1,8,6,4,4,115,8957,5.0,0.7692307692307693,1.5384615384615385,0.46153846153846156,220
2717,Near-optimal Regret Bounds for Stochastic Shortest Path,8,Near-optimal Regret Bounds for Stochastic Shortest Path,23,212,False,50,191,0,34,7,8,8,11,0,55,18268,0.6764705882352942,0.0,5.617647058823529,0.23529411764705882,51
2718,Neural Dynamic Programming for Musical Self Similarity,8,Neural Dynamic Programming for Musical Self Similarity,33,96,False,32,20,0,9,11,7,14,1,0,54,6107,3.6666666666666665,0.0,2.2222222222222223,1.5555555555555556,8
2719,Neural Tangent Kernel Analysis of Deep Narrow Neural Networks,8,Neural Tangent Kernel Analysis of Deep Narrow Neural Networks,0,88,False,69,553,15,70,5,21,19,0,2,61,32419,0.0,0.24285714285714285,7.9,0.2714285714285714,6
2721,Nonlinear Distributional Gradient Temporal-Difference Learning,8,Nonlinear Distributional Gradient Temporal-Difference Learning,32,164,False,104,114,13,22,0,12,6,0,0,62,9176,1.4545454545454546,0.5909090909090909,5.181818181818182,0.2727272727272727,11
2722,OCD: Learning to Overfit with Conditional Diffusion Models,8,OCD Learning to Overfit with Conditional Diffusion Models,64,130,True,164,26,29,13,0,10,4,0,12,57,8207,4.923076923076923,3.1538461538461537,2.0,0.3076923076923077,4
2723,Offline Reinforcement Learning with Closed-Form Policy Improvement Operators,8,Offline Reinforcement Learning with Closed-Form Policy Improvement Operators,82,155,False,228,236,63,44,0,16,26,0,36,76,19126,1.8636363636363635,2.25,5.363636363636363,0.5909090909090909,3
2724,On Efficient Low Distortion Ultrametric Embedding,8,On Efficient Low Distortion Ultrametric Embedding,40,282,False,34,14,3,20,4,7,4,0,2,49,8194,2.0,0.25,0.7,0.2,8
2725,On Lower Bounds for Standard and Robust Gaussian Process Bandit Optimization,8,On Lower Bounds for Standard and Robust Gaussian Process Bandit Optimization,53,0,False,160,92,9,20,0,10,21,0,2,76,14445,2.65,0.55,4.6,1.05,25
2726,On a Combination of Alternating Minimization and Nesterov's Momentum,8,On a Combination of Alternating Minimization and Nesterovs Momentum,64,146,False,108,341,40,42,1,14,8,0,6,67,17319,1.5238095238095237,1.0952380952380953,8.119047619047619,0.19047619047619047,38
2727,On the Generalization Gap in Reparameterizable Reinforcement Learning,8,On the Generalization Gap in Reparameterizable Reinforcement Learning,61,149,False,86,84,0,14,1,17,3,0,4,69,9260,4.357142857142857,0.2857142857142857,6.0,0.21428571428571427,36
2728,On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,8,On the Optimization of Deep Networks Implicit Acceleration by Overparameterization,45,116,False,68,29,19,18,0,14,7,0,0,82,14781,2.5,1.0555555555555556,1.6111111111111112,0.3888888888888889,431
2729,On the Unreasonable Effectiveness of the Greedy Algorithm: Greedy Adapts to Sharpness,8,On the Unreasonable Effectiveness of the Greedy Algorithm Greedy Adapts to Sharpness,45,165,False,110,115,6,23,9,5,9,2,0,84,11866,1.9565217391304348,0.2608695652173913,5.0,0.391304347826087,8
2730,Online Control with Adversarial Disturbances,8,Online Control with Adversarial Disturbances,33,97,False,29,163,0,15,8,14,22,2,0,44,6647,2.2,0.0,10.866666666666667,1.4666666666666666,204
2731,Online mirror descent and dual averaging: keeping pace in the dynamic case,8,Online mirror descent and dual averaging keeping pace in the dynamic case,36,224,False,208,229,3,37,0,13,10,3,0,73,15484,0.972972972972973,0.08108108108108109,6.1891891891891895,0.2702702702702703,26
2732,Optimal Counterfactual Explanations in Tree Ensembles,8,Optimal Counterfactual Explanations in Tree Ensembles,32,152,False,120,42,21,17,0,10,12,0,12,53,11344,1.8823529411764706,1.9411764705882353,2.4705882352941178,0.7058823529411765,43
2733,Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer,8,Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer,47,198,False,180,64,47,20,8,10,17,0,0,87,13691,2.35,2.35,3.2,0.85,15
2734,Order Constraints in Optimal Transport,8,Order Constraints in Optimal Transport,59,113,False,106,87,18,21,20,9,5,0,2,38,16172,2.8095238095238093,0.9523809523809523,4.142857142857143,0.23809523809523808,3
2735,PAC Generalization via Invariant Representations,8,PAC Generalization via Invariant Representations,37,211,True,43,38,8,26,0,12,13,3,0,48,12068,1.4230769230769231,0.3076923076923077,1.4615384615384615,0.5,3
2736,PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos,8,PIPPS Flexible Model-Based Policy Search Robust to the Curse of Chaos,28,193,True,37,8,20,10,0,7,11,5,4,69,7282,2.8,2.4,0.8,1.1,75
2737,Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models,8,Pareto Manifold Learning Tackling multiple tasks via ensembles of single-task models,57,0,False,0,0,0,38,1,6,1,1,0,84,19065,1.5,0.0,0.0,0.02631578947368421,6
2738,Perceiver: General Perception with Iterative Attention,8,Perceiver General Perception with Iterative Attention,117,184,False,99,0,94,43,0,12,5,0,14,53,14155,2.7209302325581395,2.511627906976744,0.0,0.11627906976744186,675
2739,Piecewise Linear Regression via a Difference of Convex Functions,8,Piecewise Linear Regression via a Difference of Convex Functions,30,136,False,47,119,12,20,8,13,9,2,4,64,11717,1.5,0.8,5.95,0.45,10
2740,Policy Gradient in Robust MDPs with Global Convergence Guarantee,8,Policy Gradient in Robust MDPs with Global Convergence Guarantee,79,129,False,122,322,9,35,0,13,10,0,0,64,17450,2.257142857142857,0.2571428571428571,9.2,0.2857142857142857,9
2741,PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,8,PredRNN Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning,41,116,False,68,20,34,10,6,7,5,0,6,94,6841,4.1,4.0,2.0,0.5,365
2742,Principled Knowledge Extrapolation with GANs,8,Principled Knowledge Extrapolation with GANs,42,187,False,54,98,42,18,18,8,6,0,2,44,8653,2.3333333333333335,2.4444444444444446,5.444444444444445,0.3333333333333333,5
2743,Privately detecting changes in unknown distributions,8,Privately detecting changes in unknown distributions,40,172,False,54,93,25,24,0,6,10,0,0,52,12722,1.6666666666666667,1.0416666666666667,3.875,0.4166666666666667,11
2744,Progressive Identification of True Labels for Partial-Label Learning,8,Progressive Identification of True Labels for Partial-Label Learning,72,155,False,216,158,120,20,0,28,22,0,24,68,11017,3.6,7.2,7.9,1.1,136
2745,Provable Representation Learning for Imitation Learning via Bi-level Optimization,8,Provable Representation Learning for Imitation Learning via Bi-level Optimization,43,114,False,111,119,12,26,19,12,8,0,2,81,12249,1.6538461538461537,0.5384615384615384,4.576923076923077,0.3076923076923077,49
2746,Proving Theorems using Incremental Learning and Hindsight Experience Replay,8,Proving Theorems using Incremental Learning and Hindsight Experience Replay,45,159,False,135,6,7,16,6,13,4,0,2,75,7955,2.8125,0.5625,0.375,0.25,8
2747,Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding,8,Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding,47,135,False,142,94,18,21,1,10,14,2,10,90,13013,2.238095238095238,1.3333333333333333,4.476190476190476,0.6666666666666666,43
2748,REALM: Retrieval-Augmented Language Model Pre-Training,8,REALM Retrieval-Augmented Language Model Pre-Training,43,0,True,74,25,11,12,25,10,9,0,8,53,8092,3.5833333333333335,1.5833333333333333,2.0833333333333335,0.75,1353
2749,Random Shuffling Beats SGD after Finite Epochs,8,Random Shuffling Beats SGD after Finite Epochs,43,186,True,83,304,0,36,6,16,9,0,2,46,16960,1.1944444444444444,0.05555555555555555,8.444444444444445,0.25,86
2750,Reachability-Aware Laplacian Representation in Reinforcement Learning,8,Reachability-Aware Laplacian Representation in Reinforcement Learning,42,147,False,89,46,55,25,2,14,19,0,4,69,8485,1.68,2.36,1.84,0.76,1
2751,Refined bounds for algorithm configuration: The knife-edge of dual class approximability,8,Refined bounds for algorithm configuration The knife-edge of dual class approximability,51,1,False,78,69,21,29,10,7,9,1,0,87,14567,1.7586206896551724,0.7241379310344828,2.3793103448275863,0.3103448275862069,13
2752,Reinforcement Learning with Action-Free Pre-Training from Videos,8,Reinforcement Learning with Action-Free Pre-Training from Videos,119,152,False,158,41,49,19,25,15,8,0,0,64,12244,6.2631578947368425,2.5789473684210527,2.1578947368421053,0.42105263157894735,74
2753,Representational aspects of depth and conditioning in normalizing flows,8,Representational aspects of depth and conditioning in normalizing flows,34,1,False,142,108,68,33,12,19,16,6,0,71,14118,1.0303030303030303,2.0606060606060606,3.272727272727273,0.48484848484848486,18
2754,RetrievalGuard: Provably Robust 1-Nearest Neighbor Image Retrieval,8,RetrievalGuard Provably Robust 1-Nearest Neighbor Image Retrieval,47,163,False,50,48,19,14,0,9,7,2,0,65,8434,3.357142857142857,1.3571428571428572,3.4285714285714284,0.5,10
2755,Reviving and Improving Recurrent Back-Propagation,8,Reviving and Improving Recurrent Back-Propagation,37,152,False,50,68,112,14,2,10,12,0,10,49,8700,2.642857142857143,8.714285714285714,4.857142857142857,0.8571428571428571,105
2756,Robust Group Synchronization via Quadratic Programming,8,Robust Group Synchronization via Quadratic Programming,30,129,False,64,50,21,11,0,4,14,0,2,54,7950,2.727272727272727,2.090909090909091,4.545454545454546,1.2727272727272727,6
2757,Robust Training of Neural Networks using Scale Invariant Architectures,8,Robust Training of Neural Networks using Scale Invariant Architectures,43,200,False,67,225,21,36,12,12,10,0,4,70,15533,1.1944444444444444,0.6944444444444444,6.25,0.2777777777777778,19
2758,SAUTE RL: Almost Surely Safe Reinforcement Learning Using State Augmentation,8,SAUTE RL Almost Surely Safe Reinforcement Learning Using State Augmentation,60,147,True,92,119,71,21,10,11,13,0,12,75,13229,2.857142857142857,3.9523809523809526,5.666666666666667,0.6190476190476191,30
2759,SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization,8,SQ-VAE Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization,48,131,True,136,72,61,26,23,13,15,10,20,94,12925,1.8461538461538463,3.1153846153846154,2.769230769230769,0.5769230769230769,27
2761,Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes,8,Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes,32,213,True,105,72,13,17,3,11,18,0,6,69,11115,1.8823529411764706,1.1176470588235294,4.235294117647059,1.0588235294117647,1
2762,Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic Constraints via Message Passing,8,Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic Constraints via Message Passing,50,146,False,87,38,16,14,4,10,12,0,0,101,10271,3.5714285714285716,1.1428571428571428,2.7142857142857144,0.8571428571428571,12
2763,Self-Attentive Associative Memory,8,Self-Attentive Associative Memory,44,132,False,77,79,18,19,14,6,19,1,20,33,11601,2.3157894736842106,2.0,4.157894736842105,1.0,47
2764,Semi-Cyclic Stochastic Gradient Descent,8,Semi-Cyclic Stochastic Gradient Descent,29,82,False,124,180,20,12,2,22,6,0,0,39,8765,2.4166666666666665,1.6666666666666667,15.0,0.5,91
2765,Settling the Reward Hypothesis,8,Settling the Reward Hypothesis,53,67,False,117,104,7,18,0,18,7,0,0,30,12311,2.9444444444444446,0.3888888888888889,5.777777777777778,0.3888888888888889,9
2766,Simple and Deep Graph Convolutional Networks,8,Simple and Deep Graph Convolutional Networks,52,118,False,102,43,10,13,14,10,9,0,14,44,9161,4.0,1.8461538461538463,3.3076923076923075,0.6923076923076923,1042
2767,Skew-Fit: State-Covering Self-Supervised Reinforcement Learning,8,Skew-Fit State-Covering Self-Supervised Reinforcement Learning,52,191,False,91,72,60,19,10,14,16,0,8,62,12523,2.736842105263158,3.5789473684210527,3.789473684210526,0.8421052631578947,236
2768,Solving Partial Assignment Problems using Random Clique Complexes,8,Solving Partial Assignment Problems using Random Clique Complexes,32,133,False,63,124,81,20,0,9,22,0,10,65,12417,1.6,4.55,6.2,1.1,1
2769,Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection,8,Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection,39,87,False,94,13,20,10,0,10,13,2,4,75,7248,3.9,2.4,1.3,1.3,37
2770,Stabilizing Transformers for Reinforcement Learning,8,Stabilizing Transformers for Reinforcement Learning,62,220,False,160,31,41,20,0,11,9,5,24,51,9655,3.1,3.25,1.55,0.45,276
2773,Strategies for Safe Multi-Armed Bandits with Logarithmic Regret and Risk,8,Strategies for Safe Multi-Armed Bandits with Logarithmic Regret and Risk,25,180,False,114,142,46,32,0,12,12,1,0,72,16634,0.78125,1.4375,4.4375,0.375,6
2774,Structured Output Learning with Abstention: Application to Accurate Opinion Prediction,8,Structured Output Learning with Abstention Application to Accurate Opinion Prediction,20,181,False,88,228,24,9,0,22,18,0,8,85,6885,2.2222222222222223,3.5555555555555554,25.333333333333332,2.0,7
2776,Systematic Analysis of Cluster Similarity Indices: How to Validate Validation Measures,8,Systematic Analysis of Cluster Similarity Indices How to Validate Validation Measures,34,184,False,141,92,23,31,44,12,25,10,12,85,18548,1.096774193548387,1.1290322580645162,2.967741935483871,0.8064516129032258,13
2778,Tensor Programs IIb: Architectural Universality of Neural Tangent Kernel Training Dynamics,8,Tensor Programs IIb Architectural Universality of Neural Tangent Kernel Training Dynamics,46,110,False,89,202,21,28,39,11,9,10,0,89,16466,1.6428571428571428,0.75,7.214285714285714,0.32142857142857145,53
2779,The Earth Mover's Pinball Loss: Quantiles for Histogram-Valued Regression,8,The Earth Movers Pinball Loss Quantiles for Histogram-Valued Regression,65,194,False,161,50,18,16,0,8,8,0,2,72,11075,4.0625,1.25,3.125,0.5,3
2780,The Lipschitz Constant of Self-Attention,8,The Lipschitz Constant of Self-Attention,39,138,False,77,158,31,26,0,21,10,2,4,40,14702,1.5,1.3461538461538463,6.076923076923077,0.38461538461538464,96
2781,The Value Function Polytope in Reinforcement Learning,8,The Value Function Polytope in Reinforcement Learning,31,93,False,102,166,72,20,0,22,26,0,0,53,11433,1.55,3.6,8.3,1.3,37
2782,Thinking Like Transformers,8,Thinking Like Transformers,43,182,False,31,8,48,22,1,10,6,0,4,26,13183,1.9545454545454546,2.3636363636363638,0.36363636363636365,0.2727272727272727,60
2783,Time-aware Large Kernel Convolutions,8,Time-aware Large Kernel Convolutions,75,144,False,135,25,6,12,6,6,16,0,14,36,8487,6.25,1.6666666666666667,2.0833333333333335,1.3333333333333333,28
2784,Towards Coherent and Consistent Use of Entities in Narrative Generation,8,Towards Coherent and Consistent Use of Entities in Narrative Generation,43,167,False,138,16,38,15,16,18,22,2,36,71,11494,2.8666666666666667,4.933333333333334,1.0666666666666667,1.4666666666666666,7
2785,Towards Understanding Learning in Neural Networks with Linear Teachers,8,Towards Understanding Learning in Neural Networks with Linear Teachers,41,120,False,105,90,40,29,1,21,15,7,2,70,16046,1.4137931034482758,1.4482758620689655,3.103448275862069,0.5172413793103449,15
2786,Training Linear Neural Networks: Non-Local Convergence and Complexity Results,8,Training Linear Neural Networks Non-Local Convergence and Complexity Results,80,151,False,156,436,3,29,0,20,6,0,0,76,19247,2.7586206896551726,0.10344827586206896,15.03448275862069,0.20689655172413793,25
2787,Transformer Hawkes Process,8,Transformer Hawkes Process,39,136,False,90,67,21,20,0,6,9,0,12,26,7878,1.95,1.65,3.35,0.45,198
2788,Unbiased Risk Estimators Can Mislead: A Case Study of Learning with Complementary Labels,8,Unbiased Risk Estimators Can Mislead A Case Study of Learning with Complementary Labels,36,143,False,74,42,26,11,10,7,11,0,6,87,6715,3.272727272727273,2.909090909090909,3.8181818181818183,1.0,44
2789,Understanding Robust Overfitting of Adversarial Training and Beyond,8,Understanding Robust Overfitting of Adversarial Training and Beyond,42,202,False,83,18,77,16,0,10,10,0,10,67,9651,2.625,5.4375,1.125,0.625,33
2790,UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training,8,UniLMv2 Pseudo-Masked Language Models for Unified Language Model Pre-Training,46,154,False,96,12,15,11,2,9,12,2,18,77,7471,4.181818181818182,3.0,1.0909090909090908,1.0909090909090908,349
2791,Unsupervised Discovery of Interpretable Directions in the GAN Latent Space,8,Unsupervised Discovery of Interpretable Directions in the GAN Latent Space,34,158,True,49,8,46,15,0,7,13,0,16,74,7836,2.2666666666666666,4.133333333333334,0.5333333333333333,0.8666666666666667,348
2794,Visual Grounding of Learned Physical Models,8,Visual Grounding of Learned Physical Models,45,28,False,12,0,3,10,1,5,11,4,2,43,7041,4.5,0.5,0.0,1.1,59
2795,What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?,8,What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments,57,140,False,63,6,24,11,0,7,5,3,10,98,7680,5.181818181818182,3.090909090909091,0.5454545454545454,0.45454545454545453,53
2796,Which Tricks are Important for Learning to Rank?,8,Which Tricks are Important for Learning to Rank,24,123,False,63,44,4,15,10,7,9,0,60,47,8197,1.6,4.266666666666667,2.933333333333333,0.6,3
2797,XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning,8,XtarNet Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning,21,185,False,37,16,9,15,0,7,11,0,12,90,9576,1.4,1.4,1.0666666666666667,0.7333333333333333,42
2799,A Contrastive Divergence for Combining Variational Inference and MCMC,8,A Contrastive Divergence for Combining Variational Inference and MCMC,32,126,True,76,126,12,12,0,9,9,0,4,69,9125,2.6666666666666665,1.3333333333333333,10.5,0.75,53
2801,A Langevin-like Sampler for Discrete Distributions,8,A Langevin-like Sampler for Discrete Distributions,62,136,False,212,228,96,22,32,36,26,4,16,50,13160,2.8181818181818183,5.090909090909091,10.363636363636363,1.1818181818181819,23
2802,A Progressive Batching L-BFGS Method for Machine Learning,8,A Progressive Batching L-BFGS Method for Machine Learning,58,164,True,80,262,254,24,0,18,22,6,8,57,11838,2.4166666666666665,10.916666666666666,10.916666666666666,0.9166666666666666,125
2803,A Simple yet Universal Strategy for Online Convex Optimization,8,A Simple yet Universal Strategy for Online Convex Optimization,55,187,False,178,154,0,23,0,7,12,0,0,62,8718,2.391304347826087,0.0,6.695652173913044,0.5217391304347826,10
2804,A Unified Generative Adversarial Network Training via Self-Labeling and Self-Attention,8,A Unified Generative Adversarial Network Training via Self-Labeling and Self-Attention,34,185,False,49,18,30,11,0,5,3,0,16,86,7068,3.090909090909091,4.181818181818182,1.6363636363636365,0.2727272727272727,3
2805,ADOM: Accelerated Decentralized Optimization Method for Time-Varying Networks,8,ADOM Accelerated Decentralized Optimization Method for Time-Varying Networks,34,146,True,97,118,87,17,0,11,22,0,4,76,10494,2.0,5.352941176470588,6.9411764705882355,1.2941176470588236,25
2807,Active Learning for Decision-Making from Imbalanced Observational Data,8,Active Learning for Decision-Making from Imbalanced Observational Data,43,192,False,84,38,22,15,9,10,14,5,0,70,9706,2.8666666666666667,1.4666666666666666,2.533333333333333,0.9333333333333333,26
2808,Adapting k-means algorithms for outliers,8,Adapting k-means algorithms for outliers,40,242,False,113,170,7,57,22,16,7,0,0,40,22546,0.7017543859649122,0.12280701754385964,2.982456140350877,0.12280701754385964,4
2809,Adaptive Sampling for Best Policy Identification in Markov Decision Processes,8,Adaptive Sampling for Best Policy Identification in Markov Decision Processes,28,173,False,25,50,8,43,0,8,7,1,0,77,16517,0.6511627906976745,0.18604651162790697,1.1627906976744187,0.16279069767441862,14
2810,Adversarial Attacks on Probabilistic Autoregressive Forecasting Models,8,Adversarial Attacks on Probabilistic Autoregressive Forecasting Models,54,138,False,78,48,21,15,26,11,19,4,2,70,10390,3.6,1.5333333333333334,3.2,1.2666666666666666,17
2811,Adversarial Robustness for Code,8,Adversarial Robustness for Code,72,0,False,83,14,0,18,41,12,1,0,0,31,14555,4.0,0.0,0.7777777777777778,0.05555555555555555,68
2812,Algorithms for the Communication of Samples,8,Algorithms for the Communication of Samples,40,106,False,148,200,8,21,0,14,9,2,0,43,11105,1.9047619047619047,0.38095238095238093,9.523809523809524,0.42857142857142855,27
2813,An Analytical Update Rule for General Policy Optimization,8,An Analytical Update Rule for General Policy Optimization,31,119,False,69,328,3,21,0,10,12,0,0,57,11105,1.4761904761904763,0.14285714285714285,15.619047619047619,0.5714285714285714,4
2814,An end-to-end approach for the verification problem: learning the right distance,8,An end-to-end approach for the verification problem learning the right distance,69,164,False,103,18,23,18,2,9,11,5,10,79,11273,3.8333333333333335,1.8333333333333333,1.0,0.6111111111111112,6
2815,Angular Visual Hardness,8,Angular Visual Hardness,99,189,False,112,21,137,25,0,14,8,0,18,23,14259,3.96,6.2,0.84,0.32,47
2817,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,8,Augment and Reduce Stochastic Inference for Large Categorical Distributions,58,130,False,96,46,12,11,0,6,5,0,6,75,7884,5.2727272727272725,1.6363636363636365,4.181818181818182,0.45454545454545453,21
2818,Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting,8,Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting,58,134,False,84,28,12,11,0,6,10,0,4,96,7100,5.2727272727272725,1.4545454545454546,2.5454545454545454,0.9090909090909091,171
2820,Bayesian Nonparametric Federated Learning of Neural Networks,8,Bayesian Nonparametric Federated Learning of Neural Networks,31,0,False,65,56,40,15,8,9,9,0,2,60,10773,2.066666666666667,2.8,3.7333333333333334,0.6,512
2821,Benefits and Pitfalls of the Exponential Mechanism with Applications to Hilbert Spaces and Functional PCA,8,Benefits and Pitfalls of the Exponential Mechanism with Applications to Hilbert Spaces and Functional PCA,48,136,True,93,54,14,13,0,8,2,0,4,105,7301,3.6923076923076925,1.3846153846153846,4.153846153846154,0.15384615384615385,28
2822,Biased Gradient Estimate with Drastic Variance Reduction for Meta Reinforcement Learning,8,Biased Gradient Estimate with Drastic Variance Reduction for Meta Reinforcement Learning,35,150,False,108,210,11,38,44,15,15,0,0,88,14929,0.9210526315789473,0.2894736842105263,5.526315789473684,0.39473684210526316,5
2823,Black-box density function estimation using recursive partitioning,8,Black-box density function estimation using recursive partitioning,57,107,False,50,23,606,20,28,9,14,4,0,66,12402,2.85,30.3,1.15,0.7,5
2824,Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding,8,Branchformer Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding,49,173,True,92,20,24,17,0,13,14,6,24,126,9538,2.8823529411764706,2.823529411764706,1.1764705882352942,0.8235294117647058,73
2825,Burst-Dependent Plasticity and Dendritic Amplification Support Target-Based Learning and Hierarchical Imitation Learning,8,Burst-Dependent Plasticity and Dendritic Amplification Support Target-Based Learning and Hierarchical Imitation Learning,28,117,False,20,61,12,12,0,6,6,4,2,120,6929,2.3333333333333335,1.1666666666666667,5.083333333333333,0.5,6
2826,"CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning",8,CURIOUS Intrinsically Motivated Multi-Task Multi-Goal Reinforcement Learning,33,173,True,106,0,38,15,27,10,16,0,2,76,9936,2.2,2.6666666666666665,0.0,1.0666666666666667,40
2827,Causal Imitation Learning under Temporally Correlated Noise,8,Causal Imitation Learning under Temporally Correlated Noise,39,129,False,93,103,27,14,0,10,16,0,10,59,8238,2.7857142857142856,2.642857142857143,7.357142857142857,1.1428571428571428,16
2828,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,8,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,68,176,False,155,30,86,37,18,17,11,0,12,91,23097,1.837837837837838,2.6486486486486487,0.8108108108108109,0.2972972972972973,1230
2829,Cliff Diving: Exploring Reward Surfaces in Reinforcement Learning Environments,8,Cliff Diving Exploring Reward Surfaces in Reinforcement Learning Environments,27,177,False,85,0,274,33,0,19,27,5,6,77,8033,0.8181818181818182,8.484848484848484,0.0,0.8181818181818182,4
2831,Commutative Lie Group VAE for Disentanglement Learning,8,Commutative Lie Group VAE for Disentanglement Learning,53,248,True,44,16,24,11,0,7,5,0,10,54,7408,4.818181818181818,3.090909090909091,1.4545454545454546,0.45454545454545453,16
2832,Compositional Video Synthesis with Action Graphs,8,Compositional Video Synthesis with Action Graphs,83,137,False,144,20,42,18,2,11,9,0,14,48,11176,4.611111111111111,3.111111111111111,1.1111111111111112,0.5,33
2833,Confidence Scores Make Instance-dependent Label-noise Learning Possible,8,Confidence Scores Make Instance-dependent Label-noise Learning Possible,72,155,False,118,17,35,17,26,10,8,0,4,71,7913,4.235294117647059,2.2941176470588234,1.0,0.47058823529411764,79
2835,Contextual Information-Directed Sampling,8,Contextual Information-Directed Sampling,37,126,False,130,252,3,21,9,12,15,0,4,40,10281,1.7619047619047619,0.3333333333333333,12.0,0.7142857142857143,11
2836,Contrastive UCB: Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning,8,Contrastive UCB Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning,57,199,True,104,486,6,60,0,14,15,0,4,104,24742,0.95,0.16666666666666666,8.1,0.25,18
2837,Convolutional and Residual Networks Provably Contain Lottery Tickets,8,Convolutional and Residual Networks Provably Contain Lottery Tickets,47,99,False,109,52,12,16,3,10,6,0,8,68,12649,2.9375,1.25,3.25,0.375,9
2839,Customizing ML Predictions for Online Algorithms,8,Customizing ML Predictions for Online Algorithms,36,111,True,82,208,56,27,0,20,6,0,0,48,12372,1.3333333333333333,2.074074074074074,7.703703703703703,0.2222222222222222,51
2840,DP-GP-LVM: A Bayesian Non-Parametric Model for Learning Multivariate Dependency Structures,8,DP-GP-LVM A Bayesian Non-Parametric Model for Learning Multivariate Dependency Structures,35,83,True,56,115,31,14,27,10,3,0,2,89,8808,2.5,2.357142857142857,8.214285714285714,0.21428571428571427,2
2841,Data-Efficient Double-Win Lottery Tickets from Robust Pre-training,8,Data-Efficient Double-Win Lottery Tickets from Robust Pre-training,70,161,False,68,6,31,13,13,11,2,0,4,66,7989,5.384615384615385,2.6923076923076925,0.46153846153846156,0.15384615384615385,7
2842,Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication,8,Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication,59,211,False,65,150,44,30,14,12,15,0,6,89,13017,1.9666666666666666,1.6666666666666667,5.0,0.5,430
2843,Deep Gaussian Processes with Importance-Weighted Variational Inference,8,Deep Gaussian Processes with Importance-Weighted Variational Inference,39,131,False,126,44,121,19,0,12,14,0,6,70,10470,2.0526315789473686,6.684210526315789,2.3157894736842106,0.7368421052631579,38
2844,Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,8,Deep k-Means Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions,41,175,False,89,24,8,10,1,6,7,7,8,112,7524,4.1,1.6,2.4,0.7,104
2845,DeltaGrad: Rapid retraining of machine learning models,8,DeltaGrad Rapid retraining of machine learning models,71,96,False,19,252,0,65,0,3,3,11,0,53,32649,1.0923076923076922,0.0,3.876923076923077,0.046153846153846156,139
2846,Detecting non-causal artifacts in multivariate linear regression models,8,Detecting non-causal artifacts in multivariate linear regression models,22,89,False,48,84,14,12,0,10,8,0,0,71,7608,1.8333333333333333,1.1666666666666667,7.0,0.6666666666666666,31
2847,Differentially Private Bayesian Inference for Generalized Linear Models,8,Differentially Private Bayesian Inference for Generalized Linear Models,54,134,False,128,228,34,17,0,22,34,4,0,71,10119,3.176470588235294,2.0,13.411764705882353,2.0,22
2848,Dimensionality Reduction for Tukey Regression,8,Dimensionality Reduction for Tukey Regression,40,289,False,59,80,23,46,11,11,23,0,0,45,20652,0.8695652173913043,0.5,1.7391304347826086,0.5,31
2849,Discrete Tree Flows via Tree-Structured Permutations,8,Discrete Tree Flows via Tree-Structured Permutations,31,199,False,51,92,41,32,28,16,23,2,16,52,17859,0.96875,1.78125,2.875,0.71875,2
2850,Distributed Linear Bandits under Communication Constraints,8,Distributed Linear Bandits under Communication Constraints,66,134,False,62,107,0,40,8,10,13,6,0,58,17531,1.65,0.0,2.675,0.325,5
2851,Do More Negative Samples Necessarily Hurt in Contrastive Learning?,8,Do More Negative Samples Necessarily Hurt in Contrastive Learning,38,130,False,131,64,13,16,8,15,19,4,4,65,10371,2.375,1.0625,4.0,1.1875,26
2853,Dynamics of Deep Neural Networks and Neural Tangent Hierarchy,8,Dynamics of Deep Neural Networks and Neural Tangent Hierarchy,55,280,False,33,486,0,39,0,8,5,0,0,61,16537,1.4102564102564104,0.0,12.461538461538462,0.1282051282051282,139
2854,Efficient Lottery Ticket Finding: Less Data is More,8,Efficient Lottery Ticket Finding Less Data is More,56,197,False,118,0,54,14,23,12,25,4,10,50,9544,4.0,4.571428571428571,0.0,1.7857142857142858,43
2855,Efficient Training of Robust Decision Trees Against Adversarial Examples,8,Efficient Training of Robust Decision Trees Against Adversarial Examples,36,191,False,27,38,18,10,2,8,13,3,4,72,7758,3.6,2.2,3.8,1.3,26
2856,Emphatic Algorithms for Deep Reinforcement Learning,8,Emphatic Algorithms for Deep Reinforcement Learning,31,146,False,87,96,44,26,8,12,19,0,8,51,12515,1.1923076923076923,2.0,3.6923076923076925,0.7307692307692307,18
2857,Equivariant Diffusion for Molecule Generation in 3D,8,Equivariant Diffusion for Molecule Generation in 3D,53,28,False,12,0,3,21,0,5,11,4,2,51,11812,2.5238095238095237,0.23809523809523808,0.0,0.5238095238095238,319
2858,Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network,8,Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network,65,200,False,142,10,9,13,0,10,6,3,18,87,8916,5.0,2.076923076923077,0.7692307692307693,0.46153846153846156,21
2860,Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search,8,Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search,56,147,False,54,4,25,11,4,6,11,4,6,108,7716,5.090909090909091,2.8181818181818183,0.36363636363636365,1.0,80
2861,FILTRA: Rethinking Steerable CNN by Filter Transform,8,FILTRA Rethinking Steerable CNN by Filter Transform,19,163,True,162,192,12,11,12,14,36,0,8,51,6389,1.7272727272727273,1.8181818181818181,17.454545454545453,3.272727272727273,4
2862,Fairwashing Explanations with Off-Manifold Detergent,8,Fairwashing Explanations with Off-Manifold Detergent,28,124,False,34,116,123,22,10,10,17,8,6,52,12282,1.2727272727272727,5.863636363636363,5.2727272727272725,0.7727272727272727,80
2863,Fast Projection Onto Convex Smooth Constraints,8,Fast Projection Onto Convex Smooth Constraints,51,119,False,77,78,0,19,6,11,19,2,6,46,12177,2.6842105263157894,0.3157894736842105,4.105263157894737,1.0,8
2864,Faster Rates of Convergence to Stationary Points in Differentially Private Optimization,8,Faster Rates of Convergence to Stationary Points in Differentially Private Optimization,52,195,False,41,0,0,42,0,3,3,0,0,87,18897,1.2380952380952381,0.0,0.0,0.07142857142857142,17
2865,Federated Deep AUC Maximization for Heterogeneous Data with a Constant Communication Complexity,8,Federated Deep AUC Maximization for Heterogeneous Data with a Constant Communication Complexity,49,213,True,77,572,40,52,1,16,6,0,14,95,18487,0.9423076923076923,1.0384615384615385,11.0,0.11538461538461539,34
2867,Fishr: Invariant Gradient Variances for Out-of-distribution Generalization,8,Fishr Invariant Gradient Variances for Out-of-distribution Generalization,155,1,False,12,0,3,31,0,6,12,5,2,73,21486,5.0,0.16129032258064516,0.0,0.3870967741935484,138
2868,FormulaZero: Distributionally Robust Online Adaptation via Offline Population Synthesis,8,FormulaZero Distributionally Robust Online Adaptation via Offline Population Synthesis,106,123,False,223,146,44,40,9,11,27,6,10,86,15508,2.65,1.35,3.65,0.675,23
2869,Frustratingly Easy Transferability Estimation,8,Frustratingly Easy Transferability Estimation,68,189,False,128,56,86,25,0,10,27,0,18,45,15848,2.72,4.16,2.24,1.08,40
2870,GACT: Activation Compressed Training for Generic Network Architectures,8,GACT Activation Compressed Training for Generic Network Architectures,50,148,True,52,68,30,18,1,10,20,0,14,69,9581,2.7777777777777777,2.4444444444444446,3.7777777777777777,1.1111111111111112,16
2871,GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing,8,GSmooth Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing,44,147,False,121,176,12,19,0,19,17,0,10,98,10341,2.3157894736842106,1.1578947368421053,9.263157894736842,0.8947368421052632,15
2872,Generalization Guarantees for Sparse Kernel Approximation with Entropic Optimal Features,8,Generalization Guarantees for Sparse Kernel Approximation with Entropic Optimal Features,43,122,False,56,80,12,31,0,11,2,0,6,88,8387,1.3870967741935485,0.5806451612903226,2.5806451612903225,0.06451612903225806,8
2873,Generalizing to New Physical Systems via Context-Informed Dynamics Model,8,Generalizing to New Physical Systems via Context-Informed Dynamics Model,65,155,False,147,65,43,19,20,14,19,4,8,72,13790,3.4210526315789473,2.6842105263157894,3.4210526315789473,1.0,18
2874,Geodesic Convolutional Shape Optimization,8,Geodesic Convolutional Shape Optimization,45,142,False,54,21,11,11,11,6,9,0,0,41,8148,4.090909090909091,1.0,1.9090909090909092,0.8181818181818182,68
2875,"Go Wide, Then Narrow: Efficient Training of Deep Thin Networks",8,Go Wide Then Narrow Efficient Training of Deep Thin Networks,37,209,False,61,129,6,12,24,19,9,4,12,61,8396,3.0833333333333335,1.5,10.75,0.75,16
2876,"Graph Element Networks: adaptive, structured computation and memory",8,Graph Element Networks adaptive structured computation and memory,67,163,False,240,12,108,16,9,23,55,0,6,65,10371,4.1875,7.125,0.75,3.4375,67
2877,Graphically Structured Diffusion Models,8,Graphically Structured Diffusion Models,60,109,False,118,22,79,23,7,20,12,1,6,39,13720,2.608695652173913,3.6956521739130435,0.9565217391304348,0.5217391304347826,4
2878,HardCoRe-NAS: Hard Constrained diffeRentiable Neural Architecture Search,8,HardCoRe-NAS Hard Constrained diffeRentiable Neural Architecture Search,71,116,True,104,160,32,15,3,16,21,19,14,71,10664,4.733333333333333,3.066666666666667,10.666666666666666,1.4,28
2879,High Performance Zero-Memory Overhead Direct Convolutions,8,High Performance Zero-Memory Overhead Direct Convolutions,30,2,False,36,4,16,10,0,7,18,8,4,57,6528,3.0,2.0,0.4,1.8,56
2880,How Powerful are Shallow Neural Networks with Bandlimited Random Weights?,8,How Powerful are Shallow Neural Networks with Bandlimited Random Weights,78,214,False,102,114,30,22,5,11,13,0,8,72,14525,3.5454545454545454,1.7272727272727273,5.181818181818182,0.5909090909090909,2
2881,Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging,8,Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging,81,156,False,106,64,76,16,0,10,16,8,0,103,8533,5.0625,4.75,4.0,1.0,56
2882,Implicit-PDF: Non-Parametric Representation of Probability Distributions on the Rotation Manifold,8,Implicit-PDF Non-Parametric Representation of Probability Distributions on the Rotation Manifold,53,1,True,75,4,9,22,10,13,2,0,6,96,12861,2.409090909090909,0.6818181818181818,0.18181818181818182,0.09090909090909091,59
2883,Improved Training of Generative Adversarial Networks Using Representative Features,8,Improved Training of Generative Adversarial Networks Using Representative Features,39,132,False,95,9,22,10,0,6,6,0,2,82,6464,3.9,2.4,0.9,0.6,29
2884,Improving Optimization for Models With Continuous Symmetry Breaking.,8,Improving Optimization for Models With Continuous Symmetry Breaking,37,112,False,80,34,11,10,18,7,8,0,4,67,7466,3.7,1.5,3.4,0.8,14
2885,Incentivizing Compliance with Algorithmic Instruments,8,Incentivizing Compliance with Algorithmic Instruments,24,0,False,62,925,0,53,1,16,31,22,18,53,25337,0.4528301886792453,0.33962264150943394,17.452830188679247,0.5849056603773585,4
2886,Influence Diagram Bandits: Variational Thompson Sampling for Structured Bandit Problems,8,Influence Diagram Bandits Variational Thompson Sampling for Structured Bandit Problems,49,127,False,88,85,19,16,0,11,15,0,2,86,10497,3.0625,1.3125,5.3125,0.9375,2
2887,Integer Programming for Causal Structure Learning in the Presence of Latent Variables,8,Integer Programming for Causal Structure Learning in the Presence of Latent Variables,35,157,False,38,27,19,17,0,10,8,2,10,85,8736,2.0588235294117645,1.7058823529411764,1.588235294117647,0.47058823529411764,6
2888,Interpreting Adversarially Trained Convolutional Neural Networks,8,Interpreting Adversarially Trained Convolutional Neural Networks,45,185,False,130,12,144,16,4,24,20,10,32,64,8770,2.8125,11.0,0.75,1.25,139
2889,Invertible generative models for inverse problems: mitigating representation error and dataset bias,8,Invertible generative models for inverse problems mitigating representation error and dataset bias,36,206,False,56,36,350,29,0,7,10,6,0,98,11050,1.2413793103448276,12.068965517241379,1.2413793103448276,0.3448275862068966,126
2890,Junction Tree Variational Autoencoder for Molecular Graph Generation,8,Junction Tree Variational Autoencoder for Molecular Graph Generation,44,122,False,96,26,43,17,0,9,8,0,8,68,12994,2.588235294117647,3.0,1.5294117647058822,0.47058823529411764,1122
2891,Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning,8,Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning,56,161,False,107,239,31,45,33,18,4,0,10,90,23923,1.2444444444444445,0.9111111111111111,5.311111111111111,0.08888888888888889,138
2892,Label Inference Attacks from Log-loss Scores,8,Label Inference Attacks from Log-loss Scores,22,145,False,36,44,20,19,0,10,13,0,4,44,13054,1.1578947368421053,1.263157894736842,2.3157894736842106,0.6842105263157895,8
2893,Latent Outlier Exposure for Anomaly Detection with Contaminated Data,8,Latent Outlier Exposure for Anomaly Detection with Contaminated Data,41,160,False,336,84,0,15,60,16,18,0,0,68,10505,2.7333333333333334,0.0,5.6,1.2,33
2894,Learning Antidote Data to Individual Unfairness,8,Learning Antidote Data to Individual Unfairness,52,193,False,100,26,9,14,28,10,5,0,16,47,9107,3.7142857142857144,1.7857142857142858,1.8571428571428572,0.35714285714285715,3
2895,Learning Distributions over Quantum Measurement Outcomes,8,Learning Distributions over Quantum Measurement Outcomes,40,177,False,56,162,0,25,0,7,12,0,0,56,10755,1.6,0.0,6.48,0.48,3
2896,Learning Interaction Kernels for Agent Systems on Riemannian Manifolds,8,Learning Interaction Kernels for Agent Systems on Riemannian Manifolds,52,142,False,41,137,48,39,0,11,19,2,46,70,15731,1.3333333333333333,2.41025641025641,3.5128205128205128,0.48717948717948717,6
2898,Learning Stochastic Shortest Path with Linear Function Approximation,8,Learning Stochastic Shortest Path with Linear Function Approximation,66,193,False,199,404,4,46,2,18,25,3,0,68,26873,1.434782608695652,0.08695652173913043,8.782608695652174,0.5434782608695652,24
2899,Learning fair representation with a parametric integral probability metric,8,Learning fair representation with a parametric integral probability metric,47,201,False,76,144,150,28,21,14,20,0,10,74,13602,1.6785714285714286,5.714285714285714,5.142857142857143,0.7142857142857143,12
2900,Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs,8,Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs,44,140,False,73,18,24,13,0,11,20,0,16,73,8865,3.3846153846153846,3.076923076923077,1.3846153846153846,1.5384615384615385,218
2901,Learning to Search with MCTSnets,8,Learning to Search with MCTSnets,28,162,False,64,28,24,12,5,7,13,0,0,32,7163,2.3333333333333335,2.0,2.3333333333333335,1.0833333333333333,79
2902,Leverage Score Sampling for Tensor Product Matrices in Input Sparsity Time,8,Leverage Score Sampling for Tensor Product Matrices in Input Sparsity Time,22,198,False,71,180,5,32,11,12,11,0,2,74,22695,0.6875,0.21875,5.625,0.34375,6
2903,Linear Bandit Algorithms with Sublinear Time Complexity,8,Linear Bandit Algorithms with Sublinear Time Complexity,55,159,False,97,84,6,20,8,11,13,0,10,55,13138,2.75,0.8,4.2,0.65,10
2904,Local Density Estimation in High Dimensions,8,Local Density Estimation in High Dimensions,34,122,False,52,62,39,45,0,14,19,3,2,43,15324,0.7555555555555555,0.9111111111111111,1.3777777777777778,0.4222222222222222,12
2905,Low-Precision Stochastic Gradient Langevin Dynamics,8,Low-Precision Stochastic Gradient Langevin Dynamics,54,146,False,280,256,32,21,14,30,24,4,12,51,11601,2.5714285714285716,2.0952380952380953,12.19047619047619,1.1428571428571428,9
2906,ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases,8,ME-GAN Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases,54,189,True,66,22,15,11,0,7,8,3,2,113,8052,4.909090909090909,1.5454545454545454,2.0,0.7272727272727273,14
2907,Markovian Gaussian Process Variational Autoencoders,8,Markovian Gaussian Process Variational Autoencoders,74,152,False,222,8,42,24,21,10,13,0,0,51,12118,3.0833333333333335,1.75,0.3333333333333333,0.5416666666666666,5
2908,Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians,8,Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians,35,125,False,20,46,64,10,0,6,4,0,0,102,5329,3.5,6.4,4.6,0.4,69
2910,Minimax Pareto Fairness: A Multi Objective Perspective,8,Minimax Pareto Fairness A Multi Objective Perspective,36,127,False,67,69,24,24,18,9,14,4,24,53,17219,1.5,2.0,2.875,0.5833333333333334,152
2911,Mixture Models for Diverse Machine Translation: Tricks of the Trade,8,Mixture Models for Diverse Machine Translation Tricks of the Trade,43,177,False,90,8,12,12,9,9,10,0,14,66,8883,3.5833333333333335,2.1666666666666665,0.6666666666666666,0.8333333333333334,127
2912,Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models,8,Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models,63,117,False,56,94,18,17,0,10,12,0,12,79,9982,3.7058823529411766,1.7647058823529411,5.529411764705882,0.7058823529411765,10
2913,Momentum-Based Policy Gradient Methods,8,Momentum-Based Policy Gradient Methods,57,145,False,92,170,20,24,0,8,16,0,4,38,12624,2.375,1.0,7.083333333333333,0.6666666666666666,35
2914,Multi-Agent Routing Value Iteration Network,8,Multi-Agent Routing Value Iteration Network,41,186,False,83,28,46,14,29,10,7,0,10,43,8719,2.9285714285714284,4.0,2.0,0.5,34
2915,Multi-objective training of Generative Adversarial Networks with multiple discriminators,8,Multi-objective training of Generative Adversarial Networks with multiple discriminators,34,134,False,122,24,77,16,0,13,9,2,14,88,7809,2.125,5.6875,1.5,0.5625,56
2916,NGBoost: Natural Gradient Boosting for Probabilistic Prediction,8,NGBoost Natural Gradient Boosting for Probabilistic Prediction,42,146,False,79,23,19,11,6,5,9,0,6,62,7528,3.8181818181818183,2.272727272727273,2.090909090909091,0.8181818181818182,206
2917,Nearest Neighbor and Kernel Survival Analysis: Nonasymptotic Error Bounds and Strong Consistency Rates,8,Nearest Neighbor and Kernel Survival Analysis Nonasymptotic Error Bounds and Strong Consistency Rates,52,94,False,136,339,30,38,0,17,13,0,2,101,26621,1.368421052631579,0.8421052631578947,8.921052631578947,0.34210526315789475,13
2918,Neural Implicit Dictionary Learning via Mixture-of-Expert Training,8,Neural Implicit Dictionary Learning via Mixture-of-Expert Training,81,190,False,163,26,18,12,18,7,8,0,6,66,8590,6.75,2.0,2.1666666666666665,0.6666666666666666,7
2919,Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth and Initialization,8,Neural Tangent Kernel Beyond the Infinite-Width Limit Effects of Depth and Initialization,39,186,False,70,516,43,39,0,9,18,0,0,89,20244,1.0,1.1025641025641026,13.23076923076923,0.46153846153846156,13
2920,No-Regret Learning in Time-Varying Zero-Sum Games,8,No-Regret Learning in Time-Varying Zero-Sum Games,37,171,False,110,274,5,37,11,14,14,0,2,49,24611,1.0,0.1891891891891892,7.405405405405405,0.3783783783783784,24
2921,Nonparametric Bayesian Deep Networks with Local Competition,8,Nonparametric Bayesian Deep Networks with Local Competition,39,161,False,49,33,10,9,0,6,7,0,6,59,6504,4.333333333333333,1.7777777777777777,3.6666666666666665,0.7777777777777778,27
2923,Offline Reinforcement Learning with Fisher Divergence Critic Regularization,8,Offline Reinforcement Learning with Fisher Divergence Critic Regularization,36,150,False,87,41,23,13,9,10,8,0,4,75,7988,2.769230769230769,2.076923076923077,3.1538461538461537,0.6153846153846154,222
2925,On Many-Actions Policy Gradient,8,On Many-Actions Policy Gradient,53,123,False,96,116,25,21,11,14,18,0,20,31,12399,2.5238095238095237,2.142857142857143,5.523809523809524,0.8571428571428571,0
2926,On the Adversarial Robustness of Causal Algorithmic Recourse,8,On the Adversarial Robustness of Causal Algorithmic Recourse,61,102,False,106,82,28,19,2,14,23,4,4,60,12669,3.210526315789474,1.6842105263157894,4.315789473684211,1.2105263157894737,45
2927,On the Generalization Power of Overfitted Two-Layer Neural Tangent Kernel Models,8,On the Generalization Power of Overfitted Two-Layer Neural Tangent Kernel Models,46,140,False,108,894,20,66,0,20,21,2,0,80,29745,0.696969696969697,0.30303030303030304,13.545454545454545,0.3181818181818182,7
2928,On the Power of Localized Perceptron for Label-Optimal Learning of Halfspaces with Adversarial Noise,8,On the Power of Localized Perceptron for Label-Optimal Learning of Halfspaces with Adversarial Noise,93,230,False,181,105,0,28,1,8,7,0,2,100,14438,3.3214285714285716,0.07142857142857142,3.75,0.25,8
2929,On the Variational Posterior of Dirichlet Process Deep Latent Gaussian Mixture Models,8,On the Variational Posterior of Dirichlet Process Deep Latent Gaussian Mixture Models,21,137,False,21,32,12,7,0,8,7,0,2,85,4189,3.0,2.0,4.571428571428571,1.0,3
2930,Online Convex Optimization in Adversarial Markov Decision Processes,8,Online Convex Optimization in Adversarial Markov Decision Processes,14,100,False,41,80,0,16,0,9,5,0,0,67,8624,0.875,0.0,5.0,0.3125,117
2931,Only Tails Matter: Average-Case Universality and Robustness in the Convex Regime,8,Only Tails Matter Average-Case Universality and Robustness in the Convex Regime,13,166,False,56,134,24,18,1,10,3,0,2,79,8742,0.7222222222222222,1.4444444444444444,7.444444444444445,0.16666666666666666,6
2932,Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference,8,Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference,40,104,True,119,72,52,28,7,13,23,0,6,84,9897,1.4285714285714286,2.0714285714285716,2.5714285714285716,0.8214285714285714,16
2933,Optimistic Policy Optimization with Bandit Feedback,8,Optimistic Policy Optimization with Bandit Feedback,48,152,False,131,208,0,34,17,14,7,4,2,51,18948,1.411764705882353,0.058823529411764705,6.117647058823529,0.20588235294117646,80
2935,PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits,8,PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits,31,260,True,124,48,9,22,7,7,7,2,2,70,13098,1.4090909090909092,0.5,2.1818181818181817,0.3181818181818182,18
2936,PLATINUM: Semi-Supervised Model Agnostic Meta-Learning using Submodular Mutual Information,8,PLATINUM Semi-Supervised Model Agnostic Meta-Learning using Submodular Mutual Information,59,179,True,124,46,24,17,0,9,13,0,22,89,9912,3.4705882352941178,2.7058823529411766,2.7058823529411766,0.7647058823529411,4
2937,Pareto Regret Analyses in Multi-objective Multi-armed Bandit,8,Pareto Regret Analyses in Multi-objective Multi-armed Bandit,19,130,False,115,252,15,19,7,8,9,17,2,60,13870,1.0,0.8947368421052632,13.263157894736842,0.47368421052631576,4
2939,Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding,8,Pix2Struct Screenshot Parsing as Pretraining for Visual Language Understanding,62,195,False,151,0,31,20,10,13,11,0,10,78,10300,3.1,2.05,0.0,0.55,125
2940,Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning,8,Policy Information Capacity Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning,79,182,False,135,58,50,33,26,21,14,3,44,108,20636,2.393939393939394,2.8484848484848486,1.7575757575757576,0.42424242424242425,12
2941,Predict and Constrain: Modeling Cardinality in Deep Structured Prediction,8,Predict and Constrain Modeling Cardinality in Deep Structured Prediction,26,101,False,126,14,3,13,0,8,9,0,2,72,6803,2.0,0.38461538461538464,1.0769230769230769,0.6923076923076923,9
2942,Principled Learning Method for Wasserstein distributionally robust optimization with local perturbations,8,Principled Learning Method for Wasserstein distributionally robust optimization with local perturbations,50,132,False,152,212,12,24,0,10,17,0,8,104,13841,2.0833333333333335,0.8333333333333334,8.833333333333334,0.7083333333333334,11
2943,ProGCL: Rethinking Hard Negative Mining in Graph Contrastive Learning,8,ProGCL Rethinking Hard Negative Mining in Graph Contrastive Learning,58,243,False,79,48,39,15,0,11,18,0,16,68,9311,3.8666666666666667,3.6666666666666665,3.2,1.2,68
2944,Progressive Purification for Instance-Dependent Partial Label Learning,8,Progressive Purification for Instance-Dependent Partial Label Learning,61,197,False,84,68,9,15,0,7,11,0,14,70,8640,4.066666666666666,1.5333333333333334,4.533333333333333,0.7333333333333333,5
2945,Provable Robustness of Adversarial Training for Learning Halfspaces with Noise,8,Provable Robustness of Adversarial Training for Learning Halfspaces with Noise,51,154,False,108,414,9,42,3,8,12,0,0,78,16977,1.2142857142857142,0.21428571428571427,9.857142857142858,0.2857142857142857,9
2946,Proving the Lottery Ticket Hypothesis: Pruning is All You Need,8,Proving the Lottery Ticket Hypothesis Pruning is All You Need,38,88,False,50,89,0,23,6,7,4,0,0,61,11671,1.6521739130434783,0.0,3.869565217391304,0.17391304347826086,227
2947,Quantifying and Learning Linear Symmetry-Based Disentanglement,8,Quantifying and Learning Linear Symmetry-Based Disentanglement,29,128,False,116,50,65,25,22,17,14,0,18,62,12051,1.16,3.32,2.0,0.56,10
2948,RECAPP: Crafting a More Efficient Catalyst for Convex Optimization,8,RECAPP Crafting a More Efficient Catalyst for Convex Optimization,51,132,True,264,220,8,38,32,14,6,0,2,65,18142,1.3421052631578947,0.2631578947368421,5.7894736842105265,0.15789473684210525,8
2949,Random Walks on Hypergraphs with Edge-Dependent Vertex Weights,8,Random Walks on Hypergraphs with Edge-Dependent Vertex Weights,43,156,False,114,182,15,29,0,15,5,0,4,62,13000,1.4827586206896552,0.6551724137931034,6.275862068965517,0.1724137931034483,79
2950,Ready Policy One: World Building Through Active Learning,8,Ready Policy One World Building Through Active Learning,51,155,False,62,21,21,16,0,11,12,0,12,55,8388,3.1875,2.0625,1.3125,0.75,48
2951,Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models,8,Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models,77,139,False,132,128,170,48,0,12,16,2,20,87,15798,1.6041666666666667,3.9583333333333335,2.6666666666666665,0.3333333333333333,46
2952,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,8,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control,63,144,False,87,57,22,15,0,10,14,0,0,99,11485,4.2,1.4666666666666666,3.8,0.9333333333333333,16
2954,Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search,8,Retro Learning Retrosynthetic Planning with Neural Guided A Search,30,152,False,58,20,26,15,0,11,12,2,6,66,9439,2.0,2.1333333333333333,1.3333333333333333,0.8,74
2955,Reward-Free Exploration for Reinforcement Learning,8,Reward-Free Exploration for Reinforcement Learning,34,1,False,49,226,6,38,17,9,14,3,2,50,16401,0.8947368421052632,0.21052631578947367,5.947368421052632,0.3684210526315789,168
2956,Robust Imitation Learning against Variations in Environment Dynamics,8,Robust Imitation Learning against Variations in Environment Dynamics,51,126,False,48,60,115,25,0,14,23,0,12,68,15533,2.04,5.08,2.4,0.92,10
2958,SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II,8,SCC an efficient deep reinforcement learning agent mastering the game of StarCraft II,26,131,True,29,2,18,15,11,10,12,0,6,85,9137,1.7333333333333334,1.6,0.13333333333333333,0.8,29
2959,SQL-Rank: A Listwise Approach to Collaborative Ranking,8,SQL-Rank A Listwise Approach to Collaborative Ranking,30,172,True,37,72,15,14,0,7,14,0,8,53,8961,2.142857142857143,1.6428571428571428,5.142857142857143,1.0,37
2961,Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning,8,Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning,54,1,False,0,0,0,21,1,9,3,0,0,76,15516,2.5714285714285716,0.0,0.0,0.14285714285714285,80
2962,"Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension",8,Schatten Norms in Matrix Streams Hello Sparsity Goodbye Dimension,51,163,False,66,64,10,39,13,10,19,4,2,65,18709,1.3076923076923077,0.3076923076923077,1.641025641025641,0.48717948717948717,13
2965,Sever: A Robust Meta-Algorithm for Stochastic Optimization,8,Sever A Robust Meta-Algorithm for Stochastic Optimization,59,118,False,114,46,23,34,15,11,16,2,0,57,19109,1.7352941176470589,0.6764705882352942,1.3529411764705883,0.47058823529411764,265
2966,Simple and Effective VAE Training with Calibrated Decoders,8,Simple and Effective VAE Training with Calibrated Decoders,69,158,True,157,28,31,16,7,12,6,0,0,58,9460,4.3125,1.9375,1.75,0.375,72
2968,Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation,8,Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation,37,213,False,144,57,14,15,0,10,11,6,16,115,10316,2.466666666666667,2.0,3.8,0.7333333333333333,5
2969,Special Properties of Gradient Descent with Large Learning Rates,8,Special Properties of Gradient Descent with Large Learning Rates,48,169,False,61,50,45,25,7,24,7,0,0,64,13663,1.92,1.8,2.0,0.28,5
2971,Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement,8,Stochastic Beams and Where to Find Them The Gumbel-Top-k Trick for Sampling Sequences Without Replacement,48,128,False,107,72,13,13,4,10,17,0,0,105,8909,3.6923076923076925,1.0,5.538461538461538,1.3076923076923077,164
2973,Streaming Algorithms for High-Dimensional Robust Statistics,8,Streaming Algorithms for High-Dimensional Robust Statistics,57,132,False,76,236,0,63,13,12,27,10,0,59,33233,0.9047619047619048,0.0,3.746031746031746,0.42857142857142855,17
2974,Structured Policy Iteration for Linear Quadratic Regulator,8,Structured Policy Iteration for Linear Quadratic Regulator,62,204,False,48,173,28,18,8,10,11,4,0,58,10862,3.4444444444444446,1.5555555555555556,9.61111111111111,0.6111111111111112,14
2975,Sum-of-Squares Polynomial Flow,8,Sum-of-Squares Polynomial Flow,54,126,False,164,45,21,13,0,10,2,0,6,30,9057,4.153846153846154,2.076923076923077,3.4615384615384617,0.15384615384615385,129
2976,T-Basis: a Compact Representation for Neural Networks,8,T-Basis a Compact Representation for Neural Networks,77,172,False,72,46,25,13,12,7,10,0,4,52,9710,5.923076923076923,2.230769230769231,3.5384615384615383,0.7692307692307693,22
2978,Tensor Variable Elimination for Plated Factor Graphs,8,Tensor Variable Elimination for Plated Factor Graphs,53,150,False,71,80,15,17,0,12,16,8,6,52,12445,3.1176470588235294,1.2352941176470589,4.705882352941177,0.9411764705882353,17
2979,The Effect of Natural Distribution Shift on Question Answering Models,8,The Effect of Natural Distribution Shift on Question Answering Models,67,149,False,130,8,97,73,18,13,20,0,10,69,27826,0.9178082191780822,1.4657534246575343,0.1095890410958904,0.273972602739726,125
2982,Thompson Sampling Algorithms for Mean-Variance Bandits,8,Thompson Sampling Algorithms for Mean-Variance Bandits,25,126,False,89,200,18,28,0,13,21,2,0,54,14574,0.8928571428571429,0.6428571428571429,7.142857142857143,0.75,35
2984,Towards Defending against Adversarial Examples via Attack-Invariant Features,8,Towards Defending against Adversarial Examples via Attack-Invariant Features,44,135,False,59,16,12,11,0,6,7,0,10,76,7626,4.0,2.0,1.4545454545454546,0.6363636363636364,27
2985,Towards Understanding Sharpness-Aware Minimization,8,Towards Understanding Sharpness-Aware Minimization,48,191,False,160,184,87,30,0,12,17,2,0,50,17130,1.6,2.9,6.133333333333334,0.5666666666666667,85
2986,Training Neural Networks for and by Interpolation,8,Training Neural Networks for and by Interpolation,61,0,False,286,340,24,37,73,19,34,0,24,49,15882,1.6486486486486487,1.2972972972972974,9.18918918918919,0.918918918918919,49
2987,Transformer Neural Processes: Uncertainty-Aware Meta Learning Via Sequence Modeling,8,Transformer Neural Processes Uncertainty-Aware Meta Learning Via Sequence Modeling,50,158,False,125,30,67,26,13,18,38,4,36,82,12225,1.9230769230769231,3.9615384615384617,1.1538461538461537,1.4615384615384615,50
2988,Uncertain Evidence in Probabilistic Models and Stochastic Simulators,8,Uncertain Evidence in Probabilistic Models and Stochastic Simulators,49,160,False,104,46,18,14,0,10,9,0,2,68,9672,3.5,1.4285714285714286,3.2857142857142856,0.6428571428571429,2
2989,Understanding Self-Predictive Learning for Reinforcement Learning,8,Understanding Self-Predictive Learning for Reinforcement Learning,34,177,False,106,168,35,26,27,16,12,3,0,65,15794,1.3076923076923077,1.3461538461538463,6.461538461538462,0.46153846153846156,15
2990,UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data,8,UniSpeech Unified Speech Representation Learning with Labeled and Unlabeled Data,44,91,False,71,12,6,11,7,5,6,2,10,80,7621,4.0,1.4545454545454546,1.0909090909090908,0.5454545454545454,86
2991,Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction for Few-Shot Classification,8,Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction for Few-Shot Classification,56,81,False,133,22,9,15,0,13,8,0,20,100,9141,3.7333333333333334,1.9333333333333333,1.4666666666666666,0.5333333333333333,18
2992,Utilizing Expert Features for Contrastive Learning of Time-Series Representations,8,Utilizing Expert Features for Contrastive Learning of Time-Series Representations,41,130,False,104,40,27,21,0,11,28,0,18,81,13223,1.9523809523809523,2.142857142857143,1.9047619047619047,1.3333333333333333,16
2993,Variational Implicit Processes,8,Variational Implicit Processes,113,105,False,136,94,16,19,2,12,20,0,10,30,13021,5.947368421052632,1.368421052631579,4.947368421052632,1.0526315789473684,62
2994,Voice Separation with an Unknown Number of Multiple Speakers,8,Voice Separation with an Unknown Number of Multiple Speakers,55,99,False,91,16,15,12,1,8,7,0,16,60,8185,4.583333333333333,2.5833333333333335,1.3333333333333333,0.5833333333333334,156
2995,What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?,8,What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization,86,1,False,0,0,3,26,0,12,5,0,0,97,12778,3.3076923076923075,0.11538461538461539,0.0,0.19230769230769232,108
2996,Which transformer architecture fits my data? A vocabulary bottleneck in self-attention,8,Which transformer architecture fits my data A vocabulary bottleneck in self-attention,56,158,False,122,113,22,29,0,10,17,9,10,85,18666,1.9310344827586208,1.103448275862069,3.896551724137931,0.5862068965517241,18
2997,"Yes, but Did It Work?: Evaluating Variational Inference",8,Yes but Did It Work Evaluating Variational Inference,31,73,False,65,28,37,16,0,8,17,0,0,52,9765,1.9375,2.3125,1.75,1.0625,114
2998,spred: Solving L1 Penalty with SGD,8,spred Solving L1 Penalty with SGD,36,133,True,81,84,43,16,0,8,19,0,6,33,9318,2.25,3.0625,5.25,1.1875,5
2999,A Convergence Theory for Deep Learning via Over-Parameterization,8,A Convergence Theory for Deep Learning via Over-Parameterization,68,178,False,105,152,28,53,0,17,17,3,0,64,25428,1.2830188679245282,0.5283018867924528,2.8679245283018866,0.32075471698113206,1290
3000,"A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural Networks Calibration",8,A Free Lunch From ANN Towards Efficient Accurate Spiking Neural Networks Calibration,40,163,True,115,44,9,13,0,12,13,0,18,85,8490,3.076923076923077,2.076923076923077,3.3846153846153846,1.0,131
3001,A Law of Robustness beyond Isoperimetry,8,A Law of Robustness beyond Isoperimetry,39,170,False,87,138,0,17,0,8,14,1,0,39,11153,2.2941176470588234,0.0,8.117647058823529,0.8235294117647058,2
3002,A Reductions Approach to Fair Classification,8,A Reductions Approach to Fair Classification,40,106,False,77,111,9,18,2,10,6,0,0,44,11583,2.2222222222222223,0.5,6.166666666666667,0.3333333333333333,940
3003,A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained Optimization,8,A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained Optimization,37,249,False,51,484,15,43,0,14,24,0,2,111,20564,0.8604651162790697,0.3953488372093023,11.255813953488373,0.5581395348837209,11
3004,A Unified Lottery Ticket Hypothesis for Graph Neural Networks,8,A Unified Lottery Ticket Hypothesis for Graph Neural Networks,74,214,False,90,6,36,16,20,7,14,0,10,61,11177,4.625,2.875,0.375,0.875,132
3005,AGENT: A Benchmark for Core Psychological Reasoning,8,AGENT A Benchmark for Core Psychological Reasoning,75,211,True,55,10,25,12,0,7,10,0,2,50,9210,6.25,2.25,0.8333333333333334,0.8333333333333334,46
3006,Accelerating Gossip SGD with Periodic Global Averaging,8,Accelerating Gossip SGD with Periodic Global Averaging,58,150,True,138,352,66,30,0,28,50,0,68,54,16611,1.9333333333333333,4.466666666666667,11.733333333333333,1.6666666666666667,32
3007,Active Learning on Attributed Graphs via Graph Cognizant Logistic Regression and Preemptive Query Generation,8,Active Learning on Attributed Graphs via Graph Cognizant Logistic Regression and Preemptive Query Generation,29,205,False,42,33,19,10,0,6,14,0,4,108,7663,2.9,2.3,3.3,1.4,10
3009,Adaptive Second Order Coresets for Data-efficient Machine Learning,8,Adaptive Second Order Coresets for Data-efficient Machine Learning,43,1,False,58,135,37,22,3,9,21,0,18,66,12815,1.9545454545454546,2.5,6.136363636363637,0.9545454545454546,44
3010,Adversarial Cheap Talk,8,Adversarial Cheap Talk,52,193,False,99,15,55,25,2,16,15,0,10,22,9532,2.08,2.6,0.6,0.6,8
3011,Adversarial Time-to-Event Modeling,8,Adversarial Time-to-Event Modeling,52,126,False,78,36,52,14,9,15,2,0,18,34,8706,3.7142857142857144,5.0,2.5714285714285716,0.14285714285714285,83
3012,"Align, then memorise: the dynamics of learning with feedback alignment",8,Align then memorise the dynamics of learning with feedback alignment,67,273,False,54,74,46,17,14,11,12,0,0,69,10635,3.9411764705882355,2.7058823529411766,4.352941176470588,0.7058823529411765,25
3014,An exact solver for the Weston-Watkins SVM subproblem,8,An exact solver for the Weston-Watkins SVM subproblem,48,85,True,115,261,9,33,0,7,15,9,18,53,18419,1.4545454545454546,0.8181818181818182,7.909090909090909,0.45454545454545453,2
3015,Annealed Flow Transport Monte Carlo,8,Annealed Flow Transport Monte Carlo,97,160,False,128,798,42,70,41,15,37,6,0,35,36502,1.3857142857142857,0.6,11.4,0.5285714285714286,47
3016,Architecture-Agnostic Masked Image Modeling - From ViT back to CNN,8,Architecture-Agnostic Masked Image Modeling - From ViT back to CNN,93,141,True,315,25,56,19,13,12,17,0,0,66,13889,4.894736842105263,2.9473684210526314,1.3157894736842106,0.8947368421052632,29
3019,Batch Value-function Approximation with Only Realizability,8,Batch Value-function Approximation with Only Realizability,51,121,False,141,100,7,24,16,19,35,8,2,58,16255,2.125,0.375,4.166666666666667,1.4583333333333333,98
3020,Bayesian Nonparametrics for Offline Skill Discovery,8,Bayesian Nonparametrics for Offline Skill Discovery,70,182,False,122,42,29,16,2,11,16,0,6,51,10572,4.375,2.1875,2.625,1.0,7
3021,Benefits of Overparameterized Convolutional Residual Networks: Function Approximation under Smoothness Constraint,8,Benefits of Overparameterized Convolutional Residual Networks Function Approximation under Smoothness Constraint,69,136,False,112,394,18,41,9,17,14,0,2,112,17172,1.6829268292682926,0.4878048780487805,9.609756097560975,0.34146341463414637,8
3022,Bidirectional Model-based Policy Optimization,8,Bidirectional Model-based Policy Optimization,48,138,False,95,56,21,14,0,13,8,9,10,45,9117,3.4285714285714284,2.2142857142857144,4.0,0.5714285714285714,43
3023,Blended Conditional Gradients: the unconditioning of conditional gradients,8,Blended Conditional Gradients the unconditioning of conditional gradients,27,159,False,61,101,27,33,5,9,15,0,2,73,13218,0.8181818181818182,0.8787878787878788,3.0606060606060606,0.45454545454545453,24
3024,Branching Reinforcement Learning,8,Branching Reinforcement Learning,22,151,False,65,208,10,37,5,13,15,11,0,32,19190,0.5945945945945946,0.2702702702702703,5.621621621621622,0.40540540540540543,0
3026,CURL: Contrastive Unsupervised Representations for Reinforcement Learning,8,CURL Contrastive Unsupervised Representations for Reinforcement Learning,65,94,True,169,8,33,20,0,16,21,0,14,72,13466,3.25,2.35,0.4,1.05,856
3028,Channel Equilibrium Networks for Learning Deep Representation,8,Channel Equilibrium Networks for Learning Deep Representation,48,181,False,183,86,58,19,0,14,9,0,20,61,12797,2.526315789473684,4.105263157894737,4.526315789473684,0.47368421052631576,15
3029,Clinician-in-the-Loop Decision Making: Reinforcement Learning with Near-Optimal Set-Valued Policies,8,Clinician-in-the-Loop Decision Making Reinforcement Learning with Near-Optimal Set-Valued Policies,31,140,False,84,67,38,18,4,16,13,0,6,98,11625,1.7222222222222223,2.4444444444444446,3.7222222222222223,0.7222222222222222,21
3030,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,8,Collaboration of Experts Achieving 80 Top-1 Accuracy on ImageNet with 100M FLOPs,54,143,False,150,22,43,17,0,7,19,10,20,81,10404,3.176470588235294,3.7058823529411766,1.2941176470588236,1.1176470588235294,7
3031,Comparing dynamics: deep neural networks versus glassy systems,8,Comparing dynamics deep neural networks versus glassy systems,47,166,False,60,8,23,10,0,5,2,0,0,61,7391,4.7,2.3,0.8,0.2,105
3032,Comprehensive Analysis of Negative Sampling in Knowledge Graph Representation Learning,8,Comprehensive Analysis of Negative Sampling in Knowledge Graph Representation Learning,24,163,False,84,70,17,15,15,16,34,10,10,86,9147,1.6,1.8,4.666666666666667,2.2666666666666666,11
3033,Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference Setting,8,Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference Setting,63,249,False,133,26,28,20,0,16,4,0,12,77,14656,3.15,2.0,1.3,0.2,17
3034,Constrained Discrete Black-Box Optimization using Mixed-Integer Programming,8,Constrained Discrete Black-Box Optimization using Mixed-Integer Programming,78,166,False,240,28,240,28,0,28,58,12,12,75,16797,2.7857142857142856,9.0,1.0,2.0714285714285716,13
3035,Contextual Memory Trees,8,Contextual Memory Trees,44,128,False,43,48,26,18,1,8,23,1,16,23,11496,2.4444444444444446,2.3333333333333335,2.6666666666666665,1.2777777777777777,8
3036,Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning,8,Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning,59,140,False,128,244,42,39,0,17,19,0,8,83,21078,1.5128205128205128,1.2820512820512822,6.256410256410256,0.48717948717948717,28
3037,Cooperation in the Latent Space: The Benefits of Adding Mixture Components in Variational Autoencoders,8,Cooperation in the Latent Space The Benefits of Adding Mixture Components in Variational Autoencoders,62,174,False,390,114,42,16,0,23,22,10,38,101,9826,3.875,5.0,7.125,1.375,5
3038,"CountSketches, Feature Hashing and the Median of Three",8,CountSketches Feature Hashing and the Median of Three,22,260,False,26,36,42,14,8,5,5,0,2,54,8047,1.5714285714285714,3.142857142857143,2.5714285714285716,0.35714285714285715,7
3039,DRACO: Byzantine-resilient Distributed Training via Redundant Gradients,8,DRACO Byzantine-resilient Distributed Training via Redundant Gradients,49,175,True,49,81,30,23,13,8,5,0,14,70,11255,2.130434782608696,1.9130434782608696,3.5217391304347827,0.21739130434782608,216
3040,Data-Efficient Image Recognition with Contrastive Predictive Coding,8,Data-Efficient Image Recognition with Contrastive Predictive Coding,105,122,False,186,4,9,13,20,8,7,0,8,67,8831,8.076923076923077,1.3076923076923077,0.3076923076923077,0.5384615384615384,1290
3041,Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings,8,Decentralized Submodular Maximization Bridging Discrete and Continuous Settings,60,167,False,94,196,6,33,0,9,9,1,0,79,16379,1.8181818181818181,0.18181818181818182,5.9393939393939394,0.2727272727272727,28
3042,Deep k-NN for Noisy Labels,8,Deep k-NN for Noisy Labels,48,68,True,93,54,188,10,0,12,21,0,6,26,6195,4.8,19.4,5.4,2.1,66
3043,Delving into Deep Imbalanced Regression,8,Delving into Deep Imbalanced Regression,46,157,False,88,178,43,23,0,10,23,0,40,39,17114,2.0,3.608695652173913,7.739130434782608,1.0,170
3044,Detection of Signal in the Spiked Rectangular Models,8,Detection of Signal in the Spiked Rectangular Models,28,102,False,65,252,16,38,0,9,21,5,0,52,16111,0.7368421052631579,0.42105263157894735,6.631578947368421,0.5526315789473685,8
3045,Differentially Private Community Detection for Stochastic Block Models,8,Differentially Private Community Detection for Stochastic Block Models,41,213,False,72,268,17,39,0,16,8,0,4,70,20094,1.0512820512820513,0.5384615384615384,6.871794871794871,0.20512820512820512,8
3046,Dimensionality Reduction for the Sum-of-Distances Metric,8,Dimensionality Reduction for the Sum-of-Distances Metric,32,219,False,121,369,6,27,1,21,20,0,0,56,16082,1.1851851851851851,0.2222222222222222,13.666666666666666,0.7407407407407407,8
3047,Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms,8,Discrete-Continuous Mixtures in Probabilistic Programming Generalized Semantics and Inference Algorithms,40,113,False,69,33,11,14,6,14,9,2,0,104,10643,2.857142857142857,0.7857142857142857,2.357142857142857,0.6428571428571429,24
3048,Distributed Nonparametric Regression under Communication Constraints,8,Distributed Nonparametric Regression under Communication Constraints,20,158,False,28,130,2,21,0,6,6,0,0,68,7707,0.9523809523809523,0.09523809523809523,6.190476190476191,0.2857142857142857,24
3049,Do Outliers Ruin Collaboration?,8,Do Outliers Ruin Collaboration,13,91,False,19,25,0,10,2,5,5,0,0,30,5645,1.3,0.0,2.5,0.5,12
3050,DoubleSqueeze: Parallel Stochastic Gradient Descent with Double-Pass Error-Compensated Compression,8,DoubleSqueeze Parallel Stochastic Gradient Descent with Double-Pass Error-Compensated Compression,53,251,False,117,74,18,14,7,8,9,0,0,97,7977,3.7857142857142856,1.2857142857142858,5.285714285714286,0.6428571428571429,196
3055,Equivariant Flows: exact likelihood generative learning for symmetric densities,8,Equivariant Flows exact likelihood generative learning for symmetric densities,50,150,False,55,44,33,18,15,12,21,0,4,78,9445,2.7777777777777777,2.0555555555555554,2.4444444444444446,1.1666666666666667,182
3057,Exact Optimal Accelerated Complexity for Fixed-Point Iterations,8,Exact Optimal Accelerated Complexity for Fixed-Point Iterations,108,94,False,145,256,40,38,9,14,23,0,0,63,18978,2.8421052631578947,1.0526315789473684,6.7368421052631575,0.6052631578947368,16
3059,FOCUS: Familiar Objects in Common and Uncommon Settings,8,FOCUS Familiar Objects in Common and Uncommon Settings,35,210,True,81,10,80,23,2,9,8,0,10,54,9582,1.5217391304347827,3.9130434782608696,0.43478260869565216,0.34782608695652173,6
3060,Fairwashing: the risk of rationalization,8,Fairwashing the risk of rationalization,41,178,False,42,10,43,13,10,7,9,0,4,39,7938,3.1538461538461537,3.6153846153846154,0.7692307692307693,0.6923076923076923,123
3061,Fast Rates for a kNN Classifier Robust to Unknown Asymmetric Label Noise,8,Fast Rates for a kNN Classifier Robust to Unknown Asymmetric Label Noise,28,169,False,61,103,3,11,0,9,6,1,0,72,8127,2.5454545454545454,0.2727272727272727,9.363636363636363,0.5454545454545454,24
3062,Faster Stochastic Alternating Direction Method of Multipliers for Nonconvex Optimization,8,Faster Stochastic Alternating Direction Method of Multipliers for Nonconvex Optimization,41,200,False,60,412,12,43,0,9,12,0,4,88,22379,0.9534883720930233,0.37209302325581395,9.581395348837209,0.27906976744186046,28
3064,Finding Influential Training Samples for Gradient Boosted Decision Trees,8,Finding Influential Training Samples for Gradient Boosted Decision Trees,24,151,False,49,42,10,10,0,7,8,5,10,72,7077,2.4,2.0,4.2,0.8,43
3066,Forward Operator Estimation in Generative Models with Kernel Transfer Operators,8,Forward Operator Estimation in Generative Models with Kernel Transfer Operators,57,133,False,147,38,130,29,7,18,5,0,4,79,10230,1.9655172413793103,4.620689655172414,1.3103448275862069,0.1724137931034483,3
3067,Frustratingly Simple Few-Shot Object Detection,8,Frustratingly Simple Few-Shot Object Detection,31,144,False,101,6,43,12,0,7,5,1,16,46,8870,2.5833333333333335,4.916666666666667,0.5,0.4166666666666667,420
3068,GAIN: Missing Data Imputation using Generative Adversarial Nets,8,GAIN Missing Data Imputation using Generative Adversarial Nets,34,165,True,56,40,9,10,0,8,10,0,8,62,6247,3.4,1.7,4.0,1.0,713
3069,Game Theoretic Optimization via Gradient-based Nikaido-Isoda Function,8,Game Theoretic Optimization via Gradient-based Nikaido-Isoda Function,43,139,False,67,192,43,12,4,11,11,0,0,69,8410,3.5833333333333335,3.5833333333333335,16.0,0.9166666666666666,18
3070,Generalization and Representational Limits of Graph Neural Networks,8,Generalization and Representational Limits of Graph Neural Networks,58,0,False,176,82,24,22,9,6,3,0,2,67,11874,2.6363636363636362,1.1818181818181819,3.727272727272727,0.13636363636363635,251
3071,Generating 3D Molecules for Target Protein Binding,8,Generating 3D Molecules for Target Protein Binding,58,189,False,99,60,15,13,0,9,2,4,4,50,8544,4.461538461538462,1.4615384615384615,4.615384615384615,0.15384615384615385,70
3073,Goal Misgeneralization in Deep Reinforcement Learning,8,Goal Misgeneralization in Deep Reinforcement Learning,65,91,False,144,7,36,16,15,11,8,2,4,53,9685,4.0625,2.5,0.4375,0.5,47
3074,Graph Filtration Learning,8,Graph Filtration Learning,44,1,False,81,42,12,10,0,10,4,0,4,25,7297,4.4,1.6,4.2,0.4,71
3076,Hardness and Algorithms for Robust and Sparse Optimization,8,Hardness and Algorithms for Robust and Sparse Optimization,66,244,False,69,45,4,25,5,9,5,0,2,58,13700,2.64,0.24,1.8,0.2,5
3077,High-Dimensional Experimental Design and Kernel Bandits,8,High-Dimensional Experimental Design and Kernel Bandits,31,233,False,56,316,7,34,4,14,16,0,0,55,15775,0.9117647058823529,0.20588235294117646,9.294117647058824,0.47058823529411764,50
3078,How Powerful are Spectral Graph Neural Networks,8,How Powerful are Spectral Graph Neural Networks,47,195,False,124,218,21,22,0,22,35,0,20,47,12746,2.1363636363636362,1.8636363636363635,9.909090909090908,1.5909090909090908,93
3079,HyperImpute: Generalized Iterative Imputation with Automatic Model Selection,8,HyperImpute Generalized Iterative Imputation with Automatic Model Selection,75,167,False,84,10,50,22,2,11,19,0,14,75,11057,3.409090909090909,2.909090909090909,0.45454545454545453,0.8636363636363636,32
3080,Imitating Latent Policies from Observation,8,Imitating Latent Policies from Observation,34,113,False,31,14,31,11,0,7,12,12,0,42,7250,3.090909090909091,2.8181818181818183,1.2727272727272727,1.0909090909090908,111
3081,Importance Sampling Policy Evaluation with an Estimated Behavior Policy,8,Importance Sampling Policy Evaluation with an Estimated Behavior Policy,50,177,False,56,59,36,20,9,15,11,0,2,71,12128,2.5,1.9,2.95,0.55,56
3082,Improved Zeroth-Order Variance Reduced Algorithms and Analysis for Nonconvex Optimization,8,Improved Zeroth-Order Variance Reduced Algorithms and Analysis for Nonconvex Optimization,44,191,False,194,430,46,44,0,16,31,0,10,89,20995,1.0,1.2727272727272727,9.772727272727273,0.7045454545454546,54
3083,Improving Out-of-Distribution Robustness via Selective Augmentation,8,Improving Out-of-Distribution Robustness via Selective Augmentation,75,179,False,152,172,9,31,5,11,18,9,40,67,16998,2.4193548387096775,1.5806451612903225,5.548387096774194,0.5806451612903226,136
3084,Incidence Networks for Geometric Deep Learning,8,Incidence Networks for Geometric Deep Learning,44,95,False,52,228,34,15,14,22,22,8,4,46,10284,2.933333333333333,2.533333333333333,15.2,1.4666666666666666,24
3085,Influence-Augmented Local Simulators: A Scalable Solution for Fast Deep RL in Large Networked Systems,8,Influence-Augmented Local Simulators A Scalable Solution for Fast Deep RL in Large Networked Systems,57,128,True,94,72,38,19,8,14,9,4,0,100,11867,3.0,2.0,3.789473684210526,0.47368421052631576,2
3086,Integrating Prior Knowledge in Contrastive Learning with Kernel,8,Integrating Prior Knowledge in Contrastive Learning with Kernel,62,161,False,163,104,8,28,32,11,26,5,28,63,16848,2.2142857142857144,1.2857142857142858,3.7142857142857144,0.9285714285714286,3
3087,Interpreting Embedding Models of Knowledge Bases: A Pedagogical Approach,8,Interpreting Embedding Models of Knowledge Bases A Pedagogical Approach,42,97,False,97,0,0,8,2,6,8,0,8,71,6163,5.25,1.0,0.0,1.0,19
3089,Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks,8,Just How Toxic is Data Poisoning A Unified Benchmark for Backdoor and Data Poisoning Attacks,51,153,False,107,8,22,17,32,13,27,4,52,92,11004,3.0,4.352941176470588,0.47058823529411764,1.588235294117647,128
3090,Knowing The What But Not The Where in Bayesian Optimization,8,Knowing The What But Not The Where in Bayesian Optimization,49,144,False,89,58,68,16,11,8,13,1,6,59,9366,3.0625,4.625,3.625,0.8125,27
3091,Label Ranking through Nonparametric Regression,8,Label Ranking through Nonparametric Regression,95,147,False,228,148,11,51,29,10,13,5,14,46,24437,1.8627450980392157,0.49019607843137253,2.9019607843137254,0.2549019607843137,4
3092,Latent Programmer: Discrete Latent Codes for Program Synthesis,8,Latent Programmer Discrete Latent Codes for Program Synthesis,55,153,False,137,29,28,17,9,11,8,1,10,61,9555,3.235294117647059,2.235294117647059,1.7058823529411764,0.47058823529411764,16
3093,Learning Augmented Binary Search Trees,8,Learning Augmented Binary Search Trees,24,178,False,12,0,3,15,0,6,12,4,2,38,7256,1.6,0.3333333333333333,0.0,0.8,12
3094,Learning Diverse-Structured Networks for Adversarial Robustness,8,Learning Diverse-Structured Networks for Adversarial Robustness,76,190,False,127,62,24,15,0,11,13,0,14,63,10271,5.066666666666666,2.533333333333333,4.133333333333334,0.8666666666666667,14
3096,Learning Novel Policies For Tasks,8,Learning Novel Policies For Tasks,36,167,False,37,16,25,12,0,13,6,5,12,33,7968,3.0,3.0833333333333335,1.3333333333333333,0.5,31
3097,Learning Structured Latent Factors from Dependent Data: A Generative Model Framework from Information-Theoretic Perspective,8,Learning Structured Latent Factors from Dependent Data A Generative Model Framework from Information-Theoretic Perspective,49,135,False,62,102,41,19,0,9,19,6,10,122,10952,2.5789473684210527,2.6842105263157894,5.368421052631579,1.0,4
3098,Learning for Dose Allocation in Adaptive Clinical Trials with Safety Constraints,8,Learning for Dose Allocation in Adaptive Clinical Trials with Safety Constraints,43,153,False,87,64,30,22,0,21,6,6,22,80,11968,1.9545454545454546,2.3636363636363638,2.909090909090909,0.2727272727272727,20
3099,Learning to Explore with Meta-Policy Gradient,8,Learning to Explore with Meta-Policy Gradient,32,121,False,35,14,27,10,0,7,8,0,4,45,6170,3.2,3.1,1.4,0.8,50
3100,Learning to Separate Voices by Spatial Regions,8,Learning to Separate Voices by Spatial Regions,36,195,False,98,71,61,11,0,28,28,0,6,46,7590,3.272727272727273,6.090909090909091,6.454545454545454,2.5454545454545454,2
3101,Leveraged Weighted Loss for Partial Label Learning,8,Leveraged Weighted Loss for Partial Label Learning,53,170,False,129,104,12,15,0,9,10,10,16,50,10633,3.533333333333333,1.8666666666666667,6.933333333333334,0.6666666666666666,66
3103,Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards,8,Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards,43,191,False,36,104,33,24,0,13,4,0,4,78,12209,1.7916666666666667,1.5416666666666667,4.333333333333333,0.16666666666666666,13
3104,Low-Rank Bottleneck in Multi-head Attention Models,8,Low-Rank Bottleneck in Multi-head Attention Models,33,166,False,102,68,16,17,4,8,8,0,6,50,8743,1.9411764705882353,1.2941176470588236,4.0,0.47058823529411764,63
3105,ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation,8,ME-Net Towards Effective Adversarial Robustness with Matrix Estimation,37,141,True,129,5,43,22,0,18,21,2,54,70,13312,1.6818181818181819,4.409090909090909,0.22727272727272727,0.9545454545454546,145
3107,Measuring Representational Robustness of Neural Networks Through Shared Invariances,8,Measuring Representational Robustness of Neural Networks Through Shared Invariances,45,148,False,116,48,94,15,4,24,28,0,12,83,9695,3.0,7.066666666666666,3.2,1.8666666666666667,10
3108,Meta-Learning Neural Bloom Filters,8,Meta-Learning Neural Bloom Filters,39,125,False,198,4,36,14,0,30,24,0,12,34,10366,2.7857142857142856,3.4285714285714284,0.2857142857142857,1.7142857142857142,31
3109,Minimax Weight and Q-Function Learning for Off-Policy Evaluation,8,Minimax Weight and Q-Function Learning for Off-Policy Evaluation,58,140,False,195,250,11,29,14,17,20,0,6,64,16382,2.0,0.5862068965517241,8.620689655172415,0.6896551724137931,158
3110,MoNet3D: Towards Accurate Monocular 3D Object Localization in Real Time,8,MoNet3D Towards Accurate Monocular 3D Object Localization in Real Time,34,100,False,42,14,26,10,0,8,8,3,4,70,6383,3.4,3.0,1.4,0.8,12
3111,Model-based Reinforcement Learning for Continuous Control with Posterior Sampling,8,Model-based Reinforcement Learning for Continuous Control with Posterior Sampling,33,213,False,110,64,6,15,11,11,12,0,8,81,9215,2.2,0.9333333333333333,4.266666666666667,0.8,12
3112,Monarch: Expressive Structured Matrices for Efficient and Accurate Training,8,Monarch Expressive Structured Matrices for Efficient and Accurate Training,124,259,False,255,85,21,37,16,15,23,12,26,74,20250,3.3513513513513513,1.2702702702702702,2.2972972972972974,0.6216216216216216,49
3113,Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium Meta-Solvers,8,Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium Meta-Solvers,85,94,False,89,112,19,28,4,19,30,3,4,77,19221,3.0357142857142856,0.8214285714285714,4.0,1.0714285714285714,29
3114,Multi-scale Feature Learning Dynamics: Insights for Double Descent,8,Multi-scale Feature Learning Dynamics Insights for Double Descent,73,205,False,244,356,28,24,28,14,24,0,0,65,12865,3.0416666666666665,1.1666666666666667,14.833333333333334,1.0,15
3116,Nearly Linear Row Sampling Algorithm for Quantile Regression,8,Nearly Linear Row Sampling Algorithm for Quantile Regression,48,113,False,85,91,26,20,9,12,12,0,0,60,10685,2.4,1.3,4.55,0.6,7
3117,Neural Inverse Knitting: From Images to Manufacturing Instructions,8,Neural Inverse Knitting From Images to Manufacturing Instructions,47,1,False,64,22,38,15,6,19,8,0,6,65,9525,3.1333333333333333,2.933333333333333,1.4666666666666666,0.5333333333333333,23
3119,No-Regret and Incentive-Compatible Online Learning,8,No-Regret and Incentive-Compatible Online Learning,25,152,False,59,56,27,23,1,13,7,0,0,50,9905,1.0869565217391304,1.173913043478261,2.4347826086956523,0.30434782608695654,10
3120,Nonparametric Embeddings of Sparse High-Order Interaction Events,8,Nonparametric Embeddings of Sparse High-Order Interaction Events,59,162,False,200,105,18,17,0,13,5,0,0,64,10487,3.4705882352941178,1.0588235294117647,6.176470588235294,0.29411764705882354,3
3121,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,8,Obfuscated Gradients Give a False Sense of Security Circumventing Defenses to Adversarial Examples,46,1,False,97,6,6,12,32,10,16,11,2,98,8900,3.8333333333333335,0.6666666666666666,0.5,1.3333333333333333,2852
3122,Offline Reinforcement Learning with Pseudometric Learning,8,Offline Reinforcement Learning with Pseudometric Learning,77,145,False,164,50,42,17,5,10,10,0,2,57,9908,4.529411764705882,2.588235294117647,2.9411764705882355,0.5882352941176471,34
3123,On Energy-Based Models with Overparametrized Shallow Neural Networks,8,On Energy-Based Models with Overparametrized Shallow Neural Networks,65,145,False,180,428,42,43,7,14,13,0,0,68,21215,1.5116279069767442,0.9767441860465116,9.953488372093023,0.3023255813953488,7
3124,On Matching Pursuit and Coordinate Descent,8,On Matching Pursuit and Coordinate Descent,50,109,False,75,112,4,19,17,9,8,3,0,42,10929,2.6315789473684212,0.21052631578947367,5.894736842105263,0.42105263157894735,21
3125,On the Complexity of Bayesian Generalization,8,On the Complexity of Bayesian Generalization,86,208,False,96,18,39,21,19,9,18,0,2,44,10984,4.095238095238095,1.9523809523809523,0.8571428571428571,0.8571428571428571,1
3126,On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups,8,On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups,25,1,False,40,165,4,14,7,12,13,9,2,104,11376,1.7857142857142858,0.42857142857142855,11.785714285714286,0.9285714285714286,430
3127,On the Power of Over-parametrization in Neural Networks with Quadratic Activation,8,On the Power of Over-parametrization in Neural Networks with Quadratic Activation,67,1,False,59,80,0,11,2,7,6,0,0,81,7204,6.090909090909091,0.0,7.2727272727272725,0.5454545454545454,247
3128,On the power of foundation models,8,On the power of foundation models,83,207,False,83,5,0,14,0,8,13,0,0,33,9880,5.928571428571429,0.0,0.35714285714285715,0.9285714285714286,17
3129,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,8,Online Convolutional Sparse Coding with Sample-Dependent Dictionary,42,114,False,104,74,38,11,0,10,18,3,10,67,6931,3.8181818181818183,4.363636363636363,6.7272727272727275,1.6363636363636365,5
3130,Oops I Took A Gradient: Scalable Sampling for Discrete Distributions,8,Oops I Took A Gradient Scalable Sampling for Discrete Distributions,47,107,False,143,108,82,22,6,20,25,1,4,67,12115,2.1363636363636362,3.909090909090909,4.909090909090909,1.1363636363636365,69
3131,Optimal Kronecker-Sum Approximation of Real Time Recurrent Learning,8,Optimal Kronecker-Sum Approximation of Real Time Recurrent Learning,38,143,False,52,34,36,20,0,9,18,14,8,67,15204,1.9,2.2,1.7,0.9,19
3132,Optimistic bounds for multi-output prediction,8,Optimistic bounds for multi-output prediction,46,126,False,61,193,0,28,0,10,8,3,0,45,15427,1.6428571428571428,0.0,6.892857142857143,0.2857142857142857,8
3133,Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation,8,Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation,38,147,False,113,14,31,12,27,8,12,0,24,71,9025,3.1666666666666665,4.583333333333333,1.1666666666666667,1.0,73
3134,PAC-Bayesian Offline Contextual Bandits With Guarantees,8,PAC-Bayesian Offline Contextual Bandits With Guarantees,54,119,True,85,130,11,23,8,10,17,3,2,55,13621,2.347826086956522,0.5652173913043478,5.6521739130434785,0.7391304347826086,10
3135,PLATON: Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance,8,PLATON Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance,62,177,True,161,34,11,24,3,12,14,0,18,88,8743,2.5833333333333335,1.2083333333333333,1.4166666666666667,0.5833333333333334,48
3136,Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization,8,Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization,41,140,False,176,88,36,14,0,22,32,0,48,83,8676,2.9285714285714284,6.0,6.285714285714286,2.2857142857142856,124
3137,Performative Prediction,8,Performative Prediction,42,152,False,34,108,14,32,15,14,20,0,2,23,13407,1.3125,0.5,3.375,0.625,233
3138,PixelTransformer: Sample Conditioned Signal Generation,8,PixelTransformer Sample Conditioned Signal Generation,44,103,False,39,20,28,10,2,8,6,0,0,53,6759,4.4,2.8,2.0,0.6,10
3139,Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games,8,Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games,54,181,False,115,32,0,33,4,6,5,0,2,79,20617,1.6363636363636365,0.06060606060606061,0.9696969696969697,0.15151515151515152,14
3140,Predicting Choice with Set-Dependent Aggregation,8,Predicting Choice with Set-Dependent Aggregation,50,126,False,121,39,19,24,0,10,14,0,10,48,12930,2.0833333333333335,1.2083333333333333,1.625,0.5833333333333334,16
3141,Principled Offline RL in the Presence of Rich Exogenous Information,8,Principled Offline RL in the Presence of Rich Exogenous Information,58,195,True,151,54,68,28,1,11,23,2,12,67,16533,2.0714285714285716,2.857142857142857,1.9285714285714286,0.8214285714285714,4
3142,Probabilistic Generating Circuits,8,Probabilistic Generating Circuits,48,137,False,96,54,11,15,0,10,13,0,0,33,9869,3.2,0.7333333333333333,3.6,0.8666666666666667,19
3145,ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication Acceleration! Finally!,8,ProxSkip Yes Local Gradient Steps Provably Lead to Communication Acceleration Finally,61,223,False,129,267,13,20,0,24,42,4,6,88,11612,3.05,0.95,13.35,2.1,100
3146,Quantifying and Reducing Bias in Maximum Likelihood Estimation of Structured Anomalies,8,Quantifying and Reducing Bias in Maximum Likelihood Estimation of Structured Anomalies,80,244,False,198,468,52,38,0,28,28,0,0,86,18829,2.1052631578947367,1.368421052631579,12.31578947368421,0.7368421052631579,3
3147,REPAINT: Knowledge Transfer in Deep Reinforcement Learning,8,REPAINT Knowledge Transfer in Deep Reinforcement Learning,58,136,True,132,162,61,24,7,13,17,0,12,57,15996,2.4166666666666665,3.0416666666666665,6.75,0.7083333333333334,20
3148,Random extrapolation for primal-dual coordinate descent,8,Random extrapolation for primal-dual coordinate descent,37,144,False,137,379,31,37,0,9,13,0,2,55,20153,1.0,0.8918918918918919,10.243243243243244,0.35135135135135137,15
3149,Real-Time Optimisation for Online Learning in Auctions,8,Real-Time Optimisation for Online Learning in Auctions,33,104,False,86,170,12,20,15,11,15,0,2,54,11933,1.65,0.7,8.5,0.75,5
3151,Reinforcement Learning with Prototypical Representations,8,Reinforcement Learning with Prototypical Representations,59,140,False,150,18,45,21,15,17,22,0,2,56,12480,2.8095238095238093,2.238095238095238,0.8571428571428571,1.0476190476190477,167
3152,Representing Unordered Data Using Multiset Automata and Complex Numbers,8,Representing Unordered Data Using Multiset Automata and Complex Numbers,13,108,False,61,88,6,13,3,10,8,0,2,71,7469,1.0,0.6153846153846154,6.769230769230769,0.6153846153846154,0
3153,Retroformer: Pushing the Limits of Interpretable End-to-end Retrosynthesis Transformer,8,Retroformer Pushing the Limits of Interpretable End-to-end Retrosynthesis Transformer,41,151,False,74,12,25,16,9,10,11,0,10,85,7349,2.5625,2.1875,0.75,0.6875,6
3155,Robust Inference for High-Dimensional Linear Models via Residual Randomization,8,Robust Inference for High-Dimensional Linear Models via Residual Randomization,34,117,False,129,276,48,37,6,11,12,0,2,78,14296,0.918918918918919,1.3513513513513513,7.45945945945946,0.32432432432432434,4
3156,Robust alignment of cross-session recordings of neural population activity by behaviour via unsupervised domain adaptation,8,Robust alignment of cross-session recordings of neural population activity by behaviour via unsupervised domain adaptation,20,197,False,68,8,18,15,0,9,5,0,0,122,7180,1.3333333333333333,1.2,0.5333333333333333,0.3333333333333333,15
3158,STRODE: Stochastic Boundary Ordinary Differential Equation,8,STRODE Stochastic Boundary Ordinary Differential Equation,32,187,True,36,120,18,15,3,10,15,7,0,57,8307,2.1333333333333333,1.2,8.0,1.0,4
3159,Sample-Optimal PAC Learning of Halfspaces with Malicious Noise,8,Sample-Optimal PAC Learning of Halfspaces with Malicious Noise,41,172,True,138,160,0,30,0,8,20,1,2,62,13607,1.3666666666666667,0.06666666666666667,5.333333333333333,0.6666666666666666,6
3160,Scalable Metropolis-Hastings for Exact Bayesian Inference with Large Datasets,8,Scalable Metropolis-Hastings for Exact Bayesian Inference with Large Datasets,47,157,False,89,254,29,32,0,11,15,2,2,77,14273,1.46875,0.96875,7.9375,0.46875,14
3161,Score matching enables causal discovery of nonlinear additive noise models,8,Score matching enables causal discovery of nonlinear additive noise models,48,84,False,54,33,0,13,5,9,7,0,28,74,7399,3.6923076923076925,2.1538461538461537,2.5384615384615383,0.5384615384615384,38
3162,Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings,8,Self-Consistent Trajectory Autoencoder Hierarchical Reinforcement Learning with Trajectory Embeddings,34,185,False,44,26,21,11,12,11,8,0,0,101,7537,3.090909090909091,1.9090909090909092,2.3636363636363638,0.7272727272727273,132
3164,ShaRF: Shape-conditioned Radiance Fields from a Single View,8,ShaRF Shape-conditioned Radiance Fields from a Single View,59,185,False,164,36,24,11,52,6,18,2,12,58,8322,5.363636363636363,3.272727272727273,3.272727272727273,1.6363636363636365,92
3165,Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network,8,Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network,43,132,False,122,14,29,13,0,9,12,0,6,101,8752,3.3076923076923075,2.6923076923076925,1.0769230769230769,0.9230769230769231,49
3166,Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context of Melanoma Classification,8,Skin Deep Unlearning Artefact and Instrument Debiasing in the Context of Melanoma Classification,46,130,False,165,12,70,19,0,13,11,5,16,96,12081,2.4210526315789473,4.526315789473684,0.631578947368421,0.5789473684210527,10
3167,Solving high-dimensional parabolic PDEs using the tensor train format,8,Solving high-dimensional parabolic PDEs using the tensor train format,71,126,False,64,129,31,18,0,10,13,0,20,69,12190,3.9444444444444446,2.8333333333333335,7.166666666666667,0.7222222222222222,33
3168,Spectral Approximate Inference,8,Spectral Approximate Inference,42,166,False,34,68,19,13,0,10,10,0,0,30,7909,3.230769230769231,1.4615384615384615,5.230769230769231,0.7692307692307693,2
3169,Stable and Fair Classification,8,Stable and Fair Classification,78,198,False,83,108,4,25,8,8,10,0,2,30,9748,3.12,0.24,4.32,0.4,61
3170,Stochastic Blockmodels meet Graph Neural Networks,8,Stochastic Blockmodels meet Graph Neural Networks,34,191,False,68,2,18,11,0,8,11,2,10,49,7866,3.090909090909091,2.5454545454545454,0.18181818181818182,1.0,68
3171,Stochastic Rising Bandits,8,Stochastic Rising Bandits,39,149,False,135,276,24,36,4,13,16,0,4,25,15748,1.0833333333333333,0.7777777777777778,7.666666666666667,0.4444444444444444,8
3172,Streaming Algorithms for Support-Aware Histograms,8,Streaming Algorithms for Support-Aware Histograms,32,214,False,26,88,39,20,42,17,12,0,2,49,12545,1.6,2.05,4.4,0.6,1
3173,Structured Prediction with Partial Labelling through the Infimum Loss,8,Structured Prediction with Partial Labelling through the Infimum Loss,59,0,False,142,90,32,28,12,14,20,0,0,69,16419,2.107142857142857,1.1428571428571428,3.2142857142857144,0.7142857142857143,34
3174,Super-efficiency of automatic differentiation for functions defined as a minimum,8,Super-efficiency of automatic differentiation for functions defined as a minimum,30,235,False,68,134,21,31,0,11,23,0,2,80,10484,0.967741935483871,0.7419354838709677,4.32258064516129,0.7419354838709677,37
3177,Tensor denoising and completion based on ordinal observations,8,Tensor denoising and completion based on ordinal observations,48,133,False,114,180,18,32,0,13,15,0,6,61,13526,1.5,0.75,5.625,0.46875,15
3178,The Effect of Network Width on Stochastic Gradient Descent and Generalization: an Empirical Study,8,The Effect of Network Width on Stochastic Gradient Descent and Generalization an Empirical Study,42,160,False,55,10,143,17,0,15,12,0,6,96,9721,2.4705882352941178,8.764705882352942,0.5882352941176471,0.7058823529411765,52
3179,The Mirage of Action-Dependent Baselines in Reinforcement Learning,8,The Mirage of Action-Dependent Baselines in Reinforcement Learning,43,158,False,137,70,40,19,0,13,15,0,0,66,11408,2.263157894736842,2.1052631578947367,3.6842105263157894,0.7894736842105263,113
3180,The Variational Predictive Natural Gradient,8,The Variational Predictive Natural Gradient,32,125,False,84,118,20,12,7,10,10,0,4,43,8133,2.6666666666666665,2.0,9.833333333333334,0.8333333333333334,5
3181,Thompson Sampling for (Combinatorial) Pure Exploration,8,Thompson Sampling for Combinatorial Pure Exploration,21,169,False,96,56,4,14,0,11,4,0,0,54,10230,1.5,0.2857142857142857,4.0,0.2857142857142857,5
3183,Towards Distraction-Robust Active Visual Tracking,8,Towards Distraction-Robust Active Visual Tracking,47,148,False,129,12,173,16,0,31,52,0,32,49,10925,2.9375,12.8125,0.75,3.25,25
3184,Towards Understanding and Mitigating Social Biases in Language Models,8,Towards Understanding and Mitigating Social Biases in Language Models,57,149,False,262,56,6,22,0,26,42,0,0,69,14601,2.590909090909091,0.2727272727272727,2.5454545454545454,1.9090909090909092,247
3185,Training Neural Networks with Local Error Signals,8,Training Neural Networks with Local Error Signals,69,167,False,59,16,9,14,0,7,17,0,18,49,8211,4.928571428571429,1.9285714285714286,1.1428571428571428,1.2142857142857142,190
3186,Transformer Quality in Linear Time,8,Transformer Quality in Linear Time,39,104,False,110,112,104,19,38,20,22,2,76,34,9769,2.0526315789473686,9.473684210526315,5.894736842105263,1.1578947368421053,140
3187,Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning,8,Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning,50,141,False,12,0,3,22,0,5,11,4,2,68,11628,2.272727272727273,0.22727272727272727,0.0,0.5,127
3188,Understanding Self-Training for Gradual Domain Adaptation,8,Understanding Self-Training for Gradual Domain Adaptation,50,141,False,39,189,14,40,2,9,14,0,10,57,17086,1.25,0.6,4.725,0.35,187
3189,Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces,8,Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces,54,138,False,182,128,22,19,7,11,28,3,8,99,11973,2.8421052631578947,1.5789473684210527,6.7368421052631575,1.4736842105263157,13
3190,Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video Restoration,8,Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video Restoration,62,172,False,71,42,21,11,0,6,10,0,0,77,7285,5.636363636363637,1.9090909090909092,3.8181818181818183,0.9090909090909091,8
3191,VFlow: More Expressive Generative Flows with Variational Data Augmentation,8,VFlow More Expressive Generative Flows with Variational Data Augmentation,38,132,False,73,74,41,16,0,10,12,0,12,73,8667,2.375,3.3125,4.625,0.75,55
3192,Variational Inference for Infinitely Deep Neural Networks,8,Variational Inference for Infinitely Deep Neural Networks,59,198,False,79,16,26,15,1,10,8,0,4,57,9198,3.933333333333333,2.0,1.0666666666666667,0.5333333333333333,6
3193,Voice2Series: Reprogramming Acoustic Models for Time Series Classification,8,Voice2Series Reprogramming Acoustic Models for Time Series Classification,61,149,False,91,22,27,16,0,12,18,0,10,73,10144,3.8125,2.3125,1.375,1.125,88
3194,What Makes for End-to-End Object Detection?,8,What Makes for End-to-End Object Detection,48,168,False,70,54,30,15,0,12,11,0,8,42,9095,3.2,2.533333333333333,3.6,0.7333333333333333,64
3195,White-box vs Black-box: Bayes Optimal Strategies for Membership Inference,8,White-box vs Black-box Bayes Optimal Strategies for Membership Inference,31,123,False,93,88,5,11,2,8,17,0,6,72,7387,2.8181818181818183,1.0,8.0,1.5454545454545454,255
3196,You Only Cut Once: Boosting Data Augmentation with a Single Cut,8,You Only Cut Once Boosting Data Augmentation with a Single Cut,69,146,False,76,4,19,17,1,14,16,2,0,62,10359,4.0588235294117645,1.1176470588235294,0.23529411764705882,0.9411764705882353,20
3197,A Convergence Theory for SVGD in the Population Limit under Talagrand's Inequality T1,8,A Convergence Theory for SVGD in the Population Limit under Talagrands Inequality T1,44,125,True,117,121,0,14,1,9,12,3,0,85,7790,3.142857142857143,0.0,8.642857142857142,0.8571428571428571,15
3198,A Free-Energy Principle for Representation Learning,8,A Free-Energy Principle for Representation Learning,51,118,False,88,37,26,24,1,14,13,0,0,51,9819,2.125,1.0833333333333333,1.5416666666666667,0.5416666666666666,8
3199,A Lower Bound for the Sample Complexity of Inverse Reinforcement Learning,8,A Lower Bound for the Sample Complexity of Inverse Reinforcement Learning,21,105,False,51,45,10,11,0,7,3,0,0,73,6902,1.9090909090909092,0.9090909090909091,4.090909090909091,0.2727272727272727,3
3200,A Regret Minimization Approach to Iterative Learning Control,8,A Regret Minimization Approach to Iterative Learning Control,39,83,False,64,136,5,25,16,11,14,0,0,60,11534,1.56,0.2,5.44,0.56,12
3201,A Spectral Approach to Gradient Estimation for Implicit Distributions,8,A Spectral Approach to Gradient Estimation for Implicit Distributions,51,148,False,124,128,24,15,0,12,8,2,0,69,9066,3.4,1.6,8.533333333333333,0.5333333333333333,80
3202,A Unified Theory of Decentralized SGD with Changing Topology and Local Updates,8,A Unified Theory of Decentralized SGD with Changing Topology and Local Updates,97,151,True,103,210,9,28,3,16,28,0,2,78,16984,3.4642857142857144,0.39285714285714285,7.5,1.0,380
3203,APS: Active Pretraining with Successor Features,8,APS Active Pretraining with Successor Features,65,137,True,172,36,16,15,3,10,6,0,12,46,8921,4.333333333333333,1.8666666666666667,2.4,0.4,87
3204,Accelerating Greedy Coordinate Descent Methods,8,Accelerating Greedy Coordinate Descent Methods,32,218,False,65,73,45,23,0,7,11,0,2,46,9547,1.391304347826087,2.0434782608695654,3.1739130434782608,0.4782608695652174,35
3205,Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets,8,Active Learning on a Budget Opposite Strategies Suit High and Low Budgets,75,135,False,91,130,93,21,3,14,24,19,0,73,13949,3.5714285714285716,4.428571428571429,6.190476190476191,1.1428571428571428,60
3206,Adapting to Delays and Data in Adversarial Multi-Armed Bandits,8,Adapting to Delays and Data in Adversarial Multi-Armed Bandits,21,275,False,114,117,0,21,4,9,3,0,0,62,10103,1.0,0.0,5.571428571428571,0.14285714285714285,26
3207,Adaptive Sensor Placement for Continuous Spaces,8,Adaptive Sensor Placement for Continuous Spaces,33,106,False,60,32,19,13,3,10,7,4,0,47,8515,2.5384615384615383,1.4615384615384615,2.4615384615384617,0.5384615384615384,12
3208,Adversarial Combinatorial Bandits with General Non-linear Reward Functions,8,Adversarial Combinatorial Bandits with General Non-linear Reward Functions,30,172,False,56,56,0,10,0,4,7,0,0,74,8015,3.0,0.0,5.6,0.7,11
3209,Adversarial Vulnerability of Randomized Ensembles,8,Adversarial Vulnerability of Randomized Ensembles,48,179,False,74,186,41,28,0,12,24,3,10,49,14532,1.7142857142857142,1.8214285714285714,6.642857142857143,0.8571428571428571,5
3210,Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution,8,Align-RUDDER Learning From Few Demonstrations by Reward Redistribution,127,131,True,282,48,121,42,1,8,9,13,8,70,22154,3.0238095238095237,3.0714285714285716,1.1428571428571428,0.21428571428571427,33
3211,An EM Approach to Non-autoregressive Conditional Sequence Generation,8,An EM Approach to Non-autoregressive Conditional Sequence Generation,42,190,True,165,68,12,18,14,18,29,4,22,68,11391,2.3333333333333335,1.8888888888888888,3.7777777777777777,1.6111111111111112,37
3212,An initial alignment between neural network and target is needed for gradient descent to learn,8,An initial alignment between neural network and target is needed for gradient descent to learn,17,103,False,28,162,9,26,5,11,5,2,0,94,10951,0.6538461538461539,0.34615384615384615,6.230769230769231,0.19230769230769232,15
3213,Anonymous Walk Embeddings,8,Anonymous Walk Embeddings,30,121,False,56,20,12,10,0,8,2,0,8,25,7062,3.0,2.0,2.0,0.2,168
3214,Are Generative Classifiers More Robust to Adversarial Attacks?,8,Are Generative Classifiers More Robust to Adversarial Attacks,61,112,False,162,12,73,30,16,13,18,0,2,61,16560,2.033333333333333,2.5,0.4,0.6,72
3215,Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data,8,Augmented CycleGAN Learning Many-to-Many Mappings from Unpaired Data,30,80,False,96,70,60,10,6,9,17,4,12,68,6251,3.0,7.2,7.0,1.7,386
3216,Autoregressive Quantile Networks for Generative Modeling,8,Autoregressive Quantile Networks for Generative Modeling,46,103,False,86,40,51,16,0,11,7,0,0,56,8712,2.875,3.1875,2.5,0.4375,77
3217,Batched Dueling Bandits,8,Batched Dueling Bandits,45,155,False,98,150,48,28,24,24,20,0,12,23,13202,1.6071428571428572,2.142857142857143,5.357142857142857,0.7142857142857143,9
3218,Bayesian Optimisation over Multiple Continuous and Categorical Inputs,8,Bayesian Optimisation over Multiple Continuous and Categorical Inputs,43,160,False,55,30,31,16,8,15,12,0,10,69,9103,2.6875,2.5625,1.875,0.75,73
3219,Besov Function Approximation and Binary Classification on Low-Dimensional Manifolds Using Convolutional Residual Networks,8,Besov Function Approximation and Binary Classification on Low-Dimensional Manifolds Using Convolutional Residual Networks,81,164,False,156,344,17,47,8,9,27,0,2,121,20451,1.7234042553191489,0.40425531914893614,7.319148936170213,0.574468085106383,23
3220,Bilevel Optimization: Convergence Analysis and Enhanced Design,8,Bilevel Optimization Convergence Analysis and Enhanced Design,43,186,False,151,216,31,29,0,16,17,0,8,61,15898,1.4827586206896552,1.3448275862068966,7.448275862068965,0.5862068965517241,170
3221,Blind Justice: Fairness with Encrypted Sensitive Attributes,8,Blind Justice Fairness with Encrypted Sensitive Attributes,49,110,False,81,20,18,15,15,11,16,0,2,58,10923,3.2666666666666666,1.3333333333333333,1.3333333333333333,1.0666666666666667,134
3222,Brauer's Group Equivariant Neural Networks,8,Brauers Group Equivariant Neural Networks,30,184,False,11,276,10,22,0,17,8,5,0,42,14233,1.3636363636363635,0.45454545454545453,12.545454545454545,0.36363636363636365,8
3223,Byzantine Machine Learning Made Easy by Resilient Averaging of Momentums,8,Byzantine Machine Learning Made Easy by Resilient Averaging of Momentums,66,182,False,89,388,15,38,10,12,37,0,4,72,21860,1.736842105263158,0.5,10.210526315789474,0.9736842105263158,41
3226,Channel Importance Matters in Few-Shot Image Classification,8,Channel Importance Matters in Few-Shot Image Classification,53,167,False,52,51,33,18,0,15,6,0,12,59,12872,2.9444444444444446,2.5,2.8333333333333335,0.3333333333333333,25
3227,Clipped Action Policy Gradient,8,Clipped Action Policy Gradient,29,107,False,25,80,42,13,0,8,7,0,4,30,7656,2.230769230769231,3.5384615384615383,6.153846153846154,0.5384615384615384,34
3228,Collaborative Evolutionary Reinforcement Learning,8,Collaborative Evolutionary Reinforcement Learning,49,198,False,44,2,18,12,0,8,2,0,4,49,8141,4.083333333333333,1.8333333333333333,0.16666666666666666,0.16666666666666666,89
3229,Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects,8,Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects,66,151,False,133,409,17,42,7,14,30,11,50,87,19441,1.5714285714285714,1.5952380952380953,9.738095238095237,0.7142857142857143,2
3230,Compressed-VFL: Communication-Efficient Learning with Vertically Partitioned Data,8,Compressed-VFL Communication-Efficient Learning with Vertically Partitioned Data,59,108,True,101,114,58,29,4,11,9,0,12,80,16226,2.0344827586206895,2.413793103448276,3.9310344827586206,0.3103448275862069,28
3231,Confidence-Aware Learning for Deep Neural Networks,8,Confidence-Aware Learning for Deep Neural Networks,46,176,False,166,16,15,20,0,9,14,0,20,50,12216,2.3,1.75,0.8,0.7,104
3232,Constrained Efficient Global Optimization of Expensive Black-box Functions,8,Constrained Efficient Global Optimization of Expensive Black-box Functions,47,161,False,48,48,15,14,0,14,6,0,8,74,8444,3.357142857142857,1.6428571428571428,3.4285714285714284,0.42857142857142855,2194
3233,Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model,8,Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model,28,142,False,156,92,6,17,0,11,6,0,4,71,9267,1.6470588235294117,0.5882352941176471,5.411764705882353,0.35294117647058826,13
3234,Control Regularization for Reduced Variance Reinforcement Learning,8,Control Regularization for Reduced Variance Reinforcement Learning,41,136,False,36,194,18,17,0,16,9,0,0,66,10955,2.411764705882353,1.0588235294117647,11.411764705882353,0.5294117647058824,68
3235,Cooperative Exploration for Multi-Agent Deep Reinforcement Learning,8,Cooperative Exploration for Multi-Agent Deep Reinforcement Learning,66,140,False,114,22,42,18,0,16,8,0,12,67,11676,3.6666666666666665,3.0,1.2222222222222223,0.4444444444444444,63
3236,Counterfactual Analysis in Dynamic Latent State Models,8,Counterfactual Analysis in Dynamic Latent State Models,40,132,False,90,130,31,32,27,12,15,3,4,54,20326,1.25,1.09375,4.0625,0.46875,1
3237,Cutting out the Middle-Man: Training and Evaluating Energy-Based Models without Sampling,8,Cutting out the Middle-Man Training and Evaluating Energy-Based Models without Sampling,61,108,False,136,48,52,16,6,15,17,2,0,87,9630,3.8125,3.25,3.0,1.0625,13
3238,DROCC: Deep Robust One-Class Classification,8,DROCC Deep Robust One-Class Classification,41,180,True,80,12,47,16,1,11,16,3,28,42,10877,2.5625,4.6875,0.75,1.0,125
3240,Deciding What to Learn: A Rate-Distortion Approach,8,Deciding What to Learn A Rate-Distortion Approach,54,181,False,244,24,30,19,0,24,16,0,0,49,10353,2.8421052631578947,1.5789473684210527,1.263157894736842,0.8421052631578947,14
3241,Deep Generative Learning via Variational Gradient Flow,8,Deep Generative Learning via Variational Gradient Flow,63,189,False,57,32,21,30,0,9,9,0,14,54,6820,2.1,1.1666666666666667,1.0666666666666667,0.3,31
3242,Deep kernel processes,8,Deep kernel processes,48,154,False,152,174,18,23,0,21,10,0,4,21,13079,2.0869565217391304,0.9565217391304348,7.565217391304348,0.43478260869565216,33
3245,Differentially Private Correlation Clustering,8,Differentially Private Correlation Clustering,25,78,False,106,47,5,11,8,5,9,0,0,45,7666,2.272727272727273,0.45454545454545453,4.2727272727272725,0.8181818181818182,18
3246,Dimensionality-Driven Learning with Noisy Labels,8,Dimensionality-Driven Learning with Noisy Labels,49,121,False,80,18,23,10,0,7,9,0,2,48,7321,4.9,2.5,1.8,0.9,377
3247,Discrete-Valued Latent Preference Matrix Estimation with Graph Side Information,8,Discrete-Valued Latent Preference Matrix Estimation with Graph Side Information,49,147,False,96,50,18,33,9,12,14,0,2,79,21501,1.4848484848484849,0.6060606060606061,1.5151515151515151,0.42424242424242425,5
3248,Distributed Second Order Methods with Fast Rates and Compressed Communication,8,Distributed Second Order Methods with Fast Rates and Compressed Communication,54,213,False,138,187,66,44,0,9,35,8,10,77,20925,1.2272727272727273,1.7272727272727273,4.25,0.7954545454545454,43
3249,Do Perceptually Aligned Gradients Imply Robustness?,8,Do Perceptually Aligned Gradients Imply Robustness,83,150,False,109,18,37,21,2,17,14,0,16,50,11578,3.9523809523809526,2.5238095238095237,0.8571428571428571,0.6666666666666666,2
3251,EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE,8,EDDI Efficient Dynamic Discovery of High-Value Information with Partial VAE,43,170,True,91,40,82,22,17,9,18,12,12,75,10700,1.9545454545454546,4.2727272727272725,1.8181818181818181,0.8181818181818182,113
3252,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,8,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation,43,125,False,79,28,30,18,4,13,11,4,0,83,9076,2.388888888888889,1.6666666666666667,1.5555555555555556,0.6111111111111112,59
3253,Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors,8,Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors,52,153,False,151,76,51,25,2,13,23,0,0,63,12102,2.08,2.04,3.04,0.92,178
3254,End-to-End Balancing for Causal Continuous Treatment-Effect Estimation,8,End-to-End Balancing for Causal Continuous Treatment-Effect Estimation,48,92,False,100,46,15,14,21,10,11,0,4,70,8219,3.4285714285714284,1.3571428571428572,3.2857142857142856,0.7857142857142857,11
3255,Equivariant Learning of Stochastic Fields: Gaussian Processes and Steerable Conditional Neural Processes,8,Equivariant Learning of Stochastic Fields Gaussian Processes and Steerable Conditional Neural Processes,50,120,False,142,101,37,24,0,18,27,4,10,103,13140,2.0833333333333335,1.9583333333333333,4.208333333333333,1.125,26
3256,"Estimating Q(s, s') with Deep Deterministic Dynamics Gradients",8,Estimating Qs s with Deep Deterministic Dynamics Gradients,47,104,False,82,100,143,13,0,22,37,4,8,62,9072,3.6153846153846154,11.615384615384615,7.6923076923076925,2.8461538461538463,13
3257,Exact Optimization of Conformal Predictors via Incremental and Decremental Learning,8,Exact Optimization of Conformal Predictors via Incremental and Decremental Learning,29,126,False,86,28,17,17,0,19,19,0,8,83,10917,1.7058823529411764,1.4705882352941178,1.6470588235294117,1.1176470588235294,10
3259,FP-Diffusion: Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation,8,FP-Diffusion Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation,51,154,True,142,300,51,34,2,17,30,0,16,108,17746,1.5,1.9705882352941178,8.823529411764707,0.8823529411764706,13
3260,Familywise Error Rate Control by Interactive Unmasking,8,Familywise Error Rate Control by Interactive Unmasking,20,118,False,53,142,46,29,7,16,14,0,4,54,15027,0.6896551724137931,1.7241379310344827,4.896551724137931,0.4827586206896552,10
3261,Fast Relative Entropy Coding with A* coding,8,Fast Relative Entropy Coding with A coding,41,177,False,282,648,22,30,4,30,6,0,8,42,16196,1.3666666666666667,1.0,21.6,0.2,23
3262,Fat-Tailed Variational Inference with Anisotropic Tail Adaptive Flows,8,Fat-Tailed Variational Inference with Anisotropic Tail Adaptive Flows,48,196,False,161,29,18,14,2,10,9,0,6,69,8177,3.4285714285714284,1.7142857142857142,2.0714285714285716,0.6428571428571429,5
3263,Federated Learning with Label Distribution Skew via Logits Calibration,8,Federated Learning with Label Distribution Skew via Logits Calibration,59,179,False,55,16,21,11,18,7,6,0,14,70,8652,5.363636363636363,3.1818181818181817,1.4545454545454546,0.5454545454545454,70
3264,Finding Mixed Nash Equilibria of Generative Adversarial Networks,8,Finding Mixed Nash Equilibria of Generative Adversarial Networks,60,466,False,63,136,69,30,0,12,19,3,2,64,11634,2.0,2.3666666666666667,4.533333333333333,0.6333333333333333,72
3265,Flashlight: Enabling Innovation in Tools for Machine Learning,8,Flashlight Enabling Innovation in Tools for Machine Learning,66,193,False,111,0,6,19,7,8,10,17,0,60,9427,3.473684210526316,0.3157894736842105,0.0,0.5263157894736842,21
3266,Fourier Policy Gradients,8,Fourier Policy Gradients,40,128,False,69,156,3,13,7,13,9,0,0,24,8503,3.076923076923077,0.23076923076923078,12.0,0.6923076923076923,14
3267,Full Law Identification In Graphical Models Of Missing Data: Completeness Results,8,Full Law Identification In Graphical Models Of Missing Data Completeness Results,45,154,False,113,59,12,23,0,11,6,3,4,80,16648,1.9565217391304348,0.6956521739130435,2.5652173913043477,0.2608695652173913,38
3268,GALAXY: Graph-based Active Learning at the Extreme,8,GALAXY Graph-based Active Learning at the Extreme,31,162,True,56,22,58,15,0,13,6,0,2,49,8336,2.066666666666667,4.0,1.4666666666666666,0.4,16
3270,Generalization and Robustness Implications in Object-Centric Learning,8,Generalization and Robustness Implications in Object-Centric Learning,112,165,False,135,12,211,65,18,11,17,2,16,69,24296,1.7230769230769232,3.4923076923076923,0.18461538461538463,0.26153846153846155,48
3271,Generating Counterfactual Explanations with Natural Language,8,Generating Counterfactual Explanations with Natural Language,11,153,False,21,0,6,4,7,3,3,0,2,60,3029,2.75,2.0,0.0,0.75,87
3272,Geometric Losses for Distributional Learning,8,Geometric Losses for Distributional Learning,52,1,False,106,144,19,17,16,10,18,6,2,44,10323,3.0588235294117645,1.2352941176470589,8.470588235294118,1.0588235294117647,13
3274,Graph Generative Model for Benchmarking Graph Neural Networks,8,Graph Generative Model for Benchmarking Graph Neural Networks,71,1,False,258,14,34,24,14,8,30,4,32,61,16476,2.9583333333333335,2.75,0.5833333333333334,1.25,4
3275,Greed is Still Good: Maximizing Monotone Submodular+Supermodular Functions,8,Greed is Still Good Maximizing Monotone SubmodularSupermodular Functions,62,218,False,104,74,8,32,10,15,8,3,2,72,16213,1.9375,0.3125,2.3125,0.25,45
3278,How Tempering Fixes Data Augmentation in Bayesian Neural Networks,8,How Tempering Fixes Data Augmentation in Bayesian Neural Networks,50,218,False,98,71,40,17,21,9,8,0,0,65,9808,2.9411764705882355,2.3529411764705883,4.176470588235294,0.47058823529411764,4
3279,HyperPrompt: Prompt-based Task-Conditioning of Transformers,8,HyperPrompt Prompt-based Task-Conditioning of Transformers,36,96,False,86,16,14,14,1,7,16,0,22,58,8356,2.5714285714285716,2.5714285714285716,1.1428571428571428,1.1428571428571428,63
3280,Imitation Learning by Estimating Expertise of Demonstrators,8,Imitation Learning by Estimating Expertise of Demonstrators,52,162,False,49,39,13,17,0,11,13,0,26,59,11446,3.0588235294117645,2.2941176470588234,2.2941176470588234,0.7647058823529411,32
3281,Importance Weighted Transfer of Samples in Reinforcement Learning,8,Importance Weighted Transfer of Samples in Reinforcement Learning,30,181,False,81,102,23,18,5,11,6,0,2,65,12326,1.6666666666666667,1.3888888888888888,5.666666666666667,0.3333333333333333,41
3282,"Improved, Deterministic Smoothing for L1 Certified Robustness",8,Improved Deterministic Smoothing for L1 Certified Robustness,39,218,False,157,148,42,23,0,14,4,2,6,61,12611,1.6956521739130435,2.0869565217391304,6.434782608695652,0.17391304347826086,35
3284,Incremental Sampling Without Replacement for Sequence Models,8,Incremental Sampling Without Replacement for Sequence Models,29,117,False,78,32,14,14,7,11,8,0,6,60,9137,2.0714285714285716,1.4285714285714286,2.2857142857142856,0.5714285714285714,15
3285,InfoGAN-CR: Disentangling Generative Adversarial Networks with Contrastive Regularizers,8,InfoGAN-CR Disentangling Generative Adversarial Networks with Contrastive Regularizers,46,157,True,143,54,179,45,8,22,20,6,30,86,39171,1.0222222222222221,4.644444444444445,1.2,0.4444444444444444,33
3286,Inter-domain Deep Gaussian Processes,8,Inter-domain Deep Gaussian Processes,33,128,False,98,114,39,18,2,13,12,0,2,36,9339,1.8333333333333333,2.2777777777777777,6.333333333333333,0.6666666666666666,10
3287,Interpreting Robust Optimization via Adversarial Influence Functions,8,Interpreting Robust Optimization via Adversarial Influence Functions,33,0,False,28,118,7,32,3,9,13,2,0,68,11991,1.03125,0.21875,3.6875,0.40625,12
3288,Investigating Human Priors for Playing Video Games,8,Investigating Human Priors for Playing Video Games,31,147,False,34,0,27,9,0,8,7,0,0,50,6725,3.4444444444444446,3.0,0.0,0.7777777777777778,136
3289,Just Train Twice: Improving Group Robustness without Training Group Information,8,Just Train Twice Improving Group Robustness without Training Group Information,63,138,False,175,20,29,16,17,11,14,5,26,78,11959,3.9375,3.4375,1.25,0.875,354
3291,Label-Descriptive Patterns and their Application to Characterizing Classification Errors,8,Label-Descriptive Patterns and their Application to Characterizing Classification Errors,63,1,False,74,22,10,17,2,10,23,0,8,88,12491,3.7058823529411766,1.0588235294117647,1.2941176470588236,1.3529411764705883,4
3292,Latent Space Energy-Based Model of Symbol-Vector Coupling for Text Generation and Classification,8,Latent Space Energy-Based Model of Symbol-Vector Coupling for Text Generation and Classification,49,182,False,106,40,7,12,0,6,12,0,16,96,8396,4.083333333333333,1.9166666666666667,3.3333333333333335,1.0,16
3293,Learning Autoencoders with Relational Regularization,8,Learning Autoencoders with Relational Regularization,41,138,False,63,96,71,18,0,11,9,0,8,52,9654,2.2777777777777777,4.388888888888889,5.333333333333333,0.5,39
3294,Learning Domain Adaptive Object Detection with Probabilistic Teacher,8,Learning Domain Adaptive Object Detection with Probabilistic Teacher,42,161,False,75,71,51,16,0,11,19,4,16,68,9636,2.625,4.1875,4.4375,1.1875,39
3295,Learning Intuitive Policies Using Action Features,8,Learning Intuitive Policies Using Action Features,40,143,False,79,10,21,15,0,9,10,0,10,49,9861,2.6666666666666665,2.066666666666667,0.6666666666666666,0.6666666666666666,1
3297,Learning Symmetric Embeddings for Equivariant World Models,8,Learning Symmetric Embeddings for Equivariant World Models,53,143,False,106,26,46,18,25,15,11,0,12,58,10626,2.9444444444444446,3.2222222222222223,1.4444444444444444,0.6111111111111112,29
3299,Learning to Generalize from Sparse and Underspecified Rewards,8,Learning to Generalize from Sparse and Underspecified Rewards,81,1,False,95,32,14,14,0,9,13,2,14,61,9937,5.785714285714286,2.0,2.2857142857142856,0.9285714285714286,86
3300,Learning to Simulate Complex Physics with Graph Networks,8,Learning to Simulate Complex Physics with Graph Networks,46,156,False,72,6,29,20,0,12,24,0,2,56,12579,2.3,1.55,0.3,1.2,785
3301,Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity,8,Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity,51,199,False,89,36,28,19,0,14,18,0,0,85,12353,2.6842105263157894,1.4736842105263157,1.894736842105263,0.9473684210526315,16
3302,Linear Complexity Randomized Self-attention Mechanism,8,Linear Complexity Randomized Self-attention Mechanism,100,126,False,350,154,9,31,9,17,24,4,16,53,18472,3.225806451612903,0.8064516129032258,4.967741935483871,0.7741935483870968,22
3303,Locally Private Bayesian Inference for Count Models,8,Locally Private Bayesian Inference for Count Models,62,167,False,84,34,16,10,0,6,2,0,0,51,9750,6.2,1.6,3.4,0.2,31
3305,MISSION: Ultra Large-Scale Feature Selection using Count-Sketches,8,MISSION Ultra Large-Scale Feature Selection using Count-Sketches,26,176,True,68,100,74,12,2,30,26,0,44,64,8660,2.1666666666666665,9.833333333333334,8.333333333333334,2.1666666666666665,31
3306,Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling,8,Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling,36,251,False,49,12,27,11,2,5,9,0,10,104,7533,3.272727272727273,3.3636363636363638,1.0909090909090908,0.8181818181818182,27
3307,Measuring abstract reasoning in neural networks,8,Measuring abstract reasoning in neural networks,32,181,False,43,4,33,17,12,10,11,1,18,47,8245,1.8823529411764706,3.0,0.23529411764705882,0.6470588235294118,306
3308,Meta-Learning the Inductive Bias of Simple Neural Circuits,8,Meta-Learning the Inductive Bias of Simple Neural Circuits,44,195,False,85,4,36,14,0,11,5,0,0,58,8161,3.142857142857143,2.5714285714285716,0.2857142857142857,0.35714285714285715,0
3309,Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation,8,Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation,23,174,False,40,573,4,42,5,14,27,4,0,72,20965,0.5476190476190477,0.09523809523809523,13.642857142857142,0.6428571428571429,125
3310,ModLaNets: Learning Generalisable Dynamics via Modularity and Physical Inductive Bias,8,ModLaNets Learning Generalisable Dynamics via Modularity and Physical Inductive Bias,37,171,False,45,34,36,14,0,8,6,2,8,84,7834,2.642857142857143,3.142857142857143,2.4285714285714284,0.42857142857142855,6
3311,Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes,8,Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes,44,121,False,158,255,10,32,7,11,13,0,4,94,16518,1.375,0.4375,7.96875,0.40625,78
3313,Multi-Environment Pretraining Enables Transfer to Action Limited Datasets,8,Multi-Environment Pretraining Enables Transfer to Action Limited Datasets,55,203,False,96,14,54,16,2,9,12,0,8,73,7029,3.4375,3.875,0.875,0.75,5
3314,Multiclass learning with margin: exponential rates with no bias-variance trade-off,8,Multiclass learning with margin exponential rates with no bias-variance trade-off,26,69,False,27,46,15,16,3,5,4,0,0,81,6052,1.625,0.9375,2.875,0.25,1
3315,NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient Framework,8,NLP From Scratch Without Large-Scale Pretraining A Simple and Efficient Framework,59,176,True,13,0,3,14,0,6,12,4,2,81,9210,4.214285714285714,0.35714285714285715,0.0,0.8571428571428571,35
3316,Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes,8,Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes,39,165,False,181,296,0,33,0,17,20,2,2,82,19458,1.1818181818181819,0.06060606060606061,8.969696969696969,0.6060606060606061,31
3317,Neural Inverse Rendering for General Reflectance Photometric Stereo,8,Neural Inverse Rendering for General Reflectance Photometric Stereo,46,169,False,125,40,529,30,7,10,7,5,4,67,11460,1.5333333333333334,17.766666666666666,1.3333333333333333,0.23333333333333334,90
3318,Neural Topic Modeling with Continual Lifelong Learning,8,Neural Topic Modeling with Continual Lifelong Learning,33,185,False,32,13,32,13,0,9,9,0,18,54,9209,2.5384615384615383,3.8461538461538463,1.0,0.6923076923076923,36
3319,Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent,8,Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent,59,154,False,161,222,38,26,0,13,13,12,2,73,14635,2.269230769230769,1.5384615384615385,8.538461538461538,0.5,28
3320,Nonparametric Extensions of Randomized Response for Private Confidence Sets,8,Nonparametric Extensions of Randomized Response for Private Confidence Sets,78,139,False,247,262,21,50,33,9,31,4,2,75,24984,1.56,0.46,5.24,0.62,3
3321,Object Permanence Emerges in a Random Walk along Memory,8,Object Permanence Emerges in a Random Walk along Memory,58,134,False,156,36,42,14,18,18,20,0,24,55,9800,4.142857142857143,4.714285714285714,2.5714285714285716,1.4285714285714286,11
3322,Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning,8,Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning,71,162,False,151,64,12,15,31,8,9,0,24,88,9053,4.733333333333333,2.4,4.266666666666667,0.6,12
3323,On Explainability of Graph Neural Networks via Subgraph Explorations,8,On Explainability of Graph Neural Networks via Subgraph Explorations,53,161,False,49,16,27,17,0,8,17,0,6,68,9634,3.1176470588235294,1.9411764705882353,0.9411764705882353,1.0,259
3324,On Medians of (Randomized) Pairwise Means,8,On Medians of Randomized Pairwise Means,34,241,False,128,134,16,22,0,9,19,2,8,39,13001,1.5454545454545454,1.0909090909090908,6.090909090909091,0.8636363636363636,10
3325,On the Computation and Communication Complexity of Parallel SGD with Dynamic Batch Sizes for Stochastic Non-Convex Optimization,8,On the Computation and Communication Complexity of Parallel SGD with Dynamic Batch Sizes for Stochastic Non-Convex Optimization,36,154,True,42,80,12,13,0,6,4,0,0,127,7975,2.769230769230769,0.9230769230769231,6.153846153846154,0.3076923076923077,48
3326,On the Global Convergence Rates of Softmax Policy Gradient Methods,8,On the Global Convergence Rates of Softmax Policy Gradient Methods,29,180,False,112,702,15,65,17,11,13,15,0,66,31709,0.4461538461538462,0.23076923076923078,10.8,0.2,224
3328,On the price of explainability for some clustering problems,8,On the price of explainability for some clustering problems,37,185,False,78,58,4,23,0,8,12,4,6,59,10545,1.608695652173913,0.43478260869565216,2.5217391304347827,0.5217391304347826,21
3329,Online Decision Transformer,8,Online Decision Transformer,67,120,False,90,26,38,18,15,15,12,1,10,27,11954,3.7222222222222223,2.6666666666666665,1.4444444444444444,0.6666666666666666,129
3332,Optimization Planning for 3D ConvNets,8,Optimization Planning for 3D ConvNets,56,213,False,127,16,24,11,0,6,8,0,18,37,7945,5.090909090909091,3.8181818181818183,1.4545454545454546,0.7272727272727273,6
3333,Ordinal Non-negative Matrix Factorization for Recommendation,8,Ordinal Non-negative Matrix Factorization for Recommendation,32,143,False,36,0,13,10,11,7,11,0,6,60,6844,3.2,1.9,0.0,1.1,14
3334,PAC-Learning for Strategic Classification,8,PAC-Learning for Strategic Classification,63,164,True,128,50,9,22,0,12,15,0,0,41,16687,2.8636363636363638,0.4090909090909091,2.272727272727273,0.6818181818181818,24
3335,PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration,8,PMIC Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration,39,155,True,105,26,94,19,0,15,9,0,8,99,12193,2.0526315789473686,5.368421052631579,1.368421052631579,0.47368421052631576,16
3336,Parsimonious Learning-Augmented Caching,8,Parsimonious Learning-Augmented Caching,36,116,False,49,22,3,15,10,11,5,0,2,39,9995,2.4,0.3333333333333333,1.4666666666666666,0.3333333333333333,19
3337,Performative Reinforcement Learning,8,Performative Reinforcement Learning,61,183,False,67,244,13,47,0,7,12,2,2,35,20378,1.297872340425532,0.3191489361702128,5.191489361702128,0.2553191489361702,9
3338,Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification,8,Plan Better Amid Conservatism Offline Multi-Agent Reinforcement Learning with Actor Rectification,69,187,False,160,22,56,21,11,9,14,7,18,97,10210,3.2857142857142856,3.5238095238095237,1.0476190476190477,0.6666666666666666,29
3339,Policy Optimization as Wasserstein Gradient Flows,8,Policy Optimization as Wasserstein Gradient Flows,50,131,False,72,80,7,15,15,13,12,0,8,49,10731,3.3333333333333335,1.0,5.333333333333333,0.8,63
3340,Predicting Out-of-Distribution Error with the Projection Norm,8,Predicting Out-of-Distribution Error with the Projection Norm,76,115,False,114,61,155,25,3,13,9,0,20,61,14092,3.04,7.0,2.44,0.36,26
3341,Principled Simplicial Neural Networks for Trajectory Prediction,8,Principled Simplicial Neural Networks for Trajectory Prediction,37,157,False,107,82,11,20,0,17,18,0,6,63,13136,1.85,0.85,4.1,0.9,64
3343,Projection Robust Wasserstein Barycenters,8,Projection Robust Wasserstein Barycenters,31,183,False,52,72,17,36,12,15,6,0,6,41,13876,0.8611111111111112,0.6388888888888888,2.0,0.16666666666666666,9
3344,Provable Smoothness Guarantees for Black-Box Variational Inference,8,Provable Smoothness Guarantees for Black-Box Variational Inference,50,84,False,74,85,77,22,0,13,5,0,0,66,9813,2.272727272727273,3.5,3.8636363636363638,0.22727272727272727,26
3345,Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment Restriction,8,Proximal Causal Learning with Kernels Two-Stage Estimation and Moment Restriction,79,137,False,341,415,38,47,14,14,34,18,10,81,28335,1.6808510638297873,1.0212765957446808,8.829787234042554,0.723404255319149,50
3346,Quantifying the Benefit of Using Differentiable Learning over Tangent Kernels,8,Quantifying the Benefit of Using Differentiable Learning over Tangent Kernels,47,101,False,116,122,4,29,11,11,6,4,4,77,17784,1.6206896551724137,0.27586206896551724,4.206896551724138,0.20689655172413793,32
3347,REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer,8,REvolveR Continuous Evolutionary Models for Robot-to-robot Policy Transfer,48,198,False,51,70,80,13,22,10,7,0,6,74,8505,3.6923076923076925,6.615384615384615,5.384615384615385,0.5384615384615384,12
3348,Random matrix improved covariance estimation for a large class of metrics,8,Random matrix improved covariance estimation for a large class of metrics,27,76,False,40,72,10,10,0,6,6,2,4,73,6794,2.7,1.4,7.2,0.6,9
3349,Reasoning Over Virtual Knowledge Bases With Open Predicate Relations,8,Reasoning Over Virtual Knowledge Bases With Open Predicate Relations,41,144,False,67,22,9,12,0,6,10,8,4,68,9174,3.4166666666666665,1.0833333333333333,1.8333333333333333,0.8333333333333334,22
3351,Relational Pooling for Graph Representations,8,Relational Pooling for Graph Representations,79,1,False,157,44,18,19,17,15,8,3,6,44,14621,4.157894736842105,1.263157894736842,2.3157894736842106,0.42105263157894735,218
3352,Reprogramming Pretrained Language Models for Antibody Sequence Infilling,8,Reprogramming Pretrained Language Models for Antibody Sequence Infilling,72,220,False,160,38,39,22,0,15,7,0,34,72,12304,3.272727272727273,3.3181818181818183,1.7272727272727273,0.3181818181818182,9
3353,Revealing the Structure of Deep Neural Networks via Convex Duality,8,Revealing the Structure of Deep Neural Networks via Convex Duality,46,176,False,47,338,28,32,0,8,16,2,2,66,17739,1.4375,0.9375,10.5625,0.5,65
3354,Rich Feature Construction for the Optimization-Generalization Dilemma,8,Rich Feature Construction for the Optimization-Generalization Dilemma,36,217,False,82,27,12,15,0,12,16,2,18,69,9544,2.4,2.0,1.8,1.0666666666666667,28
3355,Robust Inference via Generative Classifiers for Handling Noisy Labels,8,Robust Inference via Generative Classifiers for Handling Noisy Labels,57,165,False,237,62,30,17,0,11,10,0,16,69,10819,3.3529411764705883,2.7058823529411766,3.6470588235294117,0.5882352941176471,112
3356,Robust and Scalable Models of Microbiome Dynamics,8,Robust and Scalable Models of Microbiome Dynamics,41,247,False,41,28,14,11,0,7,7,0,0,49,8135,3.727272727272727,1.2727272727272727,2.5454545454545454,0.6363636363636364,34
3357,SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates,8,SDE-Net Equipping Deep Neural Networks with Uncertainty Estimates,51,221,True,126,50,34,20,0,11,19,0,14,65,11826,2.55,2.4,2.5,0.95,80
3358,SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning,8,SUNRISE A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning,61,153,True,242,24,65,20,0,15,9,0,8,87,10880,3.05,3.65,1.2,0.45,170
3359,Sample-Optimal Parametric Q-Learning with Linear Transition Models,8,Sample-Optimal Parametric Q-Learning with Linear Transition Models,36,155,False,69,146,0,25,4,12,14,0,0,66,11296,1.44,0.0,5.84,0.56,13
3361,Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations,8,Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations,59,206,False,120,103,32,22,25,10,22,0,0,93,14061,2.6818181818181817,1.4545454545454546,4.681818181818182,1.0,112
3362,Self-Damaging Contrastive Learning,8,Self-Damaging Contrastive Learning,61,28,False,5,0,0,13,0,5,7,0,2,34,8489,4.6923076923076925,0.15384615384615385,0.0,0.5384615384615384,57
3363,Semi-Supervised Learning with Normalizing Flows,8,Semi-Supervised Learning with Normalizing Flows,45,112,False,104,30,41,15,3,15,7,0,10,47,8841,3.0,3.4,2.0,0.4666666666666667,98
3364,Shampoo: Preconditioned Stochastic Tensor Optimization,8,Shampoo Preconditioned Stochastic Tensor Optimization,26,113,False,45,137,8,21,0,10,16,0,2,53,9630,1.2380952380952381,0.47619047619047616,6.523809523809524,0.7619047619047619,141
3365,Simple and near-optimal algorithms for hidden stratification and multi-group learning,8,Simple and near-optimal algorithms for hidden stratification and multi-group learning,57,1,False,111,163,5,31,9,11,15,1,0,85,13125,1.8387096774193548,0.16129032258064516,5.258064516129032,0.4838709677419355,16
3366,Sliced Iterative Normalizing Flows,8,Sliced Iterative Normalizing Flows,79,183,False,156,64,58,19,0,12,14,0,16,34,12593,4.157894736842105,3.8947368421052633,3.3684210526315788,0.7368421052631579,32
3367,Sorting out Lipschitz function approximation,8,Sorting out Lipschitz function approximation,68,133,False,102,13,9,21,3,6,7,3,0,44,14240,3.238095238095238,0.42857142857142855,0.6190476190476191,0.3333333333333333,268
3368,Spectral Clustering of Signed Graphs via Matrix Power Means,8,Spectral Clustering of Signed Graphs via Matrix Power Means,71,156,False,75,153,117,28,0,19,5,0,6,59,20209,2.5357142857142856,4.392857142857143,5.464285714285714,0.17857142857142858,28
3370,Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models,8,Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models,40,176,False,104,114,19,24,5,11,8,4,4,81,13948,1.6666666666666667,0.9583333333333334,4.75,0.3333333333333333,10
3371,Stochastic Sign Descent Methods: New Algorithms and Better Theory,8,Stochastic Sign Descent Methods New Algorithms and Better Theory,40,180,False,86,163,24,33,0,10,21,2,2,64,13871,1.2121212121212122,0.7878787878787878,4.9393939393939394,0.6363636363636364,32
3374,Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent,8,Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent,33,150,False,34,105,8,25,10,7,3,0,0,90,10313,1.32,0.32,4.2,0.12,55
3376,TaskNorm: Rethinking Batch Normalization for Meta-Learning,8,TaskNorm Rethinking Batch Normalization for Meta-Learning,42,130,False,150,18,9,17,11,12,16,0,0,57,11399,2.4705882352941178,0.5294117647058824,1.0588235294117647,0.9411764705882353,83
3377,TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing,8,TensorFuzz Debugging Neural Networks with Coverage-Guided Fuzzing,63,153,False,81,0,9,12,12,5,9,1,0,65,6135,5.25,0.75,0.0,0.75,278
3378,The Emergence of Individuality,8,The Emergence of Individuality,40,168,False,44,32,59,11,0,8,8,0,2,30,7683,3.6363636363636362,5.545454545454546,2.909090909090909,0.7272727272727273,21
3379,The Multivariate Community Hawkes Model for Dependent Relational Events in Continuous-time Networks,8,The Multivariate Community Hawkes Model for Dependent Relational Events in Continuous-time Networks,59,124,False,143,23,61,18,7,10,19,2,12,99,11336,3.2777777777777777,4.055555555555555,1.2777777777777777,1.0555555555555556,3
3380,The Wasserstein transform,8,The Wasserstein transform,28,51,False,45,19,15,16,3,6,5,0,0,25,5942,1.75,0.9375,1.1875,0.3125,6
3381,Thompson Sampling for Combinatorial Semi-Bandits,8,Thompson Sampling for Combinatorial Semi-Bandits,39,250,False,105,210,12,61,0,9,14,4,0,48,19696,0.639344262295082,0.19672131147540983,3.442622950819672,0.22950819672131148,104
3382,To understand deep learning we need to understand kernel learning,8,To understand deep learning we need to understand kernel learning,56,305,False,53,16,4,19,1,8,4,0,16,65,8776,2.9473684210526314,1.0526315789473684,0.8421052631578947,0.21052631578947367,367
3383,Towards Domain-Agnostic Contrastive Learning,8,Towards Domain-Agnostic Contrastive Learning,83,150,False,129,94,3,23,5,12,7,0,20,44,12516,3.608695652173913,1.0,4.086956521739131,0.30434782608695654,86
3384,Towards Understanding the Dynamics of the First-Order Adversaries,8,Towards Understanding the Dynamics of the First-Order Adversaries,30,0,False,32,104,43,27,8,10,13,2,0,65,11470,1.1111111111111112,1.5925925925925926,3.8518518518518516,0.48148148148148145,11
3385,Training Normalizing Flows from Dependent Data,8,Training Normalizing Flows from Dependent Data,43,106,False,102,36,43,17,15,8,10,15,8,46,10210,2.5294117647058822,3.0,2.1176470588235294,0.5882352941176471,1
3386,Transformers are Meta-Reinforcement Learners,8,Transformers are Meta-Reinforcement Learners,63,193,False,140,20,39,20,0,13,14,0,0,44,9973,3.15,1.95,1.0,0.7,33
3389,Unified Scaling Laws for Routed Language Models,8,Unified Scaling Laws for Routed Language Models,69,166,False,254,61,84,31,16,17,26,3,16,47,17331,2.225806451612903,3.225806451612903,1.967741935483871,0.8387096774193549,95
3390,Unsupervised Ground Metric Learning Using Wasserstein Singular Vectors,8,Unsupervised Ground Metric Learning Using Wasserstein Singular Vectors,76,190,False,73,26,19,15,0,15,8,0,4,70,9189,5.066666666666666,1.5333333333333334,1.7333333333333334,0.5333333333333333,3
3391,VILD: Variational Imitation Learning with Diverse-quality Demonstrations,8,VILD Variational Imitation Learning with Diverse-quality Demonstrations,66,152,True,178,68,36,22,27,10,9,0,4,71,13458,3.0,1.8181818181818181,3.090909090909091,0.4090909090909091,18
3392,Variational Inference for sparse network reconstruction from count data,8,Variational Inference for sparse network reconstruction from count data,52,326,False,104,54,36,30,21,6,9,0,4,71,11180,1.7333333333333334,1.3333333333333333,1.8,0.3,52
3393,Volatility Based Kernels and Moving Average Means for Accurate Forecasting with Gaussian Processes,8,Volatility Based Kernels and Moving Average Means for Accurate Forecasting with Gaussian Processes,62,130,False,136,48,48,19,13,10,17,0,4,98,10976,3.263157894736842,2.736842105263158,2.526315789473684,0.8947368421052632,2
3394,What can I do here? A Theory of Affordances in Reinforcement Learning,8,What can I do here A Theory of Affordances in Reinforcement Learning,49,162,False,71,102,88,23,0,11,10,5,0,68,12828,2.130434782608696,3.8260869565217392,4.434782608695652,0.43478260869565216,49
3395,"Whitening and Second Order Optimization Both Make Information in the Dataset Unusable During Training, and Can Reduce or Prevent Generalization",8,Whitening and Second Order Optimization Both Make Information in the Dataset Unusable During Training and Can Reduce or Prevent Generalization,86,177,False,72,44,24,23,7,13,16,13,0,143,14185,3.739130434782609,1.0434782608695652,1.9130434782608696,0.6956521739130435,8
3396,YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone,8,YourTTS Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone,48,131,True,85,2,4,9,0,9,9,0,6,87,7604,5.333333333333333,1.1111111111111112,0.2222222222222222,1.0,181
3397,A Convergent and Dimension-Independent Min-Max Optimization Algorithm,8,A Convergent and Dimension-Independent Min-Max Optimization Algorithm,56,173,False,82,134,170,53,27,15,12,0,6,69,19950,1.0566037735849056,3.3207547169811322,2.5283018867924527,0.22641509433962265,1
3398,A Fully Differentiable Beam Search Decoder,8,A Fully Differentiable Beam Search Decoder,43,161,False,90,32,13,11,0,8,7,0,4,42,6581,3.909090909090909,1.5454545454545454,2.909090909090909,0.6363636363636364,36
3400,A Regret Minimization Approach to Multi-Agent Contro,8,A Regret Minimization Approach to Multi-Agent Contro,45,1,False,2,8,0,13,4,4,2,0,0,52,9123,3.4615384615384617,0.0,0.6153846153846154,0.15384615384615385,4
3401,A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning,8,A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning,51,196,False,110,6,31,12,0,8,6,0,2,77,7950,4.25,2.75,0.5,0.5,14
3403,AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation,8,AR-DAE Towards Unbiased Neural Entropy Gradient Estimation,58,133,True,156,34,83,26,0,16,22,0,18,58,14341,2.230769230769231,3.8846153846153846,1.3076923076923077,0.8461538461538461,19
3404,Accelerating Natural Gradient with Higher-Order Invariance,8,Accelerating Natural Gradient with Higher-Order Invariance,43,143,False,234,304,48,24,0,30,34,0,0,58,11724,1.7916666666666667,2.0,12.666666666666666,1.4166666666666667,17
3405,Active Learning with Logged Data,8,Active Learning with Logged Data,48,115,False,49,58,112,21,8,14,15,6,6,32,12032,2.2857142857142856,5.619047619047619,2.761904761904762,0.7142857142857143,25
3406,Adapting to Mixing Time in Stochastic Optimization with Markovian Data,8,Adapting to Mixing Time in Stochastic Optimization with Markovian Data,45,129,False,87,152,12,18,2,21,17,4,4,70,11312,2.5,0.8888888888888888,8.444444444444445,0.9444444444444444,18
3407,Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search,8,Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search,28,139,False,98,46,23,14,22,10,10,0,2,83,9919,2.0,1.7857142857142858,3.2857142857142856,0.7142857142857143,70
3408,Adversarial Distillation of Bayesian Neural Network Posteriors,8,Adversarial Distillation of Bayesian Neural Network Posteriors,45,147,False,104,24,27,12,11,8,11,3,10,62,7547,3.75,3.0833333333333335,2.0,0.9166666666666666,51
3409,Adversarial attacks on Copyright Detection Systems,8,Adversarial attacks on Copyright Detection Systems,32,155,False,36,16,11,10,0,7,8,2,4,50,5351,3.2,1.5,1.6,0.8,31
3410,Aligned Cross Entropy for Non-Autoregressive Machine Translation,8,Aligned Cross Entropy for Non-Autoregressive Machine Translation,33,121,False,73,8,8,9,15,8,6,0,18,64,6210,3.6666666666666665,2.888888888888889,0.8888888888888888,0.6666666666666666,105
3411,"An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",8,An Efficient Generalized Bellman Update For Cooperative Inverse Reinforcement Learning,26,192,False,34,16,30,19,0,15,18,11,6,86,12099,1.368421052631579,1.894736842105263,0.8421052631578947,0.9473684210526315,25
3412,An investigation of model-free planning,8,An investigation of model-free planning,40,211,False,97,12,58,21,0,15,23,8,10,39,12361,1.9047619047619047,3.238095238095238,0.5714285714285714,1.0952380952380953,95
3413,Answering Complex Logical Queries on Knowledge Graphs via Query Computation Tree Optimization,8,Answering Complex Logical Queries on Knowledge Graphs via Query Computation Tree Optimization,36,175,False,49,84,40,20,0,13,18,0,24,93,12638,1.8,3.2,4.2,0.9,13
3414,Area Attention,8,Area Attention,32,162,False,108,24,31,10,0,11,5,2,10,14,6932,3.2,4.1,2.4,0.5,19
3415,Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment,8,Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment,59,72,False,62,8,41,13,0,12,6,0,8,101,8432,4.538461538461538,3.769230769230769,0.6153846153846154,0.46153846153846156,31
3416,Average-Reward Off-Policy Policy Evaluation with Function Approximation,8,Average-Reward Off-Policy Policy Evaluation with Function Approximation,59,135,False,114,212,15,22,0,14,13,0,4,71,12573,2.6818181818181817,0.8636363636363636,9.636363636363637,0.5909090909090909,22
3417,BayesNAS: A Bayesian Approach for Neural Architecture Search,8,BayesNAS A Bayesian Approach for Neural Architecture Search,66,175,False,190,234,21,25,14,13,19,4,12,59,17627,2.64,1.32,9.36,0.76,182
3418,Bayesian Optimistic Optimisation with Exponentially Decaying Regret,8,Bayesian Optimistic Optimisation with Exponentially Decaying Regret,35,142,False,132,44,21,21,12,16,7,3,6,67,13540,1.6666666666666667,1.2857142857142858,2.0952380952380953,0.3333333333333333,2
3419,Best Arm Identification for Cascading Bandits in the Fixed Confidence Setting,8,Best Arm Identification for Cascading Bandits in the Fixed Confidence Setting,37,150,False,136,578,90,39,0,26,58,0,8,77,20143,0.9487179487179487,2.5128205128205128,14.820512820512821,1.4871794871794872,6
3420,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,8,Bilevel Programming for Hyperparameter Optimization and Meta-Learning,47,132,False,97,33,19,12,0,10,6,0,10,69,9120,3.9166666666666665,2.4166666666666665,2.75,0.5,599
3421,Block subsampled randomized Hadamard transform for low-rank approximation on distributed architectures,8,Block subsampled randomized Hadamard transform for low-rank approximation on distributed architectures,44,155,False,51,84,12,18,0,7,6,0,0,102,9393,2.4444444444444446,0.6666666666666666,4.666666666666667,0.3333333333333333,4
3422,Break-It-Fix-It: Unsupervised Learning for Program Repair,8,Break-It-Fix-It Unsupervised Learning for Program Repair,81,221,False,64,31,15,12,0,9,8,7,10,56,9949,6.75,2.0833333333333335,2.5833333333333335,0.6666666666666666,77
3423,Byzantine-Resilient High-Dimensional SGD with Local Iterations on Heterogeneous Data,8,Byzantine-Resilient High-Dimensional SGD with Local Iterations on Heterogeneous Data,44,228,True,50,203,0,33,8,10,12,2,0,84,18014,1.3333333333333333,0.0,6.151515151515151,0.36363636363636365,30
3424,Calibrated Learning to Defer with One-vs-All Classifiers,8,Calibrated Learning to Defer with One-vs-All Classifiers,51,178,False,232,113,23,19,26,14,14,0,10,56,12178,2.6842105263157894,1.736842105263158,5.947368421052632,0.7368421052631579,28
3425,Causal Inference using Gaussian Processes with Structured Latent Confounders,8,Causal Inference using Gaussian Processes with Structured Latent Confounders,45,161,False,73,66,22,14,0,20,28,4,12,76,9120,3.2142857142857144,2.4285714285714284,4.714285714285714,2.0,16
3426,Characterization of Convex Objective Functions and Optimal Expected Convergence Rates for SGD,8,Characterization of Convex Objective Functions and Optimal Expected Convergence Rates for SGD,30,85,True,12,0,3,27,0,4,12,4,2,93,12383,1.1111111111111112,0.18518518518518517,0.0,0.4444444444444444,6
3427,"Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning",8,Closed Loop Neural-Symbolic Learning via Integrating Neural Perception Grammar Parsing and Symbolic Reasoning,69,176,False,48,44,28,16,1,10,12,9,12,111,9473,4.3125,2.5,2.75,0.75,63
3428,Collaborative Machine Learning with Incentive-Aware Model Rewards,8,Collaborative Machine Learning with Incentive-Aware Model Rewards,29,191,False,27,49,56,17,0,13,14,2,0,65,18309,1.7058823529411764,3.2941176470588234,2.8823529411764706,0.8235294117647058,88
3429,Comparison-Based Random Forests,8,Comparison-Based Random Forests,38,142,False,70,7,25,32,0,6,6,2,6,31,14228,1.1875,0.96875,0.21875,0.1875,24
3430,Compressing Gradient Optimizers via Count-Sketches,8,Compressing Gradient Optimizers via Count-Sketches,53,121,False,68,36,27,16,0,9,3,0,16,50,10604,3.3125,2.6875,2.25,0.1875,31
3431,Confidence-Budget Matching for Sequential Budgeted Learning,8,Confidence-Budget Matching for Sequential Budgeted Learning,35,180,False,107,408,0,60,5,17,23,0,0,59,30896,0.5833333333333334,0.0,6.8,0.38333333333333336,8
3432,Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks,8,Constrained Gradient Descent A Powerful and Principled Evasion Attack Against Neural Networks,69,137,False,131,30,141,26,11,19,17,0,6,93,15827,2.6538461538461537,5.653846153846154,1.1538461538461537,0.6538461538461539,2
3433,Continual Learning with Guarantees via Weight Interval Constraints,8,Continual Learning with Guarantees via Weight Interval Constraints,39,191,False,51,23,13,15,13,9,2,0,14,66,10179,2.6,1.8,1.5333333333333334,0.13333333333333333,4
3435,Cooperative Multi-Agent Bandits with Heavy Tails,8,Cooperative Multi-Agent Bandits with Heavy Tails,56,125,False,83,172,3,26,0,9,8,0,0,48,15089,2.1538461538461537,0.11538461538461539,6.615384615384615,0.3076923076923077,36
3436,Counterfactual Credit Assignment in Model-Free Reinforcement Learning,8,Counterfactual Credit Assignment in Model-Free Reinforcement Learning,55,1,False,84,16,1,30,3,6,6,0,0,69,17901,1.8333333333333333,0.03333333333333333,0.5333333333333333,0.2,48
3437,Cycle Representation Learning for Inductive Relation Prediction,8,Cycle Representation Learning for Inductive Relation Prediction,67,185,False,112,2,21,16,0,7,7,0,14,63,10753,4.1875,2.1875,0.125,0.4375,10
3440,Decision Trees for Decision-Making under the Predict-then-Optimize Framework,8,Decision Trees for Decision-Making under the Predict-then-Optimize Framework,28,0,False,74,32,30,31,0,9,8,0,0,76,10606,0.9032258064516129,0.967741935483871,1.032258064516129,0.25806451612903225,86
3441,Deep Graph Random Process for Relational-Thinking-Based Speech Recognition,8,Deep Graph Random Process for Relational-Thinking-Based Speech Recognition,51,163,False,54,100,21,16,4,11,11,9,0,74,9406,3.1875,1.3125,6.25,0.6875,16
3442,Deep networks on toroids: removing symmetries reveals the structure of flat regions in the landscape geometry,8,Deep networks on toroids removing symmetries reveals the structure of flat regions in the landscape geometry,44,221,False,91,0,130,23,10,9,10,3,0,108,14493,1.9130434782608696,5.6521739130434785,0.0,0.43478260869565216,14
3445,Differentially Private Densest Subgraph Detection,8,Differentially Private Densest Subgraph Detection,47,127,False,63,53,21,25,0,10,13,0,4,49,15673,1.88,1.0,2.12,0.52,13
3446,Direct Behavior Specification via Constrained Reinforcement Learning,8,Direct Behavior Specification via Constrained Reinforcement Learning,75,154,False,66,26,26,16,9,13,9,0,4,68,10695,4.6875,1.875,1.625,0.5625,20
3447,Discretization Drift in Two-Player Games,8,Discretization Drift in Two-Player Games,40,142,False,161,234,117,41,1,19,28,8,4,40,20012,0.975609756097561,2.951219512195122,5.7073170731707314,0.6829268292682927,10
3448,Distributed Weighted Matching via Randomized Composable Coresets,8,Distributed Weighted Matching via Randomized Composable Coresets,66,138,False,91,37,8,22,2,6,6,0,10,64,12063,3.0,0.8181818181818182,1.6818181818181819,0.2727272727272727,7
3449,Do RNN and LSTM have Long Memory?,8,Do RNN and LSTM have Long Memory,48,111,True,52,99,53,20,3,8,23,0,22,32,11084,2.4,3.75,4.95,1.15,93
3450,Doubly Robust Off-Policy Actor-Critic: Convergence and Optimality,8,Doubly Robust Off-Policy Actor-Critic Convergence and Optimality,62,201,False,77,310,9,32,0,11,7,0,0,64,18950,1.9375,0.28125,9.6875,0.21875,19
3451,EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning,8,EDEN Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning,69,123,True,124,86,55,31,0,17,22,2,2,90,19639,2.225806451612903,1.8387096774193548,2.774193548387097,0.7096774193548387,26
3452,Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation,8,Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation,54,174,False,236,140,40,18,2,16,24,0,8,95,11415,3.0,2.6666666666666665,7.777777777777778,1.3333333333333333,8
3453,Efficient end-to-end learning for quantizable representations,8,Efficient end-to-end learning for quantizable representations,36,187,False,59,26,6,10,0,8,7,0,10,61,7510,3.6,1.6,2.6,0.7,10
3455,Equivariant Networks for Pixelized Spheres,8,Equivariant Networks for Pixelized Spheres,60,142,False,140,44,40,17,2,15,15,5,6,42,10546,3.5294117647058822,2.7058823529411766,2.588235294117647,0.8823529411764706,16
3456,Estimating and Penalizing Induced Preference Shifts in Recommender Systems,8,Estimating and Penalizing Induced Preference Shifts in Recommender Systems,58,234,False,198,8,76,23,0,34,20,2,8,74,15965,2.5217391304347827,3.652173913043478,0.34782608695652173,0.8695652173913043,29
3457,Examining Scaling and Transfer of Language Model Architectures for Machine Translation,8,Examining Scaling and Transfer of Language Model Architectures for Machine Translation,59,188,False,107,16,59,16,9,9,2,0,6,86,8749,3.6875,4.0625,1.0,0.125,11
3458,Exploring Chemical Space with Score-based Out-of-distribution Generation,8,Exploring Chemical Space with Score-based Out-of-distribution Generation,79,178,False,168,56,21,21,27,11,13,0,0,72,14493,3.761904761904762,1.0,2.6666666666666665,0.6190476190476191,28
3459,FR-Train: A mutual information-based approach to fair and robust training,8,FR-Train A mutual information-based approach to fair and robust training,54,153,True,60,34,24,15,10,8,12,2,24,72,10698,3.6,3.2,2.2666666666666666,0.8,66
3462,Fault Tolerance in Iterative-Convergent Machine Learning,8,Fault Tolerance in Iterative-Convergent Machine Learning,68,1,False,88,52,45,22,8,10,17,0,0,56,10849,3.090909090909091,2.0454545454545454,2.3636363636363638,0.7727272727272727,32
3463,Federated Learning with Only Positive Labels,8,Federated Learning with Only Positive Labels,30,172,False,54,56,0,15,0,7,6,0,8,44,7224,2.0,0.5333333333333333,3.7333333333333334,0.4,84
3464,Finding Options that Minimize Planning Time,8,Finding Options that Minimize Planning Time,49,97,False,43,18,51,18,0,10,10,1,2,43,13556,2.7222222222222223,2.9444444444444446,1.0,0.5555555555555556,35
3466,Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise,8,Fractional Underdamped Langevin Dynamics Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise,61,218,True,81,112,45,20,0,14,6,0,0,104,10914,3.05,2.25,5.6,0.3,44
3467,Fully Adaptive Composition in Differential Privacy,8,Fully Adaptive Composition in Differential Privacy,44,219,False,231,77,26,23,8,7,5,0,0,50,13733,1.9130434782608696,1.1304347826086956,3.347826086956522,0.21739130434782608,26
3468,GANMEX: One-vs-One Attributions using GAN-based Model Explainability,8,GANMEX One-vs-One Attributions using GAN-based Model Explainability,44,211,True,69,18,30,18,3,13,15,0,8,67,10851,2.4444444444444446,2.111111111111111,1.0,0.8333333333333334,11
3469,"Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits",8,Garbage In Reward Out Bootstrapping Exploration in Multi-Armed Bandits,41,153,False,73,128,6,16,0,11,9,4,0,70,10744,2.5625,0.375,8.0,0.5625,63
3470,Generalized Beliefs for Cooperative AI,8,Generalized Beliefs for Cooperative AI,50,143,True,79,20,45,21,4,16,9,0,4,38,9371,2.380952380952381,2.3333333333333335,0.9523809523809523,0.42857142857142855,3
3471,Generating Images with Sparse Representations,8,Generating Images with Sparse Representations,55,148,False,65,24,65,18,6,11,9,0,6,45,7773,3.0555555555555554,3.9444444444444446,1.3333333333333333,0.5,111
3474,Graph Homomorphism Convolution,8,Graph Homomorphism Convolution,50,115,False,82,26,18,15,10,9,18,2,12,30,9953,3.3333333333333335,2.0,1.7333333333333334,1.2,33
3475,Greedy Layerwise Learning Can Scale to ImageNet,8,Greedy Layerwise Learning Can Scale to ImageNet,69,203,False,112,22,15,14,5,8,10,0,14,47,10050,4.928571428571429,2.0714285714285716,1.5714285714285714,0.7142857142857143,155
3476,Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning,8,Head2Toe Utilizing Intermediate Representations for Better Transfer Learning,91,164,False,104,8,62,25,23,18,7,0,14,76,14411,3.64,3.04,0.32,0.28,61
3477,High-Dimensional Robust Mean Estimation via Gradient Descent,8,High-Dimensional Robust Mean Estimation via Gradient Descent,49,114,False,71,144,0,33,3,9,10,1,0,60,14949,1.4848484848484849,0.0,4.363636363636363,0.30303030303030304,27
3478,How and Why to Use Experimental Data to Evaluate Methods for Observational Causal Inference,8,How and Why to Use Experimental Data to Evaluate Methods for Observational Causal Inference,57,210,False,120,10,49,23,0,15,12,0,6,91,13194,2.4782608695652173,2.391304347826087,0.43478260869565216,0.5217391304347826,14
3479,HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning,8,HyperTransformer Model Generation for Supervised and Semi-Supervised Few-Shot Learning,46,140,False,112,26,71,24,22,16,8,0,8,86,12753,1.9166666666666667,3.2916666666666665,1.0833333333333333,0.3333333333333333,44
3480,Imitation Learning from Imperfect Demonstration,8,Imitation Learning from Imperfect Demonstration,43,87,False,98,108,18,25,0,10,19,3,6,47,10019,1.72,0.96,4.32,0.76,130
3481,Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters,8,Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters,40,151,False,67,106,19,18,0,10,7,3,2,83,9175,2.2222222222222223,1.1666666666666667,5.888888888888889,0.3888888888888889,16
3482,Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process,8,Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process,64,173,False,124,54,35,25,18,14,20,0,24,81,14886,2.56,2.36,2.16,0.8,3
3483,Improving Regression Performance with Distributional Losses,8,Improving Regression Performance with Distributional Losses,32,143,False,81,42,19,12,0,9,6,0,12,59,8125,2.6666666666666665,2.5833333333333335,3.5,0.5,44
3484,"Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence",8,Independent Policy Gradient for Large-Scale Markov Potential Games Sharper Rates Function Approximation and Game-Agnostic Convergence,95,172,False,170,516,28,55,3,16,13,0,0,135,30295,1.7272727272727273,0.509090909090909,9.381818181818181,0.23636363636363636,49
3485,InfoOT: Information Maximizing Optimal Transport,8,InfoOT Information Maximizing Optimal Transport,73,125,False,182,46,18,15,10,10,18,0,14,47,9011,4.866666666666666,2.1333333333333333,3.066666666666667,1.2,7
3487,Interpreting and Disentangling Feature Components of Various Complexity from DNNs,8,Interpreting and Disentangling Feature Components of Various Complexity from DNNs,62,112,False,52,13,58,18,0,13,2,0,4,81,9079,3.4444444444444446,3.4444444444444446,0.7222222222222222,0.1111111111111111,18
3488,Investigating Why Contrastive Learning Benefits Robustness Against Label Noise,8,Investigating Why Contrastive Learning Benefits Robustness Against Label Noise,52,1,False,72,154,20,21,7,10,15,4,8,78,13131,2.4761904761904763,1.3333333333333333,7.333333333333333,0.7142857142857143,30
3489,K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning,8,K-Beam Minimax Efficient Optimization for Deep Adversarial Learning,30,120,False,56,47,44,12,0,11,10,0,2,67,9218,2.5,3.8333333333333335,3.9166666666666665,0.8333333333333334,9
3490,Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks,8,Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks,72,197,False,109,299,30,35,33,10,16,0,18,80,20978,2.057142857142857,1.3714285714285714,8.542857142857143,0.45714285714285713,25
3492,Latent Space Factorisation and Manipulation via Matrix Subspace Projection,8,Latent Space Factorisation and Manipulation via Matrix Subspace Projection,32,129,False,48,26,16,11,0,6,9,0,10,74,8064,2.909090909090909,2.3636363636363638,2.3636363636363638,0.8181818181818182,26
3493,Learning Bellman Complete Representations for Offline Policy Evaluation,8,Learning Bellman Complete Representations for Offline Policy Evaluation,51,199,False,122,224,13,34,6,13,15,1,6,71,17615,1.5,0.5588235294117647,6.588235294117647,0.4411764705882353,8
3494,Learning Dynamics of Linear Denoising Autoencoders,8,Learning Dynamics of Linear Denoising Autoencoders,36,142,False,39,114,21,13,0,8,12,0,0,50,8234,2.769230769230769,1.6153846153846154,8.76923076923077,0.9230769230769231,22
3496,Learning Optimal Fair Policies,8,Learning Optimal Fair Policies,37,164,False,66,52,11,13,0,12,10,0,2,30,10115,2.8461538461538463,1.0,4.0,0.7692307692307693,81
3498,Learning from History for Byzantine Robust Optimization,8,Learning from History for Byzantine Robust Optimization,65,144,False,163,142,22,26,19,15,12,3,4,55,15905,2.5,1.0,5.461538461538462,0.46153846153846156,117
3501,Leveraging Frequency Analysis for Deep Fake Image Recognition,8,Leveraging Frequency Analysis for Deep Fake Image Recognition,58,166,False,118,2,69,17,10,11,8,0,12,61,8709,3.411764705882353,4.764705882352941,0.11764705882352941,0.47058823529411764,350
3502,Linear Convergence of Randomized Primal-Dual Coordinate Method for Large-scale Linear Constrained Convex Programming,8,Linear Convergence of Randomized Primal-Dual Coordinate Method for Large-scale Linear Constrained Convex Programming,40,121,False,38,180,20,19,0,16,9,2,0,116,8908,2.1052631578947367,1.0526315789473684,9.473684210526315,0.47368421052631576,7
3503,Locally Private Hypothesis Testing,8,Locally Private Hypothesis Testing,36,153,False,30,75,48,28,18,9,6,0,0,34,14328,1.2857142857142858,1.7142857142857142,2.6785714285714284,0.21428571428571427,49
3504,Low-Variance and Zero-Variance Baselines for Extensive-Form Games,8,Low-Variance and Zero-Variance Baselines for Extensive-Form Games,36,160,False,74,78,12,21,6,16,4,0,0,65,11136,1.7142857142857142,0.5714285714285714,3.7142857142857144,0.19047619047619047,17
3506,Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels,8,Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels,65,125,False,182,20,50,20,11,18,8,0,8,71,10803,3.25,2.9,1.0,0.4,9
3507,Measuring dissimilarity with diffeomorphism invariance,8,Measuring dissimilarity with diffeomorphism invariance,49,102,False,75,4,47,36,26,14,16,0,0,54,13756,1.3611111111111112,1.3055555555555556,0.1111111111111111,0.4444444444444444,1
3508,Meta-Learning with Shared Amortized Variational Inference,8,Meta-Learning with Shared Amortized Variational Inference,50,135,False,160,34,27,13,0,10,8,0,10,57,8898,3.8461538461538463,2.8461538461538463,2.6153846153846154,0.6153846153846154,20
3510,Modality Competition: What Makes Joint Training of Multi-modal Network Fail in Deep Learning? (Provably),8,Modality Competition What Makes Joint Training of Multi-modal Network Fail in Deep Learning Provably,64,186,False,62,156,6,41,26,10,18,2,0,102,16281,1.5609756097560976,0.14634146341463414,3.8048780487804876,0.43902439024390244,41
3513,Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning,8,Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning,50,145,False,183,30,45,40,2,13,13,0,14,72,20256,1.25,1.475,0.75,0.325,21
3514,Multidimensional Scaling: Approximation and Complexity,8,Multidimensional Scaling Approximation and Complexity,44,132,False,60,92,16,31,0,11,7,10,2,53,13304,1.4193548387096775,0.5806451612903226,2.967741935483871,0.22580645161290322,6
3515,NOMU: Neural Optimization-based Model Uncertainty,8,NOMU Neural Optimization-based Model Uncertainty,48,189,True,395,199,161,51,71,23,32,41,44,48,36805,0.9411764705882353,4.019607843137255,3.9019607843137254,0.6274509803921569,18
3516,Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation,8,Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation,36,143,False,135,358,3,48,28,15,22,4,4,80,29339,0.75,0.14583333333333334,7.458333333333333,0.4583333333333333,24
3517,Neural Inverse Transform Sampler,8,Neural Inverse Transform Sampler,39,206,False,62,104,13,13,0,14,23,4,8,32,8009,3.0,1.6153846153846154,8.0,1.7692307692307692,4
3518,Neural Transformation Learning for Deep Anomaly Detection Beyond Images,8,Neural Transformation Learning for Deep Anomaly Detection Beyond Images,63,142,False,139,36,0,20,0,11,14,0,0,71,11790,3.15,0.0,1.8,0.7,79
3519,Noise2Noise: Learning Image Restoration without Clean Data,8,Noise2Noise Learning Image Restoration without Clean Data,28,96,False,29,34,107,12,0,6,5,0,4,57,7848,2.3333333333333335,9.25,2.8333333333333335,0.4166666666666667,1262
3520,Nonparametric Factor Trajectory Learning for Dynamic Tensor Decomposition,8,Nonparametric Factor Trajectory Learning for Dynamic Tensor Decomposition,35,28,False,88,51,18,11,0,14,19,4,6,73,8309,3.1818181818181817,2.1818181818181817,4.636363636363637,1.7272727272727273,3
3521,Object Segmentation Without Labels with Large-Scale Generative Models,8,Object Segmentation Without Labels with Large-Scale Generative Models,39,115,False,62,12,26,11,0,5,11,0,10,69,6865,3.5454545454545454,3.272727272727273,1.0909090909090908,1.0,47
3522,OmniNet: Omnidirectional Representations from Transformers,8,OmniNet Omnidirectional Representations from Transformers,41,171,False,146,19,57,16,4,8,10,15,12,57,6903,2.5625,4.3125,1.1875,0.625,19
3523,On Finite-Sample Identifiability of Contrastive Learning-Based Nonlinear Independent Component Analysis,8,On Finite-Sample Identifiability of Contrastive Learning-Based Nonlinear Independent Component Analysis,50,216,False,67,183,12,19,12,9,10,2,0,103,10973,2.6315789473684212,0.631578947368421,9.631578947368421,0.5263157894736842,1
3524,On Numerical Integration in Neural Ordinary Differential Equations,8,On Numerical Integration in Neural Ordinary Differential Equations,57,160,False,43,332,9,21,0,8,17,0,2,66,11381,2.7142857142857144,0.5238095238095238,15.80952380952381,0.8095238095238095,15
3525,On the Connection Between Adversarial Robustness and Saliency Map Interpretability,8,On the Connection Between Adversarial Robustness and Saliency Map Interpretability,26,100,False,54,84,36,12,1,7,9,2,0,82,7603,2.1666666666666665,3.0,7.0,0.75,142
3526,On the Global Convergence of Fitted Q-Iteration with Two-layer Neural Network Parametrization,8,On the Global Convergence of Fitted Q-Iteration with Two-layer Neural Network Parametrization,72,96,False,55,348,0,46,0,13,7,0,0,93,16252,1.565217391304348,0.0,7.565217391304348,0.15217391304347827,0
3528,On-Off Center-Surround Receptive Fields for Accurate and Robust Image Classification,8,On-Off Center-Surround Receptive Fields for Accurate and Robust Image Classification,55,169,False,119,72,42,21,0,10,7,0,22,84,10286,2.619047619047619,3.0476190476190474,3.4285714285714284,0.3333333333333333,14
3530,Open Vocabulary Learning on Source Code with a Graph-Structured Cache,8,Open Vocabulary Learning on Source Code with a Graph-Structured Cache,50,129,False,82,8,9,13,0,8,7,0,16,69,7744,3.8461538461538463,1.9230769230769231,0.6153846153846154,0.5384615384615384,45
3531,Optimal Minimal Margin Maximization with Boosting,8,Optimal Minimal Margin Maximization with Boosting,32,105,False,63,50,42,31,6,7,9,0,2,49,15173,1.032258064516129,1.4193548387096775,1.6129032258064515,0.2903225806451613,5
3532,Optimization Theory for ReLU Neural Networks Trained with Normalization Layers,8,Optimization Theory for ReLU Neural Networks Trained with Normalization Layers,40,126,False,80,464,2,36,12,12,3,0,0,78,18270,1.1111111111111112,0.05555555555555555,12.88888888888889,0.08333333333333333,25
3533,Orthogonal Random Forest for Causal Inference,8,Orthogonal Random Forest for Causal Inference,25,1,False,89,565,153,43,29,25,27,1,0,45,22068,0.5813953488372093,3.558139534883721,13.13953488372093,0.627906976744186,91
3534,PAC-Net: A Model Pruning Approach to Inductive Transfer Learning,8,PAC-Net A Model Pruning Approach to Inductive Transfer Learning,50,167,True,70,30,24,13,22,6,12,0,12,63,8120,3.8461538461538463,2.769230769230769,2.3076923076923075,0.9230769230769231,6
3535,POEM: Out-of-Distribution Detection with Posterior Sampling,8,POEM Out-of-Distribution Detection with Posterior Sampling,59,117,True,154,40,15,16,16,16,6,0,12,58,10622,3.6875,1.6875,2.5,0.375,67
3536,Partial Counterfactual Identification from Observational and Experimental Data,8,Partial Counterfactual Identification from Observational and Experimental Data,64,162,False,171,414,54,30,24,8,13,0,6,78,23359,2.1333333333333333,2.0,13.8,0.43333333333333335,45
3537,Permutation Search of Tensor Network Structures via Local Sampling,8,Permutation Search of Tensor Network Structures via Local Sampling,73,176,False,114,66,45,19,0,9,16,0,12,66,12874,3.8421052631578947,3.0,3.473684210526316,0.8421052631578947,10
3539,Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning,8,Policy Teaching via Environment Poisoning Training-time Adversarial Attacks against Reinforcement Learning,62,185,False,49,216,30,27,4,18,22,0,0,106,16457,2.2962962962962963,1.1111111111111112,8.0,0.8148148148148148,107
3540,Predicting feature imputability in the absence of ground truth,8,Predicting feature imputability in the absence of ground truth,26,107,False,25,0,9,5,0,5,7,5,2,62,3472,5.2,2.2,0.0,1.4,3
3541,Prior Image-Constrained Reconstruction using Style-Based Generative Models,8,Prior Image-Constrained Reconstruction using Style-Based Generative Models,41,124,False,73,85,55,26,0,10,16,0,0,74,10767,1.5769230769230769,2.1153846153846154,3.269230769230769,0.6153846153846154,23
3542,Probabilistic ODE Solutions in Millions of Dimensions,8,Probabilistic ODE Solutions in Millions of Dimensions,37,127,True,117,106,15,16,21,11,14,2,0,53,9034,2.3125,0.9375,6.625,0.875,11
3543,Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity,8,Projection-Free Online Optimization with Stochastic Gradient From Convexity to Submodularity,37,202,False,60,11,10,19,6,10,5,0,0,92,11420,1.9473684210526316,0.5263157894736842,0.5789473684210527,0.2631578947368421,69
3544,Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance,8,Provable Stochastic Optimization for Global Contrastive Learning Small Batch Does Not Harm Performance,45,210,False,68,104,26,25,0,15,9,0,18,102,11759,1.8,1.76,4.16,0.36,14
3545,Proximal and Federated Random Reshuffling,8,Proximal and Federated Random Reshuffling,54,190,False,110,197,9,21,0,16,10,0,0,41,12941,2.5714285714285716,0.42857142857142855,9.380952380952381,0.47619047619047616,24
3546,Quantile Bandits for Best Arms Identification with Concentration Inequalities,8,Quantile Bandits for Best Arms Identification with Concentration Inequalities,32,126,False,30,8,3,27,1,3,1,0,2,77,16956,1.1851851851851851,0.18518518518518517,0.2962962962962963,0.037037037037037035,10
3548,Randomization matters. How to defend against strong adversarial attacks,8,Randomization matters How to defend against strong adversarial attacks,43,165,False,40,84,12,23,19,10,6,0,6,21,13591,1.8695652173913044,0.782608695652174,3.652173913043478,0.2608695652173913,43
3550,Regression with Label Permutation in Generalized Linear Model,8,Regression with Label Permutation in Generalized Linear Model,58,170,False,66,404,18,47,1,14,24,10,6,61,18914,1.2340425531914894,0.5106382978723404,8.595744680851064,0.5106382978723404,5
3551,Relative Deviation Margin Bounds,8,Relative Deviation Margin Bounds,41,85,False,118,202,3,34,0,15,5,0,0,32,12318,1.2058823529411764,0.08823529411764706,5.9411764705882355,0.14705882352941177,11
3552,Reserve Price Optimization for First Price Auctions,8,Reserve Price Optimization for First Price Auctions,33,156,False,40,86,20,26,2,9,17,0,6,51,11496,1.2692307692307692,1.0,3.3076923076923075,0.6538461538461539,12
3553,Reverse-engineering deep ReLU networks,8,Reverse-engineering deep ReLU networks,20,124,False,38,8,12,18,0,10,8,0,0,38,8084,1.1111111111111112,0.6666666666666666,0.4444444444444444,0.4444444444444444,76
3554,Riemannian Convex Potential Maps,8,Riemannian Convex Potential Maps,52,115,False,133,72,38,13,28,11,16,0,6,32,8540,4.0,3.3846153846153846,5.538461538461538,1.2307692307692308,19
3555,Robust Influence Maximization for Hyperparametric Models,8,Robust Influence Maximization for Hyperparametric Models,28,156,False,23,10,21,12,5,7,7,0,0,56,9513,2.3333333333333335,1.75,0.8333333333333334,0.5833333333333334,14
3556,Robust and Stable Black Box Explanations,8,Robust and Stable Black Box Explanations,48,171,False,57,58,20,14,0,9,14,0,10,40,9344,3.4285714285714284,2.142857142857143,4.142857142857143,1.0,69
3557,SDQ: Stochastic Differentiable Quantization with Mixed Precision,8,SDQ Stochastic Differentiable Quantization with Mixed Precision,57,209,True,89,60,32,15,0,10,13,3,22,63,10071,3.8,3.6,4.0,0.8666666666666667,19
3558,SWALP : Stochastic Weight Averaging in Low-Precision Training,8,SWALP  Stochastic Weight Averaging in Low-Precision Training,35,88,True,78,14,9,27,5,7,8,0,6,60,14349,1.2962962962962963,0.5555555555555556,0.5185185185185185,0.2962962962962963,78
3559,Sanity Simulations for Saliency Methods,8,Sanity Simulations for Saliency Methods,37,98,False,64,0,119,28,0,8,19,3,6,39,14470,1.3214285714285714,4.464285714285714,0.0,0.6785714285714286,18
3560,Scalable Nearest Neighbor Search for Optimal Transport,8,Scalable Nearest Neighbor Search for Optimal Transport,41,105,False,43,55,28,20,17,7,12,0,14,54,9788,2.05,2.1,2.75,0.6,50
3561,Screening Rules for Lasso with Non-Convex Sparse Regularizers,8,Screening Rules for Lasso with Non-Convex Sparse Regularizers,42,144,False,100,57,13,12,2,7,11,0,2,61,7640,3.5,1.25,4.75,0.9166666666666666,21
3562,Self-Imitation Learning,8,Self-Imitation Learning,42,78,False,97,24,22,13,10,9,10,0,10,23,7945,3.230769230769231,2.4615384615384617,1.8461538461538463,0.7692307692307693,187
3563,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories,8,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories,59,151,False,69,20,95,24,19,15,10,3,8,76,12884,2.4583333333333335,4.291666666666667,0.8333333333333334,0.4166666666666667,11
3564,Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion,8,Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion,27,125,False,49,91,38,24,7,10,9,0,4,82,9246,1.125,1.75,3.7916666666666665,0.375,21
3565,Simple and sharp analysis of k-means||,8,Simple and sharp analysis of k-means,35,51,False,48,42,0,10,3,6,7,0,0,36,7431,3.5,0.0,4.2,0.7,6
3566,Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions,8,Sliced-Wasserstein Flows Nonparametric Generative Modeling via Optimal Transport and Diffusions,54,167,False,69,136,67,25,0,11,16,0,0,95,13210,2.16,2.68,5.44,0.64,104
3567,SoundDet: Polyphonic Moving Sound Event Detection and Localization from Raw Waveform,8,SoundDet Polyphonic Moving Sound Event Detection and Localization from Raw Waveform,29,230,False,49,12,18,11,0,6,11,0,8,83,7686,2.6363636363636362,2.3636363636363638,1.0909090909090908,1.0,11
3568,Spectral Frank-Wolfe Algorithm: Strict Complementarity and Linear Convergence,8,Spectral Frank-Wolfe Algorithm Strict Complementarity and Linear Convergence,28,28,False,87,214,22,23,19,19,16,4,6,76,11865,1.2173913043478262,1.2173913043478262,9.304347826086957,0.6956521739130435,14
3569,Staged Training for Transformer Language Models,8,Staged Training for Transformer Language Models,31,220,False,60,50,31,15,13,12,8,2,14,47,9181,2.066666666666667,3.0,3.3333333333333335,0.5333333333333333,23
3570,Stochastic Continuous Submodular Maximization: Boosting via Non-oblivious Function,8,Stochastic Continuous Submodular Maximization Boosting via Non-oblivious Function,43,211,False,0,0,0,29,0,10,2,0,0,81,10996,1.4827586206896552,0.0,0.0,0.06896551724137931,13
3571,Stochastic Subspace Cubic Newton Method,8,Stochastic Subspace Cubic Newton Method,60,163,False,138,102,56,29,9,14,20,2,2,39,14059,2.0689655172413794,2.0,3.5172413793103448,0.6896551724137931,37
3573,Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors,8,Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors,49,100,False,55,46,23,14,11,13,3,0,4,81,8927,3.5,1.9285714285714286,3.2857142857142856,0.21428571428571427,69
3574,Supervised Hierarchical Clustering with Exponential Linkage,8,Supervised Hierarchical Clustering with Exponential Linkage,58,194,False,44,13,16,12,6,8,12,0,0,59,9073,4.833333333333333,1.3333333333333333,1.0833333333333333,1.0,21
3575,TACO: Learning Task Decomposition via Temporal Alignment for Control,8,TACO Learning Task Decomposition via Temporal Alignment for Control,34,156,True,90,24,44,12,0,17,37,10,10,67,8092,2.8333333333333335,4.5,2.0,3.0833333333333335,76
3576,Taylor Expansion Policy Optimization,8,Taylor Expansion Policy Optimization,37,66,False,178,92,27,23,30,18,33,4,6,36,13963,1.608695652173913,1.434782608695652,4.0,1.434782608695652,12
3577,TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models,8,TeraPipe Token-Level Pipeline Parallelism for Training Large-Scale Language Models,39,143,False,92,15,31,12,0,10,7,0,8,82,8639,3.25,3.25,1.25,0.5833333333333334,75
3578,The Evolved Transformer,8,The Evolved Transformer,49,175,False,54,0,15,14,15,10,9,0,10,23,10305,3.5,1.7857142857142858,0.0,0.6428571428571429,427
3579,The Natural Language of Actions,8,The Natural Language of Actions,34,104,False,40,34,24,15,0,7,8,3,0,31,8604,2.2666666666666666,1.6,2.2666666666666666,0.5333333333333333,56
3581,Thompson Sampling for High-Dimensional Sparse Linear Contextual Bandits,8,Thompson Sampling for High-Dimensional Sparse Linear Contextual Bandits,52,99,False,99,249,17,38,8,11,16,2,6,71,15198,1.368421052631579,0.6052631578947368,6.552631578947368,0.42105263157894735,4
3582,Top-k eXtreme Contextual Bandits with Arm Hierarchy,8,Top-k eXtreme Contextual Bandits with Arm Hierarchy,48,226,False,127,135,19,32,2,13,6,0,4,51,14702,1.5,0.71875,4.21875,0.1875,7
3583,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,8,Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron,35,115,False,42,8,21,11,0,7,10,2,2,81,6581,3.1818181818181817,2.090909090909091,0.7272727272727273,0.9090909090909091,499
3584,Towards Understanding the Importance of Noise in Training Neural Networks,8,Towards Understanding the Importance of Noise in Training Neural Networks,23,118,False,80,245,9,46,0,11,10,8,2,73,17965,0.5,0.2391304347826087,5.326086956521739,0.21739130434782608,26
3585,Training OOD Detectors in their Natural Habitats,8,Training OOD Detectors in their Natural Habitats,52,151,True,60,84,8,18,21,11,7,0,8,48,10900,2.888888888888889,0.8888888888888888,4.666666666666667,0.3888888888888889,51
3586,Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention,8,Transformers are RNNs Fast Autoregressive Transformers with Linear Attention,43,102,False,64,46,52,17,0,10,12,7,10,76,8711,2.5294117647058822,3.6470588235294117,2.7058823529411766,0.7058823529411765,1017
3588,Understanding and Controlling Memory in Recurrent Neural Networks,8,Understanding and Controlling Memory in Recurrent Neural Networks,32,232,False,55,12,30,12,0,14,1,0,8,65,6617,2.6666666666666665,3.1666666666666665,1.0,0.08333333333333333,18
3589,Uniform Convergence Rate of the Kernel Density Estimator Adaptive to Intrinsic Volume Dimension,8,Uniform Convergence Rate of the Kernel Density Estimator Adaptive to Intrinsic Volume Dimension,36,217,False,99,349,0,51,0,14,4,0,0,95,16838,0.7058823529411765,0.0,6.8431372549019605,0.0784313725490196,26
3590,Unsupervised Image Representation Learning with Deep Latent Particles,8,Unsupervised Image Representation Learning with Deep Latent Particles,62,146,False,247,4,39,22,14,14,13,0,8,69,11587,2.8181818181818183,2.1363636363636362,0.18181818181818182,0.5909090909090909,4
3591,VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix,8,VLMixer Unpaired Vision-Language Pre-training via Cross-Modal CutMix,43,198,False,79,14,15,11,14,6,8,0,10,68,7533,3.909090909090909,2.272727272727273,1.2727272727272727,0.7272727272727273,26
3592,Variational Inference with Locally Enhanced Bounds for Hierarchical Models,8,Variational Inference with Locally Enhanced Bounds for Hierarchical Models,57,160,False,21,26,8,14,5,5,2,0,0,74,8239,4.071428571428571,0.5714285714285714,1.8571428571428572,0.14285714285714285,4
3593,WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points,8,WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points,59,90,True,84,200,35,26,0,9,13,0,0,72,12237,2.269230769230769,1.3461538461538463,7.6923076923076925,0.5,2
3594,What can linear interpolation of neural network loss landscapes tell us?,8,What can linear interpolation of neural network loss landscapes tell us,38,179,False,91,8,58,17,0,16,2,0,8,71,10833,2.235294117647059,3.8823529411764706,0.47058823529411764,0.11764705882352941,19
3595,Whitening for Self-Supervised Representation Learning,8,Whitening for Self-Supervised Representation Learning,65,153,False,207,26,15,12,0,10,4,0,10,53,8344,5.416666666666667,2.0833333333333335,2.1666666666666665,0.3333333333333333,245
3596,Z-GCNETs: Time Zigzags at Graph Convolutional Networks for Time Series Forecasting,8,Z-GCNETs Time Zigzags at Graph Convolutional Networks for Time Series Forecasting,51,203,False,54,22,6,11,0,10,6,0,18,81,7709,4.636363636363637,2.1818181818181817,2.0,0.5454545454545454,79
3597,A Deep Conjugate Direction Method for Iteratively Solving Linear Systems,8,A Deep Conjugate Direction Method for Iteratively Solving Linear Systems,49,254,False,97,20,16,12,0,7,3,0,0,72,7309,4.083333333333333,1.3333333333333333,1.6666666666666667,0.25,8
3598,A Functional Information Perspective on Model Interpretation,8,A Functional Information Perspective on Model Interpretation,41,115,False,62,49,10,13,7,9,10,0,4,60,8338,3.1538461538461537,1.0769230769230769,3.769230769230769,0.7692307692307693,4
3599,A Mean-field Analysis of Deep ResNet and Beyond: Towards Provable Optimization Via Overparameterization From Depth,8,A Mean-field Analysis of Deep ResNet and Beyond Towards Provable Optimization Via Overparameterization From Depth,83,240,False,61,134,3,27,8,7,12,0,2,113,10456,3.074074074074074,0.18518518518518517,4.962962962962963,0.4444444444444444,68
3600,A Representation Learning Perspective on the Importance of Train-Validation Splitting in Meta-Learning,8,A Representation Learning Perspective on the Importance of Train-Validation Splitting in Meta-Learning,51,1,False,156,160,27,38,31,18,13,0,16,102,18981,1.3421052631578947,1.131578947368421,4.2105263157894735,0.34210526315789475,16
3602,A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization,8,A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization,38,155,False,37,120,42,14,0,13,15,0,8,81,9390,2.7142857142857144,3.5714285714285716,8.571428571428571,1.0714285714285714,63
3603,ARMS: Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables,8,ARMS Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables,38,152,True,51,138,30,21,0,10,15,2,8,68,12138,1.8095238095238095,1.8095238095238095,6.571428571428571,0.7142857142857143,11
3604,Accelerating Safe Reinforcement Learning with Constraint-mismatched Baseline Policies,8,Accelerating Safe Reinforcement Learning with Constraint-mismatched Baseline Policies,64,146,False,127,157,155,34,20,17,4,0,8,85,18621,1.8823529411764706,4.794117647058823,4.617647058823529,0.11764705882352941,14
3605,Active Manifolds: A non-linear analogue to Active Subspaces,8,Active Manifolds A non-linear analogue to Active Subspaces,33,24,False,56,9,25,9,0,7,6,6,8,58,7586,3.6666666666666665,3.6666666666666665,1.0,0.6666666666666666,17
3607,Adaptive Three Operator Splitting,8,Adaptive Three Operator Splitting,50,147,False,204,260,23,36,30,12,23,0,0,33,17745,1.3888888888888888,0.6388888888888888,7.222222222222222,0.6388888888888888,29
3608,Adversarial Dueling Bandits,8,Adversarial Dueling Bandits,43,169,False,36,87,4,25,6,11,4,0,0,27,11774,1.72,0.16,3.48,0.16,18
3609,Adversarial camera stickers: A physical camera-based attack on deep learning systems,8,Adversarial camera stickers A physical camera-based attack on deep learning systems,22,187,False,42,24,36,9,3,5,9,0,6,83,6474,2.4444444444444446,4.666666666666667,2.6666666666666665,1.0,134
3610,All in the Exponential Family: Bregman Duality in Thermodynamic Variational Inference,8,All in the Exponential Family Bregman Duality in Thermodynamic Variational Inference,54,181,False,149,199,51,25,20,20,22,2,0,84,15578,2.16,2.04,7.96,0.88,14
3612,An iterative clustering algorithm for the Contextual Stochastic Block Model with optimality guarantees,8,An iterative clustering algorithm for the Contextual Stochastic Block Model with optimality guarantees,40,153,False,104,261,33,35,19,18,38,4,4,102,15835,1.1428571428571428,1.0571428571428572,7.457142857142857,1.0857142857142856,7
3613,Anticorrelated Noise Injection for Improved Generalization,8,Anticorrelated Noise Injection for Improved Generalization,45,142,False,94,142,80,24,26,9,17,2,0,58,15066,1.875,3.3333333333333335,5.916666666666667,0.7083333333333334,39
3614,Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models,8,Arithmetic Sampling Parallel Diverse Decoding for Large Language Models,30,154,False,61,60,3,17,2,10,14,1,0,71,9419,1.7647058823529411,0.17647058823529413,3.5294117647058822,0.8235294117647058,3
3616,BANG: Bridging Autoregressive and Non-autoregressive Generation with Large Scale Pretraining,8,BANG Bridging Autoregressive and Non-autoregressive Generation with Large Scale Pretraining,35,154,True,138,22,12,10,3,7,6,7,24,91,6744,3.5,3.6,2.2,0.6,39
3618,Bayesian Optimization for Distributionally Robust Chance-constrained Problem,8,Bayesian Optimization for Distributionally Robust Chance-constrained Problem,37,0,False,28,90,0,18,5,7,10,0,6,76,10864,2.0555555555555554,0.3333333333333333,5.0,0.5555555555555556,8
3619,Best Arm Identification in Graphical Bilinear Bandits,8,Best Arm Identification in Graphical Bilinear Bandits,43,113,False,116,153,7,21,6,14,9,0,2,53,12437,2.0476190476190474,0.42857142857142855,7.285714285714286,0.42857142857142855,5
3620,Bilinear Bandits with Low-rank Structure,8,Bilinear Bandits with Low-rank Structure,45,196,False,118,102,5,14,5,17,1,0,0,40,9867,3.2142857142857144,0.35714285714285715,7.285714285714286,0.07142857142857142,51
3621,Blocks Assemble! Learning to Assemble with Large-Scale Structured Reinforcement Learning,8,Blocks Assemble Learning to Assemble with Large-Scale Structured Reinforcement Learning,55,186,False,102,0,73,36,17,24,28,4,8,88,9697,1.5277777777777777,2.25,0.0,0.7777777777777778,19
3622,Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities,8,Breaking Down Out-of-Distribution Detection Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities,50,207,True,199,112,0,34,0,18,10,1,40,134,19642,1.4705882352941178,1.1764705882352942,3.2941176470588234,0.29411764705882354,18
3623,Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates,8,Byzantine-Robust Distributed Learning Towards Optimal Statistical Rates,45,153,False,65,188,4,33,7,17,14,0,10,71,16501,1.3636363636363635,0.42424242424242425,5.696969696969697,0.42424242424242425,1016
3624,Calibrated Model-Based Deep Reinforcement Learning,8,Calibrated Model-Based Deep Reinforcement Learning,41,122,False,119,26,19,14,23,13,10,2,4,50,8051,2.9285714285714284,1.6428571428571428,1.8571428571428572,0.7142857142857143,49
3625,Causal Modeling for Fairness in Dynamical Systems,8,Causal Modeling for Fairness in Dynamical Systems,82,126,False,150,34,33,17,9,12,15,0,8,49,11216,4.823529411764706,2.411764705882353,2.0,0.8823529411764706,60
3626,Characterizing Fairness Over the Set of Good Models Under Selective Labels,8,Characterizing Fairness Over the Set of Good Models Under Selective Labels,64,147,False,140,406,56,38,8,26,48,20,24,74,18842,1.6842105263157894,2.1052631578947367,10.68421052631579,1.263157894736842,51
3627,Closed-Form Diffeomorphic Transformations for Time Series Alignment,8,Closed-Form Diffeomorphic Transformations for Time Series Alignment,51,166,False,107,200,91,37,9,23,38,8,6,67,17448,1.3783783783783783,2.6216216216216215,5.405405405405405,1.027027027027027,1
3628,Collapsed Amortized Variational Inference for Switching Nonlinear Dynamical Systems,8,Collapsed Amortized Variational Inference for Switching Nonlinear Dynamical Systems,32,85,False,89,44,27,14,0,6,7,0,10,83,9006,2.2857142857142856,2.642857142857143,3.142857142857143,0.5,19
3631,Configurable Markov Decision Processes,8,Configurable Markov Decision Processes,35,104,False,53,146,45,27,0,12,15,0,8,38,16366,1.2962962962962963,1.962962962962963,5.407407407407407,0.5555555555555556,32
3632,Constrained Markov Decision Processes via Backward Value Functions,8,Constrained Markov Decision Processes via Backward Value Functions,43,192,False,136,114,32,20,0,18,17,0,0,66,11280,2.15,1.6,5.7,0.85,43
3633,Continual Reinforcement Learning with Complex Synapses,8,Continual Reinforcement Learning with Complex Synapses,29,139,False,43,24,32,14,0,8,10,8,4,54,8099,2.0714285714285716,2.5714285714285716,1.7142857142857142,0.7142857142857143,82
3634,Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks,8,Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks,81,128,False,74,55,43,28,9,12,19,2,20,80,17053,2.892857142857143,2.25,1.9642857142857142,0.6785714285714286,36
3635,Cooperative Online Learning in Stochastic and Adversarial MDPs,8,Cooperative Online Learning in Stochastic and Adversarial MDPs,67,175,False,149,249,2,52,1,15,25,0,2,62,29942,1.2884615384615385,0.07692307692307693,4.788461538461538,0.4807692307692308,2
3637,Cyclic Block Coordinate Descent With Variance Reduction for Composite Nonconvex Optimization,8,Cyclic Block Coordinate Descent With Variance Reduction for Composite Nonconvex Optimization,71,181,False,104,248,27,29,6,10,3,0,2,92,13679,2.4482758620689653,1.0,8.551724137931034,0.10344827586206896,8
3639,Data-driven Prediction of General Hamiltonian Dynamics via Learning Exactly-Symplectic Maps,8,Data-driven Prediction of General Hamiltonian Dynamics via Learning Exactly-Symplectic Maps,55,228,False,51,198,20,17,0,7,13,2,0,91,12566,3.235294117647059,1.1764705882352942,11.647058823529411,0.7647058823529411,35
3640,Decision-Focused Learning: Through the Lens of Learning to Rank,8,Decision-Focused Learning Through the Lens of Learning to Rank,27,190,False,90,46,31,13,12,10,10,0,6,62,7960,2.076923076923077,2.8461538461538463,3.5384615384615383,0.7692307692307693,27
3641,Deep Hierarchy in Bandits,8,Deep Hierarchy in Bandits,48,182,False,69,128,13,16,0,10,16,0,0,25,10561,3.0,0.8125,8.0,1.0,12
3642,Deep supervised feature selection using Stochastic Gates,8,Deep supervised feature selection using Stochastic Gates,75,152,False,72,54,55,28,5,19,14,0,6,56,11951,2.6785714285714284,2.1785714285714284,1.9285714285714286,0.5,48
3643,Denoising MCMC for Accelerating Diffusion-Based Generative Models,8,Denoising MCMC for Accelerating Diffusion-Based Generative Models,38,252,True,128,32,59,17,0,8,11,0,4,65,6712,2.235294117647059,3.7058823529411766,1.8823529411764706,0.6470588235294118,5
3645,Differentially Private Fair Learning,8,Differentially Private Fair Learning,17,212,False,81,131,6,31,0,9,14,2,2,36,13889,0.5483870967741935,0.25806451612903225,4.225806451612903,0.45161290322580644,130
3646,Direct Uncertainty Prediction for Medical Second Opinions,8,Direct Uncertainty Prediction for Medical Second Opinions,39,138,False,29,30,38,15,0,13,5,1,16,57,9588,2.6,3.6,2.0,0.3333333333333333,115
3647,Discriminative Adversarial Search for Abstractive Summarization,8,Discriminative Adversarial Search for Abstractive Summarization,39,152,False,70,8,16,10,9,8,5,0,2,63,6748,3.9,1.8,0.8,0.5,27
3648,Distribution Calibration for Regression,8,Distribution Calibration for Regression,34,92,False,44,42,7,10,2,8,5,0,10,39,7661,3.4,1.7,4.2,0.5,97
3649,Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training,8,Do We Actually Need Dense Over-Parameterization In-Time Over-Parameterization in Sparse Training,74,186,False,127,0,30,16,0,13,12,2,10,96,10852,4.625,2.5,0.0,0.75,97
3650,Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables,8,Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables,52,118,False,55,116,12,18,0,12,15,0,20,95,11550,2.888888888888889,1.7777777777777777,6.444444444444445,0.8333333333333334,29
3651,EF21-P and Friends: Improved Theoretical Communication Complexity for Distributed Optimization with Bidirectional Compression,8,EF21-P and Friends Improved Theoretical Communication Complexity for Distributed Optimization with Bidirectional Compression,58,137,False,159,322,23,47,0,15,16,0,6,124,21917,1.2340425531914894,0.6170212765957447,6.851063829787234,0.3404255319148936,15
3652,Efficient Neural Architecture Search via Parameter Sharing,8,Efficient Neural Architecture Search via Parameter Sharing,54,1,False,182,12,28,11,18,11,10,0,4,58,7634,4.909090909090909,2.909090909090909,1.0909090909090908,0.9090909090909091,2492
3653,Efficient learning of smooth probability functions from Bernoulli tests with guarantees,8,Efficient learning of smooth probability functions from Bernoulli tests with guarantees,30,97,False,46,143,20,20,7,12,22,0,0,87,12015,1.5,1.0,7.15,1.1,1
3654,End-to-End Multi-Object Detection with a Regularized Mixture Model,8,End-to-End Multi-Object Detection with a Regularized Mixture Model,34,152,False,72,28,45,16,0,14,14,3,18,66,9566,2.125,3.9375,1.75,0.875,0
3655,Equivariant Neural Rendering,8,Equivariant Neural Rendering,47,117,False,75,6,198,14,0,15,14,0,14,28,8431,3.357142857142857,15.142857142857142,0.42857142857142855,1.0,58
3657,Examining and Combating Spurious Features under Distribution Shift,8,Examining and Combating Spurious Features under Distribution Shift,57,213,False,135,44,15,15,3,13,10,0,8,66,11110,3.8,1.5333333333333334,2.933333333333333,0.6666666666666666,53
3658,Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks,8,Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks,29,126,False,42,44,52,11,0,13,8,0,12,74,7012,2.6363636363636362,5.818181818181818,4.0,0.7272727272727273,97
3659,FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels,8,FaDIn Fast Discretized Inference for Hawkes Processes with General Parametric Kernels,70,187,False,143,58,96,23,4,7,14,1,2,85,12479,3.0434782608695654,4.260869565217392,2.5217391304347827,0.6086956521739131,1
3660,Fast Algorithms for Stackelberg Prediction Game with Least Squares Loss,8,Fast Algorithms for Stackelberg Prediction Game with Least Squares Loss,38,221,False,124,80,34,16,0,8,8,6,12,71,10022,2.375,2.875,5.0,0.5,11
3661,Fast Sketching of Polynomial Kernels of Polynomial Degree,8,Fast Sketching of Polynomial Kernels of Polynomial Degree,59,1,False,56,286,0,34,12,13,18,0,2,57,13913,1.7352941176470589,0.058823529411764705,8.411764705882353,0.5294117647058824,38
3662,FeDXL: Provable Federated Learning for Deep X-Risk Optimization,8,FeDXL Provable Federated Learning for Deep X-Risk Optimization,71,282,False,104,370,9,34,0,13,11,0,10,62,20065,2.088235294117647,0.5588235294117647,10.882352941176471,0.3235294117647059,5
3663,Federated Learning with Partial Model Personalization,8,Federated Learning with Partial Model Personalization,58,119,False,189,281,40,48,1,8,19,4,28,53,23471,1.2083333333333333,1.4166666666666667,5.854166666666667,0.3958333333333333,91
3664,Finding the Stochastic Shortest Path with Low Regret: The Adversarial Cost and Unknown Transition Case,8,Finding the Stochastic Shortest Path with Low Regret The Adversarial Cost and Unknown Transition Case,20,135,False,168,261,0,39,14,14,4,0,2,101,24192,0.5128205128205128,0.05128205128205128,6.6923076923076925,0.10256410256410256,29
3665,Flexible and Efficient Long-Range Planning Through Curious Exploration,8,Flexible and Efficient Long-Range Planning Through Curious Exploration,71,256,False,48,7,21,15,0,12,27,0,2,70,11629,4.733333333333333,1.5333333333333334,0.4666666666666667,1.8,5
3666,Framework for Evaluating Faithfulness of Local Explanations,8,Framework for Evaluating Faithfulness of Local Explanations,59,88,False,44,14,39,32,7,12,20,9,14,59,10452,1.84375,1.65625,0.4375,0.625,30
3668,GANs May Have No Nash Equilibria,8,GANs May Have No Nash Equilibria,52,224,False,55,206,59,38,0,12,11,0,2,32,12233,1.368421052631579,1.605263157894737,5.421052631578948,0.2894736842105263,41
3670,Generalized Data Distribution Iteration,8,Generalized Data Distribution Iteration,49,200,False,435,176,301,82,11,19,35,20,46,39,34676,0.5975609756097561,4.2317073170731705,2.1463414634146343,0.4268292682926829,9
3671,Generative Adversarial Imitation Learning with Neural Networks: Global Optimality and Convergence Rate,8,Generative Adversarial Imitation Learning with Neural Networks Global Optimality and Convergence Rate,55,109,False,81,316,0,42,0,9,17,0,0,101,14875,1.3095238095238095,0.0,7.523809523809524,0.40476190476190477,11
3672,Geometric Scattering for Graph Data Analysis,8,Geometric Scattering for Graph Data Analysis,51,1,False,182,12,15,15,3,9,7,1,14,44,10681,3.4,1.9333333333333333,0.8,0.4666666666666667,96
3673,Going Deeper into Permutation-Sensitive Graph Neural Networks,8,Going Deeper into Permutation-Sensitive Graph Neural Networks,83,141,False,224,102,36,36,20,19,21,5,16,61,22336,2.3055555555555554,1.4444444444444444,2.8333333333333335,0.5833333333333334,23
3674,Graph Matching Networks for Learning the Similarity of Graph Structured Objects,8,Graph Matching Networks for Learning the Similarity of Graph Structured Objects,65,165,False,102,20,62,18,0,8,8,0,6,79,12426,3.611111111111111,3.7777777777777777,1.1111111111111112,0.4444444444444444,419
3675,Hermite Polynomial Features for Private Data Generation,8,Hermite Polynomial Features for Private Data Generation,43,173,False,47,158,20,25,3,15,22,3,2,55,13524,1.72,0.88,6.32,0.88,14
3676,High-Fidelity Image Generation With Fewer Labels,8,High-Fidelity Image Generation With Fewer Labels,45,119,False,100,14,67,23,5,11,7,0,28,48,9040,1.9565217391304348,4.130434782608695,0.6086956521739131,0.30434782608695654,149
3677,How could Neural Networks understand Programs?,8,How could Neural Networks understand Programs,61,245,False,124,4,6,16,0,14,18,4,20,45,10705,3.8125,1.625,0.25,1.125,49
3678,HyperTuning: Toward Adapting Large Language Models without Back-propagation,8,HyperTuning Toward Adapting Large Language Models without Back-propagation,45,157,False,104,8,20,22,6,12,12,3,0,74,9390,2.0454545454545454,0.9090909090909091,0.36363636363636365,0.5454545454545454,18
3679,Imitation by Predicting Observations,8,Imitation by Predicting Observations,68,141,False,138,88,56,19,0,20,32,0,20,36,12456,3.5789473684210527,4.0,4.631578947368421,1.6842105263157894,10
3680,Improved Algorithms for Agnostic Pool-based Active Classification,8,Improved Algorithms for Agnostic Pool-based Active Classification,38,215,False,93,379,31,43,0,20,11,2,4,65,18033,0.8837209302325582,0.813953488372093,8.813953488372093,0.2558139534883721,18
3681,Improving Adversarial Robustness by Putting More Regularizations on Less Robust Samples,8,Improving Adversarial Robustness by Putting More Regularizations on Less Robust Samples,48,131,False,192,52,4,18,9,13,20,8,42,87,9757,2.6666666666666665,2.5555555555555554,2.888888888888889,1.1111111111111112,2
3682,Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification,8,Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification,43,157,False,103,64,14,16,0,15,13,3,16,113,9953,2.6875,1.875,4.0,0.8125,7
3683,Individual Calibration with Randomized Forecasting,8,Individual Calibration with Randomized Forecasting,42,86,False,122,91,31,19,7,21,43,13,6,50,11047,2.210526315789474,1.9473684210526316,4.7894736842105265,2.263157894736842,53
3684,Information Discrepancy in Strategic Learning,8,Information Discrepancy in Strategic Learning,57,1,False,49,108,4,35,0,13,16,0,4,45,14956,1.6285714285714286,0.22857142857142856,3.085714285714286,0.45714285714285713,31
3686,Interval Bound Interpolation for Few-shot Learning with Few Tasks,8,Interval Bound Interpolation for Few-shot Learning with Few Tasks,60,199,False,410,62,19,28,0,12,6,0,50,65,16300,2.142857142857143,2.4642857142857144,2.2142857142857144,0.21428571428571427,1
3687,Involutive MCMC: a Unifying Framework,8,Involutive MCMC a Unifying Framework,38,136,True,163,316,6,35,0,10,26,3,4,36,19241,1.0857142857142856,0.2857142857142857,9.028571428571428,0.7428571428571429,31
3688,K-means++: Few More Steps Yield Constant Approximation,8,K-means Few More Steps Yield Constant Approximation,23,101,False,25,48,4,14,7,5,10,0,0,53,9050,1.6428571428571428,0.2857142857142857,3.4285714285714284,0.7142857142857143,20
3689,Knowledge Transfer with Jacobian Matching,8,Knowledge Transfer with Jacobian Matching,22,118,False,86,34,6,11,0,10,12,5,10,41,7756,2.0,1.4545454545454546,3.090909090909091,1.0909090909090908,146
3690,Lagrangian Method for Q-Function Learning (with Applications to Machine Translation),8,Lagrangian Method for Q-Function Learning with Applications to Machine Translation,52,116,False,68,26,24,31,0,12,17,0,4,84,20134,1.6774193548387097,0.9032258064516129,0.8387096774193549,0.5483870967741935,1
3691,Latent Space Policies for Hierarchical Reinforcement Learning,8,Latent Space Policies for Hierarchical Reinforcement Learning,40,195,False,83,12,24,11,0,10,14,0,4,61,8092,3.6363636363636362,2.5454545454545454,1.0909090909090908,1.2727272727272727,169
3693,Learning Efficient Multi-agent Communication: An Information Bottleneck Approach,8,Learning Efficient Multi-agent Communication An Information Bottleneck Approach,42,179,False,45,24,18,9,0,7,9,0,4,79,6993,4.666666666666667,2.4444444444444446,2.6666666666666665,1.0,71
3695,Learning Optimal Linear Regularizers,8,Learning Optimal Linear Regularizers,17,91,False,19,42,14,10,0,8,7,0,2,36,6179,1.7,1.6,4.2,0.7,7
3697,Learning from Irregularly-Sampled Time Series: A Missing Data Perspective,8,Learning from Irregularly-Sampled Time Series A Missing Data Perspective,29,1,False,86,61,47,14,0,14,13,0,6,72,9089,2.0714285714285716,3.7857142857142856,4.357142857142857,0.9285714285714286,41
3698,Learning to Groove with Inverse Sequence Transformations,8,Learning to Groove with Inverse Sequence Transformations,38,169,False,49,8,18,11,13,11,14,6,4,56,7358,3.4545454545454546,2.0,0.7272727272727273,1.2727272727272727,59
3699,Learning to Speed Up Structured Output Prediction,8,Learning to Speed Up Structured Output Prediction,34,157,False,33,140,3,13,1,13,6,0,4,49,9250,2.6153846153846154,0.5384615384615384,10.76923076923077,0.46153846153846156,6
3700,Leveraging Language to Learn Program Abstractions and Search Heuristics,8,Leveraging Language to Learn Program Abstractions and Search Heuristics,80,1,False,130,36,21,24,2,11,17,3,2,71,18335,3.3333333333333335,0.9583333333333334,1.5,0.7083333333333334,45
3701,Linear Mode Connectivity and the Lottery Ticket Hypothesis,8,Linear Mode Connectivity and the Lottery Ticket Hypothesis,36,124,False,80,0,369,30,0,15,6,0,4,58,19172,1.2,12.433333333333334,0.0,0.2,422
3702,Locally Private k-Means in One Round,8,Locally Private k-Means in One Round,72,100,False,135,107,9,35,4,10,15,2,0,36,15611,2.057142857142857,0.2571428571428571,3.057142857142857,0.42857142857142855,24
3703,Low-loss connection of weight vectors: distribution-based approaches,8,Low-loss connection of weight vectors distribution-based approaches,22,108,False,23,27,31,13,0,11,10,1,10,67,8777,1.6923076923076923,3.1538461538461537,2.076923076923077,0.7692307692307693,3
3704,MONK - Outlier-Robust Mean Embedding Estimation by Median-of-Means,8,MONK - Outlier-Robust Mean Embedding Estimation by Median-of-Means,99,131,True,108,128,13,17,0,10,2,0,2,66,11146,5.823529411764706,0.8823529411764706,7.529411764705882,0.11764705882352941,34
3705,Matching Learned Causal Effects of Neural Networks with Domain Priors,8,Matching Learned Causal Effects of Neural Networks with Domain Priors,62,181,False,96,44,49,21,1,16,16,0,32,69,15360,2.9523809523809526,3.857142857142857,2.0952380952380953,0.7619047619047619,10
3706,Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments,8,Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments,92,193,False,196,79,113,37,2,18,28,10,20,93,24267,2.4864864864864864,3.5945945945945947,2.135135135135135,0.7567567567567568,26
3707,Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation,8,Meta-StyleSpeech  Multi-Speaker Adaptive Text-to-Speech Generation,50,183,False,97,26,27,16,10,8,9,0,0,66,9090,3.125,1.6875,1.625,0.5625,98
3708,Mirror Learning: A Unifying Framework of Policy Optimisation,8,Mirror Learning A Unifying Framework of Policy Optimisation,38,174,False,124,150,14,20,4,15,10,0,0,59,10406,1.9,0.7,7.5,0.5,14
3709,Model Comparison for Semantic Grouping,8,Model Comparison for Semantic Grouping,40,111,False,64,88,8,13,0,16,6,0,14,38,7570,3.076923076923077,1.6923076923076923,6.769230769230769,0.46153846153846156,1
3710,Modeling Adversarial Noise for Adversarial Training,8,Modeling Adversarial Noise for Adversarial Training,39,128,False,45,28,17,16,0,11,10,0,18,51,8998,2.4375,2.1875,1.75,0.625,9
3711,MonoNeRF: Learning Generalizable NeRFs from Monocular Videos without Camera Poses,8,MonoNeRF Learning Generalizable NeRFs from Monocular Videos without Camera Poses,91,108,False,94,38,0,13,2,5,9,2,0,80,9109,7.0,0.0,2.923076923076923,0.6923076923076923,5
3712,Multi-Frequency Phase Synchronization,8,Multi-Frequency Phase Synchronization,36,83,False,56,130,54,12,4,12,5,0,0,37,8730,3.0,4.5,10.833333333333334,0.4166666666666667,18
3714,NP-Match: When Neural Processes meet Semi-Supervised Learning,8,NP-Match When Neural Processes meet Semi-Supervised Learning,63,179,True,104,64,12,16,0,10,5,4,10,60,11412,3.9375,1.375,4.0,0.3125,25
3715,Nearly Optimal Policy Optimization with Stable at Any Time Guarantee,8,Nearly Optimal Policy Optimization with Stable at Any Time Guarantee,40,152,False,109,214,2,24,3,11,12,2,0,68,13237,1.6666666666666667,0.08333333333333333,8.916666666666666,0.5,12
3716,Neural Kernels Without Tangents,8,Neural Kernels Without Tangents,36,1,False,97,69,16,25,16,13,14,0,16,31,9505,1.44,1.28,2.76,0.56,86
3718,Noise2Self: Blind Denoising by Self-Supervision,8,Noise2Self Blind Denoising by Self-Supervision,34,150,False,70,58,42,16,0,26,22,0,8,46,9227,2.125,3.125,3.625,1.375,504
3719,Nonparametric Hamiltonian Monte Carlo,8,Nonparametric Hamiltonian Monte Carlo,59,157,False,79,13,30,34,21,7,1,0,8,37,20484,1.7352941176470589,1.1176470588235294,0.38235294117647056,0.029411764705882353,5
3720,Oblivious Sketching for Logistic Regression,8,Oblivious Sketching for Logistic Regression,51,120,False,52,91,33,32,0,13,9,0,2,43,13891,1.59375,1.09375,2.84375,0.28125,14
3721,Omnipredictors for Constrained Optimization,8,Omnipredictors for Constrained Optimization,49,177,False,108,192,0,39,5,14,11,0,0,43,18772,1.2564102564102564,0.0,4.923076923076923,0.28205128205128205,11
3723,On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline,8,On Pre-Training for Visuo-Motor Control Revisiting a Learning-from-Scratch Baseline,58,131,False,186,0,50,16,1,10,7,0,10,83,10334,3.625,3.75,0.0,0.4375,38
3724,On the Consistency of Top-k Surrogate Losses,8,On the Consistency of Top-k Surrogate Losses,34,175,False,103,142,0,17,1,10,9,0,14,44,12119,2.0,0.8235294117647058,8.352941176470589,0.5294117647058824,38
3725,On the Global Optimality of Model-Agnostic Meta-Learning,8,On the Global Optimality of Model-Agnostic Meta-Learning,59,161,False,76,8,0,41,0,9,18,0,0,56,14968,1.4390243902439024,0.0,0.1951219512195122,0.43902439024390244,33
3726,On the Predictability of Pruning Across Scales,8,On the Predictability of Pruning Across Scales,27,117,False,68,18,92,22,0,17,5,0,2,46,11972,1.2272727272727273,4.2727272727272725,0.8181818181818182,0.22727272727272727,30
3727,On-Policy Deep Reinforcement Learning for the Average-Reward Criterion,8,On-Policy Deep Reinforcement Learning for the Average-Reward Criterion,65,145,False,217,195,18,25,0,18,17,0,4,70,13575,2.6,0.88,7.8,0.68,24
3728,Online Graph Dictionary Learning,8,Online Graph Dictionary Learning,80,152,False,187,178,19,25,26,7,13,12,16,32,15795,3.2,1.4,7.12,0.52,36
3729,Open-Sampling: Exploring Out-of-Distribution data for Re-balancing Long-tailed datasets,8,Open-Sampling Exploring Out-of-Distribution data for Re-balancing Long-tailed datasets,67,145,False,115,24,27,16,0,13,7,0,14,86,10744,4.1875,2.5625,1.5,0.4375,18
3730,Optimal Non-Convex Exact Recovery in Stochastic Block Model via Projected Power Method,8,Optimal Non-Convex Exact Recovery in Stochastic Block Model via Projected Power Method,54,152,False,195,192,17,20,0,9,17,0,6,86,13263,2.7,1.15,9.6,0.85,12
3731,"Optimization, fast and slow: optimally switching between local and Bayesian optimization",8,Optimization fast and slow optimally switching between local and Bayesian optimization,20,83,False,28,28,24,10,0,5,10,4,2,86,6882,2.0,2.6,2.8,1.0,37
3732,Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis,8,Orthogonality-Promoting Distance Metric Learning Convex Relaxation and Theoretical Analysis,66,213,False,168,106,5,31,28,12,19,0,20,91,16977,2.129032258064516,0.8064516129032258,3.4193548387096775,0.6129032258064516,27
3733,PACE: A Parallelizable Computation Encoder for Directed Acyclic Graphs,8,PACE A Parallelizable Computation Encoder for Directed Acyclic Graphs,65,171,True,141,16,13,18,1,13,10,0,14,69,12225,3.611111111111111,1.5,0.8888888888888888,0.5555555555555556,10
3734,POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging,8,POET Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging,39,146,True,57,4,15,11,0,8,9,0,2,90,7678,3.5454545454545454,1.5454545454545454,0.36363636363636365,0.8181818181818182,22
3735,Partial Trace Regression and Low-Rank Kraus Decomposition,8,Partial Trace Regression and Low-Rank Kraus Decomposition,51,130,False,70,44,35,12,3,8,6,4,8,57,8210,4.25,3.5833333333333335,3.6666666666666665,0.5,4
3736,Permutation Weighting,8,Permutation Weighting,68,1,False,165,98,30,29,0,15,13,0,2,21,14510,2.3448275862068964,1.103448275862069,3.3793103448275863,0.4482758620689655,19
3737,Planning to Explore via Self-Supervised World Models,8,Planning to Explore via Self-Supervised World Models,62,142,False,60,37,18,13,20,8,6,0,4,52,8725,4.769230769230769,1.6923076923076923,2.8461538461538463,0.46153846153846156,311
3738,PolyGen: An Autoregressive Generative Model of 3D Meshes,8,PolyGen An Autoregressive Generative Model of 3D Meshes,41,142,False,55,44,60,16,0,15,11,0,8,55,9022,2.5625,4.25,2.75,0.6875,181
3739,Prediction Rule Reshaping,8,Prediction Rule Reshaping,27,79,False,49,49,10,15,0,5,7,3,4,25,5919,1.8,0.9333333333333333,3.2666666666666666,0.4666666666666667,8
3741,Probabilistic Programs with Stochastic Conditioning,8,Probabilistic Programs with Stochastic Conditioning,58,149,False,98,109,17,15,0,9,3,0,4,51,9618,3.8666666666666667,1.4,7.266666666666667,0.2,7
3742,Projective Preferential Bayesian Optimization,8,Projective Preferential Bayesian Optimization,25,140,False,51,40,6,9,0,7,8,0,2,45,6174,2.7777777777777777,0.8888888888888888,4.444444444444445,0.8888888888888888,12
3743,Provable guarantees for decision tree induction: the agnostic setting,8,Provable guarantees for decision tree induction the agnostic setting,37,119,False,62,86,7,21,2,7,6,0,0,68,9052,1.7619047619047619,0.3333333333333333,4.095238095238095,0.2857142857142857,12
3744,Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization,8,Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization,62,206,False,128,154,95,23,8,14,12,4,16,89,12187,2.6956521739130435,4.826086956521739,6.695652173913044,0.5217391304347826,44
3745,Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding,8,Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding,33,155,True,342,452,193,40,0,21,54,5,30,78,21638,0.825,5.575,11.3,1.35,8
3746,RLang: A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents,8,RLang A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents,42,114,False,94,20,31,18,30,9,12,0,4,100,11807,2.3333333333333335,1.9444444444444444,1.1111111111111112,0.6666666666666666,0
3747,Randomized Block Cubic Newton Method,8,Randomized Block Cubic Newton Method,28,183,False,56,105,15,15,0,16,14,0,0,36,9473,1.8666666666666667,1.0,7.0,0.9333333333333333,33
3748,Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation,8,Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation,33,75,False,32,450,0,41,0,13,15,0,0,86,19525,0.8048780487804879,0.0,10.975609756097562,0.36585365853658536,15
3749,Relative Positional Encoding for Transformers with Linear Complexity,8,Relative Positional Encoding for Transformers with Linear Complexity,72,144,False,151,43,18,24,0,6,7,0,2,68,14953,3.0,0.8333333333333334,1.7916666666666667,0.2916666666666667,33
3750,Reserve Pricing in Repeated Second-Price Auctions with Strategic Bidders,8,Reserve Pricing in Repeated Second-Price Auctions with Strategic Bidders,83,113,False,52,64,0,22,0,10,7,6,10,72,13941,3.772727272727273,0.45454545454545453,2.909090909090909,0.3181818181818182,11
3751,Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis: an Integrated Framework,8,Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis an Integrated Framework,46,113,False,146,150,36,27,38,28,18,0,36,107,11994,1.7037037037037037,2.6666666666666665,5.555555555555555,0.6666666666666666,9
3752,RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests,8,RieszNet and ForestRiesz Automatic Debiased Machine Learning with Neural Nets and Random Forests,32,230,False,108,52,32,14,3,9,13,6,18,96,8834,2.2857142857142856,3.5714285714285716,3.7142857142857144,0.9285714285714286,27
3753,Robust Kernel Density Estimation with Median-of-Means principle,8,Robust Kernel Density Estimation with Median-of-Means principle,54,89,False,108,53,44,15,9,7,7,0,2,63,7239,3.6,3.066666666666667,3.533333333333333,0.4666666666666667,11
3754,Robust estimation of tree structured Gaussian Graphical Model,8,Robust estimation of tree structured Gaussian Graphical Model,26,149,False,11,186,33,32,0,10,23,11,0,61,14451,0.8125,1.03125,5.8125,0.71875,14
3755,SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies,8,SECANT Self-Expert Cloning for Zero-Shot Generalization of Visual Policies,76,137,True,120,6,0,16,0,10,13,0,0,74,11680,4.75,0.0,0.375,0.8125,46
3756,Safe Element Screening for Submodular Function Minimization,8,Safe Element Screening for Submodular Function Minimization,31,206,False,33,168,24,22,0,6,12,2,6,59,9267,1.4090909090909092,1.3636363636363635,7.636363636363637,0.5454545454545454,1
3757,Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network,8,Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network,50,204,False,66,30,19,11,10,6,10,0,2,63,8269,4.545454545454546,1.9090909090909092,2.727272727272727,0.9090909090909091,30
3758,Scalable Nonparametric Sampling from Multimodal Posteriors with the Posterior Bootstrap,8,Scalable Nonparametric Sampling from Multimodal Posteriors with the Posterior Bootstrap,59,132,False,88,148,42,21,4,10,17,18,24,87,12235,2.8095238095238093,3.142857142857143,7.0476190476190474,0.8095238095238095,30
3759,Second-Order Provable Defenses against Adversarial Attacks,8,Second-Order Provable Defenses against Adversarial Attacks,66,191,False,62,320,7,32,0,16,26,0,34,58,19201,2.0625,1.28125,10.0,0.8125,53
3760,Self-Improved Retrosynthetic Planning,8,Self-Improved Retrosynthetic Planning,34,163,False,115,0,3,14,0,8,13,0,2,37,6791,2.4285714285714284,0.35714285714285715,0.0,0.9285714285714286,19
3761,Semi-Supervised StyleGAN for Disentanglement Learning,8,Semi-Supervised StyleGAN for Disentanglement Learning,36,111,False,124,24,64,21,13,12,20,0,8,53,9518,1.7142857142857142,3.4285714285714284,1.1428571428571428,0.9523809523809523,67
3762,Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning,8,Sharp-MAML Sharpness-Aware Model-Agnostic Meta Learning,75,93,True,131,134,12,23,1,12,22,0,10,55,12955,3.260869565217391,0.9565217391304348,5.826086956521739,0.9565217391304348,50
3763,Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games,8,Simplex Neural Population Learning Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games,32,140,False,87,0,27,14,8,9,11,8,0,91,10071,2.2857142857142856,1.9285714285714286,0.0,0.7857142857142857,7
3764,Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks,8,Slot Machines Discovering Winning Combinations of Random Weights in Neural Networks,44,158,False,99,8,53,15,0,7,10,0,4,83,9010,2.933333333333333,3.8,0.5333333333333333,0.6666666666666666,7
3765,Source Separation with Deep Generative Priors,8,Source Separation with Deep Generative Priors,60,123,False,68,26,45,20,0,13,16,0,8,45,8440,3.0,2.65,1.3,0.8,33
3766,Spectral Normalisation for Deep Reinforcement Learning: an Optimisation Perspective,8,Spectral Normalisation for Deep Reinforcement Learning an Optimisation Perspective,52,169,False,116,4,16,24,0,7,6,0,2,82,13017,2.1666666666666665,0.75,0.16666666666666666,0.25,39
3768,Stochastic Coordinate Minimization with Progressive Precision for Stochastic Convex Optimization,8,Stochastic Coordinate Minimization with Progressive Precision for Stochastic Convex Optimization,54,147,False,32,110,13,36,2,10,19,0,0,96,14016,1.5,0.3611111111111111,3.0555555555555554,0.5277777777777778,2
3770,Streaming Submodular Maximization with Differential Privacy,8,Streaming Submodular Maximization with Differential Privacy,37,162,False,81,180,2,26,0,6,3,0,0,59,12978,1.4230769230769231,0.07692307692307693,6.923076923076923,0.11538461538461539,1
3771,Structured World Belief for Reinforcement Learning in POMDP,8,Structured World Belief for Reinforcement Learning in POMDP,55,174,True,229,220,180,28,0,36,46,35,24,59,14474,1.9642857142857142,7.285714285714286,7.857142857142857,1.6428571428571428,21
3773,TACTiS: Transformer-Attentional Copulas for Time Series,8,TACTiS Transformer-Attentional Copulas for Time Series,80,129,False,226,45,104,47,49,13,26,7,30,54,23206,1.702127659574468,2.851063829787234,0.9574468085106383,0.5531914893617021,22
3774,Taylor Expansion of Discount Factors,8,Taylor Expansion of Discount Factors,51,90,False,178,216,41,30,34,16,20,3,2,36,17912,1.7,1.4333333333333333,7.2,0.6666666666666666,5
3776,The FAST Algorithm for Submodular Maximization,8,The FAST Algorithm for Submodular Maximization,32,163,True,65,19,18,30,9,10,21,9,2,46,14033,1.0666666666666667,0.6666666666666666,0.6333333333333333,0.7,31
3777,The Neural Race Reduction: Dynamics of Abstraction in Gated Networks,8,The Neural Race Reduction Dynamics of Abstraction in Gated Networks,105,196,False,150,96,72,23,0,26,20,0,20,67,14922,4.565217391304348,4.0,4.173913043478261,0.8695652173913043,19
3778,The Well Tempered Lasso,8,The Well Tempered Lasso,14,160,False,21,70,4,16,3,11,2,0,2,23,6746,0.875,0.375,4.375,0.125,6
3779,Thompson Sampling for Robust Transfer in Multi-Task Bandits,8,Thompson Sampling for Robust Transfer in Multi-Task Bandits,25,170,False,130,309,60,54,18,14,13,6,0,59,26928,0.46296296296296297,1.1111111111111112,5.722222222222222,0.24074074074074073,3
3780,Topic Modeling via Full Dependence Mixtures,8,Topic Modeling via Full Dependence Mixtures,37,178,False,73,70,14,22,0,12,6,0,4,43,8882,1.6818181818181819,0.8181818181818182,3.1818181818181817,0.2727272727272727,1
3781,Towards Evaluating Adaptivity of Model-Based Reinforcement Learning Methods,8,Towards Evaluating Adaptivity of Model-Based Reinforcement Learning Methods,40,192,False,358,10,688,26,0,74,131,4,84,75,15537,1.5384615384615385,29.692307692307693,0.38461538461538464,5.038461538461538,9
3782,Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,8,Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,53,198,False,150,32,53,23,8,10,15,4,12,85,15661,2.3043478260869565,2.8260869565217392,1.391304347826087,0.6521739130434783,22
3783,Training Quantized Neural Networks to Global Optimality via Semidefinite Programming,8,Training Quantized Neural Networks to Global Optimality via Semidefinite Programming,41,121,False,43,136,26,26,0,11,16,0,0,84,10755,1.5769230769230769,1.0,5.230769230769231,0.6153846153846154,8
3784,Transformers learn in-context by gradient descent,8,Transformers learn in-context by gradient descent,55,219,False,85,36,118,24,0,6,18,0,0,49,16738,2.2916666666666665,4.916666666666667,1.5,0.75,207
3785,Understanding Clipping for Federated Learning: Convergence and Client-Level Differential Privacy,8,Understanding Clipping for Federated Learning Convergence and Client-Level Differential Privacy,41,179,False,40,88,93,26,0,6,8,1,8,95,9701,1.5769230769230769,3.8846153846153846,3.3846153846153846,0.3076923076923077,59
3786,Understanding and Mitigating Accuracy Disparity in Regression,8,Understanding and Mitigating Accuracy Disparity in Regression,58,160,False,116,100,37,21,17,11,7,0,6,61,12308,2.761904761904762,2.0476190476190474,4.761904761904762,0.3333333333333333,19
3787,"Uniform Convergence, Adversarial Spheres and a Simple Remedy",8,Uniform Convergence Adversarial Spheres and a Simple Remedy,27,186,False,75,118,35,18,0,9,17,0,0,60,9254,1.5,1.9444444444444444,6.555555555555555,0.9444444444444444,7
3788,Unsupervised Learning of Visual 3D Keypoints for Control,8,Unsupervised Learning of Visual 3D Keypoints for Control,42,154,False,54,9,38,13,22,11,10,0,2,56,8548,3.230769230769231,3.076923076923077,0.6923076923076923,0.7692307692307693,29
3789,Valid Causal Inference with (Some) Invalid Instruments,8,Valid Causal Inference with Some Invalid Instruments,32,200,False,92,14,14,14,9,8,5,0,4,54,8035,2.2857142857142856,1.2857142857142858,1.0,0.35714285714285715,20
3790,Variational Laplace Autoencoders,8,Variational Laplace Autoencoders,45,168,False,86,56,31,12,0,10,10,0,4,32,7086,3.75,2.9166666666666665,4.666666666666667,0.8333333333333334,18
3792,What do CNNs Learn in the First Layer and Why? A Linear Systems Perspective,8,What do CNNs Learn in the First Layer and Why A Linear Systems Perspective,48,183,False,64,24,98,25,0,15,3,0,16,74,9814,1.92,4.56,0.96,0.12,0
3793,Why Random Pruning Is All We Need to Start Sparse,8,Why Random Pruning Is All We Need to Start Sparse,62,196,False,212,78,22,29,2,5,19,2,64,49,18581,2.1379310344827585,2.9655172413793105,2.689655172413793,0.6551724137931034,8
3794,Zeno++: Robust Fully Asynchronous SGD,8,Zeno Robust Fully Asynchronous SGD,36,111,True,51,30,69,18,0,10,12,4,2,34,8915,2.0,3.9444444444444446,1.6666666666666667,0.6666666666666666,77
3795,A Deep Learning Approach for the Segmentation of Electroencephalography Data in Eye Tracking Applications,8,A Deep Learning Approach for the Segmentation of Electroencephalography Data in Eye Tracking Applications,50,154,False,186,4,112,21,72,34,34,26,52,105,11545,2.380952380952381,7.809523809523809,0.19047619047619047,1.619047619047619,4
3796,A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes,8,A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes,77,159,False,193,682,56,47,37,25,37,15,4,113,19375,1.6382978723404256,1.2765957446808511,14.51063829787234,0.7872340425531915,14
3797,A Resilient Distributed Boosting Algorithm,8,A Resilient Distributed Boosting Algorithm,37,90,False,103,22,4,9,12,7,3,0,0,42,6460,4.111111111111111,0.4444444444444444,2.4444444444444446,0.3333333333333333,2
3799,A Wasserstein Minimax Framework for Mixed Linear Regression,8,A Wasserstein Minimax Framework for Mixed Linear Regression,40,181,False,65,170,14,20,14,14,10,0,8,59,11728,2.0,1.1,8.5,0.5,6
3800,ARSM: Augment-REINFORCE-Swap-Merge Estimator for Gradient Backpropagation Through Categorical Variables,8,ARSM Augment-REINFORCE-Swap-Merge Estimator for Gradient Backpropagation Through Categorical Variables,50,131,True,128,40,24,20,0,11,16,0,8,102,12258,2.5,1.6,2.0,0.8,22
3801,Accelerating Shapley Explanation via Contributive Cooperator Selection,8,Accelerating Shapley Explanation via Contributive Cooperator Selection,35,157,False,39,106,30,15,0,16,12,0,8,70,9790,2.3333333333333335,2.533333333333333,7.066666666666666,0.8,13
3802,Active Multi-Task Representation Learning,8,Active Multi-Task Representation Learning,19,383,False,53,194,55,28,11,12,16,5,0,41,14106,0.6785714285714286,1.9642857142857142,6.928571428571429,0.5714285714285714,6
3806,Adversarial examples from computational constraints,8,Adversarial examples from computational constraints,33,174,False,40,44,3,19,0,8,12,0,0,51,8789,1.736842105263158,0.15789473684210525,2.3157894736842106,0.631578947368421,217
3807,Alleviating Privacy Attacks via Causal Learning,8,Alleviating Privacy Attacks via Causal Learning,41,153,False,118,358,21,23,15,15,10,1,6,47,17404,1.7826086956521738,1.173913043478261,15.565217391304348,0.43478260869565216,28
3808,An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming,8,An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming,57,139,False,100,48,15,13,0,9,11,0,6,85,8383,4.384615384615385,1.6153846153846154,3.6923076923076925,0.8461538461538461,61
3809,Analogies Explained: Towards Understanding Word Embeddings,8,Analogies Explained Towards Understanding Word Embeddings,18,116,False,45,60,13,11,0,13,14,0,0,57,7917,1.6363636363636365,1.1818181818181819,5.454545454545454,1.2727272727272727,117
3811,Asking for Knowledge: Training RL Agents to Query External Knowledge Using Language,8,Asking for Knowledge Training RL Agents to Query External Knowledge Using Language,73,171,True,95,20,80,21,3,13,14,0,28,82,12968,3.4761904761904763,5.142857142857143,0.9523809523809523,0.6666666666666666,9
3813,BEATs: Audio Pre-Training with Acoustic Tokenizers,8,BEATs Audio Pre-Training with Acoustic Tokenizers,71,247,False,230,8,14,16,6,6,10,5,8,49,8828,4.4375,1.375,0.5,0.625,76
3814,Bayesian Algorithm Execution: Estimating Computable Properties of Black-box Functions Using Mutual Information,8,Bayesian Algorithm Execution Estimating Computable Properties of Black-box Functions Using Mutual Information,59,0,False,97,66,39,29,12,6,11,0,0,109,13460,2.0344827586206895,1.3448275862068966,2.2758620689655173,0.3793103448275862,21
3815,Bayesian Optimization of Combinatorial Structures,8,Bayesian Optimization of Combinatorial Structures,50,106,False,70,29,45,15,3,11,16,1,8,49,10415,3.3333333333333335,3.533333333333333,1.9333333333333333,1.0666666666666667,121
3816,Better Depth-Width Trade-offs for Neural Networks through the lens of Dynamical Systems,8,Better Depth-Width Trade-offs for Neural Networks through the lens of Dynamical Systems,22,190,False,55,35,31,21,3,6,7,0,0,87,9494,1.0476190476190477,1.4761904761904763,1.6666666666666667,0.3333333333333333,12
3818,BoXHED: Boosted eXact Hazard Estimator with Dynamic covariates,8,BoXHED Boosted eXact Hazard Estimator with Dynamic covariates,23,137,False,66,32,11,10,0,7,7,4,10,61,7160,2.3,2.1,3.2,0.7,8
3819,Breaking Inter-Layer Co-Adaptation by Classifier Anonymization,8,Breaking Inter-Layer Co-Adaptation by Classifier Anonymization,27,119,False,26,40,40,9,0,5,5,0,4,62,6702,3.0,4.888888888888889,4.444444444444445,0.5555555555555556,3
3820,CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling,8,CAB Comprehensive Attention Benchmarking on Long Sequence Modeling,105,188,True,284,40,21,25,29,22,4,0,30,66,14066,4.2,2.04,1.6,0.16,4
3821,Calibrated and Sharp Uncertainties in Deep Learning via Density Estimation,8,Calibrated and Sharp Uncertainties in Deep Learning via Density Estimation,40,126,False,146,38,6,11,29,10,23,0,6,74,8011,3.6363636363636362,1.0909090909090908,3.4545454545454546,2.090909090909091,22
3822,Causal Proxy Models for Concept-Based Model Explanations,8,Causal Proxy Models for Concept-Based Model Explanations,64,1,False,108,24,0,23,14,8,17,0,2,56,13754,2.782608695652174,0.08695652173913043,1.0434782608695652,0.7391304347826086,22
3823,Characterizing Implicit Bias in Terms of Optimization Geometry,8,Characterizing Implicit Bias in Terms of Optimization Geometry,35,86,False,100,177,5,28,10,11,16,2,0,62,14568,1.25,0.17857142857142858,6.321428571428571,0.5714285714285714,343
3824,Closed-form marginal likelihood in Gamma-Poisson factorization,8,Closed-form marginal likelihood in Gamma-Poisson factorization,24,96,False,60,74,13,9,0,8,11,2,0,62,5668,2.6666666666666665,1.4444444444444444,8.222222222222221,1.2222222222222223,2
3825,CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints,8,CombOptNet Fit the Right NP-Hard Problem by Learning Integer Programming Constraints,52,108,True,82,38,56,16,33,8,13,0,18,84,10795,3.25,4.625,2.375,0.8125,45
3826,Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations,8,Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations,21,166,False,52,107,21,31,0,7,12,4,6,86,16686,0.6774193548387096,0.8709677419354839,3.4516129032258065,0.3870967741935484,36
3829,Constrained Monotonic Neural Networks,8,Constrained Monotonic Neural Networks,56,56,False,242,50,47,16,6,22,21,1,8,37,8834,3.5,3.4375,3.125,1.3125,5
3830,Continual Repeated Annealed Flow Transport Monte Carlo,8,Continual Repeated Annealed Flow Transport Monte Carlo,39,121,False,133,118,21,24,0,16,12,0,0,54,13563,1.625,0.875,4.916666666666667,0.5,27
3832,Coordinate Descent Methods for Fractional Minimization,8,Coordinate Descent Methods for Fractional Minimization,56,200,False,45,28,12,28,0,10,20,2,6,54,15245,2.0,0.6428571428571429,1.0,0.7142857142857143,2
3835,DVAE++: Discrete Variational Autoencoders with Overlapping Transformations,8,DVAE Discrete Variational Autoencoders with Overlapping Transformations,41,108,True,82,78,25,16,0,19,12,0,14,71,10034,2.5625,2.4375,4.875,0.75,67
3836,Data-efficient Hindsight Off-policy Option Learning,8,Data-efficient Hindsight Off-policy Option Learning,48,118,False,252,132,228,21,20,18,38,0,40,51,12171,2.2857142857142856,12.761904761904763,6.285714285714286,1.8095238095238095,45
3837,Decomposable Submodular Function Minimization via Maximum Flow,8,Decomposable Submodular Function Minimization via Maximum Flow,64,180,False,78,199,0,41,6,11,14,0,0,62,19030,1.5609756097560976,0.0,4.853658536585366,0.34146341463414637,6
3838,Deep Isometric Learning for Visual Recognition,8,Deep Isometric Learning for Visual Recognition,73,120,False,87,48,14,13,0,8,12,0,14,46,9348,5.615384615384615,2.1538461538461537,3.6923076923076925,0.9230769230769231,45
3839,DeepCoDA: personalized interpretability for compositional health data,8,DeepCoDA personalized interpretability for compositional health data,42,133,False,49,20,21,14,0,8,9,5,4,68,7760,3.0,1.7857142857142858,1.4285714285714286,0.6428571428571429,11
3840,Dense for the Price of Sparse: Improved Performance of Sparsely Initialized Networks via a Subspace Offset,8,Dense for the Price of Sparse Improved Performance of Sparsely Initialized Networks via a Subspace Offset,27,65,False,49,6,45,18,0,13,19,0,8,105,9813,1.5,2.9444444444444446,0.3333333333333333,1.0555555555555556,9
3841,Dialog Inpainting: Turning Documents into Dialogs,8,Dialog Inpainting Turning Documents into Dialogs,54,0,False,256,40,88,26,24,26,32,2,64,48,15169,2.076923076923077,5.846153846153846,1.5384615384615385,1.2307692307692308,47
3842,Directed Acyclic Transformer for Non-Autoregressive Machine Translation,8,Directed Acyclic Transformer for Non-Autoregressive Machine Translation,56,116,False,74,32,43,18,0,11,8,0,4,71,12284,3.111111111111111,2.611111111111111,1.7777777777777777,0.4444444444444444,43
3843,Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions,8,Discriminative Jackknife Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions,53,152,False,70,94,12,14,0,12,13,0,4,102,9510,3.7857142857142856,1.1428571428571428,6.714285714285714,0.9285714285714286,44
3844,Distribution Free Prediction Sets for Node Classification,8,Distribution Free Prediction Sets for Node Classification,39,127,False,51,38,6,11,0,11,8,0,6,57,7671,3.5454545454545454,1.0909090909090908,3.4545454545454546,0.7272727272727273,4
3845,Do We Need Zero Training Loss After Achieving Zero Training Error?,8,Do We Need Zero Training Loss After Achieving Zero Training Error,75,186,False,92,42,68,16,7,11,12,0,6,65,9711,4.6875,4.625,2.625,0.75,101
3846,Doubly robust off-policy evaluation with shrinkage,8,Doubly robust off-policy evaluation with shrinkage,36,1,False,79,175,44,25,14,12,11,2,20,50,16752,1.44,2.56,7.0,0.44,84
3847,ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero,8,ELF OpenGo An Analysis and Open Reimplementation of AlphaZero,29,139,True,120,2,26,13,28,10,16,0,4,61,8591,2.230769230769231,2.3076923076923075,0.15384615384615385,1.2307692307692308,102
3848,Efficient Neural Audio Synthesis,8,Efficient Neural Audio Synthesis,25,197,False,20,8,9,10,0,6,11,0,8,32,7260,2.5,1.7,0.8,1.1,790
3849,Efficient non-conjugate Gaussian process factor models for spike count data using polynomial approximations,8,Efficient non-conjugate Gaussian process factor models for spike count data using polynomial approximations,33,193,False,24,50,15,12,0,7,5,0,2,107,6466,2.75,1.4166666666666667,4.166666666666667,0.4166666666666667,16
3850,End-to-End Probabilistic Inference for Nonstationary Audio Analysis,8,End-to-End Probabilistic Inference for Nonstationary Audio Analysis,46,127,False,75,64,16,12,7,8,6,0,4,67,8092,3.8333333333333335,1.6666666666666667,5.333333333333333,0.5,5
3852,Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models,8,Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models,48,195,False,394,352,128,30,0,32,44,0,40,87,14068,1.6,5.6,11.733333333333333,1.4666666666666666,52
3853,Existence and Estimation of Critical Batch Size for Training Generative Adversarial Networks with Two Time-Scale Update Rule,8,Existence and Estimation of Critical Batch Size for Training Generative Adversarial Networks with Two Time-Scale Update Rule,41,212,False,88,250,30,24,0,7,24,4,10,124,13995,1.7083333333333333,1.6666666666666667,10.416666666666666,1.0,3
3854,Exploring Interpretable LSTM Neural Networks over Multi-Variable Data,8,Exploring Interpretable LSTM Neural Networks over Multi-Variable Data,66,146,True,180,82,42,17,4,12,22,4,24,69,10157,3.8823529411764706,3.8823529411764706,4.823529411764706,1.2941176470588236,134
3855,Failure and success of the spectral bias prediction for Kernel Ridge Regression: the case of low-dimensional data,8,Failure and success of the spectral bias prediction for Kernel Ridge Regression the case of low-dimensional data,36,193,False,47,482,36,36,0,14,10,0,0,112,18777,1.0,1.0,13.38888888888889,0.2777777777777778,11
3856,Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models,8,Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models,55,210,False,41,44,36,15,2,10,13,0,2,112,8245,3.6666666666666665,2.533333333333333,2.933333333333333,0.8666666666666667,8
3857,Fast Stochastic Bregman Gradient Methods: Sharp Analysis and Variance Reduction,8,Fast Stochastic Bregman Gradient Methods Sharp Analysis and Variance Reduction,46,136,False,135,190,11,26,2,11,13,0,0,78,12638,1.7692307692307692,0.4230769230769231,7.3076923076923075,0.5,29
3858,Feature Learning and Signal Propagation in Deep Neural Networks,8,Feature Learning and Signal Propagation in Deep Neural Networks,29,109,False,123,192,151,35,15,14,24,2,8,63,17264,0.8285714285714286,4.542857142857143,5.485714285714286,0.6857142857142857,12
3861,Flexibly Fair Representation Learning by Disentanglement,8,Flexibly Fair Representation Learning by Disentanglement,42,105,False,87,28,56,13,22,11,4,0,0,56,9327,3.230769230769231,4.3076923076923075,2.1538461538461537,0.3076923076923077,280
3863,Fully Parallel Hyperparameter Search: Reshaped Space-Filling,8,Fully Parallel Hyperparameter Search Reshaped Space-Filling,42,224,False,65,4,12,14,9,6,4,7,18,59,6997,3.0,2.142857142857143,0.2857142857142857,0.2857142857142857,19
3864,GBHT: Gradient Boosting Histogram Transform for Density Estimation,8,GBHT Gradient Boosting Histogram Transform for Density Estimation,39,151,True,51,372,32,27,0,11,19,16,18,65,17508,1.4444444444444444,1.8518518518518519,13.777777777777779,0.7037037037037037,8
3865,Gating Dropout: Communication-efficient Regularization for Sparsely Activated Transformers,8,Gating Dropout Communication-efficient Regularization for Sparsely Activated Transformers,44,185,False,73,4,16,11,0,7,9,0,12,89,7360,4.0,2.5454545454545454,0.36363636363636365,0.8181818181818182,16
3866,Generalized Doubly Reparameterized Gradient Estimators,8,Generalized Doubly Reparameterized Gradient Estimators,30,133,False,112,180,22,29,11,16,22,4,4,54,19522,1.0344827586206897,0.896551724137931,6.206896551724138,0.7586206896551724,10
3867,Generative Adversarial Transformers,8,Generative Adversarial Transformers,81,200,False,123,2,366,21,0,7,8,3,10,35,10349,3.857142857142857,17.904761904761905,0.09523809523809523,0.38095238095238093,146
3868,Geometric convergence of elliptical slice sampling,8,Geometric convergence of elliptical slice sampling,27,124,False,3,50,0,13,0,3,3,0,0,50,8995,2.076923076923077,0.0,3.8461538461538463,0.23076923076923078,8
3869,Good Initializations of Variational Bayes for Deep Models,8,Good Initializations of Variational Bayes for Deep Models,60,111,False,0,0,2,17,2,16,2,7,2,57,10302,3.5294117647058822,0.23529411764705882,0.0,0.11764705882352941,17
3871,Gromov-Wasserstein Learning for Graph Matching and Node Embedding,8,Gromov-Wasserstein Learning for Graph Matching and Node Embedding,58,131,False,73,54,37,16,0,7,14,0,10,65,11475,3.625,2.9375,3.375,0.875,216
3872,Hessian-Free High-Resolution Nesterov Acceleration for Sampling,8,Hessian-Free High-Resolution Nesterov Acceleration for Sampling,85,138,False,266,448,64,38,4,28,36,0,4,63,19209,2.236842105263158,1.7894736842105263,11.789473684210526,0.9473684210526315,3
3873,High-Performance Large-Scale Image Recognition Without Normalization,8,High-Performance Large-Scale Image Recognition Without Normalization,101,153,False,346,6,25,22,0,14,9,0,14,68,14534,4.590909090909091,1.7727272727272727,0.2727272727272727,0.4090909090909091,410
3874,How does Disagreement Help Generalization against Label Corruption?,8,How does Disagreement Help Generalization against Label Corruption,48,152,False,77,6,30,11,15,8,4,0,10,66,6926,4.363636363636363,3.6363636363636362,0.5454545454545454,0.36363636363636365,621
3875,Hyperbolic Disk Embeddings for Directed Acyclic Graphs,8,Hyperbolic Disk Embeddings for Directed Acyclic Graphs,43,1,False,80,106,18,15,0,15,19,0,4,54,7894,2.8666666666666667,1.4666666666666666,7.066666666666666,1.2666666666666666,42
3877,Improved Analysis of Score-based Generative Modeling: User-Friendly Bounds under Minimal Smoothness Assumptions,8,Improved Analysis of Score-based Generative Modeling User-Friendly Bounds under Minimal Smoothness Assumptions,40,137,False,92,562,0,36,41,17,27,0,4,110,14352,1.1111111111111112,0.1111111111111111,15.61111111111111,0.75,60
3878,Improving Adversarial Robustness via Mutual Information Estimation,8,Improving Adversarial Robustness via Mutual Information Estimation,46,173,False,57,52,21,15,0,11,9,4,12,66,9246,3.066666666666667,2.2,3.466666666666667,0.6,8
3879,Improving Robustness of Deep-Learning-Based Image Reconstruction,8,Improving Robustness of Deep-Learning-Based Image Reconstruction,51,236,False,20,62,19,12,0,6,8,2,4,64,8035,4.25,1.9166666666666667,5.166666666666667,0.6666666666666666,37
3880,Individual Preference Stability for Clustering,8,Individual Preference Stability for Clustering,69,173,False,182,108,142,60,15,16,26,0,6,46,22915,1.15,2.466666666666667,1.8,0.43333333333333335,7
3881,Information Obfuscation of Graph Neural Networks,8,Information Obfuscation of Graph Neural Networks,56,155,False,82,92,23,19,9,12,6,0,8,48,11236,2.9473684210526314,1.631578947368421,4.842105263157895,0.3157894736842105,31
3883,Interventional Causal Representation Learning,8,Interventional Causal Representation Learning,55,162,False,106,111,42,36,19,14,12,4,28,45,21825,1.5277777777777777,1.9444444444444444,3.0833333333333335,0.3333333333333333,46
3884,Is Generator Conditioning Causally Related to GAN Performance?,8,Is Generator Conditioning Causally Related to GAN Performance,49,140,True,69,16,53,14,9,9,1,0,0,61,7198,3.5,3.7857142857142856,1.1428571428571428,0.07142857142857142,108
3885,K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets,8,K-shot NAS Learnable Weight-Sharing for NAS with K-shot Supernets,44,183,True,62,58,36,17,0,15,7,1,18,65,10649,2.588235294117647,3.176470588235294,3.411764705882353,0.4117647058823529,24
3886,Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations,8,Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations,73,172,False,12,0,3,16,0,6,12,4,2,88,10226,4.5625,0.3125,0.0,0.75,27
3887,Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks,8,Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks,60,201,True,81,304,33,32,0,11,9,0,0,100,18810,1.875,1.03125,9.5,0.28125,33
3888,Latent Variable Modelling with Hyperbolic Normalizing Flows,8,Latent Variable Modelling with Hyperbolic Normalizing Flows,57,181,False,99,120,18,20,0,14,10,0,8,59,12413,2.85,1.3,6.0,0.5,55
3890,Learning Equations for Extrapolation and Control,8,Learning Equations for Extrapolation and Control,19,116,False,56,35,31,9,0,6,8,0,6,48,6741,2.111111111111111,4.111111111111111,3.888888888888889,0.8888888888888888,178
3892,Learning Optimal Tree Models Under Beam Search,8,Learning Optimal Tree Models Under Beam Search,33,198,False,51,134,6,20,0,11,15,4,18,46,13581,1.65,1.2,6.7,0.75,45
3893,Learning To Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning,8,Learning To Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning,76,229,False,161,0,62,23,10,10,14,3,6,93,11499,3.3043478260869565,2.9565217391304346,0.0,0.6086956521739131,84
3894,Learning from Similarity-Confidence Data,8,Learning from Similarity-Confidence Data,79,133,False,127,108,30,33,1,19,13,0,8,40,12037,2.393939393939394,1.1515151515151516,3.272727272727273,0.3939393939393939,10
3895,"Learning to Hash Robustly, Guaranteed",8,Learning to Hash Robustly Guaranteed,33,202,False,76,48,15,20,7,15,6,0,10,37,14566,1.65,1.25,2.4,0.3,7
3896,Learning to Stop While Learning to Predict,8,Learning to Stop While Learning to Predict,54,191,False,94,40,35,15,2,8,19,5,14,42,9201,3.6,3.2666666666666666,2.6666666666666665,1.2666666666666666,42
3897,Leveraging Low-Rank Relations Between Surrogate Tasks in Structured Prediction,8,Leveraging Low-Rank Relations Between Surrogate Tasks in Structured Prediction,58,135,False,140,10,0,42,10,12,6,0,2,78,16059,1.380952380952381,0.047619047619047616,0.23809523809523808,0.14285714285714285,11
3898,Linear Spectral Estimators and an Application to Phase Retrieval,8,Linear Spectral Estimators and an Application to Phase Retrieval,42,125,False,34,244,30,16,11,14,13,0,0,64,10765,2.625,1.875,15.25,0.8125,11
3899,Locally Sparse Neural Networks for Tabular Biomedical Data,8,Locally Sparse Neural Networks for Tabular Biomedical Data,73,176,False,61,22,67,45,0,10,26,11,26,58,14966,1.6222222222222222,2.066666666666667,0.4888888888888889,0.5777777777777777,21
3900,LowFER: Low-rank Bilinear Pooling for Link Prediction,8,LowFER Low-rank Bilinear Pooling for Link Prediction,57,208,False,192,38,21,16,0,9,20,0,20,52,11318,3.5625,2.5625,2.375,1.25,29
3901,MOTS: Minimax Optimal Thompson Sampling,8,MOTS Minimax Optimal Thompson Sampling,35,150,True,133,192,10,27,0,10,16,0,4,38,10848,1.2962962962962963,0.5185185185185185,7.111111111111111,0.5925925925925926,27
3902,Matching Normalizing Flows and Probability Paths on Manifolds,8,Matching Normalizing Flows and Probability Paths on Manifolds,25,179,False,42,106,86,15,6,15,13,0,2,61,9594,1.6666666666666667,5.866666666666666,7.066666666666666,0.8666666666666667,25
3903,Mechanistic Mode Connectivity,8,Mechanistic Mode Connectivity,127,163,False,206,42,130,40,4,19,11,0,4,29,24772,3.175,3.35,1.05,0.275,27
3904,Meta-learning Parameterized Skills,8,Meta-learning Parameterized Skills,69,92,False,118,27,60,22,0,8,16,5,6,34,13614,3.1363636363636362,3.0,1.2272727272727273,0.7272727272727273,2
3906,Model Distillation for Revenue Optimization: Interpretable Personalized Pricing,8,Model Distillation for Revenue Optimization Interpretable Personalized Pricing,53,133,False,74,16,42,18,0,9,7,0,4,78,9392,2.9444444444444446,2.5555555555555554,0.8888888888888888,0.3888888888888889,28
3907,Modeling Hierarchical Structures with Continuous Recursive Neural Networks,8,Modeling Hierarchical Structures with Continuous Recursive Neural Networks,74,157,False,121,38,0,15,0,12,11,15,18,74,10146,4.933333333333334,1.2,2.533333333333333,0.7333333333333333,11
3908,Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes,8,Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes,94,142,False,252,170,66,33,17,13,3,0,2,81,16897,2.8484848484848486,2.0606060606060606,5.151515151515151,0.09090909090909091,4
3910,Multilinear Latent Conditioning for Generating Unseen Attribute Combinations,8,Multilinear Latent Conditioning for Generating Unseen Attribute Combinations,52,128,False,46,32,29,10,0,8,5,0,4,76,6349,5.2,3.3,3.2,0.5,13
3912,Negative sampling in semi-supervised learning,8,Negative sampling in semi-supervised learning,51,116,False,99,42,12,12,5,8,11,0,12,45,8311,4.25,2.0,3.5,0.9166666666666666,20
3913,"Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps",8,Neural Language Models are not Born Equal to Fit Brain Data but Training Helps,34,226,False,51,6,80,18,0,12,13,0,4,79,8168,1.8888888888888888,4.666666666666667,0.3333333333333333,0.7222222222222222,21
3914,Neural separation of observed and unobserved distributions,8,Neural separation of observed and unobserved distributions,43,136,False,65,36,19,10,2,8,3,0,4,58,6926,4.3,2.3,3.6,0.3,24
3915,Noisin: Unbiased Regularization for Recurrent Neural Networks,8,Noisin Unbiased Regularization for Recurrent Neural Networks,49,157,False,85,58,3,10,0,7,2,0,10,60,6964,4.9,1.3,5.8,0.2,20
3917,Obtaining Adjustable Regularization for Free via Iterate Averaging,8,Obtaining Adjustable Regularization for Free via Iterate Averaging,51,174,False,64,444,22,31,24,11,18,0,2,66,16794,1.6451612903225807,0.7741935483870968,14.32258064516129,0.5806451612903226,2
3918,On Acceleration with Noise-Corrupted Gradients,8,On Acceleration with Noise-Corrupted Gradients,44,110,False,89,132,69,20,6,13,23,4,2,46,11054,2.2,3.55,6.6,1.15,77
3919,On Implicit Bias in Overparameterized Bilevel Optimization,8,On Implicit Bias in Overparameterized Bilevel Optimization,102,172,False,286,260,120,34,68,28,28,2,16,58,16045,3.0,4.0,7.647058823529412,0.8235294117647058,26
3920,On Preemption and Learning in Stochastic Scheduling,8,On Preemption and Learning in Stochastic Scheduling,28,139,False,44,319,13,39,15,13,20,5,0,51,19749,0.717948717948718,0.3333333333333333,8.179487179487179,0.5128205128205128,1
3921,On the Convergence and Robustness of Adversarial Training,8,On the Convergence and Robustness of Adversarial Training,46,209,False,73,60,26,13,0,8,9,0,6,57,8835,3.5384615384615383,2.4615384615384617,4.615384615384615,0.6923076923076923,304
3922,On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces,8,On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces,56,198,False,131,124,9,16,0,11,1,0,4,72,10388,3.5,0.8125,7.75,0.0625,18
3923,On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths,8,On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths,25,232,False,32,80,0,8,2,5,3,0,0,96,5781,3.125,0.0,10.0,0.375,44
3924,On-the-fly Rectification for Robust Large-Vocabulary Topic Inference,8,On-the-fly Rectification for Robust Large-Vocabulary Topic Inference,43,1,False,162,28,24,11,2,14,4,0,4,68,8293,3.909090909090909,2.5454545454545454,2.5454545454545454,0.36363636363636365,1
3926,Open-Vocabulary Universal Image Segmentation with MaskCLIP,8,Open-Vocabulary Universal Image Segmentation with MaskCLIP,43,134,False,159,8,47,13,4,9,10,0,18,58,7641,3.3076923076923075,5.0,0.6153846153846154,0.7692307692307693,30
3927,Optimal Off-Policy Evaluation from Multiple Logging Policies,8,Optimal Off-Policy Evaluation from Multiple Logging Policies,58,140,False,94,156,10,28,9,13,5,0,6,60,12323,2.0714285714285716,0.5714285714285714,5.571428571428571,0.17857142857142858,28
3929,Orthogonalized SGD and Nested Architectures for Anytime Neural Networks,8,Orthogonalized SGD and Nested Architectures for Anytime Neural Networks,65,1,True,85,6,28,11,3,6,14,3,6,71,8406,5.909090909090909,3.090909090909091,0.5454545454545454,1.2727272727272727,9
3931,POPQORN: Quantifying Robustness of Recurrent Neural Networks,8,POPQORN Quantifying Robustness of Recurrent Neural Networks,26,143,True,45,56,19,10,16,6,3,0,8,59,7033,2.6,2.7,5.6,0.3,69
3932,Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition,8,Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition,51,160,False,115,10,17,13,26,17,21,4,28,104,10013,3.923076923076923,3.4615384615384617,0.7692307692307693,1.6153846153846154,30
3933,Personalization Improves Privacy-Accuracy Tradeoffs in Federated Learning,8,Personalization Improves Privacy-Accuracy Tradeoffs in Federated Learning,42,1,False,92,114,19,18,17,9,8,0,0,73,11338,2.3333333333333335,1.0555555555555556,6.333333333333333,0.4444444444444444,19
3935,Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix,8,Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix,37,147,False,73,100,37,15,4,11,15,0,10,69,9426,2.466666666666667,3.1333333333333333,6.666666666666667,1.0,8
3936,Prediction-Centric Learning of Independent Cascade Dynamics from Partial Observations,8,Prediction-Centric Learning of Independent Cascade Dynamics from Partial Observations,49,166,False,48,94,50,20,0,11,16,0,2,85,11953,2.45,2.6,4.7,0.8,8
3937,"Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt",8,Prioritized Training on Points that are Learnable Worth Learning and Not Yet Learnt,63,167,False,128,17,27,19,29,17,4,0,8,85,12357,3.3157894736842106,1.8421052631578947,0.8947368421052632,0.21052631578947367,83
3939,PromptBoosting: Black-Box Text Classification with Ten Forward Passes,8,PromptBoosting Black-Box Text Classification with Ten Forward Passes,51,185,False,190,14,15,16,10,9,7,0,16,68,10731,3.1875,1.9375,0.875,0.4375,23
3940,Provably Adversarially Robust Nearest Prototype Classifiers,8,Provably Adversarially Robust Nearest Prototype Classifiers,41,186,False,102,281,17,23,5,25,18,4,28,59,13913,1.7826086956521738,1.9565217391304348,12.217391304347826,0.782608695652174,8
3941,Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing - and Back,8,Pseudo-task Augmentation From Deep Multitask Learning to Intratask Sharing - and Back,64,114,False,54,28,17,10,0,7,9,2,6,85,8077,6.4,2.3,2.8,0.9,45
3942,Quantitative Universal Approximation Bounds for Deep Belief Networks,8,Quantitative Universal Approximation Bounds for Deep Belief Networks,67,68,False,33,112,0,17,2,5,5,0,0,68,5860,3.9411764705882355,0.0,6.588235294117647,0.29411764705882354,1
3943,RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting,8,RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting,86,148,True,99,62,45,33,7,14,17,3,50,68,14973,2.606060606060606,2.878787878787879,1.878787878787879,0.5151515151515151,17
3944,Randomized Block-Diagonal Preconditioning for Parallel Learning,8,Randomized Block-Diagonal Preconditioning for Parallel Learning,32,122,False,102,151,67,26,0,13,22,2,2,63,12384,1.2307692307692308,2.6538461538461537,5.8076923076923075,0.8461538461538461,1
3945,Recomposing the Reinforcement Learning Building Blocks with Hypernetworks,8,Recomposing the Reinforcement Learning Building Blocks with Hypernetworks,64,168,False,89,98,57,28,0,12,16,9,22,73,13886,2.2857142857142856,2.8214285714285716,3.5,0.5714285714285714,21
3946,Regret Minimization and Convergence to Equilibria in General-sum Markov Games,8,Regret Minimization and Convergence to Equilibria in General-sum Markov Games,59,184,False,95,251,4,37,8,10,12,0,0,77,16216,1.5945945945945945,0.10810810810810811,6.783783783783784,0.32432432432432434,15
3947,Reliable Fidelity and Diversity Metrics for Generative Models,8,Reliable Fidelity and Diversity Metrics for Generative Models,25,144,False,39,22,51,10,0,6,8,4,2,61,7027,2.5,5.3,2.2,0.8,248
3949,Revisiting End-to-End Speech-to-Text Translation From Scratch,8,Revisiting End-to-End Speech-to-Text Translation From Scratch,68,214,False,102,10,15,13,14,9,4,0,12,61,8926,5.230769230769231,2.076923076923077,0.7692307692307693,0.3076923076923077,28
3950,Rigging the Lottery: Making All Tickets Winners,8,Rigging the Lottery Making All Tickets Winners,63,174,False,270,0,90,19,0,38,8,6,16,46,11230,3.3157894736842106,5.578947368421052,0.0,0.42105263157894735,462
3951,Robust Learning from Untrusted Sources,8,Robust Learning from Untrusted Sources,52,126,False,118,74,11,21,0,9,8,0,22,38,12706,2.4761904761904763,1.5714285714285714,3.5238095238095237,0.38095238095238093,63
3952,Robust learning with the Hilbert-Schmidt independence criterion,8,Robust learning with the Hilbert-Schmidt independence criterion,41,1,False,97,136,10,16,0,9,14,10,6,63,11516,2.5625,1.0,8.5,0.875,47
3953,SG-PALM: a Fast Physically Interpretable Tensor Graphical Model,8,SG-PALM a Fast Physically Interpretable Tensor Graphical Model,53,129,True,136,172,42,24,3,12,18,1,4,62,13525,2.2083333333333335,1.9166666666666667,7.166666666666667,0.75,4
3954,Safe Exploration for Efficient Policy Evaluation and Comparison,8,Safe Exploration for Efficient Policy Evaluation and Comparison,54,71,False,194,314,14,21,0,22,42,0,0,63,14313,2.5714285714285716,0.6666666666666666,14.952380952380953,2.0,7
3955,Scalable Adaptive Computation for Iterative Generation,8,Scalable Adaptive Computation for Iterative Generation,63,202,False,87,6,57,21,2,10,8,0,10,54,8782,3.0,3.1904761904761907,0.2857142857142857,0.38095238095238093,50
3957,Second-order optimization with lazy Hessians,8,Second-order optimization with lazy Hessians,40,124,False,49,15,14,24,6,16,8,0,4,44,13271,1.6666666666666667,0.75,0.625,0.3333333333333333,8
3958,Self-Organized Polynomial-Time Coordination Graphs,8,Self-Organized Polynomial-Time Coordination Graphs,54,148,False,179,32,52,17,12,15,15,0,8,50,10684,3.176470588235294,3.5294117647058822,1.8823529411764706,0.8823529411764706,8
3959,Semiparametric Contextual Bandits,8,Semiparametric Contextual Bandits,37,133,False,122,184,3,26,8,10,3,0,0,33,12137,1.4230769230769231,0.11538461538461539,7.076923076923077,0.11538461538461539,43
3960,Sharpened Quasi-Newton Methods: Faster Superlinear Rate and Larger Local Convergence Neighborhood,8,Sharpened Quasi-Newton Methods Faster Superlinear Rate and Larger Local Convergence Neighborhood,30,221,False,68,344,18,32,0,22,16,4,6,96,12747,0.9375,0.75,10.75,0.5,8
3962,"Small Data, Big Decisions: Model Selection in the Small-Data Regime",8,Small Data Big Decisions Model Selection in the Small-Data Regime,33,134,False,81,10,35,14,0,13,27,16,8,66,7652,2.357142857142857,3.0714285714285716,0.7142857142857143,1.9285714285714286,33
3963,Sparse Bayesian Learning via Stepwise Regression,8,Sparse Bayesian Learning via Stepwise Regression,61,155,False,156,42,12,11,6,6,10,0,4,48,7956,5.545454545454546,1.4545454545454546,3.8181818181818183,0.9090909090909091,2
3964,Spectral Subsampling MCMC for Stationary Time Series,8,Spectral Subsampling MCMC for Stationary Time Series,41,102,True,120,40,24,12,0,9,13,0,2,52,7410,3.4166666666666665,2.1666666666666665,3.3333333333333335,1.0833333333333333,12
3967,Stochastic Variance-Reduced Hamilton Monte Carlo Methods,8,Stochastic Variance-Reduced Hamilton Monte Carlo Methods,44,111,False,143,244,22,23,0,12,15,1,8,56,13198,1.9130434782608696,1.3043478260869565,10.608695652173912,0.6521739130434783,31
3968,Streaming and Distributed Algorithms for Robust Column Subset Selection,8,Streaming and Distributed Algorithms for Robust Column Subset Selection,46,202,False,123,92,10,52,9,16,18,3,2,71,23187,0.8846153846153846,0.23076923076923078,1.7692307692307692,0.34615384615384615,6
3969,Structured agents for physical construction,8,Structured agents for physical construction,64,157,False,70,20,64,26,0,15,26,0,6,43,15174,2.4615384615384617,2.6923076923076925,0.7692307692307693,1.0,88
3971,TAM: Topology-Aware Margin Loss for Class-Imbalanced Node Classification,8,TAM Topology-Aware Margin Loss for Class-Imbalanced Node Classification,49,136,True,139,18,20,15,13,10,17,0,14,71,10211,3.2666666666666666,2.2666666666666666,1.2,1.1333333333333333,23
3972,TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL,8,TeachMyAgent a Benchmark for Automatic Curriculum Learning in Deep RL,79,197,True,127,2,12,39,11,7,5,1,2,69,20311,2.0256410256410255,0.358974358974359,0.05128205128205128,0.1282051282051282,19
3973,Test-Time Training Can Close the Natural Distribution Shift Performance Gap in Deep Learning Based Compressed Sensing,8,Test-Time Training Can Close the Natural Distribution Shift Performance Gap in Deep Learning Based Compressed Sensing,60,164,False,124,82,152,29,29,17,13,0,42,117,11341,2.0689655172413794,6.689655172413793,2.8275862068965516,0.4482758620689655,20
3974,The Fast Johnson-Lindenstrauss Transform is Even Faster,8,The Fast Johnson-Lindenstrauss Transform is Even Faster,27,186,False,40,220,0,28,11,5,4,7,0,55,15760,0.9642857142857143,0.0,7.857142857142857,0.14285714285714285,4
3975,The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization,8,The Neural Tangent Kernel in High Dimensions Triple Descent and a Multi-Scale Theory of Generalization,45,178,False,45,118,12,31,0,13,21,10,0,102,20769,1.4516129032258065,0.3870967741935484,3.806451612903226,0.6774193548387096,101
3976,The advantages of multiple classes for reducing overfitting from test set reuse,8,The advantages of multiple classes for reducing overfitting from test set reuse,28,241,False,75,3,18,27,1,8,5,0,0,79,12488,1.037037037037037,0.6666666666666666,0.1111111111111111,0.18518518518518517,27
3977,Thompson Sampling via Local Uncertainty,8,Thompson Sampling via Local Uncertainty,43,117,False,118,22,28,16,0,11,9,0,4,39,10464,2.6875,2.0,1.375,0.5625,13
3978,Topological Autoencoders,8,Topological Autoencoders,70,135,False,84,45,80,21,11,7,16,6,4,24,11259,3.3333333333333335,4.0,2.142857142857143,0.7619047619047619,111
3979,Towards Explaining Distribution Shifts,8,Towards Explaining Distribution Shifts,47,158,False,72,46,31,22,6,11,17,0,2,38,15489,2.1363636363636362,1.5,2.090909090909091,0.7727272727272727,8
3980,Towards the Unification and Robustness of Perturbation and Gradient Based Explanations,8,Towards the Unification and Robustness of Perturbation and Gradient Based Explanations,47,171,False,53,116,41,16,11,14,15,0,0,86,10832,2.9375,2.5625,7.25,0.9375,41
3981,Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints,8,Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints,32,1,False,78,26,0,27,1,9,9,0,0,96,13543,1.1851851851851851,0.0,0.9629629629629629,0.3333333333333333,95
3982,Translatotron 2: High-quality direct speech-to-speech translation with voice preservation,8,Translatotron 2 High-quality direct speech-to-speech translation with voice preservation,66,138,False,170,0,14,15,4,9,12,2,16,88,9191,4.4,2.0,0.0,0.8,41
3983,Understanding Contrastive Learning Requires Incorporating Inductive Biases,8,Understanding Contrastive Learning Requires Incorporating Inductive Biases,54,1,False,146,323,13,44,32,14,30,8,8,74,20617,1.2272727272727273,0.4772727272727273,7.340909090909091,0.6818181818181818,81
3984,Understanding and Mitigating the Tradeoff Between Robustness and Accuracy,8,Understanding and Mitigating the Tradeoff Between Robustness and Accuracy,39,155,False,115,155,50,26,23,16,27,12,6,73,16792,1.5,2.1538461538461537,5.961538461538462,1.0384615384615385,185
3985,Unifying Vision-and-Language Tasks via Text Generation,8,Unifying Vision-and-Language Tasks via Text Generation,85,171,False,106,2,14,15,6,9,16,0,28,54,9460,5.666666666666667,2.8,0.13333333333333333,1.0666666666666667,425
3986,Unsupervised Representation Learning via Neural Activation Coding,8,Unsupervised Representation Learning via Neural Activation Coding,44,164,False,160,46,12,10,0,8,11,0,12,65,7071,4.4,2.4,4.6,1.1,7
3987,Validating Causal Inference Methods,8,Validating Causal Inference Methods,51,246,False,70,12,25,14,8,16,16,6,4,35,8517,3.642857142857143,2.0714285714285716,0.8571428571428571,1.1428571428571428,15
3988,Variational Mixtures of ODEs for Inferring Cellular Gene Expression Dynamics,8,Variational Mixtures of ODEs for Inferring Cellular Gene Expression Dynamics,34,195,False,45,32,26,15,0,9,8,4,6,76,9261,2.2666666666666666,2.1333333333333333,2.1333333333333333,0.5333333333333333,12
3990,What does LIME really see in images?,8,What does LIME really see in images,24,152,True,84,165,60,27,4,13,23,0,4,35,13726,0.8888888888888888,2.3703703703703702,6.111111111111111,0.8518518518518519,28
3991,"Why Should I Trust You, Bellman? The Bellman Error is a Poor Replacement for Value Error",8,Why Should I Trust You Bellman The Bellman Error is a Poor Replacement for Value Error,61,155,False,110,82,47,26,0,13,24,0,12,87,12752,2.3461538461538463,2.269230769230769,3.1538461538461537,0.9230769230769231,22
3992,Zero-Shot AutoML with Pretrained Models,8,Zero-Shot AutoML with Pretrained Models,91,149,False,122,32,9,17,8,9,16,0,0,39,10024,5.352941176470588,0.5294117647058824,1.8823529411764706,0.9411764705882353,5
